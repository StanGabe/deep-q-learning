{"cells":[{"cell_type":"markdown","metadata":{"id":"_vk6J8-b8-8v"},"source":["# CS 5814 Homework 4, Part 2: Deep Q-Learning"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"csIfanhh8-8y","executionInfo":{"status":"ok","timestamp":1714701042177,"user_tz":240,"elapsed":24943,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"f20dd133-d724-4987-d952-fa6d9bfa21ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Requirement already satisfied: xvfbwrapper in /usr/local/lib/python3.10/dist-packages (0.2.9)\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n","Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (3.1.7)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n"]}],"source":["!pip3 install gym pyvirtualdisplay # gym is the OpenAI gym: https://github.com/openai/gym\n","!pip3 install xvfbwrapper pyvirtualdisplay\n","!pip3 install pyopengl\n","!pip3 install ffmpeg-python"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0zHcZ4K-wx8","executionInfo":{"status":"ok","timestamp":1714700852549,"user_tz":240,"elapsed":1178,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"1082ec44-73ee-403a-a7f0-f18de55bda4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","datadir = \"/content/drive/My Drive/DQN/\" # path to the homework\n","if not os.path.exists(datadir):\n","  !ln -s \"\" $datadir # path to the homework\n","os.chdir(datadir)\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vek6KXew-2Ld","executionInfo":{"status":"ok","timestamp":1714700863045,"user_tz":240,"elapsed":152,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"f152ce27-671f-41c5-d3a9-784dd7bd126a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/DQN\n"]}]},{"cell_type":"markdown","metadata":{"id":"QdBhchT-8-8z"},"source":["You should take a look at [this paper](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) before beginning. You'll be playing the game of __Breakout__."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHPyjEBP8-80"},"outputs":[],"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from model import Model\n","from utils import count_max_lives, check_if_live, process_frame, get_initialization_state\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["!pip show gym"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wlLy1u0_aQc","executionInfo":{"status":"ok","timestamp":1714700878699,"user_tz":240,"elapsed":6406,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"65936540-6640-4e1e-bf36-0e239234cd47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: gym\n","Version: 0.21.0\n","Summary: Gym: A universal API for reinforcement learning environments.\n","Home-page: https://github.com/openai/gym\n","Author: OpenAI\n","Author-email: jkterry@umd.edu\n","License: None\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: numpy, cloudpickle\n","Required-by: dopamine-rl\n"]}]},{"cell_type":"markdown","metadata":{"id":"ngqM8KFL8-80"},"source":["## Initialize env"]},{"cell_type":"markdown","metadata":{"id":"0aN7BReV8-80"},"source":["Refer to the Gym [documentation](https://www.gymlibrary.dev/environments/atari/breakout/) for more details on the environment. There are three action_to_takes in this game - \"left\", \"right\" (to move the paddle) and \"fire\" (this releases the ball)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoIYfNV38-80"},"outputs":[],"source":["env = gym.make('BreakoutDeterministic-v4')\n","# v0 vs v4: v0 has repeat_action_to_take_probability of 0.25 (meaning 25% of the time the previous action_to_take will be used instead of the new action_to_take), while v4 has 0 (always follow your issued action_to_take)\n","# Deterministic: a fixed frame_counterskip of 4, while for the env without Deterministic, frame_counterskip is sampled from (2,5)\n","# https://github.com/openai/gym/issues/1280\n","state = env.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"laaMFU-M8-81"},"outputs":[],"source":["max_number_of_lives_in_game = count_max_lives(env)\n","state_size = env.observation_space.shape\n","action_to_take_size = 3"]},{"cell_type":"markdown","metadata":{"id":"7tZvi_rz8-81"},"source":["## Create your agent"]},{"cell_type":"markdown","metadata":{"id":"JBXFKv-k8-81"},"source":["The agent is defined in the __your_agent.py__ file. We have coded a network for you already in the __model.py__ file. You shouldn't change the implementation we have there for fairness.\n","\n","Once you get that working, you'll need to then create a double agent (see [this paper](https://arxiv.org/pdf/1509.06461.pdf)) in the __your_double_agent.py__ file. We have a switch below which determines which to train."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJZWSV9B8-81"},"outputs":[],"source":["double_d = True # switch\n","\n","if double_d:\n","    from your_double_agent import EnvironmentAgent\n","else:\n","    from your_agent import EnvironmentAgent\n","\n","agent = EnvironmentAgent(action_to_take_size) # buff size\n","rl_reward_from_eval = deque(maxlen=evaluation_reward_window) # This is avg rl_reward from 100 games\n","cnt_frame= 0\n","memory_size = 0"]},{"cell_type":"code","source":[],"metadata":{"id":"zjO4kWOAjUYJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kqQKFWWC8-82"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"131uuRy48-82","outputId":"89c95c79-0c17-431f-d6df-73c1d10c3f18","executionInfo":{"status":"error","timestamp":1714700604374,"user_tz":240,"elapsed":11526977,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["For episode: 0   the run_score was: 0.0   and mem length: 123   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 0.0\n","For episode: 1   the run_score was: 1.0   and mem length: 275   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 0.5\n","For episode: 2   the run_score was: 0.0   and mem length: 399   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 0.3333333333333333\n","For episode: 3   the run_score was: 2.0   and mem length: 618   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 0.75\n","For episode: 4   the run_score was: 1.0   and mem length: 769   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 0.8\n","For episode: 5   the run_score was: 0.0   and mem length: 892   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 0.6666666666666666\n","For episode: 6   the run_score was: 2.0   and mem length: 1095   eps: 1.0    steps: 203    lr: 0.0001     eval rl_reward: 0.8571428571428571\n","For episode: 7   the run_score was: 2.0   and mem length: 1314   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.0\n","For episode: 8   the run_score was: 1.0   and mem length: 1487   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.0\n","For episode: 9   the run_score was: 0.0   and mem length: 1611   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 0.9\n","For episode: 10   the run_score was: 1.0   and mem length: 1781   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 0.9090909090909091\n","For episode: 11   the run_score was: 3.0   and mem length: 2010   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.0833333333333333\n","For episode: 12   the run_score was: 2.0   and mem length: 2227   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.1538461538461537\n","For episode: 13   the run_score was: 2.0   and mem length: 2446   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.2142857142857142\n","For episode: 14   the run_score was: 2.0   and mem length: 2644   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.2666666666666666\n","For episode: 15   the run_score was: 1.0   and mem length: 2817   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 16   the run_score was: 1.0   and mem length: 2987   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.2352941176470589\n","For episode: 17   the run_score was: 1.0   and mem length: 3159   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.2222222222222223\n","For episode: 18   the run_score was: 1.0   and mem length: 3310   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.2105263157894737\n","For episode: 19   the run_score was: 0.0   and mem length: 3433   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.15\n","For episode: 20   the run_score was: 0.0   and mem length: 3557   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.0952380952380953\n","For episode: 21   the run_score was: 0.0   and mem length: 3680   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.0454545454545454\n","For episode: 22   the run_score was: 3.0   and mem length: 3927   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.1304347826086956\n","For episode: 23   the run_score was: 4.0   and mem length: 4205   eps: 1.0    steps: 278    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 24   the run_score was: 1.0   and mem length: 4375   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 25   the run_score was: 1.0   and mem length: 4545   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.2307692307692308\n","For episode: 26   the run_score was: 2.0   and mem length: 4744   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.2592592592592593\n","For episode: 27   the run_score was: 0.0   and mem length: 4867   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.2142857142857142\n","For episode: 28   the run_score was: 1.0   and mem length: 5038   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.206896551724138\n","For episode: 29   the run_score was: 3.0   and mem length: 5265   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.2666666666666666\n","For episode: 30   the run_score was: 0.0   and mem length: 5389   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2258064516129032\n","For episode: 31   the run_score was: 0.0   and mem length: 5512   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.1875\n","For episode: 32   the run_score was: 1.0   and mem length: 5681   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.1818181818181819\n","For episode: 33   the run_score was: 1.0   and mem length: 5833   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.1764705882352942\n","For episode: 34   the run_score was: 0.0   and mem length: 5957   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.1428571428571428\n","For episode: 35   the run_score was: 1.0   and mem length: 6128   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.1388888888888888\n","For episode: 36   the run_score was: 0.0   and mem length: 6251   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.1081081081081081\n","For episode: 37   the run_score was: 1.0   and mem length: 6403   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.105263157894737\n","For episode: 38   the run_score was: 2.0   and mem length: 6602   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.1282051282051282\n","For episode: 39   the run_score was: 1.0   and mem length: 6754   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.125\n","For episode: 40   the run_score was: 1.0   and mem length: 6906   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.1219512195121952\n","For episode: 41   the run_score was: 2.0   and mem length: 7104   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.1428571428571428\n","For episode: 42   the run_score was: 0.0   and mem length: 7228   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.1162790697674418\n","For episode: 43   the run_score was: 1.0   and mem length: 7380   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.1136363636363635\n","For episode: 44   the run_score was: 2.0   and mem length: 7562   eps: 1.0    steps: 182    lr: 0.0001     eval rl_reward: 1.1333333333333333\n","For episode: 45   the run_score was: 3.0   and mem length: 7809   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.173913043478261\n","For episode: 46   the run_score was: 1.0   and mem length: 7961   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.1702127659574468\n","For episode: 47   the run_score was: 3.0   and mem length: 8191   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.2083333333333333\n","For episode: 48   the run_score was: 4.0   and mem length: 8470   eps: 1.0    steps: 279    lr: 0.0001     eval rl_reward: 1.2653061224489797\n","For episode: 49   the run_score was: 1.0   and mem length: 8622   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 50   the run_score was: 0.0   and mem length: 8745   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.2352941176470589\n","For episode: 51   the run_score was: 2.0   and mem length: 8967   eps: 1.0    steps: 222    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 52   the run_score was: 0.0   and mem length: 9091   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2264150943396226\n","For episode: 53   the run_score was: 1.0   and mem length: 9243   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.2222222222222223\n","For episode: 54   the run_score was: 1.0   and mem length: 9413   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.2181818181818183\n","For episode: 55   the run_score was: 2.0   and mem length: 9631   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.2321428571428572\n","For episode: 56   the run_score was: 3.0   and mem length: 9860   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.263157894736842\n","For episode: 57   the run_score was: 2.0   and mem length: 10078   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.2758620689655173\n","For episode: 58   the run_score was: 2.0   and mem length: 10277   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.2881355932203389\n","For episode: 59   the run_score was: 0.0   and mem length: 10400   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.2666666666666666\n","For episode: 60   the run_score was: 1.0   and mem length: 10552   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.2622950819672132\n","For episode: 61   the run_score was: 0.0   and mem length: 10676   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2419354838709677\n","For episode: 62   the run_score was: 0.0   and mem length: 10800   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2222222222222223\n","For episode: 63   the run_score was: 1.0   and mem length: 10952   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.21875\n","For episode: 64   the run_score was: 0.0   and mem length: 11076   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 65   the run_score was: 2.0   and mem length: 11300   eps: 1.0    steps: 224    lr: 0.0001     eval rl_reward: 1.2121212121212122\n","For episode: 66   the run_score was: 3.0   and mem length: 11531   eps: 1.0    steps: 231    lr: 0.0001     eval rl_reward: 1.2388059701492538\n","For episode: 67   the run_score was: 2.0   and mem length: 11750   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 68   the run_score was: 1.0   and mem length: 11920   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.2463768115942029\n","For episode: 69   the run_score was: 3.0   and mem length: 12164   eps: 1.0    steps: 244    lr: 0.0001     eval rl_reward: 1.2714285714285714\n","For episode: 70   the run_score was: 4.0   and mem length: 12440   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.3098591549295775\n","For episode: 71   the run_score was: 1.0   and mem length: 12612   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.3055555555555556\n","For episode: 72   the run_score was: 1.0   and mem length: 12784   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.3013698630136987\n","For episode: 73   the run_score was: 0.0   and mem length: 12907   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.2837837837837838\n","For episode: 74   the run_score was: 0.0   and mem length: 13031   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2666666666666666\n","For episode: 75   the run_score was: 0.0   and mem length: 13154   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 76   the run_score was: 0.0   and mem length: 13278   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2337662337662338\n","For episode: 77   the run_score was: 4.0   and mem length: 13599   eps: 1.0    steps: 321    lr: 0.0001     eval rl_reward: 1.2692307692307692\n","For episode: 78   the run_score was: 1.0   and mem length: 13768   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.2658227848101267\n","For episode: 79   the run_score was: 2.0   and mem length: 13988   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.275\n","For episode: 80   the run_score was: 0.0   and mem length: 14111   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.2592592592592593\n","For episode: 81   the run_score was: 0.0   and mem length: 14235   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2439024390243902\n","For episode: 82   the run_score was: 3.0   and mem length: 14503   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.2650602409638554\n","For episode: 83   the run_score was: 4.0   and mem length: 14779   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.2976190476190477\n","For episode: 84   the run_score was: 0.0   and mem length: 14903   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.2823529411764707\n","For episode: 85   the run_score was: 3.0   and mem length: 15152   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.302325581395349\n","For episode: 86   the run_score was: 3.0   and mem length: 15364   eps: 1.0    steps: 212    lr: 0.0001     eval rl_reward: 1.3218390804597702\n","For episode: 87   the run_score was: 1.0   and mem length: 15533   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.3181818181818181\n","For episode: 88   the run_score was: 2.0   and mem length: 15752   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.3258426966292134\n","For episode: 89   the run_score was: 0.0   and mem length: 15876   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3111111111111111\n","For episode: 90   the run_score was: 3.0   and mem length: 16125   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.3296703296703296\n","For episode: 91   the run_score was: 3.0   and mem length: 16354   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.3478260869565217\n","For episode: 92   the run_score was: 2.0   and mem length: 16572   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.3548387096774193\n","For episode: 93   the run_score was: 1.0   and mem length: 16723   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.351063829787234\n","For episode: 94   the run_score was: 2.0   and mem length: 16941   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.3578947368421053\n","For episode: 95   the run_score was: 2.0   and mem length: 17157   eps: 1.0    steps: 216    lr: 0.0001     eval rl_reward: 1.3645833333333333\n","For episode: 96   the run_score was: 0.0   and mem length: 17280   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.3505154639175259\n","For episode: 97   the run_score was: 0.0   and mem length: 17403   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.336734693877551\n","For episode: 98   the run_score was: 2.0   and mem length: 17601   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.3434343434343434\n","For episode: 99   the run_score was: 2.0   and mem length: 17800   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 100   the run_score was: 3.0   and mem length: 18027   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 101   the run_score was: 1.0   and mem length: 18197   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 102   the run_score was: 0.0   and mem length: 18321   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 103   the run_score was: 0.0   and mem length: 18445   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 104   the run_score was: 2.0   and mem length: 18644   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 105   the run_score was: 2.0   and mem length: 18861   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 106   the run_score was: 0.0   and mem length: 18985   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 107   the run_score was: 0.0   and mem length: 19109   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 108   the run_score was: 0.0   and mem length: 19232   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 109   the run_score was: 1.0   and mem length: 19384   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 110   the run_score was: 0.0   and mem length: 19507   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 111   the run_score was: 0.0   and mem length: 19630   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 112   the run_score was: 0.0   and mem length: 19754   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 113   the run_score was: 2.0   and mem length: 19936   eps: 1.0    steps: 182    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 114   the run_score was: 2.0   and mem length: 20135   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 115   the run_score was: 0.0   and mem length: 20258   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 116   the run_score was: 3.0   and mem length: 20526   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 117   the run_score was: 0.0   and mem length: 20650   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 118   the run_score was: 0.0   and mem length: 20774   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 119   the run_score was: 0.0   and mem length: 20898   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 120   the run_score was: 2.0   and mem length: 21097   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 121   the run_score was: 0.0   and mem length: 21221   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 122   the run_score was: 0.0   and mem length: 21344   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 123   the run_score was: 2.0   and mem length: 21544   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 124   the run_score was: 1.0   and mem length: 21714   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 125   the run_score was: 0.0   and mem length: 21837   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 126   the run_score was: 1.0   and mem length: 21988   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 127   the run_score was: 2.0   and mem length: 22205   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 128   the run_score was: 0.0   and mem length: 22329   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 129   the run_score was: 4.0   and mem length: 22645   eps: 1.0    steps: 316    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 130   the run_score was: 2.0   and mem length: 22844   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 131   the run_score was: 1.0   and mem length: 23014   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 132   the run_score was: 2.0   and mem length: 23234   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 133   the run_score was: 2.0   and mem length: 23433   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 134   the run_score was: 0.0   and mem length: 23556   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 135   the run_score was: 2.0   and mem length: 23757   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 136   the run_score was: 3.0   and mem length: 24020   eps: 1.0    steps: 263    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 137   the run_score was: 0.0   and mem length: 24143   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 138   the run_score was: 3.0   and mem length: 24410   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 139   the run_score was: 0.0   and mem length: 24534   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 140   the run_score was: 0.0   and mem length: 24658   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 141   the run_score was: 4.0   and mem length: 24959   eps: 1.0    steps: 301    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 142   the run_score was: 1.0   and mem length: 25110   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 143   the run_score was: 1.0   and mem length: 25261   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 144   the run_score was: 1.0   and mem length: 25413   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 145   the run_score was: 2.0   and mem length: 25612   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 146   the run_score was: 3.0   and mem length: 25838   eps: 1.0    steps: 226    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 147   the run_score was: 2.0   and mem length: 26036   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 148   the run_score was: 1.0   and mem length: 26206   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 149   the run_score was: 0.0   and mem length: 26330   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 150   the run_score was: 0.0   and mem length: 26454   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 151   the run_score was: 0.0   and mem length: 26578   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 152   the run_score was: 4.0   and mem length: 26872   eps: 1.0    steps: 294    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 153   the run_score was: 2.0   and mem length: 27071   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 154   the run_score was: 3.0   and mem length: 27318   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 155   the run_score was: 2.0   and mem length: 27519   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 156   the run_score was: 0.0   and mem length: 27643   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 157   the run_score was: 0.0   and mem length: 27767   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 158   the run_score was: 1.0   and mem length: 27918   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 159   the run_score was: 2.0   and mem length: 28117   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 160   the run_score was: 3.0   and mem length: 28366   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 161   the run_score was: 1.0   and mem length: 28538   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 162   the run_score was: 2.0   and mem length: 28737   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 163   the run_score was: 3.0   and mem length: 29004   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 164   the run_score was: 2.0   and mem length: 29203   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 165   the run_score was: 0.0   and mem length: 29327   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 166   the run_score was: 2.0   and mem length: 29508   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 167   the run_score was: 1.0   and mem length: 29679   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 168   the run_score was: 0.0   and mem length: 29802   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 169   the run_score was: 0.0   and mem length: 29926   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 170   the run_score was: 0.0   and mem length: 30049   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 171   the run_score was: 0.0   and mem length: 30173   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 172   the run_score was: 0.0   and mem length: 30297   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 173   the run_score was: 0.0   and mem length: 30420   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 174   the run_score was: 2.0   and mem length: 30603   eps: 1.0    steps: 183    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 175   the run_score was: 3.0   and mem length: 30833   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 176   the run_score was: 1.0   and mem length: 30984   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 177   the run_score was: 0.0   and mem length: 31108   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 178   the run_score was: 1.0   and mem length: 31280   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 179   the run_score was: 0.0   and mem length: 31404   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 180   the run_score was: 4.0   and mem length: 31679   eps: 1.0    steps: 275    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 181   the run_score was: 4.0   and mem length: 31977   eps: 1.0    steps: 298    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 182   the run_score was: 2.0   and mem length: 32175   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 183   the run_score was: 0.0   and mem length: 32298   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 184   the run_score was: 1.0   and mem length: 32449   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 185   the run_score was: 0.0   and mem length: 32573   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 186   the run_score was: 0.0   and mem length: 32696   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 187   the run_score was: 1.0   and mem length: 32868   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 188   the run_score was: 0.0   and mem length: 32992   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 189   the run_score was: 3.0   and mem length: 33239   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 190   the run_score was: 0.0   and mem length: 33363   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 191   the run_score was: 2.0   and mem length: 33563   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 192   the run_score was: 4.0   and mem length: 33822   eps: 1.0    steps: 259    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 193   the run_score was: 3.0   and mem length: 34072   eps: 1.0    steps: 250    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 194   the run_score was: 1.0   and mem length: 34224   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 195   the run_score was: 2.0   and mem length: 34425   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 196   the run_score was: 5.0   and mem length: 34741   eps: 1.0    steps: 316    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 197   the run_score was: 3.0   and mem length: 34970   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 198   the run_score was: 3.0   and mem length: 35218   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 199   the run_score was: 1.0   and mem length: 35388   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 200   the run_score was: 2.0   and mem length: 35607   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 201   the run_score was: 0.0   and mem length: 35731   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 202   the run_score was: 3.0   and mem length: 35960   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 203   the run_score was: 1.0   and mem length: 36132   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 204   the run_score was: 2.0   and mem length: 36352   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 205   the run_score was: 0.0   and mem length: 36475   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 206   the run_score was: 1.0   and mem length: 36645   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 207   the run_score was: 0.0   and mem length: 36768   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 208   the run_score was: 3.0   and mem length: 36998   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 209   the run_score was: 1.0   and mem length: 37150   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 210   the run_score was: 3.0   and mem length: 37399   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 211   the run_score was: 1.0   and mem length: 37570   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 212   the run_score was: 3.0   and mem length: 37818   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 213   the run_score was: 0.0   and mem length: 37941   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 214   the run_score was: 4.0   and mem length: 38217   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 215   the run_score was: 0.0   and mem length: 38341   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 216   the run_score was: 2.0   and mem length: 38524   eps: 1.0    steps: 183    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 217   the run_score was: 0.0   and mem length: 38648   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 218   the run_score was: 0.0   and mem length: 38772   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 219   the run_score was: 4.0   and mem length: 39089   eps: 1.0    steps: 317    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 220   the run_score was: 0.0   and mem length: 39213   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 221   the run_score was: 1.0   and mem length: 39385   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 222   the run_score was: 3.0   and mem length: 39633   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 223   the run_score was: 2.0   and mem length: 39831   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 224   the run_score was: 3.0   and mem length: 40077   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 225   the run_score was: 2.0   and mem length: 40275   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 226   the run_score was: 0.0   and mem length: 40399   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 227   the run_score was: 0.0   and mem length: 40522   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 228   the run_score was: 0.0   and mem length: 40646   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 229   the run_score was: 0.0   and mem length: 40769   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 230   the run_score was: 1.0   and mem length: 40940   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 231   the run_score was: 0.0   and mem length: 41064   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 232   the run_score was: 0.0   and mem length: 41187   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 233   the run_score was: 0.0   and mem length: 41311   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 234   the run_score was: 2.0   and mem length: 41528   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 235   the run_score was: 2.0   and mem length: 41745   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 236   the run_score was: 1.0   and mem length: 41916   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 237   the run_score was: 2.0   and mem length: 42115   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 238   the run_score was: 2.0   and mem length: 42334   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 239   the run_score was: 2.0   and mem length: 42553   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 240   the run_score was: 4.0   and mem length: 42871   eps: 1.0    steps: 318    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 241   the run_score was: 0.0   and mem length: 42995   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 242   the run_score was: 1.0   and mem length: 43147   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 243   the run_score was: 0.0   and mem length: 43271   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 244   the run_score was: 1.0   and mem length: 43424   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 245   the run_score was: 3.0   and mem length: 43691   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 246   the run_score was: 1.0   and mem length: 43861   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 247   the run_score was: 0.0   and mem length: 43984   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 248   the run_score was: 1.0   and mem length: 44154   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 249   the run_score was: 1.0   and mem length: 44325   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 250   the run_score was: 2.0   and mem length: 44524   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 251   the run_score was: 1.0   and mem length: 44697   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 252   the run_score was: 4.0   and mem length: 44974   eps: 1.0    steps: 277    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 253   the run_score was: 0.0   and mem length: 45098   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 254   the run_score was: 1.0   and mem length: 45268   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 255   the run_score was: 0.0   and mem length: 45392   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 256   the run_score was: 0.0   and mem length: 45516   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 257   the run_score was: 0.0   and mem length: 45640   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 258   the run_score was: 1.0   and mem length: 45811   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 259   the run_score was: 0.0   and mem length: 45935   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 260   the run_score was: 4.0   and mem length: 46231   eps: 1.0    steps: 296    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 261   the run_score was: 0.0   and mem length: 46354   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 262   the run_score was: 0.0   and mem length: 46478   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 263   the run_score was: 0.0   and mem length: 46602   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 264   the run_score was: 1.0   and mem length: 46773   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 265   the run_score was: 0.0   and mem length: 46896   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 266   the run_score was: 0.0   and mem length: 47019   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 267   the run_score was: 1.0   and mem length: 47191   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 268   the run_score was: 2.0   and mem length: 47389   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 269   the run_score was: 1.0   and mem length: 47560   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 270   the run_score was: 1.0   and mem length: 47729   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 271   the run_score was: 0.0   and mem length: 47853   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 272   the run_score was: 3.0   and mem length: 48102   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 273   the run_score was: 2.0   and mem length: 48303   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 274   the run_score was: 0.0   and mem length: 48426   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 275   the run_score was: 0.0   and mem length: 48550   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 276   the run_score was: 2.0   and mem length: 48750   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 277   the run_score was: 2.0   and mem length: 48969   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 278   the run_score was: 2.0   and mem length: 49150   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 279   the run_score was: 0.0   and mem length: 49274   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 280   the run_score was: 3.0   and mem length: 49540   eps: 1.0    steps: 266    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 281   the run_score was: 0.0   and mem length: 49664   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 282   the run_score was: 1.0   and mem length: 49834   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 283   the run_score was: 0.0   and mem length: 49957   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 284   the run_score was: 1.0   and mem length: 50126   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 285   the run_score was: 1.0   and mem length: 50278   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 286   the run_score was: 4.0   and mem length: 50576   eps: 1.0    steps: 298    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 287   the run_score was: 0.0   and mem length: 50700   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 288   the run_score was: 2.0   and mem length: 50898   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 289   the run_score was: 1.0   and mem length: 51051   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 290   the run_score was: 1.0   and mem length: 51220   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 291   the run_score was: 0.0   and mem length: 51344   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 292   the run_score was: 1.0   and mem length: 51514   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 293   the run_score was: 2.0   and mem length: 51712   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 294   the run_score was: 2.0   and mem length: 51910   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 295   the run_score was: 4.0   and mem length: 52208   eps: 1.0    steps: 298    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 296   the run_score was: 0.0   and mem length: 52332   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 297   the run_score was: 1.0   and mem length: 52503   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 298   the run_score was: 4.0   and mem length: 52824   eps: 1.0    steps: 321    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 299   the run_score was: 1.0   and mem length: 52994   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 300   the run_score was: 2.0   and mem length: 53211   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 301   the run_score was: 0.0   and mem length: 53335   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 302   the run_score was: 1.0   and mem length: 53506   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 303   the run_score was: 3.0   and mem length: 53738   eps: 1.0    steps: 232    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 304   the run_score was: 1.0   and mem length: 53907   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 305   the run_score was: 2.0   and mem length: 54105   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 306   the run_score was: 2.0   and mem length: 54323   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 307   the run_score was: 4.0   and mem length: 54620   eps: 1.0    steps: 297    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 308   the run_score was: 3.0   and mem length: 54846   eps: 1.0    steps: 226    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 309   the run_score was: 1.0   and mem length: 54998   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 310   the run_score was: 2.0   and mem length: 55214   eps: 1.0    steps: 216    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 311   the run_score was: 1.0   and mem length: 55383   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 312   the run_score was: 5.0   and mem length: 55727   eps: 1.0    steps: 344    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 313   the run_score was: 1.0   and mem length: 55896   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 314   the run_score was: 6.0   and mem length: 56254   eps: 1.0    steps: 358    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 315   the run_score was: 0.0   and mem length: 56378   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 316   the run_score was: 2.0   and mem length: 56597   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 317   the run_score was: 2.0   and mem length: 56798   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 318   the run_score was: 1.0   and mem length: 56950   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 319   the run_score was: 2.0   and mem length: 57148   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 320   the run_score was: 2.0   and mem length: 57347   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 321   the run_score was: 1.0   and mem length: 57519   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 322   the run_score was: 0.0   and mem length: 57643   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 323   the run_score was: 1.0   and mem length: 57796   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 324   the run_score was: 2.0   and mem length: 57998   eps: 1.0    steps: 202    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 325   the run_score was: 2.0   and mem length: 58179   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 326   the run_score was: 1.0   and mem length: 58331   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 327   the run_score was: 0.0   and mem length: 58455   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 328   the run_score was: 2.0   and mem length: 58655   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 329   the run_score was: 1.0   and mem length: 58807   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 330   the run_score was: 1.0   and mem length: 58958   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 331   the run_score was: 0.0   and mem length: 59082   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 332   the run_score was: 0.0   and mem length: 59206   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 333   the run_score was: 0.0   and mem length: 59330   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 334   the run_score was: 1.0   and mem length: 59482   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 335   the run_score was: 2.0   and mem length: 59703   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 336   the run_score was: 0.0   and mem length: 59826   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 337   the run_score was: 3.0   and mem length: 60073   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 338   the run_score was: 0.0   and mem length: 60197   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 339   the run_score was: 1.0   and mem length: 60366   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 340   the run_score was: 2.0   and mem length: 60567   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 341   the run_score was: 3.0   and mem length: 60812   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 342   the run_score was: 0.0   and mem length: 60936   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 343   the run_score was: 0.0   and mem length: 61060   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 344   the run_score was: 0.0   and mem length: 61183   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 345   the run_score was: 1.0   and mem length: 61335   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 346   the run_score was: 0.0   and mem length: 61458   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 347   the run_score was: 2.0   and mem length: 61677   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 348   the run_score was: 3.0   and mem length: 61906   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 349   the run_score was: 3.0   and mem length: 62151   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 350   the run_score was: 1.0   and mem length: 62304   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 351   the run_score was: 2.0   and mem length: 62504   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 352   the run_score was: 2.0   and mem length: 62703   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 353   the run_score was: 1.0   and mem length: 62872   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 354   the run_score was: 1.0   and mem length: 63042   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 355   the run_score was: 4.0   and mem length: 63317   eps: 1.0    steps: 275    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 356   the run_score was: 0.0   and mem length: 63441   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 357   the run_score was: 0.0   and mem length: 63565   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 358   the run_score was: 0.0   and mem length: 63689   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 359   the run_score was: 2.0   and mem length: 63908   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 360   the run_score was: 2.0   and mem length: 64129   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 361   the run_score was: 1.0   and mem length: 64282   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 362   the run_score was: 0.0   and mem length: 64406   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 363   the run_score was: 0.0   and mem length: 64530   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 364   the run_score was: 0.0   and mem length: 64653   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 365   the run_score was: 1.0   and mem length: 64823   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 366   the run_score was: 0.0   and mem length: 64947   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 367   the run_score was: 0.0   and mem length: 65071   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 368   the run_score was: 1.0   and mem length: 65242   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 369   the run_score was: 1.0   and mem length: 65394   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 370   the run_score was: 1.0   and mem length: 65564   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 371   the run_score was: 0.0   and mem length: 65688   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 372   the run_score was: 0.0   and mem length: 65811   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 373   the run_score was: 0.0   and mem length: 65935   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 374   the run_score was: 2.0   and mem length: 66156   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 375   the run_score was: 0.0   and mem length: 66279   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 376   the run_score was: 0.0   and mem length: 66402   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 377   the run_score was: 2.0   and mem length: 66601   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 378   the run_score was: 3.0   and mem length: 66849   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 379   the run_score was: 1.0   and mem length: 67001   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 380   the run_score was: 2.0   and mem length: 67217   eps: 1.0    steps: 216    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 381   the run_score was: 4.0   and mem length: 67515   eps: 1.0    steps: 298    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 382   the run_score was: 0.0   and mem length: 67639   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 383   the run_score was: 3.0   and mem length: 67907   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 384   the run_score was: 3.0   and mem length: 68178   eps: 1.0    steps: 271    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 385   the run_score was: 0.0   and mem length: 68301   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 386   the run_score was: 0.0   and mem length: 68425   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 387   the run_score was: 2.0   and mem length: 68624   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 388   the run_score was: 0.0   and mem length: 68748   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 389   the run_score was: 2.0   and mem length: 68946   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 390   the run_score was: 3.0   and mem length: 69194   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 391   the run_score was: 1.0   and mem length: 69365   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 392   the run_score was: 1.0   and mem length: 69516   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 393   the run_score was: 1.0   and mem length: 69686   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 394   the run_score was: 6.0   and mem length: 70023   eps: 1.0    steps: 337    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 395   the run_score was: 0.0   and mem length: 70146   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 396   the run_score was: 0.0   and mem length: 70270   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 397   the run_score was: 1.0   and mem length: 70442   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 398   the run_score was: 3.0   and mem length: 70672   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 399   the run_score was: 3.0   and mem length: 70900   eps: 1.0    steps: 228    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 400   the run_score was: 1.0   and mem length: 71070   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 401   the run_score was: 2.0   and mem length: 71271   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 402   the run_score was: 4.0   and mem length: 71585   eps: 1.0    steps: 314    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 403   the run_score was: 3.0   and mem length: 71833   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 404   the run_score was: 0.0   and mem length: 71957   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 405   the run_score was: 0.0   and mem length: 72081   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 406   the run_score was: 1.0   and mem length: 72251   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 407   the run_score was: 2.0   and mem length: 72475   eps: 1.0    steps: 224    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 408   the run_score was: 3.0   and mem length: 72706   eps: 1.0    steps: 231    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 409   the run_score was: 0.0   and mem length: 72829   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 410   the run_score was: 1.0   and mem length: 72981   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 411   the run_score was: 1.0   and mem length: 73133   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 412   the run_score was: 2.0   and mem length: 73332   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 413   the run_score was: 0.0   and mem length: 73456   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 414   the run_score was: 0.0   and mem length: 73580   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 415   the run_score was: 2.0   and mem length: 73801   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 416   the run_score was: 0.0   and mem length: 73924   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 417   the run_score was: 2.0   and mem length: 74144   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 418   the run_score was: 3.0   and mem length: 74393   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 419   the run_score was: 0.0   and mem length: 74516   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 420   the run_score was: 3.0   and mem length: 74764   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 421   the run_score was: 3.0   and mem length: 75030   eps: 1.0    steps: 266    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 422   the run_score was: 1.0   and mem length: 75181   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 423   the run_score was: 1.0   and mem length: 75334   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 424   the run_score was: 0.0   and mem length: 75457   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 425   the run_score was: 3.0   and mem length: 75684   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 426   the run_score was: 1.0   and mem length: 75835   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 427   the run_score was: 2.0   and mem length: 76036   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 428   the run_score was: 0.0   and mem length: 76159   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 429   the run_score was: 2.0   and mem length: 76358   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 430   the run_score was: 1.0   and mem length: 76510   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 431   the run_score was: 0.0   and mem length: 76633   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 432   the run_score was: 2.0   and mem length: 76832   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 433   the run_score was: 1.0   and mem length: 76984   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 434   the run_score was: 0.0   and mem length: 77108   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 435   the run_score was: 1.0   and mem length: 77280   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 436   the run_score was: 0.0   and mem length: 77403   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 437   the run_score was: 2.0   and mem length: 77623   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 438   the run_score was: 0.0   and mem length: 77747   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 439   the run_score was: 1.0   and mem length: 77898   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 440   the run_score was: 1.0   and mem length: 78067   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 441   the run_score was: 1.0   and mem length: 78220   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 442   the run_score was: 0.0   and mem length: 78344   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 443   the run_score was: 1.0   and mem length: 78513   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 444   the run_score was: 3.0   and mem length: 78762   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 445   the run_score was: 1.0   and mem length: 78932   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 446   the run_score was: 1.0   and mem length: 79103   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 447   the run_score was: 3.0   and mem length: 79348   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 448   the run_score was: 0.0   and mem length: 79472   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 449   the run_score was: 0.0   and mem length: 79596   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 450   the run_score was: 0.0   and mem length: 79720   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 451   the run_score was: 2.0   and mem length: 79937   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 452   the run_score was: 3.0   and mem length: 80165   eps: 1.0    steps: 228    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 453   the run_score was: 5.0   and mem length: 80501   eps: 1.0    steps: 336    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 454   the run_score was: 2.0   and mem length: 80701   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 455   the run_score was: 1.0   and mem length: 80874   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 456   the run_score was: 3.0   and mem length: 81122   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 457   the run_score was: 3.0   and mem length: 81349   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 458   the run_score was: 3.0   and mem length: 81599   eps: 1.0    steps: 250    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 459   the run_score was: 3.0   and mem length: 81863   eps: 1.0    steps: 264    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 460   the run_score was: 3.0   and mem length: 82092   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 461   the run_score was: 1.0   and mem length: 82262   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 462   the run_score was: 2.0   and mem length: 82461   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 463   the run_score was: 2.0   and mem length: 82679   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 464   the run_score was: 4.0   and mem length: 82973   eps: 1.0    steps: 294    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 465   the run_score was: 0.0   and mem length: 83097   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 466   the run_score was: 1.0   and mem length: 83266   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 467   the run_score was: 3.0   and mem length: 83516   eps: 1.0    steps: 250    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 468   the run_score was: 1.0   and mem length: 83668   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 469   the run_score was: 0.0   and mem length: 83792   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 470   the run_score was: 2.0   and mem length: 83990   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 471   the run_score was: 0.0   and mem length: 84113   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 472   the run_score was: 3.0   and mem length: 84363   eps: 1.0    steps: 250    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 473   the run_score was: 3.0   and mem length: 84591   eps: 1.0    steps: 228    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 474   the run_score was: 0.0   and mem length: 84714   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 475   the run_score was: 0.0   and mem length: 84838   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 476   the run_score was: 1.0   and mem length: 85008   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 477   the run_score was: 0.0   and mem length: 85132   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 478   the run_score was: 0.0   and mem length: 85256   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 479   the run_score was: 2.0   and mem length: 85454   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 480   the run_score was: 1.0   and mem length: 85624   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 481   the run_score was: 0.0   and mem length: 85748   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 482   the run_score was: 1.0   and mem length: 85918   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 483   the run_score was: 1.0   and mem length: 86069   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 484   the run_score was: 1.0   and mem length: 86240   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 485   the run_score was: 0.0   and mem length: 86364   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 486   the run_score was: 2.0   and mem length: 86584   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 487   the run_score was: 3.0   and mem length: 86830   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 488   the run_score was: 0.0   and mem length: 86954   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 489   the run_score was: 3.0   and mem length: 87221   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 490   the run_score was: 8.0   and mem length: 87542   eps: 1.0    steps: 321    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 491   the run_score was: 2.0   and mem length: 87759   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 492   the run_score was: 1.0   and mem length: 87930   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 493   the run_score was: 2.0   and mem length: 88111   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 494   the run_score was: 2.0   and mem length: 88309   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 495   the run_score was: 0.0   and mem length: 88433   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 496   the run_score was: 0.0   and mem length: 88557   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 497   the run_score was: 0.0   and mem length: 88681   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 498   the run_score was: 1.0   and mem length: 88851   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 499   the run_score was: 1.0   and mem length: 89023   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 500   the run_score was: 1.0   and mem length: 89195   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 501   the run_score was: 0.0   and mem length: 89318   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 502   the run_score was: 0.0   and mem length: 89442   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 503   the run_score was: 0.0   and mem length: 89566   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 504   the run_score was: 2.0   and mem length: 89783   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 505   the run_score was: 0.0   and mem length: 89907   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 506   the run_score was: 2.0   and mem length: 90127   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 507   the run_score was: 1.0   and mem length: 90279   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 508   the run_score was: 0.0   and mem length: 90403   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 509   the run_score was: 2.0   and mem length: 90602   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 510   the run_score was: 0.0   and mem length: 90726   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 511   the run_score was: 1.0   and mem length: 90895   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 512   the run_score was: 3.0   and mem length: 91142   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 513   the run_score was: 2.0   and mem length: 91360   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 514   the run_score was: 0.0   and mem length: 91484   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 515   the run_score was: 1.0   and mem length: 91656   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 516   the run_score was: 3.0   and mem length: 91904   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 517   the run_score was: 2.0   and mem length: 92103   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 518   the run_score was: 0.0   and mem length: 92226   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 519   the run_score was: 3.0   and mem length: 92471   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 520   the run_score was: 0.0   and mem length: 92594   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 521   the run_score was: 2.0   and mem length: 92796   eps: 1.0    steps: 202    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 522   the run_score was: 0.0   and mem length: 92920   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 523   the run_score was: 0.0   and mem length: 93043   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 524   the run_score was: 1.0   and mem length: 93213   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 525   the run_score was: 3.0   and mem length: 93460   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 526   the run_score was: 4.0   and mem length: 93757   eps: 1.0    steps: 297    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 527   the run_score was: 2.0   and mem length: 93955   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 528   the run_score was: 0.0   and mem length: 94078   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 529   the run_score was: 1.0   and mem length: 94230   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 530   the run_score was: 1.0   and mem length: 94399   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 531   the run_score was: 1.0   and mem length: 94550   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 532   the run_score was: 2.0   and mem length: 94767   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 533   the run_score was: 1.0   and mem length: 94936   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 534   the run_score was: 2.0   and mem length: 95138   eps: 1.0    steps: 202    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 535   the run_score was: 1.0   and mem length: 95290   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 536   the run_score was: 5.0   and mem length: 95640   eps: 1.0    steps: 350    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 537   the run_score was: 0.0   and mem length: 95763   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 538   the run_score was: 2.0   and mem length: 95961   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 539   the run_score was: 2.0   and mem length: 96160   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 540   the run_score was: 3.0   and mem length: 96404   eps: 1.0    steps: 244    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 541   the run_score was: 0.0   and mem length: 96528   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 542   the run_score was: 1.0   and mem length: 96698   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 543   the run_score was: 1.0   and mem length: 96867   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 544   the run_score was: 2.0   and mem length: 97086   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 545   the run_score was: 0.0   and mem length: 97210   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 546   the run_score was: 2.0   and mem length: 97408   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 547   the run_score was: 2.0   and mem length: 97628   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 548   the run_score was: 1.0   and mem length: 97780   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 549   the run_score was: 1.0   and mem length: 97933   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 550   the run_score was: 2.0   and mem length: 98150   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 551   the run_score was: 2.0   and mem length: 98349   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 552   the run_score was: 0.0   and mem length: 98473   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 553   the run_score was: 2.0   and mem length: 98690   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 554   the run_score was: 1.0   and mem length: 98842   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 555   the run_score was: 0.0   and mem length: 98966   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 556   the run_score was: 0.0   and mem length: 99090   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 557   the run_score was: 2.0   and mem length: 99288   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 558   the run_score was: 1.0   and mem length: 99440   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 559   the run_score was: 0.0   and mem length: 99564   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 560   the run_score was: 0.0   and mem length: 99688   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 561   the run_score was: 0.0   and mem length: 99811   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 562   the run_score was: 0.0   and mem length: 99934   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 563   the run_score was: 0.0   and mem length: 100057   eps: 0.9998851600000025    steps: 123    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 564   the run_score was: 2.0   and mem length: 100237   eps: 0.9995287600000102    steps: 180    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 565   the run_score was: 0.0   and mem length: 100360   eps: 0.9992852200000155    steps: 123    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 566   the run_score was: 0.0   and mem length: 100484   eps: 0.9990397000000208    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 567   the run_score was: 0.0   and mem length: 100608   eps: 0.9987941800000262    steps: 124    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 568   the run_score was: 0.0   and mem length: 100732   eps: 0.9985486600000315    steps: 124    lr: 0.0001     eval rl_reward: 1.18\n","For episode: 569   the run_score was: 2.0   and mem length: 100930   eps: 0.99815662000004    steps: 198    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 570   the run_score was: 3.0   and mem length: 101195   eps: 0.9976319200000514    steps: 265    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 571   the run_score was: 1.0   and mem length: 101348   eps: 0.997328980000058    steps: 153    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 572   the run_score was: 2.0   and mem length: 101569   eps: 0.9968914000000675    steps: 221    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 573   the run_score was: 2.0   and mem length: 101768   eps: 0.996497380000076    steps: 199    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 574   the run_score was: 1.0   and mem length: 101920   eps: 0.9961964200000826    steps: 152    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 575   the run_score was: 2.0   and mem length: 102101   eps: 0.9958380400000904    steps: 181    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 576   the run_score was: 2.0   and mem length: 102323   eps: 0.9953984800000999    steps: 222    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 577   the run_score was: 0.0   and mem length: 102447   eps: 0.9951529600001052    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 578   the run_score was: 0.0   and mem length: 102570   eps: 0.9949094200001105    steps: 123    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 579   the run_score was: 1.0   and mem length: 102742   eps: 0.9945688600001179    steps: 172    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 580   the run_score was: 0.0   and mem length: 102865   eps: 0.9943253200001232    steps: 123    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 581   the run_score was: 0.0   and mem length: 102989   eps: 0.9940798000001285    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 582   the run_score was: 0.0   and mem length: 103112   eps: 0.9938362600001338    steps: 123    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 583   the run_score was: 0.0   and mem length: 103236   eps: 0.9935907400001391    steps: 124    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 584   the run_score was: 3.0   and mem length: 103462   eps: 0.9931432600001489    steps: 226    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 585   the run_score was: 1.0   and mem length: 103632   eps: 0.9928066600001562    steps: 170    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 586   the run_score was: 0.0   and mem length: 103756   eps: 0.9925611400001615    steps: 124    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 587   the run_score was: 1.0   and mem length: 103927   eps: 0.9922225600001688    steps: 171    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 588   the run_score was: 2.0   and mem length: 104125   eps: 0.9918305200001774    steps: 198    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 589   the run_score was: 1.0   and mem length: 104276   eps: 0.9915315400001838    steps: 151    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 590   the run_score was: 3.0   and mem length: 104545   eps: 0.9909989200001954    steps: 269    lr: 0.0001     eval rl_reward: 1.14\n","For episode: 591   the run_score was: 0.0   and mem length: 104668   eps: 0.9907553800002007    steps: 123    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 592   the run_score was: 2.0   and mem length: 104886   eps: 0.9903237400002101    steps: 218    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 593   the run_score was: 1.0   and mem length: 105057   eps: 0.9899851600002174    steps: 171    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 594   the run_score was: 2.0   and mem length: 105274   eps: 0.9895555000002267    steps: 217    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 595   the run_score was: 1.0   and mem length: 105425   eps: 0.9892565200002332    steps: 151    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 596   the run_score was: 3.0   and mem length: 105655   eps: 0.9888011200002431    steps: 230    lr: 0.0001     eval rl_reward: 1.16\n","For episode: 597   the run_score was: 4.0   and mem length: 105933   eps: 0.9882506800002551    steps: 278    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 598   the run_score was: 0.0   and mem length: 106056   eps: 0.9880071400002604    steps: 123    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 599   the run_score was: 3.0   and mem length: 106269   eps: 0.9875854000002695    steps: 213    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 600   the run_score was: 0.0   and mem length: 106393   eps: 0.9873398800002748    steps: 124    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 601   the run_score was: 3.0   and mem length: 106620   eps: 0.9868904200002846    steps: 227    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 602   the run_score was: 3.0   and mem length: 106864   eps: 0.9864073000002951    steps: 244    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 603   the run_score was: 2.0   and mem length: 107083   eps: 0.9859736800003045    steps: 219    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 604   the run_score was: 1.0   and mem length: 107255   eps: 0.9856331200003119    steps: 172    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 605   the run_score was: 1.0   and mem length: 107407   eps: 0.9853321600003184    steps: 152    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 606   the run_score was: 0.0   and mem length: 107531   eps: 0.9850866400003238    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 607   the run_score was: 2.0   and mem length: 107748   eps: 0.9846569800003331    steps: 217    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 608   the run_score was: 0.0   and mem length: 107872   eps: 0.9844114600003384    steps: 124    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 609   the run_score was: 1.0   and mem length: 108024   eps: 0.984110500000345    steps: 152    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 610   the run_score was: 2.0   and mem length: 108223   eps: 0.9837164800003535    steps: 199    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 611   the run_score was: 1.0   and mem length: 108394   eps: 0.9833779000003608    steps: 171    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 612   the run_score was: 1.0   and mem length: 108567   eps: 0.9830353600003683    steps: 173    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 613   the run_score was: 1.0   and mem length: 108720   eps: 0.9827324200003749    steps: 153    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 614   the run_score was: 0.0   and mem length: 108843   eps: 0.9824888800003801    steps: 123    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 615   the run_score was: 2.0   and mem length: 109041   eps: 0.9820968400003887    steps: 198    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 616   the run_score was: 5.0   and mem length: 109350   eps: 0.9814850200004019    steps: 309    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 617   the run_score was: 2.0   and mem length: 109569   eps: 0.9810514000004114    steps: 219    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 618   the run_score was: 0.0   and mem length: 109692   eps: 0.9808078600004166    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 619   the run_score was: 3.0   and mem length: 109961   eps: 0.9802752400004282    steps: 269    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 620   the run_score was: 1.0   and mem length: 110113   eps: 0.9799742800004347    steps: 152    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 621   the run_score was: 0.0   and mem length: 110236   eps: 0.97973074000044    steps: 123    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 622   the run_score was: 3.0   and mem length: 110502   eps: 0.9792040600004515    steps: 266    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 623   the run_score was: 1.0   and mem length: 110671   eps: 0.9788694400004587    steps: 169    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 624   the run_score was: 2.0   and mem length: 110854   eps: 0.9785071000004666    steps: 183    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 625   the run_score was: 0.0   and mem length: 110978   eps: 0.9782615800004719    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 626   the run_score was: 0.0   and mem length: 111102   eps: 0.9780160600004772    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 627   the run_score was: 0.0   and mem length: 111226   eps: 0.9777705400004826    steps: 124    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 628   the run_score was: 0.0   and mem length: 111350   eps: 0.9775250200004879    steps: 124    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 629   the run_score was: 3.0   and mem length: 111617   eps: 0.9769963600004994    steps: 267    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 630   the run_score was: 2.0   and mem length: 111836   eps: 0.9765627400005088    steps: 219    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 631   the run_score was: 1.0   and mem length: 112006   eps: 0.9762261400005161    steps: 170    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 632   the run_score was: 0.0   and mem length: 112130   eps: 0.9759806200005214    steps: 124    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 633   the run_score was: 1.0   and mem length: 112300   eps: 0.9756440200005287    steps: 170    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 634   the run_score was: 0.0   and mem length: 112424   eps: 0.9753985000005341    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 635   the run_score was: 0.0   and mem length: 112547   eps: 0.9751549600005394    steps: 123    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 636   the run_score was: 1.0   and mem length: 112718   eps: 0.9748163800005467    steps: 171    lr: 0.0001     eval rl_reward: 1.17\n","For episode: 637   the run_score was: 0.0   and mem length: 112841   eps: 0.974572840000552    steps: 123    lr: 0.0001     eval rl_reward: 1.17\n","For episode: 638   the run_score was: 2.0   and mem length: 113023   eps: 0.9742124800005598    steps: 182    lr: 0.0001     eval rl_reward: 1.17\n","For episode: 639   the run_score was: 0.0   and mem length: 113147   eps: 0.9739669600005652    steps: 124    lr: 0.0001     eval rl_reward: 1.15\n","For episode: 640   the run_score was: 0.0   and mem length: 113270   eps: 0.9737234200005704    steps: 123    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 641   the run_score was: 1.0   and mem length: 113423   eps: 0.973420480000577    steps: 153    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 642   the run_score was: 0.0   and mem length: 113547   eps: 0.9731749600005823    steps: 124    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 643   the run_score was: 2.0   and mem length: 113746   eps: 0.9727809400005909    steps: 199    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 644   the run_score was: 2.0   and mem length: 113945   eps: 0.9723869200005995    steps: 199    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 645   the run_score was: 1.0   and mem length: 114117   eps: 0.9720463600006068    steps: 172    lr: 0.0001     eval rl_reward: 1.14\n","For episode: 646   the run_score was: 1.0   and mem length: 114287   eps: 0.9717097600006142    steps: 170    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 647   the run_score was: 2.0   and mem length: 114508   eps: 0.9712721800006237    steps: 221    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 648   the run_score was: 1.0   and mem length: 114677   eps: 0.9709375600006309    steps: 169    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 649   the run_score was: 1.0   and mem length: 114829   eps: 0.9706366000006375    steps: 152    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 650   the run_score was: 2.0   and mem length: 115049   eps: 0.9702010000006469    steps: 220    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 651   the run_score was: 1.0   and mem length: 115219   eps: 0.9698644000006542    steps: 170    lr: 0.0001     eval rl_reward: 1.12\n","For episode: 652   the run_score was: 1.0   and mem length: 115392   eps: 0.9695218600006617    steps: 173    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 653   the run_score was: 2.0   and mem length: 115591   eps: 0.9691278400006702    steps: 199    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 654   the run_score was: 1.0   and mem length: 115762   eps: 0.9687892600006776    steps: 171    lr: 0.0001     eval rl_reward: 1.13\n","For episode: 655   the run_score was: 2.0   and mem length: 115961   eps: 0.9683952400006861    steps: 199    lr: 0.0001     eval rl_reward: 1.15\n","For episode: 656   the run_score was: 4.0   and mem length: 116235   eps: 0.9678527200006979    steps: 274    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 657   the run_score was: 2.0   and mem length: 116434   eps: 0.9674587000007064    steps: 199    lr: 0.0001     eval rl_reward: 1.19\n","For episode: 658   the run_score was: 2.0   and mem length: 116632   eps: 0.967066660000715    steps: 198    lr: 0.0001     eval rl_reward: 1.2\n","For episode: 659   the run_score was: 2.0   and mem length: 116851   eps: 0.9666330400007244    steps: 219    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 660   the run_score was: 2.0   and mem length: 117049   eps: 0.9662410000007329    steps: 198    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 661   the run_score was: 3.0   and mem length: 117296   eps: 0.9657519400007435    steps: 247    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 662   the run_score was: 1.0   and mem length: 117448   eps: 0.96545098000075    steps: 152    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 663   the run_score was: 0.0   and mem length: 117571   eps: 0.9652074400007553    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 664   the run_score was: 3.0   and mem length: 117802   eps: 0.9647500600007652    steps: 231    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 665   the run_score was: 0.0   and mem length: 117925   eps: 0.9645065200007705    steps: 123    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 666   the run_score was: 0.0   and mem length: 118049   eps: 0.9642610000007759    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 667   the run_score was: 1.0   and mem length: 118219   eps: 0.9639244000007832    steps: 170    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 668   the run_score was: 0.0   and mem length: 118342   eps: 0.9636808600007885    steps: 123    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 669   the run_score was: 2.0   and mem length: 118541   eps: 0.963286840000797    steps: 199    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 670   the run_score was: 0.0   and mem length: 118664   eps: 0.9630433000008023    steps: 123    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 671   the run_score was: 3.0   and mem length: 118914   eps: 0.962548300000813    steps: 250    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 672   the run_score was: 1.0   and mem length: 119066   eps: 0.9622473400008196    steps: 152    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 673   the run_score was: 1.0   and mem length: 119217   eps: 0.9619483600008261    steps: 151    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 674   the run_score was: 0.0   and mem length: 119341   eps: 0.9617028400008314    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 675   the run_score was: 3.0   and mem length: 119610   eps: 0.961170220000843    steps: 269    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 676   the run_score was: 1.0   and mem length: 119762   eps: 0.9608692600008495    steps: 152    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 677   the run_score was: 0.0   and mem length: 119885   eps: 0.9606257200008548    steps: 123    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 678   the run_score was: 3.0   and mem length: 120132   eps: 0.9601366600008654    steps: 247    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 679   the run_score was: 2.0   and mem length: 120349   eps: 0.9597070000008747    steps: 217    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 680   the run_score was: 3.0   and mem length: 120576   eps: 0.9592575400008845    steps: 227    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 681   the run_score was: 3.0   and mem length: 120790   eps: 0.9588338200008937    steps: 214    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 682   the run_score was: 4.0   and mem length: 121066   eps: 0.9582873400009055    steps: 276    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 683   the run_score was: 1.0   and mem length: 121236   eps: 0.9579507400009128    steps: 170    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 684   the run_score was: 3.0   and mem length: 121463   eps: 0.9575012800009226    steps: 227    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 685   the run_score was: 0.0   and mem length: 121587   eps: 0.9572557600009279    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 686   the run_score was: 6.0   and mem length: 121956   eps: 0.9565251400009438    steps: 369    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 687   the run_score was: 0.0   and mem length: 122080   eps: 0.9562796200009491    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 688   the run_score was: 1.0   and mem length: 122249   eps: 0.9559450000009564    steps: 169    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 689   the run_score was: 1.0   and mem length: 122418   eps: 0.9556103800009637    steps: 169    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 690   the run_score was: 2.0   and mem length: 122638   eps: 0.9551747800009731    steps: 220    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 691   the run_score was: 2.0   and mem length: 122836   eps: 0.9547827400009816    steps: 198    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 692   the run_score was: 3.0   and mem length: 123084   eps: 0.9542917000009923    steps: 248    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 693   the run_score was: 1.0   and mem length: 123253   eps: 0.9539570800009995    steps: 169    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 694   the run_score was: 1.0   and mem length: 123423   eps: 0.9536204800010069    steps: 170    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 695   the run_score was: 1.0   and mem length: 123594   eps: 0.9532819000010142    steps: 171    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 696   the run_score was: 1.0   and mem length: 123747   eps: 0.9529789600010208    steps: 153    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 697   the run_score was: 4.0   and mem length: 124007   eps: 0.952464160001032    steps: 260    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 698   the run_score was: 0.0   and mem length: 124131   eps: 0.9522186400010373    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 699   the run_score was: 1.0   and mem length: 124282   eps: 0.9519196600010438    steps: 151    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 700   the run_score was: 0.0   and mem length: 124406   eps: 0.9516741400010491    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 701   the run_score was: 0.0   and mem length: 124530   eps: 0.9514286200010544    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 702   the run_score was: 0.0   and mem length: 124654   eps: 0.9511831000010598    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 703   the run_score was: 3.0   and mem length: 124902   eps: 0.9506920600010704    steps: 248    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 704   the run_score was: 0.0   and mem length: 125025   eps: 0.9504485200010757    steps: 123    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 705   the run_score was: 2.0   and mem length: 125244   eps: 0.9500149000010851    steps: 219    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 706   the run_score was: 1.0   and mem length: 125413   eps: 0.9496802800010924    steps: 169    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 707   the run_score was: 2.0   and mem length: 125632   eps: 0.9492466600011018    steps: 219    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 708   the run_score was: 1.0   and mem length: 125801   eps: 0.9489120400011091    steps: 169    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 709   the run_score was: 3.0   and mem length: 126029   eps: 0.9484606000011189    steps: 228    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 710   the run_score was: 2.0   and mem length: 126228   eps: 0.9480665800011274    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 711   the run_score was: 0.0   and mem length: 126352   eps: 0.9478210600011328    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 712   the run_score was: 1.0   and mem length: 126523   eps: 0.9474824800011401    steps: 171    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 713   the run_score was: 0.0   and mem length: 126647   eps: 0.9472369600011454    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 714   the run_score was: 0.0   and mem length: 126770   eps: 0.9469934200011507    steps: 123    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 715   the run_score was: 0.0   and mem length: 126894   eps: 0.946747900001156    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 716   the run_score was: 1.0   and mem length: 127066   eps: 0.9464073400011634    steps: 172    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 717   the run_score was: 0.0   and mem length: 127189   eps: 0.9461638000011687    steps: 123    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 718   the run_score was: 2.0   and mem length: 127406   eps: 0.9457341400011781    steps: 217    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 719   the run_score was: 3.0   and mem length: 127636   eps: 0.945278740001188    steps: 230    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 720   the run_score was: 0.0   and mem length: 127760   eps: 0.9450332200011933    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 721   the run_score was: 0.0   and mem length: 127883   eps: 0.9447896800011986    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 722   the run_score was: 2.0   and mem length: 128104   eps: 0.9443521000012081    steps: 221    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 723   the run_score was: 1.0   and mem length: 128275   eps: 0.9440135200012154    steps: 171    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 724   the run_score was: 3.0   and mem length: 128503   eps: 0.9435620800012252    steps: 228    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 725   the run_score was: 1.0   and mem length: 128655   eps: 0.9432611200012317    steps: 152    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 726   the run_score was: 4.0   and mem length: 128932   eps: 0.9427126600012437    steps: 277    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 727   the run_score was: 2.0   and mem length: 129117   eps: 0.9423463600012516    steps: 185    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 728   the run_score was: 1.0   and mem length: 129268   eps: 0.9420473800012581    steps: 151    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 729   the run_score was: 1.0   and mem length: 129419   eps: 0.9417484000012646    steps: 151    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 730   the run_score was: 2.0   and mem length: 129618   eps: 0.9413543800012731    steps: 199    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 731   the run_score was: 0.0   and mem length: 129741   eps: 0.9411108400012784    steps: 123    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 732   the run_score was: 0.0   and mem length: 129865   eps: 0.9408653200012838    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 733   the run_score was: 1.0   and mem length: 130037   eps: 0.9405247600012911    steps: 172    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 734   the run_score was: 1.0   and mem length: 130189   eps: 0.9402238000012977    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 735   the run_score was: 0.0   and mem length: 130313   eps: 0.939978280001303    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 736   the run_score was: 1.0   and mem length: 130483   eps: 0.9396416800013103    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 737   the run_score was: 1.0   and mem length: 130653   eps: 0.9393050800013176    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 738   the run_score was: 0.0   and mem length: 130777   eps: 0.939059560001323    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 739   the run_score was: 0.0   and mem length: 130900   eps: 0.9388160200013282    steps: 123    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 740   the run_score was: 2.0   and mem length: 131119   eps: 0.9383824000013377    steps: 219    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 741   the run_score was: 1.0   and mem length: 131290   eps: 0.938043820001345    steps: 171    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 742   the run_score was: 3.0   and mem length: 131539   eps: 0.9375508000013557    steps: 249    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 743   the run_score was: 2.0   and mem length: 131755   eps: 0.937123120001365    steps: 216    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 744   the run_score was: 3.0   and mem length: 132002   eps: 0.9366340600013756    steps: 247    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 745   the run_score was: 1.0   and mem length: 132154   eps: 0.9363331000013821    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 746   the run_score was: 0.0   and mem length: 132278   eps: 0.9360875800013875    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 747   the run_score was: 3.0   and mem length: 132488   eps: 0.9356717800013965    steps: 210    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 748   the run_score was: 2.0   and mem length: 132687   eps: 0.9352777600014051    steps: 199    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 749   the run_score was: 2.0   and mem length: 132886   eps: 0.9348837400014136    steps: 199    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 750   the run_score was: 1.0   and mem length: 133038   eps: 0.9345827800014201    steps: 152    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 751   the run_score was: 1.0   and mem length: 133189   eps: 0.9342838000014266    steps: 151    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 752   the run_score was: 3.0   and mem length: 133420   eps: 0.9338264200014366    steps: 231    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 753   the run_score was: 3.0   and mem length: 133651   eps: 0.9333690400014465    steps: 231    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 754   the run_score was: 3.0   and mem length: 133896   eps: 0.932883940001457    steps: 245    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 755   the run_score was: 1.0   and mem length: 134068   eps: 0.9325433800014644    steps: 172    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 756   the run_score was: 0.0   and mem length: 134192   eps: 0.9322978600014697    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 757   the run_score was: 1.0   and mem length: 134344   eps: 0.9319969000014763    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 758   the run_score was: 2.0   and mem length: 134543   eps: 0.9316028800014848    steps: 199    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 759   the run_score was: 0.0   and mem length: 134667   eps: 0.9313573600014902    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 760   the run_score was: 2.0   and mem length: 134867   eps: 0.9309613600014988    steps: 200    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 761   the run_score was: 0.0   and mem length: 134990   eps: 0.930717820001504    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 762   the run_score was: 2.0   and mem length: 135171   eps: 0.9303594400015118    steps: 181    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 763   the run_score was: 2.0   and mem length: 135390   eps: 0.9299258200015212    steps: 219    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 764   the run_score was: 0.0   and mem length: 135514   eps: 0.9296803000015266    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 765   the run_score was: 2.0   and mem length: 135712   eps: 0.9292882600015351    steps: 198    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 766   the run_score was: 3.0   and mem length: 135941   eps: 0.9288348400015449    steps: 229    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 767   the run_score was: 0.0   and mem length: 136064   eps: 0.9285913000015502    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 768   the run_score was: 4.0   and mem length: 136381   eps: 0.9279636400015638    steps: 317    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 769   the run_score was: 3.0   and mem length: 136628   eps: 0.9274745800015745    steps: 247    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 770   the run_score was: 2.0   and mem length: 136847   eps: 0.9270409600015839    steps: 219    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 771   the run_score was: 1.0   and mem length: 137019   eps: 0.9267004000015913    steps: 172    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 772   the run_score was: 1.0   and mem length: 137171   eps: 0.9263994400015978    steps: 152    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 773   the run_score was: 1.0   and mem length: 137322   eps: 0.9261004600016043    steps: 151    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 774   the run_score was: 2.0   and mem length: 137521   eps: 0.9257064400016128    steps: 199    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 775   the run_score was: 0.0   and mem length: 137644   eps: 0.9254629000016181    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 776   the run_score was: 0.0   and mem length: 137767   eps: 0.9252193600016234    steps: 123    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 777   the run_score was: 0.0   and mem length: 137890   eps: 0.9249758200016287    steps: 123    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 778   the run_score was: 0.0   and mem length: 138014   eps: 0.924730300001634    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 779   the run_score was: 0.0   and mem length: 138137   eps: 0.9244867600016393    steps: 123    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 780   the run_score was: 3.0   and mem length: 138405   eps: 0.9239561200016508    steps: 268    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 781   the run_score was: 0.0   and mem length: 138529   eps: 0.9237106000016562    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 782   the run_score was: 1.0   and mem length: 138699   eps: 0.9233740000016635    steps: 170    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 783   the run_score was: 2.0   and mem length: 138880   eps: 0.9230156200016713    steps: 181    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 784   the run_score was: 0.0   and mem length: 139003   eps: 0.9227720800016765    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 785   the run_score was: 0.0   and mem length: 139127   eps: 0.9225265600016819    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 786   the run_score was: 0.0   and mem length: 139251   eps: 0.9222810400016872    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 787   the run_score was: 3.0   and mem length: 139518   eps: 0.9217523800016987    steps: 267    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 788   the run_score was: 3.0   and mem length: 139766   eps: 0.9212613400017093    steps: 248    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 789   the run_score was: 4.0   and mem length: 140062   eps: 0.9206752600017221    steps: 296    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 790   the run_score was: 2.0   and mem length: 140281   eps: 0.9202416400017315    steps: 219    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 791   the run_score was: 1.0   and mem length: 140433   eps: 0.919940680001738    steps: 152    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 792   the run_score was: 0.0   and mem length: 140557   eps: 0.9196951600017433    steps: 124    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 793   the run_score was: 1.0   and mem length: 140727   eps: 0.9193585600017506    steps: 170    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 794   the run_score was: 6.0   and mem length: 141066   eps: 0.9186873400017652    steps: 339    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 795   the run_score was: 1.0   and mem length: 141217   eps: 0.9183883600017717    steps: 151    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 796   the run_score was: 2.0   and mem length: 141415   eps: 0.9179963200017802    steps: 198    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 797   the run_score was: 1.0   and mem length: 141567   eps: 0.9176953600017868    steps: 152    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 798   the run_score was: 0.0   and mem length: 141691   eps: 0.9174498400017921    steps: 124    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 799   the run_score was: 4.0   and mem length: 141968   eps: 0.916901380001804    steps: 277    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 800   the run_score was: 1.0   and mem length: 142140   eps: 0.9165608200018114    steps: 172    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 801   the run_score was: 3.0   and mem length: 142358   eps: 0.9161291800018208    steps: 218    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 802   the run_score was: 2.0   and mem length: 142580   eps: 0.9156896200018303    steps: 222    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 803   the run_score was: 3.0   and mem length: 142812   eps: 0.9152302600018403    steps: 232    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 804   the run_score was: 2.0   and mem length: 143011   eps: 0.9148362400018488    steps: 199    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 805   the run_score was: 1.0   and mem length: 143180   eps: 0.9145016200018561    steps: 169    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 806   the run_score was: 2.0   and mem length: 143379   eps: 0.9141076000018646    steps: 199    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 807   the run_score was: 6.0   and mem length: 143774   eps: 0.9133255000018816    steps: 395    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 808   the run_score was: 1.0   and mem length: 143926   eps: 0.9130245400018882    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 809   the run_score was: 0.0   and mem length: 144050   eps: 0.9127790200018935    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 810   the run_score was: 2.0   and mem length: 144270   eps: 0.9123434200019029    steps: 220    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 811   the run_score was: 2.0   and mem length: 144489   eps: 0.9119098000019124    steps: 219    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 812   the run_score was: 0.0   and mem length: 144612   eps: 0.9116662600019176    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 813   the run_score was: 2.0   and mem length: 144811   eps: 0.9112722400019262    steps: 199    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 814   the run_score was: 2.0   and mem length: 145010   eps: 0.9108782200019347    steps: 199    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 815   the run_score was: 4.0   and mem length: 145285   eps: 0.9103337200019466    steps: 275    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 816   the run_score was: 1.0   and mem length: 145437   eps: 0.9100327600019531    steps: 152    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 817   the run_score was: 3.0   and mem length: 145665   eps: 0.9095813200019629    steps: 228    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 818   the run_score was: 1.0   and mem length: 145834   eps: 0.9092467000019702    steps: 169    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 819   the run_score was: 1.0   and mem length: 146003   eps: 0.9089120800019774    steps: 169    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 820   the run_score was: 2.0   and mem length: 146221   eps: 0.9084804400019868    steps: 218    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 821   the run_score was: 1.0   and mem length: 146393   eps: 0.9081398800019942    steps: 172    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 822   the run_score was: 3.0   and mem length: 146620   eps: 0.907690420002004    steps: 227    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 823   the run_score was: 1.0   and mem length: 146772   eps: 0.9073894600020105    steps: 152    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 824   the run_score was: 2.0   and mem length: 146970   eps: 0.906997420002019    steps: 198    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 825   the run_score was: 3.0   and mem length: 147218   eps: 0.9065063800020297    steps: 248    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 826   the run_score was: 2.0   and mem length: 147416   eps: 0.9061143400020382    steps: 198    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 827   the run_score was: 5.0   and mem length: 147718   eps: 0.9055163800020511    steps: 302    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 828   the run_score was: 1.0   and mem length: 147888   eps: 0.9051797800020585    steps: 170    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 829   the run_score was: 1.0   and mem length: 148040   eps: 0.904878820002065    steps: 152    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 830   the run_score was: 2.0   and mem length: 148239   eps: 0.9044848000020735    steps: 199    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 831   the run_score was: 0.0   and mem length: 148362   eps: 0.9042412600020788    steps: 123    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 832   the run_score was: 1.0   and mem length: 148533   eps: 0.9039026800020862    steps: 171    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 833   the run_score was: 1.0   and mem length: 148703   eps: 0.9035660800020935    steps: 170    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 834   the run_score was: 0.0   and mem length: 148827   eps: 0.9033205600020988    steps: 124    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 835   the run_score was: 1.0   and mem length: 148978   eps: 0.9030215800021053    steps: 151    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 836   the run_score was: 2.0   and mem length: 149177   eps: 0.9026275600021139    steps: 199    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 837   the run_score was: 2.0   and mem length: 149360   eps: 0.9022652200021217    steps: 183    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 838   the run_score was: 0.0   and mem length: 149483   eps: 0.902021680002127    steps: 123    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 839   the run_score was: 1.0   and mem length: 149655   eps: 0.9016811200021344    steps: 172    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 840   the run_score was: 3.0   and mem length: 149905   eps: 0.9011861200021452    steps: 250    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 841   the run_score was: 2.0   and mem length: 150106   eps: 0.9007881400021538    steps: 201    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 842   the run_score was: 3.0   and mem length: 150355   eps: 0.9002951200021645    steps: 249    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 843   the run_score was: 1.0   and mem length: 150506   eps: 0.899996140002171    steps: 151    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 844   the run_score was: 1.0   and mem length: 150679   eps: 0.8996536000021784    steps: 173    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 845   the run_score was: 10.0   and mem length: 151132   eps: 0.8987566600021979    steps: 453    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 846   the run_score was: 3.0   and mem length: 151397   eps: 0.8982319600022093    steps: 265    lr: 0.0001     eval rl_reward: 1.74\n","For episode: 847   the run_score was: 2.0   and mem length: 151596   eps: 0.8978379400022178    steps: 199    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 848   the run_score was: 3.0   and mem length: 151827   eps: 0.8973805600022278    steps: 231    lr: 0.0001     eval rl_reward: 1.74\n","For episode: 849   the run_score was: 2.0   and mem length: 152046   eps: 0.8969469400022372    steps: 219    lr: 0.0001     eval rl_reward: 1.74\n","For episode: 850   the run_score was: 0.0   and mem length: 152170   eps: 0.8967014200022425    steps: 124    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 851   the run_score was: 3.0   and mem length: 152400   eps: 0.8962460200022524    steps: 230    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 852   the run_score was: 1.0   and mem length: 152571   eps: 0.8959074400022597    steps: 171    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 853   the run_score was: 2.0   and mem length: 152790   eps: 0.8954738200022692    steps: 219    lr: 0.0001     eval rl_reward: 1.72\n","For episode: 854   the run_score was: 2.0   and mem length: 152989   eps: 0.8950798000022777    steps: 199    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 855   the run_score was: 3.0   and mem length: 153259   eps: 0.8945452000022893    steps: 270    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 856   the run_score was: 3.0   and mem length: 153527   eps: 0.8940145600023008    steps: 268    lr: 0.0001     eval rl_reward: 1.76\n","For episode: 857   the run_score was: 1.0   and mem length: 153696   eps: 0.8936799400023081    steps: 169    lr: 0.0001     eval rl_reward: 1.76\n","For episode: 858   the run_score was: 0.0   and mem length: 153819   eps: 0.8934364000023134    steps: 123    lr: 0.0001     eval rl_reward: 1.74\n","For episode: 859   the run_score was: 2.0   and mem length: 154037   eps: 0.8930047600023228    steps: 218    lr: 0.0001     eval rl_reward: 1.76\n","For episode: 860   the run_score was: 3.0   and mem length: 154289   eps: 0.8925058000023336    steps: 252    lr: 0.0001     eval rl_reward: 1.77\n","For episode: 861   the run_score was: 3.0   and mem length: 154517   eps: 0.8920543600023434    steps: 228    lr: 0.0001     eval rl_reward: 1.8\n","For episode: 862   the run_score was: 2.0   and mem length: 154716   eps: 0.891660340002352    steps: 199    lr: 0.0001     eval rl_reward: 1.8\n","For episode: 863   the run_score was: 4.0   and mem length: 154975   eps: 0.8911475200023631    steps: 259    lr: 0.0001     eval rl_reward: 1.82\n","For episode: 864   the run_score was: 3.0   and mem length: 155242   eps: 0.8906188600023746    steps: 267    lr: 0.0001     eval rl_reward: 1.85\n","For episode: 865   the run_score was: 1.0   and mem length: 155393   eps: 0.890319880002381    steps: 151    lr: 0.0001     eval rl_reward: 1.84\n","For episode: 866   the run_score was: 0.0   and mem length: 155516   eps: 0.8900763400023863    steps: 123    lr: 0.0001     eval rl_reward: 1.81\n","For episode: 867   the run_score was: 2.0   and mem length: 155735   eps: 0.8896427200023957    steps: 219    lr: 0.0001     eval rl_reward: 1.83\n","For episode: 868   the run_score was: 2.0   and mem length: 155953   eps: 0.8892110800024051    steps: 218    lr: 0.0001     eval rl_reward: 1.81\n","For episode: 869   the run_score was: 6.0   and mem length: 156345   eps: 0.888434920002422    steps: 392    lr: 0.0001     eval rl_reward: 1.84\n","For episode: 870   the run_score was: 0.0   and mem length: 156468   eps: 0.8881913800024273    steps: 123    lr: 0.0001     eval rl_reward: 1.82\n","For episode: 871   the run_score was: 1.0   and mem length: 156641   eps: 0.8878488400024347    steps: 173    lr: 0.0001     eval rl_reward: 1.82\n","For episode: 872   the run_score was: 3.0   and mem length: 156906   eps: 0.8873241400024461    steps: 265    lr: 0.0001     eval rl_reward: 1.84\n","For episode: 873   the run_score was: 2.0   and mem length: 157105   eps: 0.8869301200024546    steps: 199    lr: 0.0001     eval rl_reward: 1.85\n","For episode: 874   the run_score was: 3.0   and mem length: 157332   eps: 0.8864806600024644    steps: 227    lr: 0.0001     eval rl_reward: 1.86\n","For episode: 875   the run_score was: 2.0   and mem length: 157531   eps: 0.886086640002473    steps: 199    lr: 0.0001     eval rl_reward: 1.88\n","For episode: 876   the run_score was: 7.0   and mem length: 157944   eps: 0.8852689000024907    steps: 413    lr: 0.0001     eval rl_reward: 1.95\n","For episode: 877   the run_score was: 2.0   and mem length: 158162   eps: 0.8848372600025001    steps: 218    lr: 0.0001     eval rl_reward: 1.97\n","For episode: 878   the run_score was: 3.0   and mem length: 158409   eps: 0.8843482000025107    steps: 247    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 879   the run_score was: 3.0   and mem length: 158636   eps: 0.8838987400025204    steps: 227    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 880   the run_score was: 2.0   and mem length: 158819   eps: 0.8835364000025283    steps: 183    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 881   the run_score was: 0.0   and mem length: 158943   eps: 0.8832908800025336    steps: 124    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 882   the run_score was: 2.0   and mem length: 159162   eps: 0.882857260002543    steps: 219    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 883   the run_score was: 0.0   and mem length: 159286   eps: 0.8826117400025484    steps: 124    lr: 0.0001     eval rl_reward: 2.01\n","For episode: 884   the run_score was: 4.0   and mem length: 159585   eps: 0.8820197200025612    steps: 299    lr: 0.0001     eval rl_reward: 2.05\n","For episode: 885   the run_score was: 3.0   and mem length: 159834   eps: 0.8815267000025719    steps: 249    lr: 0.0001     eval rl_reward: 2.08\n","For episode: 886   the run_score was: 8.0   and mem length: 160164   eps: 0.8808733000025861    steps: 330    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 887   the run_score was: 0.0   and mem length: 160288   eps: 0.8806277800025915    steps: 124    lr: 0.0001     eval rl_reward: 2.13\n","For episode: 888   the run_score was: 2.0   and mem length: 160486   eps: 0.8802357400026    steps: 198    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 889   the run_score was: 1.0   and mem length: 160659   eps: 0.8798932000026074    steps: 173    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 890   the run_score was: 2.0   and mem length: 160881   eps: 0.8794536400026169    steps: 222    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 891   the run_score was: 5.0   and mem length: 161232   eps: 0.878758660002632    steps: 351    lr: 0.0001     eval rl_reward: 2.13\n","For episode: 892   the run_score was: 1.0   and mem length: 161384   eps: 0.8784577000026386    steps: 152    lr: 0.0001     eval rl_reward: 2.14\n","For episode: 893   the run_score was: 7.0   and mem length: 161771   eps: 0.8776914400026552    steps: 387    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 894   the run_score was: 3.0   and mem length: 162018   eps: 0.8772023800026658    steps: 247    lr: 0.0001     eval rl_reward: 2.17\n","For episode: 895   the run_score was: 2.0   and mem length: 162199   eps: 0.8768440000026736    steps: 181    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 896   the run_score was: 0.0   and mem length: 162323   eps: 0.8765984800026789    steps: 124    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 897   the run_score was: 4.0   and mem length: 162602   eps: 0.8760460600026909    steps: 279    lr: 0.0001     eval rl_reward: 2.19\n","For episode: 898   the run_score was: 1.0   and mem length: 162775   eps: 0.8757035200026984    steps: 173    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 899   the run_score was: 2.0   and mem length: 162992   eps: 0.8752738600027077    steps: 217    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 900   the run_score was: 6.0   and mem length: 163339   eps: 0.8745868000027226    steps: 347    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 901   the run_score was: 0.0   and mem length: 163462   eps: 0.8743432600027279    steps: 123    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 902   the run_score was: 1.0   and mem length: 163613   eps: 0.8740442800027344    steps: 151    lr: 0.0001     eval rl_reward: 2.19\n","For episode: 903   the run_score was: 6.0   and mem length: 163969   eps: 0.8733394000027497    steps: 356    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 904   the run_score was: 2.0   and mem length: 164188   eps: 0.8729057800027591    steps: 219    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 905   the run_score was: 3.0   and mem length: 164434   eps: 0.8724187000027697    steps: 246    lr: 0.0001     eval rl_reward: 2.24\n","For episode: 906   the run_score was: 3.0   and mem length: 164661   eps: 0.8719692400027794    steps: 227    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 907   the run_score was: 1.0   and mem length: 164831   eps: 0.8716326400027867    steps: 170    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 908   the run_score was: 4.0   and mem length: 165126   eps: 0.8710485400027994    steps: 295    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 909   the run_score was: 1.0   and mem length: 165277   eps: 0.8707495600028059    steps: 151    lr: 0.0001     eval rl_reward: 2.24\n","For episode: 910   the run_score was: 0.0   and mem length: 165401   eps: 0.8705040400028112    steps: 124    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 911   the run_score was: 1.0   and mem length: 165553   eps: 0.8702030800028178    steps: 152    lr: 0.0001     eval rl_reward: 2.21\n","For episode: 912   the run_score was: 2.0   and mem length: 165771   eps: 0.8697714400028271    steps: 218    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 913   the run_score was: 5.0   and mem length: 166068   eps: 0.8691833800028399    steps: 297    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 914   the run_score was: 2.0   and mem length: 166267   eps: 0.8687893600028485    steps: 199    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 915   the run_score was: 0.0   and mem length: 166391   eps: 0.8685438400028538    steps: 124    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 916   the run_score was: 2.0   and mem length: 166572   eps: 0.8681854600028616    steps: 181    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 917   the run_score was: 3.0   and mem length: 166822   eps: 0.8676904600028723    steps: 250    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 918   the run_score was: 3.0   and mem length: 167069   eps: 0.8672014000028829    steps: 247    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 919   the run_score was: 3.0   and mem length: 167296   eps: 0.8667519400028927    steps: 227    lr: 0.0001     eval rl_reward: 2.27\n","For episode: 920   the run_score was: 2.0   and mem length: 167494   eps: 0.8663599000029012    steps: 198    lr: 0.0001     eval rl_reward: 2.27\n","For episode: 921   the run_score was: 2.0   and mem length: 167692   eps: 0.8659678600029097    steps: 198    lr: 0.0001     eval rl_reward: 2.28\n","For episode: 922   the run_score was: 3.0   and mem length: 167940   eps: 0.8654768200029204    steps: 248    lr: 0.0001     eval rl_reward: 2.28\n","For episode: 923   the run_score was: 9.0   and mem length: 168292   eps: 0.8647798600029355    steps: 352    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 924   the run_score was: 4.0   and mem length: 168551   eps: 0.8642670400029466    steps: 259    lr: 0.0001     eval rl_reward: 2.38\n","For episode: 925   the run_score was: 1.0   and mem length: 168722   eps: 0.863928460002954    steps: 171    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 926   the run_score was: 3.0   and mem length: 168990   eps: 0.8633978200029655    steps: 268    lr: 0.0001     eval rl_reward: 2.37\n","For episode: 927   the run_score was: 3.0   and mem length: 169257   eps: 0.862869160002977    steps: 267    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 928   the run_score was: 0.0   and mem length: 169380   eps: 0.8626256200029823    steps: 123    lr: 0.0001     eval rl_reward: 2.34\n","For episode: 929   the run_score was: 2.0   and mem length: 169579   eps: 0.8622316000029908    steps: 199    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 930   the run_score was: 3.0   and mem length: 169806   eps: 0.8617821400030006    steps: 227    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 931   the run_score was: 5.0   and mem length: 170154   eps: 0.8610931000030155    steps: 348    lr: 0.0001     eval rl_reward: 2.41\n","For episode: 932   the run_score was: 0.0   and mem length: 170278   eps: 0.8608475800030209    steps: 124    lr: 0.0001     eval rl_reward: 2.4\n","For episode: 933   the run_score was: 2.0   and mem length: 170477   eps: 0.8604535600030294    steps: 199    lr: 0.0001     eval rl_reward: 2.41\n","For episode: 934   the run_score was: 3.0   and mem length: 170706   eps: 0.8600001400030393    steps: 229    lr: 0.0001     eval rl_reward: 2.44\n","For episode: 935   the run_score was: 1.0   and mem length: 170876   eps: 0.8596635400030466    steps: 170    lr: 0.0001     eval rl_reward: 2.44\n","For episode: 936   the run_score was: 0.0   and mem length: 171000   eps: 0.8594180200030519    steps: 124    lr: 0.0001     eval rl_reward: 2.42\n","For episode: 937   the run_score was: 3.0   and mem length: 171247   eps: 0.8589289600030625    steps: 247    lr: 0.0001     eval rl_reward: 2.43\n","For episode: 938   the run_score was: 1.0   and mem length: 171418   eps: 0.8585903800030699    steps: 171    lr: 0.0001     eval rl_reward: 2.44\n","For episode: 939   the run_score was: 0.0   and mem length: 171542   eps: 0.8583448600030752    steps: 124    lr: 0.0001     eval rl_reward: 2.43\n","For episode: 940   the run_score was: 3.0   and mem length: 171788   eps: 0.8578577800030858    steps: 246    lr: 0.0001     eval rl_reward: 2.43\n","For episode: 941   the run_score was: 1.0   and mem length: 171940   eps: 0.8575568200030923    steps: 152    lr: 0.0001     eval rl_reward: 2.42\n","For episode: 942   the run_score was: 2.0   and mem length: 172139   eps: 0.8571628000031009    steps: 199    lr: 0.0001     eval rl_reward: 2.41\n","For episode: 943   the run_score was: 3.0   and mem length: 172368   eps: 0.8567093800031107    steps: 229    lr: 0.0001     eval rl_reward: 2.43\n","For episode: 944   the run_score was: 1.0   and mem length: 172520   eps: 0.8564084200031172    steps: 152    lr: 0.0001     eval rl_reward: 2.43\n","For episode: 945   the run_score was: 0.0   and mem length: 172643   eps: 0.8561648800031225    steps: 123    lr: 0.0001     eval rl_reward: 2.33\n","For episode: 946   the run_score was: 2.0   and mem length: 172862   eps: 0.8557312600031319    steps: 219    lr: 0.0001     eval rl_reward: 2.32\n","For episode: 947   the run_score was: 5.0   and mem length: 173206   eps: 0.8550501400031467    steps: 344    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 948   the run_score was: 3.0   and mem length: 173454   eps: 0.8545591000031574    steps: 248    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 949   the run_score was: 2.0   and mem length: 173675   eps: 0.8541215200031669    steps: 221    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 950   the run_score was: 3.0   and mem length: 173943   eps: 0.8535908800031784    steps: 268    lr: 0.0001     eval rl_reward: 2.38\n","For episode: 951   the run_score was: 1.0   and mem length: 174095   eps: 0.8532899200031849    steps: 152    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 952   the run_score was: 1.0   and mem length: 174246   eps: 0.8529909400031914    steps: 151    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 953   the run_score was: 1.0   and mem length: 174416   eps: 0.8526543400031987    steps: 170    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 954   the run_score was: 2.0   and mem length: 174615   eps: 0.8522603200032073    steps: 199    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 955   the run_score was: 0.0   and mem length: 174739   eps: 0.8520148000032126    steps: 124    lr: 0.0001     eval rl_reward: 2.32\n","For episode: 956   the run_score was: 4.0   and mem length: 174999   eps: 0.8515000000032238    steps: 260    lr: 0.0001     eval rl_reward: 2.33\n","For episode: 957   the run_score was: 3.0   and mem length: 175246   eps: 0.8510109400032344    steps: 247    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 958   the run_score was: 2.0   and mem length: 175467   eps: 0.8505733600032439    steps: 221    lr: 0.0001     eval rl_reward: 2.37\n","For episode: 959   the run_score was: 2.0   and mem length: 175665   eps: 0.8501813200032524    steps: 198    lr: 0.0001     eval rl_reward: 2.37\n","For episode: 960   the run_score was: 1.0   and mem length: 175836   eps: 0.8498427400032598    steps: 171    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 961   the run_score was: 1.0   and mem length: 175987   eps: 0.8495437600032663    steps: 151    lr: 0.0001     eval rl_reward: 2.33\n","For episode: 962   the run_score was: 0.0   and mem length: 176111   eps: 0.8492982400032716    steps: 124    lr: 0.0001     eval rl_reward: 2.31\n","For episode: 963   the run_score was: 7.0   and mem length: 176493   eps: 0.848541880003288    steps: 382    lr: 0.0001     eval rl_reward: 2.34\n","For episode: 964   the run_score was: 1.0   and mem length: 176663   eps: 0.8482052800032953    steps: 170    lr: 0.0001     eval rl_reward: 2.32\n","For episode: 965   the run_score was: 1.0   and mem length: 176833   eps: 0.8478686800033026    steps: 170    lr: 0.0001     eval rl_reward: 2.32\n","For episode: 966   the run_score was: 2.0   and mem length: 177015   eps: 0.8475083200033104    steps: 182    lr: 0.0001     eval rl_reward: 2.34\n","For episode: 967   the run_score was: 3.0   and mem length: 177244   eps: 0.8470549000033203    steps: 229    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 968   the run_score was: 3.0   and mem length: 177474   eps: 0.8465995000033302    steps: 230    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 969   the run_score was: 4.0   and mem length: 177751   eps: 0.8460510400033421    steps: 277    lr: 0.0001     eval rl_reward: 2.34\n","For episode: 970   the run_score was: 3.0   and mem length: 178015   eps: 0.8455283200033534    steps: 264    lr: 0.0001     eval rl_reward: 2.37\n","For episode: 971   the run_score was: 1.0   and mem length: 178187   eps: 0.8451877600033608    steps: 172    lr: 0.0001     eval rl_reward: 2.37\n","For episode: 972   the run_score was: 2.0   and mem length: 178386   eps: 0.8447937400033694    steps: 199    lr: 0.0001     eval rl_reward: 2.36\n","For episode: 973   the run_score was: 1.0   and mem length: 178558   eps: 0.8444531800033768    steps: 172    lr: 0.0001     eval rl_reward: 2.35\n","For episode: 974   the run_score was: 1.0   and mem length: 178710   eps: 0.8441522200033833    steps: 152    lr: 0.0001     eval rl_reward: 2.33\n","For episode: 975   the run_score was: 1.0   and mem length: 178880   eps: 0.8438156200033906    steps: 170    lr: 0.0001     eval rl_reward: 2.32\n","For episode: 976   the run_score was: 3.0   and mem length: 179128   eps: 0.8433245800034013    steps: 248    lr: 0.0001     eval rl_reward: 2.28\n","For episode: 977   the run_score was: 2.0   and mem length: 179328   eps: 0.8429285800034099    steps: 200    lr: 0.0001     eval rl_reward: 2.28\n","For episode: 978   the run_score was: 1.0   and mem length: 179480   eps: 0.8426276200034164    steps: 152    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 979   the run_score was: 0.0   and mem length: 179604   eps: 0.8423821000034217    steps: 124    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 980   the run_score was: 4.0   and mem length: 179899   eps: 0.8417980000034344    steps: 295    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 981   the run_score was: 1.0   and mem length: 180070   eps: 0.8414594200034418    steps: 171    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 982   the run_score was: 2.0   and mem length: 180268   eps: 0.8410673800034503    steps: 198    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 983   the run_score was: 1.0   and mem length: 180419   eps: 0.8407684000034568    steps: 151    lr: 0.0001     eval rl_reward: 2.27\n","For episode: 984   the run_score was: 5.0   and mem length: 180747   eps: 0.8401189600034709    steps: 328    lr: 0.0001     eval rl_reward: 2.28\n","For episode: 985   the run_score was: 0.0   and mem length: 180870   eps: 0.8398754200034761    steps: 123    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 986   the run_score was: 4.0   and mem length: 181130   eps: 0.8393606200034873    steps: 260    lr: 0.0001     eval rl_reward: 2.21\n","For episode: 987   the run_score was: 4.0   and mem length: 181372   eps: 0.8388814600034977    steps: 242    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 988   the run_score was: 3.0   and mem length: 181583   eps: 0.8384636800035068    steps: 211    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 989   the run_score was: 1.0   and mem length: 181735   eps: 0.8381627200035133    steps: 152    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 990   the run_score was: 2.0   and mem length: 181937   eps: 0.837762760003522    steps: 202    lr: 0.0001     eval rl_reward: 2.26\n","For episode: 991   the run_score was: 2.0   and mem length: 182138   eps: 0.8373647800035307    steps: 201    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 992   the run_score was: 0.0   and mem length: 182262   eps: 0.837119260003536    steps: 124    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 993   the run_score was: 3.0   and mem length: 182509   eps: 0.8366302000035466    steps: 247    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 994   the run_score was: 3.0   and mem length: 182735   eps: 0.8361827200035563    steps: 226    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 995   the run_score was: 2.0   and mem length: 182918   eps: 0.8358203800035642    steps: 183    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 996   the run_score was: 5.0   and mem length: 183263   eps: 0.835137280003579    steps: 345    lr: 0.0001     eval rl_reward: 2.23\n","For episode: 997   the run_score was: 2.0   and mem length: 183461   eps: 0.8347452400035875    steps: 198    lr: 0.0001     eval rl_reward: 2.21\n","For episode: 998   the run_score was: 2.0   and mem length: 183662   eps: 0.8343472600035962    steps: 201    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 999   the run_score was: 0.0   and mem length: 183785   eps: 0.8341037200036014    steps: 123    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 1000   the run_score was: 2.0   and mem length: 183984   eps: 0.83370970000361    steps: 199    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 1001   the run_score was: 2.0   and mem length: 184182   eps: 0.8333176600036185    steps: 198    lr: 0.0001     eval rl_reward: 2.18\n","For episode: 1002   the run_score was: 2.0   and mem length: 184382   eps: 0.8329216600036271    steps: 200    lr: 0.0001     eval rl_reward: 2.19\n","For episode: 1003   the run_score was: 0.0   and mem length: 184505   eps: 0.8326781200036324    steps: 123    lr: 0.0001     eval rl_reward: 2.13\n","For episode: 1004   the run_score was: 1.0   and mem length: 184678   eps: 0.8323355800036398    steps: 173    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 1005   the run_score was: 0.0   and mem length: 184802   eps: 0.8320900600036452    steps: 124    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 1006   the run_score was: 3.0   and mem length: 185049   eps: 0.8316010000036558    steps: 247    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 1007   the run_score was: 6.0   and mem length: 185366   eps: 0.8309733400036694    steps: 317    lr: 0.0001     eval rl_reward: 2.14\n","For episode: 1008   the run_score was: 6.0   and mem length: 185742   eps: 0.8302288600036856    steps: 376    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 1009   the run_score was: 2.0   and mem length: 185924   eps: 0.8298685000036934    steps: 182    lr: 0.0001     eval rl_reward: 2.17\n","For episode: 1010   the run_score was: 2.0   and mem length: 186125   eps: 0.829470520003702    steps: 201    lr: 0.0001     eval rl_reward: 2.19\n","For episode: 1011   the run_score was: 2.0   and mem length: 186323   eps: 0.8290784800037105    steps: 198    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 1012   the run_score was: 4.0   and mem length: 186598   eps: 0.8285339800037224    steps: 275    lr: 0.0001     eval rl_reward: 2.22\n","For episode: 1013   the run_score was: 0.0   and mem length: 186722   eps: 0.8282884600037277    steps: 124    lr: 0.0001     eval rl_reward: 2.17\n","For episode: 1014   the run_score was: 1.0   and mem length: 186894   eps: 0.8279479000037351    steps: 172    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 1015   the run_score was: 0.0   and mem length: 187017   eps: 0.8277043600037404    steps: 123    lr: 0.0001     eval rl_reward: 2.16\n","For episode: 1016   the run_score was: 1.0   and mem length: 187188   eps: 0.8273657800037477    steps: 171    lr: 0.0001     eval rl_reward: 2.15\n","For episode: 1017   the run_score was: 0.0   and mem length: 187311   eps: 0.827122240003753    steps: 123    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 1018   the run_score was: 0.0   and mem length: 187434   eps: 0.8268787000037583    steps: 123    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 1019   the run_score was: 5.0   and mem length: 187772   eps: 0.8262094600037728    steps: 338    lr: 0.0001     eval rl_reward: 2.11\n","For episode: 1020   the run_score was: 3.0   and mem length: 188019   eps: 0.8257204000037834    steps: 247    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 1021   the run_score was: 0.0   and mem length: 188143   eps: 0.8254748800037888    steps: 124    lr: 0.0001     eval rl_reward: 2.1\n","For episode: 1022   the run_score was: 6.0   and mem length: 188503   eps: 0.8247620800038042    steps: 360    lr: 0.0001     eval rl_reward: 2.13\n","For episode: 1023   the run_score was: 0.0   and mem length: 188627   eps: 0.8245165600038096    steps: 124    lr: 0.0001     eval rl_reward: 2.04\n","For episode: 1024   the run_score was: 1.0   and mem length: 188779   eps: 0.8242156000038161    steps: 152    lr: 0.0001     eval rl_reward: 2.01\n","For episode: 1025   the run_score was: 1.0   and mem length: 188949   eps: 0.8238790000038234    steps: 170    lr: 0.0001     eval rl_reward: 2.01\n","For episode: 1026   the run_score was: 2.0   and mem length: 189151   eps: 0.8234790400038321    steps: 202    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1027   the run_score was: 4.0   and mem length: 189448   eps: 0.8228909800038449    steps: 297    lr: 0.0001     eval rl_reward: 2.01\n","For episode: 1028   the run_score was: 1.0   and mem length: 189599   eps: 0.8225920000038514    steps: 151    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1029   the run_score was: 0.0   and mem length: 189722   eps: 0.8223484600038566    steps: 123    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1030   the run_score was: 1.0   and mem length: 189892   eps: 0.822011860003864    steps: 170    lr: 0.0001     eval rl_reward: 1.98\n","For episode: 1031   the run_score was: 1.0   and mem length: 190065   eps: 0.8216693200038714    steps: 173    lr: 0.0001     eval rl_reward: 1.94\n","For episode: 1032   the run_score was: 1.0   and mem length: 190238   eps: 0.8213267800038788    steps: 173    lr: 0.0001     eval rl_reward: 1.95\n","For episode: 1033   the run_score was: 3.0   and mem length: 190489   eps: 0.8208298000038896    steps: 251    lr: 0.0001     eval rl_reward: 1.96\n","For episode: 1034   the run_score was: 4.0   and mem length: 190787   eps: 0.8202397600039024    steps: 298    lr: 0.0001     eval rl_reward: 1.97\n","For episode: 1035   the run_score was: 2.0   and mem length: 190989   eps: 0.8198398000039111    steps: 202    lr: 0.0001     eval rl_reward: 1.98\n","For episode: 1036   the run_score was: 2.0   and mem length: 191172   eps: 0.819477460003919    steps: 183    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1037   the run_score was: 2.0   and mem length: 191388   eps: 0.8190497800039283    steps: 216    lr: 0.0001     eval rl_reward: 1.99\n","For episode: 1038   the run_score was: 2.0   and mem length: 191588   eps: 0.8186537800039368    steps: 200    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1039   the run_score was: 0.0   and mem length: 191712   eps: 0.8184082600039422    steps: 124    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1040   the run_score was: 3.0   and mem length: 191979   eps: 0.8178796000039537    steps: 267    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1041   the run_score was: 3.0   and mem length: 192249   eps: 0.8173450000039653    steps: 270    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1042   the run_score was: 3.0   and mem length: 192480   eps: 0.8168876200039752    steps: 231    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 1043   the run_score was: 2.0   and mem length: 192660   eps: 0.8165312200039829    steps: 180    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1044   the run_score was: 3.0   and mem length: 192870   eps: 0.816115420003992    steps: 210    lr: 0.0001     eval rl_reward: 2.04\n","For episode: 1045   the run_score was: 2.0   and mem length: 193068   eps: 0.8157233800040005    steps: 198    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1046   the run_score was: 2.0   and mem length: 193271   eps: 0.8153214400040092    steps: 203    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1047   the run_score was: 6.0   and mem length: 193622   eps: 0.8146264600040243    steps: 351    lr: 0.0001     eval rl_reward: 2.07\n","For episode: 1048   the run_score was: 3.0   and mem length: 193889   eps: 0.8140978000040358    steps: 267    lr: 0.0001     eval rl_reward: 2.07\n","For episode: 1049   the run_score was: 2.0   and mem length: 194110   eps: 0.8136602200040453    steps: 221    lr: 0.0001     eval rl_reward: 2.07\n","For episode: 1050   the run_score was: 0.0   and mem length: 194234   eps: 0.8134147000040506    steps: 124    lr: 0.0001     eval rl_reward: 2.04\n","For episode: 1051   the run_score was: 3.0   and mem length: 194463   eps: 0.8129612800040604    steps: 229    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1052   the run_score was: 1.0   and mem length: 194634   eps: 0.8126227000040678    steps: 171    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1053   the run_score was: 0.0   and mem length: 194758   eps: 0.8123771800040731    steps: 124    lr: 0.0001     eval rl_reward: 2.05\n","For episode: 1054   the run_score was: 2.0   and mem length: 194957   eps: 0.8119831600040817    steps: 199    lr: 0.0001     eval rl_reward: 2.05\n","For episode: 1055   the run_score was: 4.0   and mem length: 195218   eps: 0.8114663800040929    steps: 261    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 1056   the run_score was: 1.0   and mem length: 195388   eps: 0.8111297800041002    steps: 170    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1057   the run_score was: 3.0   and mem length: 195636   eps: 0.8106387400041108    steps: 248    lr: 0.0001     eval rl_reward: 2.06\n","For episode: 1058   the run_score was: 3.0   and mem length: 195906   eps: 0.8101041400041225    steps: 270    lr: 0.0001     eval rl_reward: 2.07\n","For episode: 1059   the run_score was: 0.0   and mem length: 196030   eps: 0.8098586200041278    steps: 124    lr: 0.0001     eval rl_reward: 2.05\n","For episode: 1060   the run_score was: 5.0   and mem length: 196357   eps: 0.8092111600041418    steps: 327    lr: 0.0001     eval rl_reward: 2.09\n","For episode: 1061   the run_score was: 6.0   and mem length: 196719   eps: 0.8084944000041574    steps: 362    lr: 0.0001     eval rl_reward: 2.14\n","For episode: 1062   the run_score was: 3.0   and mem length: 196966   eps: 0.808005340004168    steps: 247    lr: 0.0001     eval rl_reward: 2.17\n","For episode: 1063   the run_score was: 2.0   and mem length: 197149   eps: 0.8076430000041759    steps: 183    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 1064   the run_score was: 0.0   and mem length: 197273   eps: 0.8073974800041812    steps: 124    lr: 0.0001     eval rl_reward: 2.11\n","For episode: 1065   the run_score was: 2.0   and mem length: 197454   eps: 0.807039100004189    steps: 181    lr: 0.0001     eval rl_reward: 2.12\n","For episode: 1066   the run_score was: 0.0   and mem length: 197578   eps: 0.8067935800041943    steps: 124    lr: 0.0001     eval rl_reward: 2.1\n","For episode: 1067   the run_score was: 0.0   and mem length: 197702   eps: 0.8065480600041997    steps: 124    lr: 0.0001     eval rl_reward: 2.07\n","For episode: 1068   the run_score was: 0.0   and mem length: 197826   eps: 0.806302540004205    steps: 124    lr: 0.0001     eval rl_reward: 2.04\n","For episode: 1069   the run_score was: 4.0   and mem length: 198123   eps: 0.8057144800042177    steps: 297    lr: 0.0001     eval rl_reward: 2.04\n","For episode: 1070   the run_score was: 2.0   and mem length: 198321   eps: 0.8053224400042263    steps: 198    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 1071   the run_score was: 0.0   and mem length: 198445   eps: 0.8050769200042316    steps: 124    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1072   the run_score was: 2.0   and mem length: 198644   eps: 0.8046829000042401    steps: 199    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1073   the run_score was: 2.0   and mem length: 198844   eps: 0.8042869000042487    steps: 200    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 1074   the run_score was: 1.0   and mem length: 199014   eps: 0.803950300004256    steps: 170    lr: 0.0001     eval rl_reward: 2.03\n","For episode: 1075   the run_score was: 0.0   and mem length: 199138   eps: 0.8037047800042614    steps: 124    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1076   the run_score was: 0.0   and mem length: 199262   eps: 0.8034592600042667    steps: 124    lr: 0.0001     eval rl_reward: 1.99\n","For episode: 1077   the run_score was: 1.0   and mem length: 199432   eps: 0.803122660004274    steps: 170    lr: 0.0001     eval rl_reward: 1.98\n","For episode: 1078   the run_score was: 3.0   and mem length: 199678   eps: 0.8026355800042846    steps: 246    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 1079   the run_score was: 2.0   and mem length: 199877   eps: 0.8022415600042931    steps: 199    lr: 0.0001     eval rl_reward: 2.02\n","For episode: 1080   the run_score was: 3.0   and mem length: 200104   eps: 0.8017921000043029    steps: 227    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1081   the run_score was: 1.0   and mem length: 200274   eps: 0.8014555000043102    steps: 170    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1082   the run_score was: 0.0   and mem length: 200398   eps: 0.8012099800043155    steps: 124    lr: 4e-05     eval rl_reward: 1.99\n","For episode: 1083   the run_score was: 5.0   and mem length: 200717   eps: 0.8005783600043292    steps: 319    lr: 4e-05     eval rl_reward: 2.03\n","For episode: 1084   the run_score was: 2.0   and mem length: 200937   eps: 0.8001427600043387    steps: 220    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1085   the run_score was: 1.0   and mem length: 201109   eps: 0.7998022000043461    steps: 172    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1086   the run_score was: 2.0   and mem length: 201330   eps: 0.7993646200043556    steps: 221    lr: 4e-05     eval rl_reward: 1.99\n","For episode: 1087   the run_score was: 5.0   and mem length: 201661   eps: 0.7987092400043698    steps: 331    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1088   the run_score was: 0.0   and mem length: 201785   eps: 0.7984637200043752    steps: 124    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1089   the run_score was: 1.0   and mem length: 201957   eps: 0.7981231600043825    steps: 172    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1090   the run_score was: 2.0   and mem length: 202157   eps: 0.7977271600043911    steps: 200    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1091   the run_score was: 3.0   and mem length: 202405   eps: 0.7972361200044018    steps: 248    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1092   the run_score was: 3.0   and mem length: 202655   eps: 0.7967411200044126    steps: 250    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1093   the run_score was: 3.0   and mem length: 202905   eps: 0.7962461200044233    steps: 250    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1094   the run_score was: 4.0   and mem length: 203183   eps: 0.7956956800044352    steps: 278    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1095   the run_score was: 2.0   and mem length: 203381   eps: 0.7953036400044438    steps: 198    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1096   the run_score was: 2.0   and mem length: 203598   eps: 0.7948739800044531    steps: 217    lr: 4e-05     eval rl_reward: 1.99\n","For episode: 1097   the run_score was: 3.0   and mem length: 203843   eps: 0.7943888800044636    steps: 245    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1098   the run_score was: 1.0   and mem length: 203995   eps: 0.7940879200044701    steps: 152    lr: 4e-05     eval rl_reward: 1.99\n","For episode: 1099   the run_score was: 6.0   and mem length: 204338   eps: 0.7934087800044849    steps: 343    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1100   the run_score was: 4.0   and mem length: 204579   eps: 0.7929316000044953    steps: 241    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1101   the run_score was: 5.0   and mem length: 204896   eps: 0.7923039400045089    steps: 317    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1102   the run_score was: 3.0   and mem length: 205164   eps: 0.7917733000045204    steps: 268    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1103   the run_score was: 1.0   and mem length: 205317   eps: 0.791470360004527    steps: 153    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1104   the run_score was: 2.0   and mem length: 205515   eps: 0.7910783200045355    steps: 198    lr: 4e-05     eval rl_reward: 2.13\n","For episode: 1105   the run_score was: 2.0   and mem length: 205735   eps: 0.7906427200045449    steps: 220    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1106   the run_score was: 2.0   and mem length: 205958   eps: 0.7902011800045545    steps: 223    lr: 4e-05     eval rl_reward: 2.14\n","For episode: 1107   the run_score was: 5.0   and mem length: 206263   eps: 0.7895972800045676    steps: 305    lr: 4e-05     eval rl_reward: 2.13\n","For episode: 1108   the run_score was: 3.0   and mem length: 206492   eps: 0.7891438600045775    steps: 229    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1109   the run_score was: 9.0   and mem length: 207012   eps: 0.7881142600045998    steps: 520    lr: 4e-05     eval rl_reward: 2.17\n","For episode: 1110   the run_score was: 7.0   and mem length: 207376   eps: 0.7873935400046155    steps: 364    lr: 4e-05     eval rl_reward: 2.22\n","For episode: 1111   the run_score was: 1.0   and mem length: 207546   eps: 0.7870569400046228    steps: 170    lr: 4e-05     eval rl_reward: 2.21\n","For episode: 1112   the run_score was: 4.0   and mem length: 207822   eps: 0.7865104600046346    steps: 276    lr: 4e-05     eval rl_reward: 2.21\n","For episode: 1113   the run_score was: 3.0   and mem length: 208052   eps: 0.7860550600046445    steps: 230    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1114   the run_score was: 3.0   and mem length: 208279   eps: 0.7856056000046543    steps: 227    lr: 4e-05     eval rl_reward: 2.26\n","For episode: 1115   the run_score was: 2.0   and mem length: 208496   eps: 0.7851759400046636    steps: 217    lr: 4e-05     eval rl_reward: 2.28\n","For episode: 1116   the run_score was: 4.0   and mem length: 208795   eps: 0.7845839200046765    steps: 299    lr: 4e-05     eval rl_reward: 2.31\n","For episode: 1117   the run_score was: 3.0   and mem length: 209060   eps: 0.7840592200046879    steps: 265    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1118   the run_score was: 3.0   and mem length: 209327   eps: 0.7835305600046993    steps: 267    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1119   the run_score was: 2.0   and mem length: 209543   eps: 0.7831028800047086    steps: 216    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1120   the run_score was: 3.0   and mem length: 209772   eps: 0.7826494600047185    steps: 229    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1121   the run_score was: 1.0   and mem length: 209943   eps: 0.7823108800047258    steps: 171    lr: 4e-05     eval rl_reward: 2.35\n","For episode: 1122   the run_score was: 4.0   and mem length: 210199   eps: 0.7818040000047368    steps: 256    lr: 4e-05     eval rl_reward: 2.33\n","For episode: 1123   the run_score was: 1.0   and mem length: 210372   eps: 0.7814614600047443    steps: 173    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1124   the run_score was: 3.0   and mem length: 210599   eps: 0.781012000004754    steps: 227    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1125   the run_score was: 3.0   and mem length: 210848   eps: 0.7805189800047647    steps: 249    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1126   the run_score was: 0.0   and mem length: 210972   eps: 0.78027346000477    steps: 124    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1127   the run_score was: 2.0   and mem length: 211193   eps: 0.7798358800047795    steps: 221    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1128   the run_score was: 4.0   and mem length: 211452   eps: 0.7793230600047907    steps: 259    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1129   the run_score was: 0.0   and mem length: 211576   eps: 0.779077540004796    steps: 124    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1130   the run_score was: 2.0   and mem length: 211775   eps: 0.7786835200048046    steps: 199    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1131   the run_score was: 0.0   and mem length: 211898   eps: 0.7784399800048099    steps: 123    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1132   the run_score was: 3.0   and mem length: 212127   eps: 0.7779865600048197    steps: 229    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1133   the run_score was: 0.0   and mem length: 212250   eps: 0.777743020004825    steps: 123    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1134   the run_score was: 3.0   and mem length: 212477   eps: 0.7772935600048347    steps: 227    lr: 4e-05     eval rl_reward: 2.35\n","For episode: 1135   the run_score was: 4.0   and mem length: 212774   eps: 0.7767055000048475    steps: 297    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1136   the run_score was: 3.0   and mem length: 213045   eps: 0.7761689200048592    steps: 271    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1137   the run_score was: 3.0   and mem length: 213272   eps: 0.7757194600048689    steps: 227    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1138   the run_score was: 3.0   and mem length: 213519   eps: 0.7752304000048795    steps: 247    lr: 4e-05     eval rl_reward: 2.4\n","For episode: 1139   the run_score was: 5.0   and mem length: 213808   eps: 0.774658180004892    steps: 289    lr: 4e-05     eval rl_reward: 2.45\n","For episode: 1140   the run_score was: 0.0   and mem length: 213932   eps: 0.7744126600048973    steps: 124    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1141   the run_score was: 3.0   and mem length: 214159   eps: 0.773963200004907    steps: 227    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1142   the run_score was: 2.0   and mem length: 214340   eps: 0.7736048200049148    steps: 181    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1143   the run_score was: 3.0   and mem length: 214574   eps: 0.7731415000049249    steps: 234    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1144   the run_score was: 0.0   and mem length: 214698   eps: 0.7728959800049302    steps: 124    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1145   the run_score was: 2.0   and mem length: 214881   eps: 0.7725336400049381    steps: 183    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1146   the run_score was: 5.0   and mem length: 215206   eps: 0.771890140004952    steps: 325    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1147   the run_score was: 2.0   and mem length: 215405   eps: 0.7714961200049606    steps: 199    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1148   the run_score was: 1.0   and mem length: 215575   eps: 0.7711595200049679    steps: 170    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1149   the run_score was: 2.0   and mem length: 215758   eps: 0.7707971800049758    steps: 183    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1150   the run_score was: 2.0   and mem length: 215957   eps: 0.7704031600049843    steps: 199    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1151   the run_score was: 2.0   and mem length: 216176   eps: 0.7699695400049937    steps: 219    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1152   the run_score was: 1.0   and mem length: 216329   eps: 0.7696666000050003    steps: 153    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1153   the run_score was: 4.0   and mem length: 216626   eps: 0.7690785400050131    steps: 297    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1154   the run_score was: 4.0   and mem length: 216919   eps: 0.7684984000050257    steps: 293    lr: 4e-05     eval rl_reward: 2.43\n","For episode: 1155   the run_score was: 1.0   and mem length: 217089   eps: 0.768161800005033    steps: 170    lr: 4e-05     eval rl_reward: 2.4\n","For episode: 1156   the run_score was: 4.0   and mem length: 217367   eps: 0.7676113600050449    steps: 278    lr: 4e-05     eval rl_reward: 2.43\n","For episode: 1157   the run_score was: 2.0   and mem length: 217566   eps: 0.7672173400050535    steps: 199    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1158   the run_score was: 2.0   and mem length: 217764   eps: 0.766825300005062    steps: 198    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1159   the run_score was: 3.0   and mem length: 218010   eps: 0.7663382200050726    steps: 246    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1160   the run_score was: 2.0   and mem length: 218191   eps: 0.7659798400050803    steps: 181    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1161   the run_score was: 3.0   and mem length: 218419   eps: 0.7655284000050901    steps: 228    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1162   the run_score was: 2.0   and mem length: 218617   eps: 0.7651363600050987    steps: 198    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1163   the run_score was: 2.0   and mem length: 218837   eps: 0.7647007600051081    steps: 220    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1164   the run_score was: 2.0   and mem length: 219037   eps: 0.7643047600051167    steps: 200    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1165   the run_score was: 1.0   and mem length: 219207   eps: 0.763968160005124    steps: 170    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1166   the run_score was: 6.0   and mem length: 219546   eps: 0.7632969400051386    steps: 339    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1167   the run_score was: 1.0   and mem length: 219698   eps: 0.7629959800051451    steps: 152    lr: 4e-05     eval rl_reward: 2.45\n","For episode: 1168   the run_score was: 1.0   and mem length: 219867   eps: 0.7626613600051524    steps: 169    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1169   the run_score was: 1.0   and mem length: 220019   eps: 0.7623604000051589    steps: 152    lr: 4e-05     eval rl_reward: 2.43\n","For episode: 1170   the run_score was: 3.0   and mem length: 220265   eps: 0.7618733200051695    steps: 246    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1171   the run_score was: 0.0   and mem length: 220389   eps: 0.7616278000051748    steps: 124    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1172   the run_score was: 2.0   and mem length: 220588   eps: 0.7612337800051834    steps: 199    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1173   the run_score was: 2.0   and mem length: 220787   eps: 0.7608397600051919    steps: 199    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1174   the run_score was: 5.0   and mem length: 221110   eps: 0.7602002200052058    steps: 323    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1175   the run_score was: 3.0   and mem length: 221358   eps: 0.7597091800052165    steps: 248    lr: 4e-05     eval rl_reward: 2.51\n","For episode: 1176   the run_score was: 3.0   and mem length: 221568   eps: 0.7592933800052255    steps: 210    lr: 4e-05     eval rl_reward: 2.54\n","For episode: 1177   the run_score was: 2.0   and mem length: 221766   eps: 0.758901340005234    steps: 198    lr: 4e-05     eval rl_reward: 2.55\n","For episode: 1178   the run_score was: 6.0   and mem length: 222122   eps: 0.7581964600052493    steps: 356    lr: 4e-05     eval rl_reward: 2.58\n","For episode: 1179   the run_score was: 3.0   and mem length: 222369   eps: 0.7577074000052599    steps: 247    lr: 4e-05     eval rl_reward: 2.59\n","For episode: 1180   the run_score was: 1.0   and mem length: 222520   eps: 0.7574084200052664    steps: 151    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1181   the run_score was: 1.0   and mem length: 222672   eps: 0.757107460005273    steps: 152    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1182   the run_score was: 4.0   and mem length: 222985   eps: 0.7564877200052864    steps: 313    lr: 4e-05     eval rl_reward: 2.61\n","For episode: 1183   the run_score was: 1.0   and mem length: 223137   eps: 0.756186760005293    steps: 152    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1184   the run_score was: 1.0   and mem length: 223288   eps: 0.7558877800052994    steps: 151    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1185   the run_score was: 1.0   and mem length: 223440   eps: 0.755586820005306    steps: 152    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1186   the run_score was: 4.0   and mem length: 223734   eps: 0.7550047000053186    steps: 294    lr: 4e-05     eval rl_reward: 2.58\n","For episode: 1187   the run_score was: 4.0   and mem length: 224014   eps: 0.7544503000053306    steps: 280    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1188   the run_score was: 6.0   and mem length: 224371   eps: 0.753743440005346    steps: 357    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1189   the run_score was: 1.0   and mem length: 224541   eps: 0.7534068400053533    steps: 170    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1190   the run_score was: 3.0   and mem length: 224789   eps: 0.752915800005364    steps: 248    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1191   the run_score was: 4.0   and mem length: 225056   eps: 0.7523871400053754    steps: 267    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1192   the run_score was: 1.0   and mem length: 225208   eps: 0.752086180005382    steps: 152    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1193   the run_score was: 3.0   and mem length: 225419   eps: 0.751668400005391    steps: 211    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1194   the run_score was: 7.0   and mem length: 225843   eps: 0.7508288800054093    steps: 424    lr: 4e-05     eval rl_reward: 2.66\n","For episode: 1195   the run_score was: 4.0   and mem length: 226119   eps: 0.7502824000054211    steps: 276    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1196   the run_score was: 5.0   and mem length: 226427   eps: 0.7496725600054344    steps: 308    lr: 4e-05     eval rl_reward: 2.71\n","For episode: 1197   the run_score was: 5.0   and mem length: 226770   eps: 0.7489934200054491    steps: 343    lr: 4e-05     eval rl_reward: 2.73\n","For episode: 1198   the run_score was: 6.0   and mem length: 227148   eps: 0.7482449800054654    steps: 378    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1199   the run_score was: 2.0   and mem length: 227346   eps: 0.7478529400054739    steps: 198    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1200   the run_score was: 4.0   and mem length: 227621   eps: 0.7473084400054857    steps: 275    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1201   the run_score was: 5.0   and mem length: 227936   eps: 0.7466847400054992    steps: 315    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1202   the run_score was: 1.0   and mem length: 228106   eps: 0.7463481400055065    steps: 170    lr: 4e-05     eval rl_reward: 2.72\n","For episode: 1203   the run_score was: 1.0   and mem length: 228277   eps: 0.7460095600055139    steps: 171    lr: 4e-05     eval rl_reward: 2.72\n","For episode: 1204   the run_score was: 3.0   and mem length: 228503   eps: 0.7455620800055236    steps: 226    lr: 4e-05     eval rl_reward: 2.73\n","For episode: 1205   the run_score was: 6.0   and mem length: 228870   eps: 0.7448354200055394    steps: 367    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1206   the run_score was: 3.0   and mem length: 229116   eps: 0.74434834000555    steps: 246    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1207   the run_score was: 2.0   and mem length: 229315   eps: 0.7439543200055585    steps: 199    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1208   the run_score was: 3.0   and mem length: 229561   eps: 0.7434672400055691    steps: 246    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1209   the run_score was: 2.0   and mem length: 229742   eps: 0.7431088600055769    steps: 181    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1210   the run_score was: 4.0   and mem length: 229983   eps: 0.7426316800055872    steps: 241    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1211   the run_score was: 2.0   and mem length: 230187   eps: 0.742227760005596    steps: 204    lr: 4e-05     eval rl_reward: 2.66\n","For episode: 1212   the run_score was: 5.0   and mem length: 230517   eps: 0.7415743600056102    steps: 330    lr: 4e-05     eval rl_reward: 2.67\n","For episode: 1213   the run_score was: 2.0   and mem length: 230716   eps: 0.7411803400056187    steps: 199    lr: 4e-05     eval rl_reward: 2.66\n","For episode: 1214   the run_score was: 2.0   and mem length: 230935   eps: 0.7407467200056281    steps: 219    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1215   the run_score was: 6.0   and mem length: 231302   eps: 0.7400200600056439    steps: 367    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1216   the run_score was: 2.0   and mem length: 231501   eps: 0.7396260400056525    steps: 199    lr: 4e-05     eval rl_reward: 2.67\n","For episode: 1217   the run_score was: 6.0   and mem length: 231874   eps: 0.7388875000056685    steps: 373    lr: 4e-05     eval rl_reward: 2.7\n","For episode: 1218   the run_score was: 2.0   and mem length: 232073   eps: 0.738493480005677    steps: 199    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1219   the run_score was: 5.0   and mem length: 232399   eps: 0.7378480000056911    steps: 326    lr: 4e-05     eval rl_reward: 2.72\n","For episode: 1220   the run_score was: 5.0   and mem length: 232720   eps: 0.7372124200057049    steps: 321    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1221   the run_score was: 4.0   and mem length: 232997   eps: 0.7366639600057168    steps: 277    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1222   the run_score was: 2.0   and mem length: 233198   eps: 0.7362659800057254    steps: 201    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1223   the run_score was: 3.0   and mem length: 233446   eps: 0.7357749400057361    steps: 248    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1224   the run_score was: 3.0   and mem length: 233691   eps: 0.7352898400057466    steps: 245    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1225   the run_score was: 4.0   and mem length: 233967   eps: 0.7347433600057585    steps: 276    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1226   the run_score was: 2.0   and mem length: 234147   eps: 0.7343869600057662    steps: 180    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1227   the run_score was: 2.0   and mem length: 234367   eps: 0.7339513600057757    steps: 220    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1228   the run_score was: 1.0   and mem length: 234540   eps: 0.7336088200057831    steps: 173    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1229   the run_score was: 3.0   and mem length: 234767   eps: 0.7331593600057928    steps: 227    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1230   the run_score was: 7.0   and mem length: 235182   eps: 0.7323376600058107    steps: 415    lr: 4e-05     eval rl_reward: 2.85\n","For episode: 1231   the run_score was: 1.0   and mem length: 235334   eps: 0.7320367000058172    steps: 152    lr: 4e-05     eval rl_reward: 2.86\n","For episode: 1232   the run_score was: 4.0   and mem length: 235592   eps: 0.7315258600058283    steps: 258    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1233   the run_score was: 3.0   and mem length: 235859   eps: 0.7309972000058398    steps: 267    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1234   the run_score was: 2.0   and mem length: 236060   eps: 0.7305992200058484    steps: 201    lr: 4e-05     eval rl_reward: 2.89\n","For episode: 1235   the run_score was: 5.0   and mem length: 236368   eps: 0.7299893800058617    steps: 308    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1236   the run_score was: 3.0   and mem length: 236597   eps: 0.7295359600058715    steps: 229    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1237   the run_score was: 6.0   and mem length: 236996   eps: 0.7287459400058887    steps: 399    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1238   the run_score was: 0.0   and mem length: 237120   eps: 0.728500420005894    steps: 124    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1239   the run_score was: 2.0   and mem length: 237319   eps: 0.7281064000059025    steps: 199    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1240   the run_score was: 3.0   and mem length: 237588   eps: 0.7275737800059141    steps: 269    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1241   the run_score was: 5.0   and mem length: 237891   eps: 0.7269738400059271    steps: 303    lr: 4e-05     eval rl_reward: 2.92\n","For episode: 1242   the run_score was: 3.0   and mem length: 238138   eps: 0.7264847800059377    steps: 247    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1243   the run_score was: 4.0   and mem length: 238434   eps: 0.7258987000059505    steps: 296    lr: 4e-05     eval rl_reward: 2.94\n","For episode: 1244   the run_score was: 6.0   and mem length: 238790   eps: 0.7251938200059658    steps: 356    lr: 4e-05     eval rl_reward: 3.0\n","For episode: 1245   the run_score was: 3.0   and mem length: 239037   eps: 0.7247047600059764    steps: 247    lr: 4e-05     eval rl_reward: 3.01\n","For episode: 1246   the run_score was: 2.0   and mem length: 239261   eps: 0.724261240005986    steps: 224    lr: 4e-05     eval rl_reward: 2.98\n","For episode: 1247   the run_score was: 5.0   and mem length: 239585   eps: 0.723619720006    steps: 324    lr: 4e-05     eval rl_reward: 3.01\n","For episode: 1248   the run_score was: 7.0   and mem length: 239960   eps: 0.7228772200060161    steps: 375    lr: 4e-05     eval rl_reward: 3.07\n","For episode: 1249   the run_score was: 0.0   and mem length: 240084   eps: 0.7226317000060214    steps: 124    lr: 4e-05     eval rl_reward: 3.05\n","For episode: 1250   the run_score was: 3.0   and mem length: 240311   eps: 0.7221822400060312    steps: 227    lr: 4e-05     eval rl_reward: 3.06\n","For episode: 1251   the run_score was: 3.0   and mem length: 240540   eps: 0.721728820006041    steps: 229    lr: 4e-05     eval rl_reward: 3.07\n","For episode: 1252   the run_score was: 3.0   and mem length: 240769   eps: 0.7212754000060508    steps: 229    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1253   the run_score was: 3.0   and mem length: 241017   eps: 0.7207843600060615    steps: 248    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1254   the run_score was: 1.0   and mem length: 241187   eps: 0.7204477600060688    steps: 170    lr: 4e-05     eval rl_reward: 3.05\n","For episode: 1255   the run_score was: 5.0   and mem length: 241491   eps: 0.7198458400060819    steps: 304    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1256   the run_score was: 3.0   and mem length: 241718   eps: 0.7193963800060916    steps: 227    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1257   the run_score was: 2.0   and mem length: 241916   eps: 0.7190043400061001    steps: 198    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1258   the run_score was: 3.0   and mem length: 242144   eps: 0.7185529000061099    steps: 228    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1259   the run_score was: 2.0   and mem length: 242344   eps: 0.7181569000061185    steps: 200    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1260   the run_score was: 2.0   and mem length: 242543   eps: 0.7177628800061271    steps: 199    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1261   the run_score was: 3.0   and mem length: 242810   eps: 0.7172342200061386    steps: 267    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1262   the run_score was: 5.0   and mem length: 243117   eps: 0.7166263600061518    steps: 307    lr: 4e-05     eval rl_reward: 3.11\n","For episode: 1263   the run_score was: 2.0   and mem length: 243300   eps: 0.7162640200061596    steps: 183    lr: 4e-05     eval rl_reward: 3.11\n","For episode: 1264   the run_score was: 3.0   and mem length: 243513   eps: 0.7158422800061688    steps: 213    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1265   the run_score was: 5.0   and mem length: 243828   eps: 0.7152185800061823    steps: 315    lr: 4e-05     eval rl_reward: 3.16\n","For episode: 1266   the run_score was: 1.0   and mem length: 244001   eps: 0.7148760400061898    steps: 173    lr: 4e-05     eval rl_reward: 3.11\n","For episode: 1267   the run_score was: 5.0   and mem length: 244292   eps: 0.7142998600062023    steps: 291    lr: 4e-05     eval rl_reward: 3.15\n","For episode: 1268   the run_score was: 3.0   and mem length: 244522   eps: 0.7138444600062122    steps: 230    lr: 4e-05     eval rl_reward: 3.17\n","For episode: 1269   the run_score was: 3.0   and mem length: 244769   eps: 0.7133554000062228    steps: 247    lr: 4e-05     eval rl_reward: 3.19\n","For episode: 1270   the run_score was: 3.0   and mem length: 244997   eps: 0.7129039600062326    steps: 228    lr: 4e-05     eval rl_reward: 3.19\n","For episode: 1271   the run_score was: 8.0   and mem length: 245422   eps: 0.7120624600062508    steps: 425    lr: 4e-05     eval rl_reward: 3.27\n","For episode: 1272   the run_score was: 4.0   and mem length: 245698   eps: 0.7115159800062627    steps: 276    lr: 4e-05     eval rl_reward: 3.29\n","For episode: 1273   the run_score was: 5.0   and mem length: 246033   eps: 0.7108526800062771    steps: 335    lr: 4e-05     eval rl_reward: 3.32\n","For episode: 1274   the run_score was: 2.0   and mem length: 246232   eps: 0.7104586600062857    steps: 199    lr: 4e-05     eval rl_reward: 3.29\n","For episode: 1275   the run_score was: 2.0   and mem length: 246453   eps: 0.7100210800062952    steps: 221    lr: 4e-05     eval rl_reward: 3.28\n","For episode: 1276   the run_score was: 1.0   and mem length: 246605   eps: 0.7097201200063017    steps: 152    lr: 4e-05     eval rl_reward: 3.26\n","For episode: 1277   the run_score was: 5.0   and mem length: 246949   eps: 0.7090390000063165    steps: 344    lr: 4e-05     eval rl_reward: 3.29\n","For episode: 1278   the run_score was: 5.0   and mem length: 247237   eps: 0.7084687600063289    steps: 288    lr: 4e-05     eval rl_reward: 3.28\n","For episode: 1279   the run_score was: 3.0   and mem length: 247448   eps: 0.7080509800063379    steps: 211    lr: 4e-05     eval rl_reward: 3.28\n","For episode: 1280   the run_score was: 4.0   and mem length: 247726   eps: 0.7075005400063499    steps: 278    lr: 4e-05     eval rl_reward: 3.31\n","For episode: 1281   the run_score was: 2.0   and mem length: 247926   eps: 0.7071045400063585    steps: 200    lr: 4e-05     eval rl_reward: 3.32\n","For episode: 1282   the run_score was: 2.0   and mem length: 248125   eps: 0.706710520006367    steps: 199    lr: 4e-05     eval rl_reward: 3.3\n","For episode: 1283   the run_score was: 6.0   and mem length: 248508   eps: 0.7059521800063835    steps: 383    lr: 4e-05     eval rl_reward: 3.35\n","For episode: 1284   the run_score was: 3.0   and mem length: 248717   eps: 0.7055383600063925    steps: 209    lr: 4e-05     eval rl_reward: 3.37\n","For episode: 1285   the run_score was: 5.0   and mem length: 249024   eps: 0.7049305000064057    steps: 307    lr: 4e-05     eval rl_reward: 3.41\n","For episode: 1286   the run_score was: 6.0   and mem length: 249388   eps: 0.7042097800064213    steps: 364    lr: 4e-05     eval rl_reward: 3.43\n","For episode: 1287   the run_score was: 7.0   and mem length: 249748   eps: 0.7034969800064368    steps: 360    lr: 4e-05     eval rl_reward: 3.46\n","For episode: 1288   the run_score was: 7.0   and mem length: 250136   eps: 0.7027287400064535    steps: 388    lr: 4e-05     eval rl_reward: 3.47\n","For episode: 1289   the run_score was: 3.0   and mem length: 250382   eps: 0.702241660006464    steps: 246    lr: 4e-05     eval rl_reward: 3.49\n","For episode: 1290   the run_score was: 3.0   and mem length: 250611   eps: 0.7017882400064739    steps: 229    lr: 4e-05     eval rl_reward: 3.49\n","For episode: 1291   the run_score was: 3.0   and mem length: 250882   eps: 0.7012516600064855    steps: 271    lr: 4e-05     eval rl_reward: 3.48\n","For episode: 1292   the run_score was: 1.0   and mem length: 251052   eps: 0.7009150600064928    steps: 170    lr: 4e-05     eval rl_reward: 3.48\n","For episode: 1293   the run_score was: 5.0   and mem length: 251378   eps: 0.7002695800065069    steps: 326    lr: 4e-05     eval rl_reward: 3.5\n","For episode: 1294   the run_score was: 5.0   and mem length: 251718   eps: 0.6995963800065215    steps: 340    lr: 4e-05     eval rl_reward: 3.48\n","For episode: 1295   the run_score was: 3.0   and mem length: 251948   eps: 0.6991409800065314    steps: 230    lr: 4e-05     eval rl_reward: 3.47\n","For episode: 1296   the run_score was: 3.0   and mem length: 252197   eps: 0.6986479600065421    steps: 249    lr: 4e-05     eval rl_reward: 3.45\n","For episode: 1297   the run_score was: 2.0   and mem length: 252398   eps: 0.6982499800065507    steps: 201    lr: 4e-05     eval rl_reward: 3.42\n","For episode: 1298   the run_score was: 4.0   and mem length: 252694   eps: 0.6976639000065634    steps: 296    lr: 4e-05     eval rl_reward: 3.4\n","For episode: 1299   the run_score was: 2.0   and mem length: 252895   eps: 0.6972659200065721    steps: 201    lr: 4e-05     eval rl_reward: 3.4\n","For episode: 1300   the run_score was: 5.0   and mem length: 253238   eps: 0.6965867800065868    steps: 343    lr: 4e-05     eval rl_reward: 3.41\n","For episode: 1301   the run_score was: 2.0   and mem length: 253460   eps: 0.6961472200065963    steps: 222    lr: 4e-05     eval rl_reward: 3.38\n","For episode: 1302   the run_score was: 4.0   and mem length: 253756   eps: 0.6955611400066091    steps: 296    lr: 4e-05     eval rl_reward: 3.41\n","For episode: 1303   the run_score was: 4.0   and mem length: 254029   eps: 0.6950206000066208    steps: 273    lr: 4e-05     eval rl_reward: 3.44\n","For episode: 1304   the run_score was: 4.0   and mem length: 254323   eps: 0.6944384800066334    steps: 294    lr: 4e-05     eval rl_reward: 3.45\n","For episode: 1305   the run_score was: 3.0   and mem length: 254572   eps: 0.6939454600066441    steps: 249    lr: 4e-05     eval rl_reward: 3.42\n","For episode: 1306   the run_score was: 4.0   and mem length: 254867   eps: 0.6933613600066568    steps: 295    lr: 4e-05     eval rl_reward: 3.43\n","For episode: 1307   the run_score was: 5.0   and mem length: 255164   eps: 0.6927733000066696    steps: 297    lr: 4e-05     eval rl_reward: 3.46\n","For episode: 1308   the run_score was: 6.0   and mem length: 255500   eps: 0.692108020006684    steps: 336    lr: 4e-05     eval rl_reward: 3.49\n","For episode: 1309   the run_score was: 4.0   and mem length: 255816   eps: 0.6914823400066976    steps: 316    lr: 4e-05     eval rl_reward: 3.51\n","For episode: 1310   the run_score was: 11.0   and mem length: 256270   eps: 0.6905834200067171    steps: 454    lr: 4e-05     eval rl_reward: 3.58\n","For episode: 1311   the run_score was: 3.0   and mem length: 256497   eps: 0.6901339600067269    steps: 227    lr: 4e-05     eval rl_reward: 3.59\n","For episode: 1312   the run_score was: 9.0   and mem length: 256844   eps: 0.6894469000067418    steps: 347    lr: 4e-05     eval rl_reward: 3.63\n","For episode: 1313   the run_score was: 6.0   and mem length: 257225   eps: 0.6886925200067582    steps: 381    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1314   the run_score was: 5.0   and mem length: 257532   eps: 0.6880846600067714    steps: 307    lr: 4e-05     eval rl_reward: 3.7\n","For episode: 1315   the run_score was: 3.0   and mem length: 257746   eps: 0.6876609400067806    steps: 214    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1316   the run_score was: 7.0   and mem length: 258126   eps: 0.6869085400067969    steps: 380    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1317   the run_score was: 6.0   and mem length: 258503   eps: 0.6861620800068131    steps: 377    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1318   the run_score was: 2.0   and mem length: 258701   eps: 0.6857700400068216    steps: 198    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1319   the run_score was: 5.0   and mem length: 259027   eps: 0.6851245600068356    steps: 326    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1320   the run_score was: 1.0   and mem length: 259180   eps: 0.6848216200068422    steps: 153    lr: 4e-05     eval rl_reward: 3.68\n","For episode: 1321   the run_score was: 3.0   and mem length: 259431   eps: 0.684324640006853    steps: 251    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1322   the run_score was: 5.0   and mem length: 259757   eps: 0.683679160006867    steps: 326    lr: 4e-05     eval rl_reward: 3.7\n","For episode: 1323   the run_score was: 5.0   and mem length: 260063   eps: 0.6830732800068802    steps: 306    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1324   the run_score was: 2.0   and mem length: 260244   eps: 0.682714900006888    steps: 181    lr: 4e-05     eval rl_reward: 3.71\n","For episode: 1325   the run_score was: 7.0   and mem length: 260676   eps: 0.6818595400069065    steps: 432    lr: 4e-05     eval rl_reward: 3.74\n","For episode: 1326   the run_score was: 3.0   and mem length: 260924   eps: 0.6813685000069172    steps: 248    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1327   the run_score was: 4.0   and mem length: 261200   eps: 0.680822020006929    steps: 276    lr: 4e-05     eval rl_reward: 3.77\n","For episode: 1328   the run_score was: 2.0   and mem length: 261401   eps: 0.6804240400069377    steps: 201    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1329   the run_score was: 3.0   and mem length: 261631   eps: 0.6799686400069476    steps: 230    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1330   the run_score was: 4.0   and mem length: 261888   eps: 0.6794597800069586    steps: 257    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1331   the run_score was: 4.0   and mem length: 262130   eps: 0.678980620006969    steps: 242    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1332   the run_score was: 1.0   and mem length: 262282   eps: 0.6786796600069755    steps: 152    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1333   the run_score was: 2.0   and mem length: 262481   eps: 0.6782856400069841    steps: 199    lr: 4e-05     eval rl_reward: 3.74\n","For episode: 1334   the run_score was: 4.0   and mem length: 262761   eps: 0.6777312400069961    steps: 280    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1335   the run_score was: 2.0   and mem length: 262960   eps: 0.6773372200070047    steps: 199    lr: 4e-05     eval rl_reward: 3.73\n","For episode: 1336   the run_score was: 3.0   and mem length: 263208   eps: 0.6768461800070154    steps: 248    lr: 4e-05     eval rl_reward: 3.73\n","For episode: 1337   the run_score was: 4.0   and mem length: 263484   eps: 0.6762997000070272    steps: 276    lr: 4e-05     eval rl_reward: 3.71\n","For episode: 1338   the run_score was: 3.0   and mem length: 263711   eps: 0.675850240007037    steps: 227    lr: 4e-05     eval rl_reward: 3.74\n","For episode: 1339   the run_score was: 1.0   and mem length: 263882   eps: 0.6755116600070443    steps: 171    lr: 4e-05     eval rl_reward: 3.73\n","For episode: 1340   the run_score was: 5.0   and mem length: 264210   eps: 0.6748622200070584    steps: 328    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1341   the run_score was: 5.0   and mem length: 264552   eps: 0.6741850600070731    steps: 342    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1342   the run_score was: 4.0   and mem length: 264849   eps: 0.6735970000070859    steps: 297    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1343   the run_score was: 0.0   and mem length: 264973   eps: 0.6733514800070912    steps: 124    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1344   the run_score was: 3.0   and mem length: 265200   eps: 0.672902020007101    steps: 227    lr: 4e-05     eval rl_reward: 3.69\n","For episode: 1345   the run_score was: 4.0   and mem length: 265478   eps: 0.6723515800071129    steps: 278    lr: 4e-05     eval rl_reward: 3.7\n","For episode: 1346   the run_score was: 1.0   and mem length: 265630   eps: 0.6720506200071195    steps: 152    lr: 4e-05     eval rl_reward: 3.69\n","For episode: 1347   the run_score was: 4.0   and mem length: 265908   eps: 0.6715001800071314    steps: 278    lr: 4e-05     eval rl_reward: 3.68\n","For episode: 1348   the run_score was: 0.0   and mem length: 266032   eps: 0.6712546600071367    steps: 124    lr: 4e-05     eval rl_reward: 3.61\n","For episode: 1349   the run_score was: 3.0   and mem length: 266244   eps: 0.6708349000071459    steps: 212    lr: 4e-05     eval rl_reward: 3.64\n","For episode: 1350   the run_score was: 4.0   and mem length: 266489   eps: 0.6703498000071564    steps: 245    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1351   the run_score was: 5.0   and mem length: 266833   eps: 0.6696686800071712    steps: 344    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1352   the run_score was: 7.0   and mem length: 267222   eps: 0.6688984600071879    steps: 389    lr: 4e-05     eval rl_reward: 3.71\n","For episode: 1353   the run_score was: 5.0   and mem length: 267537   eps: 0.6682747600072014    steps: 315    lr: 4e-05     eval rl_reward: 3.73\n","For episode: 1354   the run_score was: 3.0   and mem length: 267764   eps: 0.6678253000072112    steps: 227    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1355   the run_score was: 3.0   and mem length: 268013   eps: 0.6673322800072219    steps: 249    lr: 4e-05     eval rl_reward: 3.73\n","For episode: 1356   the run_score was: 4.0   and mem length: 268273   eps: 0.6668174800072331    steps: 260    lr: 4e-05     eval rl_reward: 3.74\n","For episode: 1357   the run_score was: 3.0   and mem length: 268518   eps: 0.6663323800072436    steps: 245    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1358   the run_score was: 4.0   and mem length: 268818   eps: 0.6657383800072565    steps: 300    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1359   the run_score was: 4.0   and mem length: 269096   eps: 0.6651879400072684    steps: 278    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1360   the run_score was: 2.0   and mem length: 269295   eps: 0.664793920007277    steps: 199    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1361   the run_score was: 8.0   and mem length: 269713   eps: 0.663966280007295    steps: 418    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1362   the run_score was: 3.0   and mem length: 269942   eps: 0.6635128600073048    steps: 229    lr: 4e-05     eval rl_reward: 3.81\n","For episode: 1363   the run_score was: 5.0   and mem length: 270284   eps: 0.6628357000073195    steps: 342    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1364   the run_score was: 5.0   and mem length: 270629   eps: 0.6621526000073343    steps: 345    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1365   the run_score was: 5.0   and mem length: 270955   eps: 0.6615071200073483    steps: 326    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1366   the run_score was: 5.0   and mem length: 271259   eps: 0.6609052000073614    steps: 304    lr: 4e-05     eval rl_reward: 3.9\n","For episode: 1367   the run_score was: 0.0   and mem length: 271383   eps: 0.6606596800073667    steps: 124    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1368   the run_score was: 2.0   and mem length: 271582   eps: 0.6602656600073753    steps: 199    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1369   the run_score was: 2.0   and mem length: 271801   eps: 0.6598320400073847    steps: 219    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1370   the run_score was: 5.0   and mem length: 272148   eps: 0.6591449800073996    steps: 347    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1371   the run_score was: 0.0   and mem length: 272272   eps: 0.658899460007405    steps: 124    lr: 4e-05     eval rl_reward: 3.77\n","For episode: 1372   the run_score was: 5.0   and mem length: 272583   eps: 0.6582836800074183    steps: 311    lr: 4e-05     eval rl_reward: 3.78\n","For episode: 1373   the run_score was: 4.0   and mem length: 272859   eps: 0.6577372000074302    steps: 276    lr: 4e-05     eval rl_reward: 3.77\n","For episode: 1374   the run_score was: 4.0   and mem length: 273136   eps: 0.6571887400074421    steps: 277    lr: 4e-05     eval rl_reward: 3.79\n","For episode: 1375   the run_score was: 9.0   and mem length: 273675   eps: 0.6561215200074653    steps: 539    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1376   the run_score was: 3.0   and mem length: 273902   eps: 0.655672060007475    steps: 227    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1377   the run_score was: 4.0   and mem length: 274219   eps: 0.6550444000074886    steps: 317    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1378   the run_score was: 4.0   and mem length: 274492   eps: 0.6545038600075004    steps: 273    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1379   the run_score was: 5.0   and mem length: 274818   eps: 0.6538583800075144    steps: 326    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1380   the run_score was: 5.0   and mem length: 275120   eps: 0.6532604200075274    steps: 302    lr: 4e-05     eval rl_reward: 3.89\n","For episode: 1381   the run_score was: 3.0   and mem length: 275366   eps: 0.652773340007538    steps: 246    lr: 4e-05     eval rl_reward: 3.9\n","For episode: 1382   the run_score was: 1.0   and mem length: 275518   eps: 0.6524723800075445    steps: 152    lr: 4e-05     eval rl_reward: 3.89\n","For episode: 1383   the run_score was: 4.0   and mem length: 275795   eps: 0.6519239200075564    steps: 277    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1384   the run_score was: 3.0   and mem length: 276024   eps: 0.6514705000075662    steps: 229    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1385   the run_score was: 5.0   and mem length: 276370   eps: 0.6507854200075811    steps: 346    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1386   the run_score was: 4.0   and mem length: 276626   eps: 0.6502785400075921    steps: 256    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1387   the run_score was: 3.0   and mem length: 276838   eps: 0.6498587800076012    steps: 212    lr: 4e-05     eval rl_reward: 3.81\n","For episode: 1388   the run_score was: 6.0   and mem length: 277234   eps: 0.6490747000076182    steps: 396    lr: 4e-05     eval rl_reward: 3.8\n","For episode: 1389   the run_score was: 2.0   and mem length: 277432   eps: 0.6486826600076268    steps: 198    lr: 4e-05     eval rl_reward: 3.79\n","For episode: 1390   the run_score was: 5.0   and mem length: 277758   eps: 0.6480371800076408    steps: 326    lr: 4e-05     eval rl_reward: 3.81\n","For episode: 1391   the run_score was: 5.0   and mem length: 278087   eps: 0.6473857600076549    steps: 329    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1392   the run_score was: 3.0   and mem length: 278314   eps: 0.6469363000076647    steps: 227    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1393   the run_score was: 4.0   and mem length: 278572   eps: 0.6464254600076758    steps: 258    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1394   the run_score was: 4.0   and mem length: 278832   eps: 0.6459106600076869    steps: 260    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1395   the run_score was: 3.0   and mem length: 279077   eps: 0.6454255600076975    steps: 245    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1396   the run_score was: 3.0   and mem length: 279303   eps: 0.6449780800077072    steps: 226    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1397   the run_score was: 2.0   and mem length: 279483   eps: 0.6446216800077149    steps: 180    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1398   the run_score was: 5.0   and mem length: 279807   eps: 0.6439801600077288    steps: 324    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1399   the run_score was: 6.0   and mem length: 280203   eps: 0.6431960800077459    steps: 396    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1400   the run_score was: 3.0   and mem length: 280430   eps: 0.6427466200077556    steps: 227    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1401   the run_score was: 1.0   and mem length: 280581   eps: 0.6424476400077621    steps: 151    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1402   the run_score was: 5.0   and mem length: 280888   eps: 0.6418397800077753    steps: 307    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1403   the run_score was: 3.0   and mem length: 281114   eps: 0.641392300007785    steps: 226    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1404   the run_score was: 3.0   and mem length: 281364   eps: 0.6408973000077958    steps: 250    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1405   the run_score was: 3.0   and mem length: 281575   eps: 0.6404795200078048    steps: 211    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1406   the run_score was: 5.0   and mem length: 281916   eps: 0.6398043400078195    steps: 341    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1407   the run_score was: 5.0   and mem length: 282239   eps: 0.6391648000078334    steps: 323    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1408   the run_score was: 3.0   and mem length: 282465   eps: 0.6387173200078431    steps: 226    lr: 4e-05     eval rl_reward: 3.82\n","For episode: 1409   the run_score was: 3.0   and mem length: 282692   eps: 0.6382678600078528    steps: 227    lr: 4e-05     eval rl_reward: 3.81\n","For episode: 1410   the run_score was: 5.0   and mem length: 283039   eps: 0.6375808000078678    steps: 347    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1411   the run_score was: 4.0   and mem length: 283300   eps: 0.637064020007879    steps: 261    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1412   the run_score was: 2.0   and mem length: 283499   eps: 0.6366700000078875    steps: 199    lr: 4e-05     eval rl_reward: 3.69\n","For episode: 1413   the run_score was: 2.0   and mem length: 283718   eps: 0.636236380007897    steps: 219    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1414   the run_score was: 6.0   and mem length: 284075   eps: 0.6355295200079123    steps: 357    lr: 4e-05     eval rl_reward: 3.66\n","For episode: 1415   the run_score was: 4.0   and mem length: 284343   eps: 0.6349988800079238    steps: 268    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1416   the run_score was: 7.0   and mem length: 284729   eps: 0.6342346000079404    steps: 386    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1417   the run_score was: 4.0   and mem length: 284970   eps: 0.6337574200079508    steps: 241    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1418   the run_score was: 4.0   and mem length: 285245   eps: 0.6332129200079626    steps: 275    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1419   the run_score was: 3.0   and mem length: 285456   eps: 0.6327951400079717    steps: 211    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1420   the run_score was: 2.0   and mem length: 285639   eps: 0.6324328000079795    steps: 183    lr: 4e-05     eval rl_reward: 3.66\n","For episode: 1421   the run_score was: 2.0   and mem length: 285839   eps: 0.6320368000079881    steps: 200    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1422   the run_score was: 3.0   and mem length: 286085   eps: 0.6315497200079987    steps: 246    lr: 4e-05     eval rl_reward: 3.63\n","For episode: 1423   the run_score was: 3.0   and mem length: 286317   eps: 0.6310903600080087    steps: 232    lr: 4e-05     eval rl_reward: 3.61\n","For episode: 1424   the run_score was: 3.0   and mem length: 286531   eps: 0.6306666400080179    steps: 214    lr: 4e-05     eval rl_reward: 3.62\n","For episode: 1425   the run_score was: 2.0   and mem length: 286714   eps: 0.6303043000080257    steps: 183    lr: 4e-05     eval rl_reward: 3.57\n","For episode: 1426   the run_score was: 3.0   and mem length: 286941   eps: 0.6298548400080355    steps: 227    lr: 4e-05     eval rl_reward: 3.57\n","For episode: 1427   the run_score was: 2.0   and mem length: 287124   eps: 0.6294925000080434    steps: 183    lr: 4e-05     eval rl_reward: 3.55\n","For episode: 1428   the run_score was: 6.0   and mem length: 287461   eps: 0.6288252400080578    steps: 337    lr: 4e-05     eval rl_reward: 3.59\n","For episode: 1429   the run_score was: 2.0   and mem length: 287663   eps: 0.6284252800080665    steps: 202    lr: 4e-05     eval rl_reward: 3.58\n","For episode: 1430   the run_score was: 3.0   and mem length: 287893   eps: 0.6279698800080764    steps: 230    lr: 4e-05     eval rl_reward: 3.57\n","For episode: 1431   the run_score was: 4.0   and mem length: 288169   eps: 0.6274234000080883    steps: 276    lr: 4e-05     eval rl_reward: 3.57\n","For episode: 1432   the run_score was: 3.0   and mem length: 288397   eps: 0.6269719600080981    steps: 228    lr: 4e-05     eval rl_reward: 3.59\n","For episode: 1433   the run_score was: 5.0   and mem length: 288705   eps: 0.6263621200081113    steps: 308    lr: 4e-05     eval rl_reward: 3.62\n","For episode: 1434   the run_score was: 4.0   and mem length: 288983   eps: 0.6258116800081233    steps: 278    lr: 4e-05     eval rl_reward: 3.62\n","For episode: 1435   the run_score was: 3.0   and mem length: 289215   eps: 0.6253523200081332    steps: 232    lr: 4e-05     eval rl_reward: 3.63\n","For episode: 1436   the run_score was: 4.0   and mem length: 289492   eps: 0.6248038600081451    steps: 277    lr: 4e-05     eval rl_reward: 3.64\n","For episode: 1437   the run_score was: 2.0   and mem length: 289674   eps: 0.624443500008153    steps: 182    lr: 4e-05     eval rl_reward: 3.62\n","For episode: 1438   the run_score was: 5.0   and mem length: 289944   eps: 0.6239089000081646    steps: 270    lr: 4e-05     eval rl_reward: 3.64\n","For episode: 1439   the run_score was: 7.0   and mem length: 290349   eps: 0.623107000008182    steps: 405    lr: 4e-05     eval rl_reward: 3.7\n","For episode: 1440   the run_score was: 4.0   and mem length: 290623   eps: 0.6225644800081938    steps: 274    lr: 4e-05     eval rl_reward: 3.69\n","For episode: 1441   the run_score was: 1.0   and mem length: 290795   eps: 0.6222239200082011    steps: 172    lr: 4e-05     eval rl_reward: 3.65\n","For episode: 1442   the run_score was: 6.0   and mem length: 291138   eps: 0.6215447800082159    steps: 343    lr: 4e-05     eval rl_reward: 3.67\n","For episode: 1443   the run_score was: 4.0   and mem length: 291416   eps: 0.6209943400082278    steps: 278    lr: 4e-05     eval rl_reward: 3.71\n","For episode: 1444   the run_score was: 4.0   and mem length: 291713   eps: 0.6204062800082406    steps: 297    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1445   the run_score was: 4.0   and mem length: 291970   eps: 0.6198974200082517    steps: 257    lr: 4e-05     eval rl_reward: 3.72\n","For episode: 1446   the run_score was: 4.0   and mem length: 292246   eps: 0.6193509400082635    steps: 276    lr: 4e-05     eval rl_reward: 3.75\n","For episode: 1447   the run_score was: 5.0   and mem length: 292552   eps: 0.6187450600082767    steps: 306    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1448   the run_score was: 4.0   and mem length: 292828   eps: 0.6181985800082885    steps: 276    lr: 4e-05     eval rl_reward: 3.8\n","For episode: 1449   the run_score was: 4.0   and mem length: 293106   eps: 0.6176481400083005    steps: 278    lr: 4e-05     eval rl_reward: 3.81\n","For episode: 1450   the run_score was: 3.0   and mem length: 293335   eps: 0.6171947200083103    steps: 229    lr: 4e-05     eval rl_reward: 3.8\n","For episode: 1451   the run_score was: 4.0   and mem length: 293591   eps: 0.6166878400083213    steps: 256    lr: 4e-05     eval rl_reward: 3.79\n","For episode: 1452   the run_score was: 4.0   and mem length: 293854   eps: 0.6161671000083326    steps: 263    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1453   the run_score was: 5.0   and mem length: 294180   eps: 0.6155216200083466    steps: 326    lr: 4e-05     eval rl_reward: 3.76\n","For episode: 1454   the run_score was: 10.0   and mem length: 294626   eps: 0.6146385400083658    steps: 446    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1455   the run_score was: 3.0   and mem length: 294858   eps: 0.6141791800083758    steps: 232    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1456   the run_score was: 6.0   and mem length: 295216   eps: 0.6134703400083912    steps: 358    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1457   the run_score was: 6.0   and mem length: 295555   eps: 0.6127991200084058    steps: 339    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1458   the run_score was: 1.0   and mem length: 295707   eps: 0.6124981600084123    steps: 152    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1459   the run_score was: 6.0   and mem length: 296060   eps: 0.6117992200084275    steps: 353    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1460   the run_score was: 2.0   and mem length: 296262   eps: 0.6113992600084361    steps: 202    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1461   the run_score was: 4.0   and mem length: 296520   eps: 0.6108884200084472    steps: 258    lr: 4e-05     eval rl_reward: 3.83\n","For episode: 1462   the run_score was: 5.0   and mem length: 296852   eps: 0.6102310600084615    steps: 332    lr: 4e-05     eval rl_reward: 3.85\n","For episode: 1463   the run_score was: 4.0   and mem length: 297111   eps: 0.6097182400084726    steps: 259    lr: 4e-05     eval rl_reward: 3.84\n","For episode: 1464   the run_score was: 8.0   and mem length: 297540   eps: 0.6088688200084911    steps: 429    lr: 4e-05     eval rl_reward: 3.87\n","For episode: 1465   the run_score was: 6.0   and mem length: 297932   eps: 0.6080926600085079    steps: 392    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1466   the run_score was: 3.0   and mem length: 298161   eps: 0.6076392400085178    steps: 229    lr: 4e-05     eval rl_reward: 3.86\n","For episode: 1467   the run_score was: 2.0   and mem length: 298360   eps: 0.6072452200085263    steps: 199    lr: 4e-05     eval rl_reward: 3.88\n","For episode: 1468   the run_score was: 3.0   and mem length: 298574   eps: 0.6068215000085355    steps: 214    lr: 4e-05     eval rl_reward: 3.89\n","For episode: 1469   the run_score was: 6.0   and mem length: 298922   eps: 0.6061324600085505    steps: 348    lr: 4e-05     eval rl_reward: 3.93\n","For episode: 1470   the run_score was: 4.0   and mem length: 299206   eps: 0.6055701400085627    steps: 284    lr: 4e-05     eval rl_reward: 3.92\n","For episode: 1471   the run_score was: 4.0   and mem length: 299481   eps: 0.6050256400085745    steps: 275    lr: 4e-05     eval rl_reward: 3.96\n","For episode: 1472   the run_score was: 4.0   and mem length: 299758   eps: 0.6044771800085864    steps: 277    lr: 4e-05     eval rl_reward: 3.95\n","For episode: 1473   the run_score was: 6.0   and mem length: 300117   eps: 0.6037663600086018    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 3.97\n","For episode: 1474   the run_score was: 5.0   and mem length: 300423   eps: 0.603160480008615    steps: 306    lr: 1.6000000000000003e-05     eval rl_reward: 3.98\n","For episode: 1475   the run_score was: 5.0   and mem length: 300784   eps: 0.6024457000086305    steps: 361    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1476   the run_score was: 4.0   and mem length: 301081   eps: 0.6018576400086433    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 3.95\n","For episode: 1477   the run_score was: 3.0   and mem length: 301313   eps: 0.6013982800086533    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1478   the run_score was: 6.0   and mem length: 301708   eps: 0.6006161800086702    steps: 395    lr: 1.6000000000000003e-05     eval rl_reward: 3.96\n","For episode: 1479   the run_score was: 4.0   and mem length: 301948   eps: 0.6001409800086805    steps: 240    lr: 1.6000000000000003e-05     eval rl_reward: 3.95\n","For episode: 1480   the run_score was: 6.0   and mem length: 302288   eps: 0.5994677800086952    steps: 340    lr: 1.6000000000000003e-05     eval rl_reward: 3.96\n","For episode: 1481   the run_score was: 4.0   and mem length: 302552   eps: 0.5989450600087065    steps: 264    lr: 1.6000000000000003e-05     eval rl_reward: 3.97\n","For episode: 1482   the run_score was: 5.0   and mem length: 302859   eps: 0.5983372000087197    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.01\n","For episode: 1483   the run_score was: 4.0   and mem length: 303155   eps: 0.5977511200087324    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 4.01\n","For episode: 1484   the run_score was: 5.0   and mem length: 303508   eps: 0.5970521800087476    steps: 353    lr: 1.6000000000000003e-05     eval rl_reward: 4.03\n","For episode: 1485   the run_score was: 3.0   and mem length: 303737   eps: 0.5965987600087574    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.01\n","For episode: 1486   the run_score was: 4.0   and mem length: 304033   eps: 0.5960126800087702    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 4.01\n","For episode: 1487   the run_score was: 7.0   and mem length: 304444   eps: 0.5951989000087878    steps: 411    lr: 1.6000000000000003e-05     eval rl_reward: 4.05\n","For episode: 1488   the run_score was: 8.0   and mem length: 304900   eps: 0.5942960200088074    steps: 456    lr: 1.6000000000000003e-05     eval rl_reward: 4.07\n","For episode: 1489   the run_score was: 1.0   and mem length: 305052   eps: 0.593995060008814    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 4.06\n","For episode: 1490   the run_score was: 7.0   and mem length: 305487   eps: 0.5931337600088327    steps: 435    lr: 1.6000000000000003e-05     eval rl_reward: 4.08\n","For episode: 1491   the run_score was: 4.0   and mem length: 305762   eps: 0.5925892600088445    steps: 275    lr: 1.6000000000000003e-05     eval rl_reward: 4.07\n","For episode: 1492   the run_score was: 3.0   and mem length: 305989   eps: 0.5921398000088542    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 4.07\n","For episode: 1493   the run_score was: 5.0   and mem length: 306315   eps: 0.5914943200088683    steps: 326    lr: 1.6000000000000003e-05     eval rl_reward: 4.08\n","For episode: 1494   the run_score was: 6.0   and mem length: 306707   eps: 0.5907181600088851    steps: 392    lr: 1.6000000000000003e-05     eval rl_reward: 4.1\n","For episode: 1495   the run_score was: 3.0   and mem length: 306954   eps: 0.5902291000088957    steps: 247    lr: 1.6000000000000003e-05     eval rl_reward: 4.1\n","For episode: 1496   the run_score was: 3.0   and mem length: 307181   eps: 0.5897796400089055    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 4.1\n","For episode: 1497   the run_score was: 10.0   and mem length: 307570   eps: 0.5890094200089222    steps: 389    lr: 1.6000000000000003e-05     eval rl_reward: 4.18\n","For episode: 1498   the run_score was: 2.0   and mem length: 307753   eps: 0.5886470800089301    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 4.15\n","For episode: 1499   the run_score was: 3.0   and mem length: 308000   eps: 0.5881580200089407    steps: 247    lr: 1.6000000000000003e-05     eval rl_reward: 4.12\n","For episode: 1500   the run_score was: 4.0   and mem length: 308276   eps: 0.5876115400089525    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.13\n","For episode: 1501   the run_score was: 5.0   and mem length: 308583   eps: 0.5870036800089657    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.17\n","For episode: 1502   the run_score was: 3.0   and mem length: 308814   eps: 0.5865463000089757    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.15\n","For episode: 1503   the run_score was: 3.0   and mem length: 309064   eps: 0.5860513000089864    steps: 250    lr: 1.6000000000000003e-05     eval rl_reward: 4.15\n","For episode: 1504   the run_score was: 5.0   and mem length: 309364   eps: 0.5854573000089993    steps: 300    lr: 1.6000000000000003e-05     eval rl_reward: 4.17\n","For episode: 1505   the run_score was: 3.0   and mem length: 309592   eps: 0.5850058600090091    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 4.17\n","For episode: 1506   the run_score was: 4.0   and mem length: 309834   eps: 0.5845267000090195    steps: 242    lr: 1.6000000000000003e-05     eval rl_reward: 4.16\n","For episode: 1507   the run_score was: 5.0   and mem length: 310143   eps: 0.5839148800090328    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 4.16\n","For episode: 1508   the run_score was: 5.0   and mem length: 310470   eps: 0.5832674200090469    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 4.18\n","For episode: 1509   the run_score was: 5.0   and mem length: 310780   eps: 0.5826536200090602    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 4.2\n","For episode: 1510   the run_score was: 10.0   and mem length: 311238   eps: 0.5817467800090799    steps: 458    lr: 1.6000000000000003e-05     eval rl_reward: 4.25\n","For episode: 1511   the run_score was: 6.0   and mem length: 311594   eps: 0.5810419000090952    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 4.27\n","For episode: 1512   the run_score was: 2.0   and mem length: 311795   eps: 0.5806439200091038    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 4.27\n","For episode: 1513   the run_score was: 5.0   and mem length: 312100   eps: 0.5800400200091169    steps: 305    lr: 1.6000000000000003e-05     eval rl_reward: 4.3\n","For episode: 1514   the run_score was: 4.0   and mem length: 312396   eps: 0.5794539400091296    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 4.28\n","For episode: 1515   the run_score was: 0.0   and mem length: 312520   eps: 0.579208420009135    steps: 124    lr: 1.6000000000000003e-05     eval rl_reward: 4.24\n","For episode: 1516   the run_score was: 5.0   and mem length: 312827   eps: 0.5786005600091482    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.22\n","For episode: 1517   the run_score was: 6.0   and mem length: 313140   eps: 0.5779808200091616    steps: 313    lr: 1.6000000000000003e-05     eval rl_reward: 4.24\n","For episode: 1518   the run_score was: 2.0   and mem length: 313341   eps: 0.5775828400091703    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 4.22\n","For episode: 1519   the run_score was: 3.0   and mem length: 313571   eps: 0.5771274400091801    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 4.22\n","For episode: 1520   the run_score was: 3.0   and mem length: 313820   eps: 0.5766344200091909    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 4.23\n","For episode: 1521   the run_score was: 6.0   and mem length: 314144   eps: 0.5759929000092048    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 4.27\n","For episode: 1522   the run_score was: 6.0   and mem length: 314541   eps: 0.5752068400092218    steps: 397    lr: 1.6000000000000003e-05     eval rl_reward: 4.3\n","For episode: 1523   the run_score was: 4.0   and mem length: 314817   eps: 0.5746603600092337    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.31\n","For episode: 1524   the run_score was: 5.0   and mem length: 315124   eps: 0.5740525000092469    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.33\n","For episode: 1525   the run_score was: 8.0   and mem length: 315561   eps: 0.5731872400092657    steps: 437    lr: 1.6000000000000003e-05     eval rl_reward: 4.39\n","For episode: 1526   the run_score was: 7.0   and mem length: 315915   eps: 0.5724863200092809    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 4.43\n","For episode: 1527   the run_score was: 6.0   and mem length: 316268   eps: 0.5717873800092961    steps: 353    lr: 1.6000000000000003e-05     eval rl_reward: 4.47\n","For episode: 1528   the run_score was: 4.0   and mem length: 316565   eps: 0.5711993200093088    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 4.45\n","For episode: 1529   the run_score was: 6.0   and mem length: 316918   eps: 0.570500380009324    steps: 353    lr: 1.6000000000000003e-05     eval rl_reward: 4.49\n","For episode: 1530   the run_score was: 4.0   and mem length: 317200   eps: 0.5699420200093361    steps: 282    lr: 1.6000000000000003e-05     eval rl_reward: 4.5\n","For episode: 1531   the run_score was: 4.0   and mem length: 317495   eps: 0.5693579200093488    steps: 295    lr: 1.6000000000000003e-05     eval rl_reward: 4.5\n","For episode: 1532   the run_score was: 6.0   and mem length: 317849   eps: 0.568657000009364    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 4.53\n","For episode: 1533   the run_score was: 5.0   and mem length: 318153   eps: 0.5680550800093771    steps: 304    lr: 1.6000000000000003e-05     eval rl_reward: 4.53\n","For episode: 1534   the run_score was: 3.0   and mem length: 318399   eps: 0.5675680000093877    steps: 246    lr: 1.6000000000000003e-05     eval rl_reward: 4.52\n","For episode: 1535   the run_score was: 6.0   and mem length: 318793   eps: 0.5667878800094046    steps: 394    lr: 1.6000000000000003e-05     eval rl_reward: 4.55\n","For episode: 1536   the run_score was: 4.0   and mem length: 319090   eps: 0.5661998200094174    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 4.55\n","For episode: 1537   the run_score was: 5.0   and mem length: 319402   eps: 0.5655820600094308    steps: 312    lr: 1.6000000000000003e-05     eval rl_reward: 4.58\n","For episode: 1538   the run_score was: 8.0   and mem length: 319836   eps: 0.5647227400094494    steps: 434    lr: 1.6000000000000003e-05     eval rl_reward: 4.61\n","For episode: 1539   the run_score was: 5.0   and mem length: 320120   eps: 0.5641604200094616    steps: 284    lr: 1.6000000000000003e-05     eval rl_reward: 4.59\n","For episode: 1540   the run_score was: 2.0   and mem length: 320339   eps: 0.5637268000094711    steps: 219    lr: 1.6000000000000003e-05     eval rl_reward: 4.57\n","For episode: 1541   the run_score was: 7.0   and mem length: 320689   eps: 0.5630338000094861    steps: 350    lr: 1.6000000000000003e-05     eval rl_reward: 4.63\n","For episode: 1542   the run_score was: 6.0   and mem length: 321028   eps: 0.5623625800095007    steps: 339    lr: 1.6000000000000003e-05     eval rl_reward: 4.63\n","For episode: 1543   the run_score was: 8.0   and mem length: 321451   eps: 0.5615250400095189    steps: 423    lr: 1.6000000000000003e-05     eval rl_reward: 4.67\n","For episode: 1544   the run_score was: 3.0   and mem length: 321680   eps: 0.5610716200095287    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.66\n","For episode: 1545   the run_score was: 6.0   and mem length: 322035   eps: 0.560368720009544    steps: 355    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1546   the run_score was: 4.0   and mem length: 322311   eps: 0.5598222400095558    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1547   the run_score was: 5.0   and mem length: 322597   eps: 0.5592559600095681    steps: 286    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1548   the run_score was: 6.0   and mem length: 322974   eps: 0.5585095000095843    steps: 377    lr: 1.6000000000000003e-05     eval rl_reward: 4.7\n","For episode: 1549   the run_score was: 5.0   and mem length: 323297   eps: 0.5578699600095982    steps: 323    lr: 1.6000000000000003e-05     eval rl_reward: 4.71\n","For episode: 1550   the run_score was: 4.0   and mem length: 323540   eps: 0.5573888200096087    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 4.72\n","For episode: 1551   the run_score was: 8.0   and mem length: 324016   eps: 0.5564463400096291    steps: 476    lr: 1.6000000000000003e-05     eval rl_reward: 4.76\n","For episode: 1552   the run_score was: 3.0   and mem length: 324265   eps: 0.5559533200096398    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 4.75\n","For episode: 1553   the run_score was: 4.0   and mem length: 324525   eps: 0.555438520009651    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.74\n","For episode: 1554   the run_score was: 3.0   and mem length: 324771   eps: 0.5549514400096616    steps: 246    lr: 1.6000000000000003e-05     eval rl_reward: 4.67\n","For episode: 1555   the run_score was: 4.0   and mem length: 325070   eps: 0.5543594200096744    steps: 299    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1556   the run_score was: 7.0   and mem length: 325494   eps: 0.5535199000096926    steps: 424    lr: 1.6000000000000003e-05     eval rl_reward: 4.69\n","For episode: 1557   the run_score was: 8.0   and mem length: 325953   eps: 0.5526110800097124    steps: 459    lr: 1.6000000000000003e-05     eval rl_reward: 4.71\n","For episode: 1558   the run_score was: 3.0   and mem length: 326198   eps: 0.5521259800097229    steps: 245    lr: 1.6000000000000003e-05     eval rl_reward: 4.73\n","For episode: 1559   the run_score was: 6.0   and mem length: 326555   eps: 0.5514191200097383    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 4.73\n","For episode: 1560   the run_score was: 5.0   and mem length: 326880   eps: 0.5507756200097522    steps: 325    lr: 1.6000000000000003e-05     eval rl_reward: 4.76\n","For episode: 1561   the run_score was: 6.0   and mem length: 327202   eps: 0.5501380600097661    steps: 322    lr: 1.6000000000000003e-05     eval rl_reward: 4.78\n","For episode: 1562   the run_score was: 3.0   and mem length: 327433   eps: 0.549680680009776    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.76\n","For episode: 1563   the run_score was: 7.0   and mem length: 327817   eps: 0.5489203600097925    steps: 384    lr: 1.6000000000000003e-05     eval rl_reward: 4.79\n","For episode: 1564   the run_score was: 6.0   and mem length: 328157   eps: 0.5482471600098071    steps: 340    lr: 1.6000000000000003e-05     eval rl_reward: 4.77\n","For episode: 1565   the run_score was: 3.0   and mem length: 328388   eps: 0.547789780009817    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.74\n","For episode: 1566   the run_score was: 7.0   and mem length: 328815   eps: 0.5469443200098354    steps: 427    lr: 1.6000000000000003e-05     eval rl_reward: 4.78\n","For episode: 1567   the run_score was: 5.0   and mem length: 329146   eps: 0.5462889400098496    steps: 331    lr: 1.6000000000000003e-05     eval rl_reward: 4.81\n","For episode: 1568   the run_score was: 2.0   and mem length: 329366   eps: 0.5458533400098591    steps: 220    lr: 1.6000000000000003e-05     eval rl_reward: 4.8\n","For episode: 1569   the run_score was: 8.0   and mem length: 329810   eps: 0.5449742200098782    steps: 444    lr: 1.6000000000000003e-05     eval rl_reward: 4.82\n","For episode: 1570   the run_score was: 6.0   and mem length: 330140   eps: 0.5443208200098923    steps: 330    lr: 1.6000000000000003e-05     eval rl_reward: 4.84\n","For episode: 1571   the run_score was: 6.0   and mem length: 330512   eps: 0.5435842600099083    steps: 372    lr: 1.6000000000000003e-05     eval rl_reward: 4.86\n","For episode: 1572   the run_score was: 2.0   and mem length: 330713   eps: 0.543186280009917    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 4.84\n","For episode: 1573   the run_score was: 7.0   and mem length: 331111   eps: 0.5423982400099341    steps: 398    lr: 1.6000000000000003e-05     eval rl_reward: 4.85\n","For episode: 1574   the run_score was: 7.0   and mem length: 331552   eps: 0.541525060009953    steps: 441    lr: 1.6000000000000003e-05     eval rl_reward: 4.87\n","For episode: 1575   the run_score was: 4.0   and mem length: 331814   eps: 0.5410063000099643    steps: 262    lr: 1.6000000000000003e-05     eval rl_reward: 4.86\n","For episode: 1576   the run_score was: 3.0   and mem length: 332062   eps: 0.540515260009975    steps: 248    lr: 1.6000000000000003e-05     eval rl_reward: 4.85\n","For episode: 1577   the run_score was: 5.0   and mem length: 332358   eps: 0.5399291800099877    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 4.87\n","For episode: 1578   the run_score was: 5.0   and mem length: 332663   eps: 0.5393252800100008    steps: 305    lr: 1.6000000000000003e-05     eval rl_reward: 4.86\n","For episode: 1579   the run_score was: 2.0   and mem length: 332882   eps: 0.5388916600100102    steps: 219    lr: 1.6000000000000003e-05     eval rl_reward: 4.84\n","For episode: 1580   the run_score was: 5.0   and mem length: 333212   eps: 0.5382382600100244    steps: 330    lr: 1.6000000000000003e-05     eval rl_reward: 4.83\n","For episode: 1581   the run_score was: 6.0   and mem length: 333540   eps: 0.5375888200100385    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 4.85\n","For episode: 1582   the run_score was: 4.0   and mem length: 333801   eps: 0.5370720400100497    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 4.84\n","For episode: 1583   the run_score was: 9.0   and mem length: 334145   eps: 0.5363909200100645    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 4.89\n","For episode: 1584   the run_score was: 5.0   and mem length: 334455   eps: 0.5357771200100778    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 4.89\n","For episode: 1585   the run_score was: 6.0   and mem length: 334814   eps: 0.5350663000100933    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 4.92\n","For episode: 1586   the run_score was: 7.0   and mem length: 335260   eps: 0.5341832200101124    steps: 446    lr: 1.6000000000000003e-05     eval rl_reward: 4.95\n","For episode: 1587   the run_score was: 7.0   and mem length: 335676   eps: 0.5333595400101303    steps: 416    lr: 1.6000000000000003e-05     eval rl_reward: 4.95\n","For episode: 1588   the run_score was: 6.0   and mem length: 336017   eps: 0.532684360010145    steps: 341    lr: 1.6000000000000003e-05     eval rl_reward: 4.93\n","For episode: 1589   the run_score was: 9.0   and mem length: 336351   eps: 0.5320230400101593    steps: 334    lr: 1.6000000000000003e-05     eval rl_reward: 5.01\n","For episode: 1590   the run_score was: 4.0   and mem length: 336614   eps: 0.5315023000101706    steps: 263    lr: 1.6000000000000003e-05     eval rl_reward: 4.98\n","For episode: 1591   the run_score was: 5.0   and mem length: 336920   eps: 0.5308964200101838    steps: 306    lr: 1.6000000000000003e-05     eval rl_reward: 4.99\n","For episode: 1592   the run_score was: 6.0   and mem length: 337311   eps: 0.5301222400102006    steps: 391    lr: 1.6000000000000003e-05     eval rl_reward: 5.02\n","For episode: 1593   the run_score was: 7.0   and mem length: 337741   eps: 0.5292708400102191    steps: 430    lr: 1.6000000000000003e-05     eval rl_reward: 5.04\n","For episode: 1594   the run_score was: 3.0   and mem length: 337972   eps: 0.528813460010229    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 5.01\n","For episode: 1595   the run_score was: 3.0   and mem length: 338222   eps: 0.5283184600102397    steps: 250    lr: 1.6000000000000003e-05     eval rl_reward: 5.01\n","For episode: 1596   the run_score was: 5.0   and mem length: 338553   eps: 0.527663080010254    steps: 331    lr: 1.6000000000000003e-05     eval rl_reward: 5.03\n","For episode: 1597   the run_score was: 5.0   and mem length: 338880   eps: 0.527015620010268    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 4.98\n","For episode: 1598   the run_score was: 5.0   and mem length: 339169   eps: 0.5264434000102804    steps: 289    lr: 1.6000000000000003e-05     eval rl_reward: 5.01\n","For episode: 1599   the run_score was: 6.0   and mem length: 339487   eps: 0.5258137600102941    steps: 318    lr: 1.6000000000000003e-05     eval rl_reward: 5.04\n","For episode: 1600   the run_score was: 5.0   and mem length: 339794   eps: 0.5252059000103073    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 5.05\n","For episode: 1601   the run_score was: 7.0   and mem length: 340162   eps: 0.5244772600103231    steps: 368    lr: 1.6000000000000003e-05     eval rl_reward: 5.07\n","For episode: 1602   the run_score was: 4.0   and mem length: 340439   eps: 0.523928800010335    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 5.08\n","For episode: 1603   the run_score was: 7.0   and mem length: 340829   eps: 0.5231566000103518    steps: 390    lr: 1.6000000000000003e-05     eval rl_reward: 5.12\n","For episode: 1604   the run_score was: 7.0   and mem length: 341199   eps: 0.5224240000103677    steps: 370    lr: 1.6000000000000003e-05     eval rl_reward: 5.14\n","For episode: 1605   the run_score was: 7.0   and mem length: 341566   eps: 0.5216973400103835    steps: 367    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1606   the run_score was: 7.0   and mem length: 341958   eps: 0.5209211800104003    steps: 392    lr: 1.6000000000000003e-05     eval rl_reward: 5.21\n","For episode: 1607   the run_score was: 4.0   and mem length: 342234   eps: 0.5203747000104122    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1608   the run_score was: 5.0   and mem length: 342523   eps: 0.5198024800104246    steps: 289    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1609   the run_score was: 5.0   and mem length: 342839   eps: 0.5191768000104382    steps: 316    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1610   the run_score was: 5.0   and mem length: 343170   eps: 0.5185214200104524    steps: 331    lr: 1.6000000000000003e-05     eval rl_reward: 5.15\n","For episode: 1611   the run_score was: 7.0   and mem length: 343545   eps: 0.5177789200104685    steps: 375    lr: 1.6000000000000003e-05     eval rl_reward: 5.16\n","For episode: 1612   the run_score was: 6.0   and mem length: 343901   eps: 0.5170740400104838    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1613   the run_score was: 3.0   and mem length: 344129   eps: 0.5166226000104936    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1614   the run_score was: 6.0   and mem length: 344502   eps: 0.5158840600105097    steps: 373    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1615   the run_score was: 3.0   and mem length: 344730   eps: 0.5154326200105195    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 5.23\n","For episode: 1616   the run_score was: 9.0   and mem length: 345188   eps: 0.5145257800105392    steps: 458    lr: 1.6000000000000003e-05     eval rl_reward: 5.27\n","For episode: 1617   the run_score was: 7.0   and mem length: 345591   eps: 0.5137278400105565    steps: 403    lr: 1.6000000000000003e-05     eval rl_reward: 5.28\n","For episode: 1618   the run_score was: 7.0   and mem length: 345941   eps: 0.5130348400105715    steps: 350    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1619   the run_score was: 6.0   and mem length: 346301   eps: 0.512322040010587    steps: 360    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1620   the run_score was: 6.0   and mem length: 346661   eps: 0.5116092400106025    steps: 360    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1621   the run_score was: 6.0   and mem length: 346982   eps: 0.5109736600106163    steps: 321    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1622   the run_score was: 7.0   and mem length: 347387   eps: 0.5101717600106337    steps: 405    lr: 1.6000000000000003e-05     eval rl_reward: 5.4\n","For episode: 1623   the run_score was: 6.0   and mem length: 347713   eps: 0.5095262800106477    steps: 326    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1624   the run_score was: 5.0   and mem length: 348020   eps: 0.5089184200106609    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1625   the run_score was: 5.0   and mem length: 348363   eps: 0.5082392800106756    steps: 343    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1626   the run_score was: 6.0   and mem length: 348736   eps: 0.5075007400106917    steps: 373    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1627   the run_score was: 6.0   and mem length: 349063   eps: 0.5068532800107057    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1628   the run_score was: 4.0   and mem length: 349325   eps: 0.506334520010717    steps: 262    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1629   the run_score was: 8.0   and mem length: 349770   eps: 0.5054534200107361    steps: 445    lr: 1.6000000000000003e-05     eval rl_reward: 5.4\n","For episode: 1630   the run_score was: 8.0   and mem length: 350194   eps: 0.5046139000107543    steps: 424    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1631   the run_score was: 5.0   and mem length: 350463   eps: 0.5040812800107659    steps: 269    lr: 1.6000000000000003e-05     eval rl_reward: 5.45\n","For episode: 1632   the run_score was: 3.0   and mem length: 350731   eps: 0.5035506400107774    steps: 268    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1633   the run_score was: 3.0   and mem length: 350980   eps: 0.5030576200107881    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 5.4\n","For episode: 1634   the run_score was: 6.0   and mem length: 351337   eps: 0.5023507600108035    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 5.43\n","For episode: 1635   the run_score was: 5.0   and mem length: 351629   eps: 0.501772600010816    steps: 292    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1636   the run_score was: 2.0   and mem length: 351828   eps: 0.5013785800108246    steps: 199    lr: 1.6000000000000003e-05     eval rl_reward: 5.4\n","For episode: 1637   the run_score was: 4.0   and mem length: 352149   eps: 0.5007430000108384    steps: 321    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1638   the run_score was: 12.0   and mem length: 352674   eps: 0.4997035000108526    steps: 525    lr: 1.6000000000000003e-05     eval rl_reward: 5.43\n","For episode: 1639   the run_score was: 6.0   and mem length: 353009   eps: 0.4990402000108484    steps: 335    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1640   the run_score was: 6.0   and mem length: 353378   eps: 0.4983095800108438    steps: 369    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1641   the run_score was: 3.0   and mem length: 353627   eps: 0.4978165600108407    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1642   the run_score was: 4.0   and mem length: 353869   eps: 0.49733740001083765    steps: 242    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1643   the run_score was: 3.0   and mem length: 354098   eps: 0.4968839800108348    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 5.37\n","For episode: 1644   the run_score was: 5.0   and mem length: 354423   eps: 0.4962404800108307    steps: 325    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1645   the run_score was: 5.0   and mem length: 354753   eps: 0.4955870800108266    steps: 330    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1646   the run_score was: 9.0   and mem length: 355201   eps: 0.49470004001082096    steps: 448    lr: 1.6000000000000003e-05     eval rl_reward: 5.43\n","For episode: 1647   the run_score was: 5.0   and mem length: 355512   eps: 0.49408426001081707    steps: 311    lr: 1.6000000000000003e-05     eval rl_reward: 5.43\n","For episode: 1648   the run_score was: 7.0   and mem length: 355926   eps: 0.4932645400108119    steps: 414    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1649   the run_score was: 7.0   and mem length: 356277   eps: 0.4925695600108075    steps: 351    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1650   the run_score was: 3.0   and mem length: 356510   eps: 0.49210822001080456    steps: 233    lr: 1.6000000000000003e-05     eval rl_reward: 5.45\n","For episode: 1651   the run_score was: 4.0   and mem length: 356767   eps: 0.49159936001080135    steps: 257    lr: 1.6000000000000003e-05     eval rl_reward: 5.41\n","For episode: 1652   the run_score was: 8.0   and mem length: 357175   eps: 0.49079152001079623    steps: 408    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1653   the run_score was: 5.0   and mem length: 357469   eps: 0.49020940001079255    steps: 294    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1654   the run_score was: 4.0   and mem length: 357730   eps: 0.4896926200107893    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1655   the run_score was: 6.0   and mem length: 358089   eps: 0.4889818000107848    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 5.5\n","For episode: 1656   the run_score was: 3.0   and mem length: 358317   eps: 0.4885303600107819    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1657   the run_score was: 4.0   and mem length: 358575   eps: 0.4880195200107787    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1658   the run_score was: 7.0   and mem length: 358935   eps: 0.4873067200107742    steps: 360    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1659   the run_score was: 10.0   and mem length: 359346   eps: 0.48649294001076904    steps: 411    lr: 1.6000000000000003e-05     eval rl_reward: 5.5\n","For episode: 1660   the run_score was: 5.0   and mem length: 359657   eps: 0.48587716001076514    steps: 311    lr: 1.6000000000000003e-05     eval rl_reward: 5.5\n","For episode: 1661   the run_score was: 4.0   and mem length: 359920   eps: 0.48535642001076185    steps: 263    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1662   the run_score was: 3.0   and mem length: 360133   eps: 0.4849346800107592    steps: 213    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1663   the run_score was: 5.0   and mem length: 360449   eps: 0.4843090000107552    steps: 316    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1664   the run_score was: 4.0   and mem length: 360726   eps: 0.48376054001075175    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1665   the run_score was: 6.0   and mem length: 361074   eps: 0.4830715000107474    steps: 348    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1666   the run_score was: 4.0   and mem length: 361353   eps: 0.4825190800107439    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1667   the run_score was: 6.0   and mem length: 361687   eps: 0.4818577600107397    steps: 334    lr: 1.6000000000000003e-05     eval rl_reward: 5.45\n","For episode: 1668   the run_score was: 3.0   and mem length: 361916   eps: 0.48140434001073684    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1669   the run_score was: 9.0   and mem length: 362260   eps: 0.48072322001073253    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1670   the run_score was: 6.0   and mem length: 362618   eps: 0.48001438001072805    steps: 358    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1671   the run_score was: 6.0   and mem length: 362994   eps: 0.47926990001072334    steps: 376    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1672   the run_score was: 2.0   and mem length: 363175   eps: 0.47891152001072107    steps: 181    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1673   the run_score was: 4.0   and mem length: 363451   eps: 0.4783650400107176    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1674   the run_score was: 7.0   and mem length: 363858   eps: 0.4775591800107125    steps: 407    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1675   the run_score was: 6.0   and mem length: 364215   eps: 0.47685232001070804    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 5.46\n","For episode: 1676   the run_score was: 6.0   and mem length: 364568   eps: 0.4761533800107036    steps: 353    lr: 1.6000000000000003e-05     eval rl_reward: 5.49\n","For episode: 1677   the run_score was: 5.0   and mem length: 364861   eps: 0.47557324001069995    steps: 293    lr: 1.6000000000000003e-05     eval rl_reward: 5.49\n","For episode: 1678   the run_score was: 6.0   and mem length: 365217   eps: 0.4748683600106955    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 5.5\n","For episode: 1679   the run_score was: 3.0   and mem length: 365464   eps: 0.4743793000106924    steps: 247    lr: 1.6000000000000003e-05     eval rl_reward: 5.51\n","For episode: 1680   the run_score was: 4.0   and mem length: 365743   eps: 0.4738268800106889    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 5.5\n","For episode: 1681   the run_score was: 4.0   and mem length: 366045   eps: 0.4732289200106851    steps: 302    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1682   the run_score was: 3.0   and mem length: 366294   eps: 0.472735900010682    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1683   the run_score was: 3.0   and mem length: 366526   eps: 0.4722765400106791    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 5.41\n","For episode: 1684   the run_score was: 5.0   and mem length: 366854   eps: 0.471627100010675    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 5.41\n","For episode: 1685   the run_score was: 6.0   and mem length: 367198   eps: 0.4709459800106707    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 5.41\n","For episode: 1686   the run_score was: 11.0   and mem length: 367584   eps: 0.47018170001066584    steps: 386    lr: 1.6000000000000003e-05     eval rl_reward: 5.45\n","For episode: 1687   the run_score was: 4.0   and mem length: 367864   eps: 0.46962730001066233    steps: 280    lr: 1.6000000000000003e-05     eval rl_reward: 5.42\n","For episode: 1688   the run_score was: 3.0   and mem length: 368094   eps: 0.46917190001065945    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 5.39\n","For episode: 1689   the run_score was: 4.0   and mem length: 368373   eps: 0.46861948001065595    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1690   the run_score was: 8.0   and mem length: 368766   eps: 0.46784134001065103    steps: 393    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1691   the run_score was: 4.0   and mem length: 369061   eps: 0.46725724001064733    steps: 295    lr: 1.6000000000000003e-05     eval rl_reward: 5.37\n","For episode: 1692   the run_score was: 3.0   and mem length: 369310   eps: 0.4667642200106442    steps: 249    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1693   the run_score was: 6.0   and mem length: 369692   eps: 0.46600786001063943    steps: 382    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1694   the run_score was: 6.0   and mem length: 370049   eps: 0.46530100001063496    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1695   the run_score was: 5.0   and mem length: 370373   eps: 0.4646594800106309    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1696   the run_score was: 2.0   and mem length: 370572   eps: 0.4642654600106284    steps: 199    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1697   the run_score was: 5.0   and mem length: 370921   eps: 0.46357444001062403    steps: 349    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1698   the run_score was: 7.0   and mem length: 371311   eps: 0.46280224001061915    steps: 390    lr: 1.6000000000000003e-05     eval rl_reward: 5.37\n","For episode: 1699   the run_score was: 4.0   and mem length: 371572   eps: 0.4622854600106159    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1700   the run_score was: 7.0   and mem length: 371971   eps: 0.4614954400106109    steps: 399    lr: 1.6000000000000003e-05     eval rl_reward: 5.37\n","For episode: 1701   the run_score was: 3.0   and mem length: 372202   eps: 0.461038060010608    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1702   the run_score was: 5.0   and mem length: 372507   eps: 0.46043416001060417    steps: 305    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1703   the run_score was: 7.0   and mem length: 372916   eps: 0.45962434001059904    steps: 409    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1704   the run_score was: 3.0   and mem length: 373166   eps: 0.4591293400105959    steps: 250    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1705   the run_score was: 7.0   and mem length: 373562   eps: 0.45834526001059095    steps: 396    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1706   the run_score was: 3.0   and mem length: 373810   eps: 0.45785422001058784    steps: 248    lr: 1.6000000000000003e-05     eval rl_reward: 5.26\n","For episode: 1707   the run_score was: 9.0   and mem length: 374264   eps: 0.45695530001058215    steps: 454    lr: 1.6000000000000003e-05     eval rl_reward: 5.31\n","For episode: 1708   the run_score was: 5.0   and mem length: 374573   eps: 0.4563434800105783    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 5.31\n","For episode: 1709   the run_score was: 4.0   and mem length: 374832   eps: 0.45583066001057504    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1710   the run_score was: 4.0   and mem length: 375090   eps: 0.4553198200105718    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 5.29\n","For episode: 1711   the run_score was: 3.0   and mem length: 375304   eps: 0.4548961000105691    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 5.25\n","For episode: 1712   the run_score was: 8.0   and mem length: 375696   eps: 0.4541199400105642    steps: 392    lr: 1.6000000000000003e-05     eval rl_reward: 5.27\n","For episode: 1713   the run_score was: 6.0   and mem length: 376054   eps: 0.45341110001055973    steps: 358    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1714   the run_score was: 9.0   and mem length: 376502   eps: 0.4525240600105541    steps: 448    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1715   the run_score was: 8.0   and mem length: 376906   eps: 0.45172414001054906    steps: 404    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1716   the run_score was: 4.0   and mem length: 377200   eps: 0.4511420200105454    steps: 294    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1717   the run_score was: 4.0   and mem length: 377462   eps: 0.4506232600105421    steps: 262    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1718   the run_score was: 3.0   and mem length: 377694   eps: 0.4501639000105392    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 5.26\n","For episode: 1719   the run_score was: 6.0   and mem length: 378037   eps: 0.4494847600105349    steps: 343    lr: 1.6000000000000003e-05     eval rl_reward: 5.26\n","For episode: 1720   the run_score was: 3.0   and mem length: 378250   eps: 0.4490630200105322    steps: 213    lr: 1.6000000000000003e-05     eval rl_reward: 5.23\n","For episode: 1721   the run_score was: 5.0   and mem length: 378579   eps: 0.4484116000105281    steps: 329    lr: 1.6000000000000003e-05     eval rl_reward: 5.22\n","For episode: 1722   the run_score was: 4.0   and mem length: 378857   eps: 0.4478611600105246    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 5.19\n","For episode: 1723   the run_score was: 5.0   and mem length: 379173   eps: 0.44723548001052066    steps: 316    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1724   the run_score was: 5.0   and mem length: 379480   eps: 0.4466276200105168    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1725   the run_score was: 6.0   and mem length: 379853   eps: 0.44588908001051214    steps: 373    lr: 1.6000000000000003e-05     eval rl_reward: 5.19\n","For episode: 1726   the run_score was: 5.0   and mem length: 380166   eps: 0.4452693400105082    steps: 313    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1727   the run_score was: 4.0   and mem length: 380425   eps: 0.444756520010505    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 5.16\n","For episode: 1728   the run_score was: 3.0   and mem length: 380639   eps: 0.4443328000105023    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 5.15\n","For episode: 1729   the run_score was: 3.0   and mem length: 380885   eps: 0.4438457200104992    steps: 246    lr: 1.6000000000000003e-05     eval rl_reward: 5.1\n","For episode: 1730   the run_score was: 4.0   and mem length: 381126   eps: 0.4433685400104962    steps: 241    lr: 1.6000000000000003e-05     eval rl_reward: 5.06\n","For episode: 1731   the run_score was: 5.0   and mem length: 381435   eps: 0.4427567200104923    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 5.06\n","For episode: 1732   the run_score was: 10.0   and mem length: 381971   eps: 0.4416954400104856    steps: 536    lr: 1.6000000000000003e-05     eval rl_reward: 5.13\n","For episode: 1733   the run_score was: 8.0   and mem length: 382397   eps: 0.44085196001048027    steps: 426    lr: 1.6000000000000003e-05     eval rl_reward: 5.18\n","For episode: 1734   the run_score was: 5.0   and mem length: 382701   eps: 0.44025004001047646    steps: 304    lr: 1.6000000000000003e-05     eval rl_reward: 5.17\n","For episode: 1735   the run_score was: 3.0   and mem length: 382933   eps: 0.43979068001047356    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 5.15\n","For episode: 1736   the run_score was: 4.0   and mem length: 383231   eps: 0.4392006400104698    steps: 298    lr: 1.6000000000000003e-05     eval rl_reward: 5.17\n","For episode: 1737   the run_score was: 7.0   and mem length: 383607   eps: 0.4384561600104651    steps: 376    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1738   the run_score was: 5.0   and mem length: 383916   eps: 0.43784434001046124    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 5.13\n","For episode: 1739   the run_score was: 5.0   and mem length: 384243   eps: 0.43719688001045715    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 5.12\n","For episode: 1740   the run_score was: 6.0   and mem length: 384571   eps: 0.43654744001045304    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 5.12\n","For episode: 1741   the run_score was: 3.0   and mem length: 384781   eps: 0.4361316400104504    steps: 210    lr: 1.6000000000000003e-05     eval rl_reward: 5.12\n","For episode: 1742   the run_score was: 4.0   and mem length: 385024   eps: 0.43565050001044736    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 5.12\n","For episode: 1743   the run_score was: 7.0   and mem length: 385409   eps: 0.43488820001044254    steps: 385    lr: 1.6000000000000003e-05     eval rl_reward: 5.16\n","For episode: 1744   the run_score was: 4.0   and mem length: 385688   eps: 0.43433578001043904    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 5.15\n","For episode: 1745   the run_score was: 7.0   and mem length: 386060   eps: 0.4335992200104344    steps: 372    lr: 1.6000000000000003e-05     eval rl_reward: 5.17\n","For episode: 1746   the run_score was: 7.0   and mem length: 386435   eps: 0.4328567200104297    steps: 375    lr: 1.6000000000000003e-05     eval rl_reward: 5.15\n","For episode: 1747   the run_score was: 9.0   and mem length: 386899   eps: 0.4319380000104239    steps: 464    lr: 1.6000000000000003e-05     eval rl_reward: 5.19\n","For episode: 1748   the run_score was: 7.0   and mem length: 387326   eps: 0.4310925400104185    steps: 427    lr: 1.6000000000000003e-05     eval rl_reward: 5.19\n","For episode: 1749   the run_score was: 5.0   and mem length: 387618   eps: 0.43051438001041487    steps: 292    lr: 1.6000000000000003e-05     eval rl_reward: 5.17\n","For episode: 1750   the run_score was: 6.0   and mem length: 387953   eps: 0.42985108001041067    steps: 335    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1751   the run_score was: 4.0   and mem length: 388196   eps: 0.4293699400104076    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 5.2\n","For episode: 1752   the run_score was: 7.0   and mem length: 388604   eps: 0.4285621000104025    steps: 408    lr: 1.6000000000000003e-05     eval rl_reward: 5.19\n","For episode: 1753   the run_score was: 10.0   and mem length: 389121   eps: 0.42753844001039604    steps: 517    lr: 1.6000000000000003e-05     eval rl_reward: 5.24\n","For episode: 1754   the run_score was: 7.0   and mem length: 389509   eps: 0.4267702000103912    steps: 388    lr: 1.6000000000000003e-05     eval rl_reward: 5.27\n","For episode: 1755   the run_score was: 6.0   and mem length: 389851   eps: 0.4260930400103869    steps: 342    lr: 1.6000000000000003e-05     eval rl_reward: 5.27\n","For episode: 1756   the run_score was: 9.0   and mem length: 390301   eps: 0.42520204001038125    steps: 450    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1757   the run_score was: 4.0   and mem length: 390564   eps: 0.42468130001037796    steps: 263    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1758   the run_score was: 5.0   and mem length: 390912   eps: 0.4239922600103736    steps: 348    lr: 1.6000000000000003e-05     eval rl_reward: 5.31\n","For episode: 1759   the run_score was: 6.0   and mem length: 391267   eps: 0.42328936001036915    steps: 355    lr: 1.6000000000000003e-05     eval rl_reward: 5.27\n","For episode: 1760   the run_score was: 7.0   and mem length: 391671   eps: 0.4224894400103641    steps: 404    lr: 1.6000000000000003e-05     eval rl_reward: 5.29\n","For episode: 1761   the run_score was: 6.0   and mem length: 392009   eps: 0.42182020001035986    steps: 338    lr: 1.6000000000000003e-05     eval rl_reward: 5.31\n","For episode: 1762   the run_score was: 8.0   and mem length: 392438   eps: 0.4209707800103545    steps: 429    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1763   the run_score was: 3.0   and mem length: 392668   eps: 0.4205153800103516    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1764   the run_score was: 4.0   and mem length: 392928   eps: 0.42000058001034835    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1765   the run_score was: 4.0   and mem length: 393205   eps: 0.4194521200103449    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 5.32\n","For episode: 1766   the run_score was: 6.0   and mem length: 393549   eps: 0.41877100001034057    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 5.34\n","For episode: 1767   the run_score was: 4.0   and mem length: 393810   eps: 0.4182542200103373    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 5.32\n","For episode: 1768   the run_score was: 6.0   and mem length: 394192   eps: 0.4174978600103325    steps: 382    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1769   the run_score was: 6.0   and mem length: 394551   eps: 0.416787040010328    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 5.32\n","For episode: 1770   the run_score was: 6.0   and mem length: 394910   eps: 0.4160762200103235    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 5.32\n","For episode: 1771   the run_score was: 4.0   and mem length: 395173   eps: 0.4155554800103202    steps: 263    lr: 1.6000000000000003e-05     eval rl_reward: 5.3\n","For episode: 1772   the run_score was: 5.0   and mem length: 395476   eps: 0.4149555400103164    steps: 303    lr: 1.6000000000000003e-05     eval rl_reward: 5.33\n","For episode: 1773   the run_score was: 6.0   and mem length: 395853   eps: 0.4142090800103117    steps: 377    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1774   the run_score was: 8.0   and mem length: 396260   eps: 0.4134032200103066    steps: 407    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1775   the run_score was: 8.0   and mem length: 396687   eps: 0.41255776001030126    steps: 427    lr: 1.6000000000000003e-05     eval rl_reward: 5.38\n","For episode: 1776   the run_score was: 4.0   and mem length: 396930   eps: 0.4120766200102982    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1777   the run_score was: 5.0   and mem length: 397253   eps: 0.41143708001029416    steps: 323    lr: 1.6000000000000003e-05     eval rl_reward: 5.36\n","For episode: 1778   the run_score was: 5.0   and mem length: 397569   eps: 0.4108114000102902    steps: 316    lr: 1.6000000000000003e-05     eval rl_reward: 5.35\n","For episode: 1779   the run_score was: 9.0   and mem length: 398075   eps: 0.40980952001028387    steps: 506    lr: 1.6000000000000003e-05     eval rl_reward: 5.41\n","For episode: 1780   the run_score was: 6.0   and mem length: 398431   eps: 0.4091046400102794    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 5.43\n","For episode: 1781   the run_score was: 5.0   and mem length: 398722   eps: 0.40852846001027576    steps: 291    lr: 1.6000000000000003e-05     eval rl_reward: 5.44\n","For episode: 1782   the run_score was: 4.0   and mem length: 398965   eps: 0.4080473200102727    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 5.45\n","For episode: 1783   the run_score was: 5.0   and mem length: 399294   eps: 0.4073959000102686    steps: 329    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1784   the run_score was: 6.0   and mem length: 399625   eps: 0.40674052001026445    steps: 331    lr: 1.6000000000000003e-05     eval rl_reward: 5.48\n","For episode: 1785   the run_score was: 5.0   and mem length: 399933   eps: 0.4061306800102606    steps: 308    lr: 1.6000000000000003e-05     eval rl_reward: 5.47\n","For episode: 1786   the run_score was: 6.0   and mem length: 400277   eps: 0.4054495600102563    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 5.42\n","For episode: 1787   the run_score was: 9.0   and mem length: 400742   eps: 0.40452886001025046    steps: 465    lr: 6.400000000000001e-06     eval rl_reward: 5.47\n","For episode: 1788   the run_score was: 2.0   and mem length: 400942   eps: 0.40413286001024795    steps: 200    lr: 6.400000000000001e-06     eval rl_reward: 5.46\n","For episode: 1789   the run_score was: 7.0   and mem length: 401335   eps: 0.40335472001024303    steps: 393    lr: 6.400000000000001e-06     eval rl_reward: 5.49\n","For episode: 1790   the run_score was: 5.0   and mem length: 401660   eps: 0.40271122001023896    steps: 325    lr: 6.400000000000001e-06     eval rl_reward: 5.46\n","For episode: 1791   the run_score was: 4.0   and mem length: 401938   eps: 0.4021607800102355    steps: 278    lr: 6.400000000000001e-06     eval rl_reward: 5.46\n","For episode: 1792   the run_score was: 7.0   and mem length: 402363   eps: 0.40131928001023015    steps: 425    lr: 6.400000000000001e-06     eval rl_reward: 5.5\n","For episode: 1793   the run_score was: 5.0   and mem length: 402690   eps: 0.40067182001022605    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.49\n","For episode: 1794   the run_score was: 4.0   and mem length: 402986   eps: 0.40008574001022235    steps: 296    lr: 6.400000000000001e-06     eval rl_reward: 5.47\n","For episode: 1795   the run_score was: 8.0   and mem length: 403440   eps: 0.39918682001021666    steps: 454    lr: 6.400000000000001e-06     eval rl_reward: 5.5\n","For episode: 1796   the run_score was: 6.0   and mem length: 403781   eps: 0.3985116400102124    steps: 341    lr: 6.400000000000001e-06     eval rl_reward: 5.54\n","For episode: 1797   the run_score was: 4.0   and mem length: 404041   eps: 0.39799684001020913    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 1798   the run_score was: 4.0   and mem length: 404304   eps: 0.39747610001020584    steps: 263    lr: 6.400000000000001e-06     eval rl_reward: 5.5\n","For episode: 1799   the run_score was: 7.0   and mem length: 404730   eps: 0.3966326200102005    steps: 426    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 1800   the run_score was: 6.0   and mem length: 405033   eps: 0.3960326800101967    steps: 303    lr: 6.400000000000001e-06     eval rl_reward: 5.52\n","For episode: 1801   the run_score was: 5.0   and mem length: 405335   eps: 0.3954347200101929    steps: 302    lr: 6.400000000000001e-06     eval rl_reward: 5.54\n","For episode: 1802   the run_score was: 8.0   and mem length: 405761   eps: 0.3945912400101876    steps: 426    lr: 6.400000000000001e-06     eval rl_reward: 5.57\n","For episode: 1803   the run_score was: 8.0   and mem length: 406185   eps: 0.39375172001018227    steps: 424    lr: 6.400000000000001e-06     eval rl_reward: 5.58\n","For episode: 1804   the run_score was: 3.0   and mem length: 406399   eps: 0.3933280000101796    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.58\n","For episode: 1805   the run_score was: 12.0   and mem length: 406838   eps: 0.3924587800101741    steps: 439    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 1806   the run_score was: 4.0   and mem length: 407119   eps: 0.39190240001017057    steps: 281    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 1807   the run_score was: 6.0   and mem length: 407476   eps: 0.3911955400101661    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.61\n","For episode: 1808   the run_score was: 6.0   and mem length: 407849   eps: 0.3904570000101614    steps: 373    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 1809   the run_score was: 5.0   and mem length: 408154   eps: 0.3898531000101576    steps: 305    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 1810   the run_score was: 5.0   and mem length: 408484   eps: 0.38919970001015347    steps: 330    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 1811   the run_score was: 5.0   and mem length: 408772   eps: 0.38862946001014986    steps: 288    lr: 6.400000000000001e-06     eval rl_reward: 5.66\n","For episode: 1812   the run_score was: 8.0   and mem length: 409218   eps: 0.3877463800101443    steps: 446    lr: 6.400000000000001e-06     eval rl_reward: 5.66\n","For episode: 1813   the run_score was: 9.0   and mem length: 409674   eps: 0.38684350001013856    steps: 456    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 1814   the run_score was: 3.0   and mem length: 409886   eps: 0.3864237400101359    steps: 212    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 1815   the run_score was: 9.0   and mem length: 410340   eps: 0.3855248200101302    steps: 454    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 1816   the run_score was: 8.0   and mem length: 410795   eps: 0.3846239200101245    steps: 455    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 1817   the run_score was: 5.0   and mem length: 411124   eps: 0.3839725000101204    steps: 329    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 1818   the run_score was: 10.0   and mem length: 411617   eps: 0.3829963600101142    steps: 493    lr: 6.400000000000001e-06     eval rl_reward: 5.76\n","For episode: 1819   the run_score was: 5.0   and mem length: 411950   eps: 0.38233702001011005    steps: 333    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 1820   the run_score was: 4.0   and mem length: 412213   eps: 0.38181628001010676    steps: 263    lr: 6.400000000000001e-06     eval rl_reward: 5.76\n","For episode: 1821   the run_score was: 6.0   and mem length: 412552   eps: 0.3811450600101025    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.77\n","For episode: 1822   the run_score was: 8.0   and mem length: 412994   eps: 0.380269900010097    steps: 442    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 1823   the run_score was: 4.0   and mem length: 413237   eps: 0.37978876001009393    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.8\n","For episode: 1824   the run_score was: 6.0   and mem length: 413564   eps: 0.37914130001008983    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 1825   the run_score was: 10.0   and mem length: 414068   eps: 0.3781433800100835    steps: 504    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 1826   the run_score was: 5.0   and mem length: 414360   eps: 0.37756522001007986    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 1827   the run_score was: 5.0   and mem length: 414668   eps: 0.376955380010076    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.86\n","For episode: 1828   the run_score was: 4.0   and mem length: 414908   eps: 0.376480180010073    steps: 240    lr: 6.400000000000001e-06     eval rl_reward: 5.87\n","For episode: 1829   the run_score was: 4.0   and mem length: 415187   eps: 0.3759277600100695    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 1830   the run_score was: 9.0   and mem length: 415643   eps: 0.3750248800100638    steps: 456    lr: 6.400000000000001e-06     eval rl_reward: 5.93\n","For episode: 1831   the run_score was: 6.0   and mem length: 416041   eps: 0.3742368400100588    steps: 398    lr: 6.400000000000001e-06     eval rl_reward: 5.94\n","For episode: 1832   the run_score was: 4.0   and mem length: 416284   eps: 0.37375570001005576    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 1833   the run_score was: 9.0   and mem length: 416725   eps: 0.37288252001005023    steps: 441    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 1834   the run_score was: 5.0   and mem length: 417051   eps: 0.37223704001004615    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 1835   the run_score was: 6.0   and mem length: 417389   eps: 0.3715678000100419    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 1836   the run_score was: 10.0   and mem length: 417788   eps: 0.3707777800100369    steps: 399    lr: 6.400000000000001e-06     eval rl_reward: 5.98\n","For episode: 1837   the run_score was: 4.0   and mem length: 418033   eps: 0.37029268001003385    steps: 245    lr: 6.400000000000001e-06     eval rl_reward: 5.95\n","For episode: 1838   the run_score was: 8.0   and mem length: 418468   eps: 0.3694313800100284    steps: 435    lr: 6.400000000000001e-06     eval rl_reward: 5.98\n","For episode: 1839   the run_score was: 6.0   and mem length: 418812   eps: 0.3687502600100241    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 5.99\n","For episode: 1840   the run_score was: 14.0   and mem length: 419347   eps: 0.3676909600100174    steps: 535    lr: 6.400000000000001e-06     eval rl_reward: 6.07\n","For episode: 1841   the run_score was: 5.0   and mem length: 419638   eps: 0.36711478001001374    steps: 291    lr: 6.400000000000001e-06     eval rl_reward: 6.09\n","For episode: 1842   the run_score was: 8.0   and mem length: 420088   eps: 0.3662237800100081    steps: 450    lr: 6.400000000000001e-06     eval rl_reward: 6.13\n","For episode: 1843   the run_score was: 8.0   and mem length: 420508   eps: 0.36539218001000284    steps: 420    lr: 6.400000000000001e-06     eval rl_reward: 6.14\n","For episode: 1844   the run_score was: 4.0   and mem length: 420770   eps: 0.36487342000999956    steps: 262    lr: 6.400000000000001e-06     eval rl_reward: 6.14\n","For episode: 1845   the run_score was: 8.0   and mem length: 421195   eps: 0.36403192000999424    steps: 425    lr: 6.400000000000001e-06     eval rl_reward: 6.15\n","For episode: 1846   the run_score was: 6.0   and mem length: 421554   eps: 0.36332110000998974    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 6.14\n","For episode: 1847   the run_score was: 9.0   and mem length: 422036   eps: 0.3623667400099837    steps: 482    lr: 6.400000000000001e-06     eval rl_reward: 6.14\n","For episode: 1848   the run_score was: 4.0   and mem length: 422314   eps: 0.3618163000099802    steps: 278    lr: 6.400000000000001e-06     eval rl_reward: 6.11\n","For episode: 1849   the run_score was: 8.0   and mem length: 422756   eps: 0.3609411400099747    steps: 442    lr: 6.400000000000001e-06     eval rl_reward: 6.14\n","For episode: 1850   the run_score was: 3.0   and mem length: 423007   eps: 0.36044416000997154    steps: 251    lr: 6.400000000000001e-06     eval rl_reward: 6.11\n","For episode: 1851   the run_score was: 10.0   and mem length: 423503   eps: 0.3594620800099653    steps: 496    lr: 6.400000000000001e-06     eval rl_reward: 6.17\n","For episode: 1852   the run_score was: 7.0   and mem length: 423930   eps: 0.35861662000996    steps: 427    lr: 6.400000000000001e-06     eval rl_reward: 6.17\n","For episode: 1853   the run_score was: 3.0   and mem length: 424141   eps: 0.35819884000995733    steps: 211    lr: 6.400000000000001e-06     eval rl_reward: 6.1\n","For episode: 1854   the run_score was: 3.0   and mem length: 424371   eps: 0.35774344000995445    steps: 230    lr: 6.400000000000001e-06     eval rl_reward: 6.06\n","For episode: 1855   the run_score was: 4.0   and mem length: 424629   eps: 0.3572326000099512    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 6.04\n","For episode: 1856   the run_score was: 11.0   and mem length: 425111   eps: 0.3562782400099452    steps: 482    lr: 6.400000000000001e-06     eval rl_reward: 6.06\n","For episode: 1857   the run_score was: 15.0   and mem length: 425572   eps: 0.3553654600099394    steps: 461    lr: 6.400000000000001e-06     eval rl_reward: 6.17\n","For episode: 1858   the run_score was: 6.0   and mem length: 425936   eps: 0.35464474000993484    steps: 364    lr: 6.400000000000001e-06     eval rl_reward: 6.18\n","For episode: 1859   the run_score was: 7.0   and mem length: 426310   eps: 0.35390422000993016    steps: 374    lr: 6.400000000000001e-06     eval rl_reward: 6.19\n","For episode: 1860   the run_score was: 6.0   and mem length: 426636   eps: 0.3532587400099261    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 6.18\n","For episode: 1861   the run_score was: 6.0   and mem length: 427012   eps: 0.35251426000992137    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 6.18\n","For episode: 1862   the run_score was: 10.0   and mem length: 427518   eps: 0.351512380009915    steps: 506    lr: 6.400000000000001e-06     eval rl_reward: 6.2\n","For episode: 1863   the run_score was: 5.0   and mem length: 427845   eps: 0.35086492000991093    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 6.22\n","For episode: 1864   the run_score was: 5.0   and mem length: 428151   eps: 0.3502590400099071    steps: 306    lr: 6.400000000000001e-06     eval rl_reward: 6.23\n","For episode: 1865   the run_score was: 5.0   and mem length: 428461   eps: 0.3496452400099032    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 6.24\n","For episode: 1866   the run_score was: 7.0   and mem length: 428834   eps: 0.34890670000989854    steps: 373    lr: 6.400000000000001e-06     eval rl_reward: 6.25\n","For episode: 1867   the run_score was: 8.0   and mem length: 429297   eps: 0.34798996000989274    steps: 463    lr: 6.400000000000001e-06     eval rl_reward: 6.29\n","For episode: 1868   the run_score was: 9.0   and mem length: 429737   eps: 0.34711876000988723    steps: 440    lr: 6.400000000000001e-06     eval rl_reward: 6.32\n","For episode: 1869   the run_score was: 3.0   and mem length: 429968   eps: 0.34666138000988433    steps: 231    lr: 6.400000000000001e-06     eval rl_reward: 6.29\n","For episode: 1870   the run_score was: 6.0   and mem length: 430304   eps: 0.3459961000098801    steps: 336    lr: 6.400000000000001e-06     eval rl_reward: 6.29\n","For episode: 1871   the run_score was: 8.0   and mem length: 430724   eps: 0.34516450000987486    steps: 420    lr: 6.400000000000001e-06     eval rl_reward: 6.33\n","For episode: 1872   the run_score was: 7.0   and mem length: 431125   eps: 0.34437052000986984    steps: 401    lr: 6.400000000000001e-06     eval rl_reward: 6.35\n","For episode: 1873   the run_score was: 6.0   and mem length: 431475   eps: 0.34367752000986546    steps: 350    lr: 6.400000000000001e-06     eval rl_reward: 6.35\n","For episode: 1874   the run_score was: 9.0   and mem length: 431942   eps: 0.3427528600098596    steps: 467    lr: 6.400000000000001e-06     eval rl_reward: 6.36\n","For episode: 1875   the run_score was: 11.0   and mem length: 432330   eps: 0.34198462000985475    steps: 388    lr: 6.400000000000001e-06     eval rl_reward: 6.39\n","For episode: 1876   the run_score was: 7.0   and mem length: 432739   eps: 0.3411748000098496    steps: 409    lr: 6.400000000000001e-06     eval rl_reward: 6.42\n","For episode: 1877   the run_score was: 9.0   and mem length: 433227   eps: 0.3402085600098435    steps: 488    lr: 6.400000000000001e-06     eval rl_reward: 6.46\n","For episode: 1878   the run_score was: 7.0   and mem length: 433612   eps: 0.3394462600098387    steps: 385    lr: 6.400000000000001e-06     eval rl_reward: 6.48\n","For episode: 1879   the run_score was: 5.0   and mem length: 433921   eps: 0.3388344400098348    steps: 309    lr: 6.400000000000001e-06     eval rl_reward: 6.44\n","For episode: 1880   the run_score was: 8.0   and mem length: 434309   eps: 0.33806620000982995    steps: 388    lr: 6.400000000000001e-06     eval rl_reward: 6.46\n","For episode: 1881   the run_score was: 8.0   and mem length: 434713   eps: 0.3372662800098249    steps: 404    lr: 6.400000000000001e-06     eval rl_reward: 6.49\n","For episode: 1882   the run_score was: 6.0   and mem length: 435055   eps: 0.3365891200098206    steps: 342    lr: 6.400000000000001e-06     eval rl_reward: 6.51\n","For episode: 1883   the run_score was: 8.0   and mem length: 435498   eps: 0.33571198000981506    steps: 443    lr: 6.400000000000001e-06     eval rl_reward: 6.54\n","For episode: 1884   the run_score was: 7.0   and mem length: 435905   eps: 0.33490612000980996    steps: 407    lr: 6.400000000000001e-06     eval rl_reward: 6.55\n","For episode: 1885   the run_score was: 7.0   and mem length: 436290   eps: 0.33414382000980514    steps: 385    lr: 6.400000000000001e-06     eval rl_reward: 6.57\n","For episode: 1886   the run_score was: 5.0   and mem length: 436620   eps: 0.333490420009801    steps: 330    lr: 6.400000000000001e-06     eval rl_reward: 6.56\n","For episode: 1887   the run_score was: 4.0   and mem length: 436882   eps: 0.3329716600097977    steps: 262    lr: 6.400000000000001e-06     eval rl_reward: 6.51\n","For episode: 1888   the run_score was: 3.0   and mem length: 437094   eps: 0.33255190000979507    steps: 212    lr: 6.400000000000001e-06     eval rl_reward: 6.52\n","For episode: 1889   the run_score was: 5.0   and mem length: 437385   eps: 0.3319757200097914    steps: 291    lr: 6.400000000000001e-06     eval rl_reward: 6.5\n","For episode: 1890   the run_score was: 7.0   and mem length: 437792   eps: 0.3311698600097863    steps: 407    lr: 6.400000000000001e-06     eval rl_reward: 6.52\n","For episode: 1891   the run_score was: 9.0   and mem length: 438262   eps: 0.33023926000978043    steps: 470    lr: 6.400000000000001e-06     eval rl_reward: 6.57\n","For episode: 1892   the run_score was: 6.0   and mem length: 438621   eps: 0.32952844000977594    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 6.56\n","For episode: 1893   the run_score was: 11.0   and mem length: 439149   eps: 0.3284830000097693    steps: 528    lr: 6.400000000000001e-06     eval rl_reward: 6.62\n","For episode: 1894   the run_score was: 5.0   and mem length: 439473   eps: 0.32784148000976526    steps: 324    lr: 6.400000000000001e-06     eval rl_reward: 6.63\n","For episode: 1895   the run_score was: 13.0   and mem length: 440078   eps: 0.3266435800097577    steps: 605    lr: 6.400000000000001e-06     eval rl_reward: 6.68\n","For episode: 1896   the run_score was: 12.0   and mem length: 440657   eps: 0.32549716000975043    steps: 579    lr: 6.400000000000001e-06     eval rl_reward: 6.74\n","For episode: 1897   the run_score was: 5.0   and mem length: 440967   eps: 0.32488336000974655    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 6.75\n","For episode: 1898   the run_score was: 6.0   and mem length: 441311   eps: 0.32420224000974224    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 6.77\n","For episode: 1899   the run_score was: 6.0   and mem length: 441632   eps: 0.3235666600097382    steps: 321    lr: 6.400000000000001e-06     eval rl_reward: 6.76\n","For episode: 1900   the run_score was: 10.0   and mem length: 442079   eps: 0.3226816000097326    steps: 447    lr: 6.400000000000001e-06     eval rl_reward: 6.8\n","For episode: 1901   the run_score was: 5.0   and mem length: 442391   eps: 0.3220638400097287    steps: 312    lr: 6.400000000000001e-06     eval rl_reward: 6.8\n","For episode: 1902   the run_score was: 7.0   and mem length: 442760   eps: 0.3213332200097241    steps: 369    lr: 6.400000000000001e-06     eval rl_reward: 6.79\n","For episode: 1903   the run_score was: 9.0   and mem length: 443230   eps: 0.3204026200097182    steps: 470    lr: 6.400000000000001e-06     eval rl_reward: 6.8\n","For episode: 1904   the run_score was: 4.0   and mem length: 443473   eps: 0.31992148000971515    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 6.81\n","For episode: 1905   the run_score was: 5.0   and mem length: 443765   eps: 0.3193433200097115    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 6.74\n","For episode: 1906   the run_score was: 11.0   and mem length: 444338   eps: 0.3182087800097043    steps: 573    lr: 6.400000000000001e-06     eval rl_reward: 6.81\n","For episode: 1907   the run_score was: 6.0   and mem length: 444678   eps: 0.31753558000970006    steps: 340    lr: 6.400000000000001e-06     eval rl_reward: 6.81\n","For episode: 1908   the run_score was: 9.0   and mem length: 445133   eps: 0.31663468000969436    steps: 455    lr: 6.400000000000001e-06     eval rl_reward: 6.84\n","For episode: 1909   the run_score was: 4.0   and mem length: 445378   eps: 0.3161495800096913    steps: 245    lr: 6.400000000000001e-06     eval rl_reward: 6.83\n","For episode: 1910   the run_score was: 13.0   and mem length: 445892   eps: 0.31513186000968485    steps: 514    lr: 6.400000000000001e-06     eval rl_reward: 6.91\n","For episode: 1911   the run_score was: 11.0   and mem length: 446450   eps: 0.31402702000967786    steps: 558    lr: 6.400000000000001e-06     eval rl_reward: 6.97\n","For episode: 1912   the run_score was: 6.0   and mem length: 446797   eps: 0.3133399600096735    steps: 347    lr: 6.400000000000001e-06     eval rl_reward: 6.95\n","For episode: 1913   the run_score was: 5.0   and mem length: 447092   eps: 0.3127558600096698    steps: 295    lr: 6.400000000000001e-06     eval rl_reward: 6.91\n","For episode: 1914   the run_score was: 5.0   and mem length: 447400   eps: 0.31214602000966596    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 6.93\n","For episode: 1915   the run_score was: 14.0   and mem length: 447959   eps: 0.31103920000965896    steps: 559    lr: 6.400000000000001e-06     eval rl_reward: 6.98\n","For episode: 1916   the run_score was: 12.0   and mem length: 448535   eps: 0.30989872000965174    steps: 576    lr: 6.400000000000001e-06     eval rl_reward: 7.02\n","For episode: 1917   the run_score was: 11.0   and mem length: 449041   eps: 0.3088968400096454    steps: 506    lr: 6.400000000000001e-06     eval rl_reward: 7.08\n","For episode: 1918   the run_score was: 5.0   and mem length: 449371   eps: 0.30824344000964127    steps: 330    lr: 6.400000000000001e-06     eval rl_reward: 7.03\n","For episode: 1919   the run_score was: 4.0   and mem length: 449635   eps: 0.30772072000963796    steps: 264    lr: 6.400000000000001e-06     eval rl_reward: 7.02\n","For episode: 1920   the run_score was: 4.0   and mem length: 449892   eps: 0.30721186000963474    steps: 257    lr: 6.400000000000001e-06     eval rl_reward: 7.02\n","For episode: 1921   the run_score was: 12.0   and mem length: 450335   eps: 0.3063347200096292    steps: 443    lr: 6.400000000000001e-06     eval rl_reward: 7.08\n","For episode: 1922   the run_score was: 6.0   and mem length: 450713   eps: 0.30558628000962446    steps: 378    lr: 6.400000000000001e-06     eval rl_reward: 7.06\n","For episode: 1923   the run_score was: 6.0   and mem length: 451057   eps: 0.30490516000962015    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 7.08\n","For episode: 1924   the run_score was: 5.0   and mem length: 451370   eps: 0.3042854200096162    steps: 313    lr: 6.400000000000001e-06     eval rl_reward: 7.07\n","For episode: 1925   the run_score was: 13.0   and mem length: 452001   eps: 0.3030360400096083    steps: 631    lr: 6.400000000000001e-06     eval rl_reward: 7.1\n","For episode: 1926   the run_score was: 13.0   and mem length: 452624   eps: 0.3018025000096005    steps: 623    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1927   the run_score was: 5.0   and mem length: 452927   eps: 0.3012025600095967    steps: 303    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1928   the run_score was: 4.0   and mem length: 453167   eps: 0.3007273600095937    steps: 240    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1929   the run_score was: 6.0   and mem length: 453500   eps: 0.30006802000958954    steps: 333    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1930   the run_score was: 11.0   and mem length: 454015   eps: 0.2990483200095831    steps: 515    lr: 6.400000000000001e-06     eval rl_reward: 7.22\n","For episode: 1931   the run_score was: 4.0   and mem length: 454292   eps: 0.2984998600095796    steps: 277    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1932   the run_score was: 4.0   and mem length: 454534   eps: 0.2980207000095766    steps: 242    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1933   the run_score was: 12.0   and mem length: 455120   eps: 0.29686042000956925    steps: 586    lr: 6.400000000000001e-06     eval rl_reward: 7.23\n","For episode: 1934   the run_score was: 8.0   and mem length: 455547   eps: 0.2960149600095639    steps: 427    lr: 6.400000000000001e-06     eval rl_reward: 7.26\n","For episode: 1935   the run_score was: 6.0   and mem length: 455850   eps: 0.2954150200095601    steps: 303    lr: 6.400000000000001e-06     eval rl_reward: 7.26\n","For episode: 1936   the run_score was: 4.0   and mem length: 456113   eps: 0.2948942800095568    steps: 263    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1937   the run_score was: 5.0   and mem length: 456462   eps: 0.29420326000955244    steps: 349    lr: 6.400000000000001e-06     eval rl_reward: 7.21\n","For episode: 1938   the run_score was: 5.0   and mem length: 456794   eps: 0.2935459000095483    steps: 332    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1939   the run_score was: 10.0   and mem length: 457267   eps: 0.29260936000954235    steps: 473    lr: 6.400000000000001e-06     eval rl_reward: 7.22\n","For episode: 1940   the run_score was: 6.0   and mem length: 457645   eps: 0.2918609200095376    steps: 378    lr: 6.400000000000001e-06     eval rl_reward: 7.14\n","For episode: 1941   the run_score was: 6.0   and mem length: 457962   eps: 0.29123326000953365    steps: 317    lr: 6.400000000000001e-06     eval rl_reward: 7.15\n","For episode: 1942   the run_score was: 10.0   and mem length: 458489   eps: 0.29018980000952704    steps: 527    lr: 6.400000000000001e-06     eval rl_reward: 7.17\n","For episode: 1943   the run_score was: 5.0   and mem length: 458781   eps: 0.2896116400095234    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 7.14\n","For episode: 1944   the run_score was: 8.0   and mem length: 459193   eps: 0.2887958800095182    steps: 412    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1945   the run_score was: 5.0   and mem length: 459486   eps: 0.28821574000951455    steps: 293    lr: 6.400000000000001e-06     eval rl_reward: 7.15\n","For episode: 1946   the run_score was: 4.0   and mem length: 459783   eps: 0.28762768000951083    steps: 297    lr: 6.400000000000001e-06     eval rl_reward: 7.13\n","For episode: 1947   the run_score was: 2.0   and mem length: 459965   eps: 0.28726732000950855    steps: 182    lr: 6.400000000000001e-06     eval rl_reward: 7.06\n","For episode: 1948   the run_score was: 10.0   and mem length: 460292   eps: 0.28661986000950446    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 7.12\n","For episode: 1949   the run_score was: 8.0   and mem length: 460728   eps: 0.285756580009499    steps: 436    lr: 6.400000000000001e-06     eval rl_reward: 7.12\n","For episode: 1950   the run_score was: 11.0   and mem length: 461246   eps: 0.2847309400094925    steps: 518    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1951   the run_score was: 6.0   and mem length: 461607   eps: 0.284016160009488    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 7.16\n","For episode: 1952   the run_score was: 11.0   and mem length: 462010   eps: 0.28321822000948293    steps: 403    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1953   the run_score was: 10.0   and mem length: 462497   eps: 0.28225396000947683    steps: 487    lr: 6.400000000000001e-06     eval rl_reward: 7.27\n","For episode: 1954   the run_score was: 12.0   and mem length: 463132   eps: 0.2809966600094689    steps: 635    lr: 6.400000000000001e-06     eval rl_reward: 7.36\n","For episode: 1955   the run_score was: 4.0   and mem length: 463392   eps: 0.2804818600094656    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 7.36\n","For episode: 1956   the run_score was: 9.0   and mem length: 463848   eps: 0.2795789800094599    steps: 456    lr: 6.400000000000001e-06     eval rl_reward: 7.34\n","For episode: 1957   the run_score was: 5.0   and mem length: 464158   eps: 0.278965180009456    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 7.24\n","For episode: 1958   the run_score was: 6.0   and mem length: 464496   eps: 0.2782959400094518    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 7.24\n","For episode: 1959   the run_score was: 9.0   and mem length: 464974   eps: 0.2773495000094458    steps: 478    lr: 6.400000000000001e-06     eval rl_reward: 7.26\n","For episode: 1960   the run_score was: 9.0   and mem length: 465435   eps: 0.27643672000944003    steps: 461    lr: 6.400000000000001e-06     eval rl_reward: 7.29\n","For episode: 1961   the run_score was: 9.0   and mem length: 465890   eps: 0.27553582000943433    steps: 455    lr: 6.400000000000001e-06     eval rl_reward: 7.32\n","For episode: 1962   the run_score was: 8.0   and mem length: 466333   eps: 0.2746586800094288    steps: 443    lr: 6.400000000000001e-06     eval rl_reward: 7.3\n","For episode: 1963   the run_score was: 6.0   and mem length: 466671   eps: 0.27398944000942455    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 7.31\n","For episode: 1964   the run_score was: 9.0   and mem length: 466998   eps: 0.27334198000942045    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 7.35\n","For episode: 1965   the run_score was: 6.0   and mem length: 467351   eps: 0.272643040009416    steps: 353    lr: 6.400000000000001e-06     eval rl_reward: 7.36\n","For episode: 1966   the run_score was: 4.0   and mem length: 467631   eps: 0.2720886400094125    steps: 280    lr: 6.400000000000001e-06     eval rl_reward: 7.33\n","For episode: 1967   the run_score was: 4.0   and mem length: 467893   eps: 0.27156988000940924    steps: 262    lr: 6.400000000000001e-06     eval rl_reward: 7.29\n","For episode: 1968   the run_score was: 5.0   and mem length: 468222   eps: 0.2709184600094051    steps: 329    lr: 6.400000000000001e-06     eval rl_reward: 7.25\n","For episode: 1969   the run_score was: 9.0   and mem length: 468655   eps: 0.2700611200093997    steps: 433    lr: 6.400000000000001e-06     eval rl_reward: 7.31\n","For episode: 1970   the run_score was: 8.0   and mem length: 469107   eps: 0.26916616000939403    steps: 452    lr: 6.400000000000001e-06     eval rl_reward: 7.33\n","For episode: 1971   the run_score was: 7.0   and mem length: 469510   eps: 0.268368220009389    steps: 403    lr: 6.400000000000001e-06     eval rl_reward: 7.32\n","For episode: 1972   the run_score was: 9.0   and mem length: 469965   eps: 0.2674673200093833    steps: 455    lr: 6.400000000000001e-06     eval rl_reward: 7.34\n","For episode: 1973   the run_score was: 3.0   and mem length: 470196   eps: 0.2670099400093804    steps: 231    lr: 6.400000000000001e-06     eval rl_reward: 7.31\n","For episode: 1974   the run_score was: 5.0   and mem length: 470506   eps: 0.2663961400093765    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 7.27\n","For episode: 1975   the run_score was: 10.0   and mem length: 470882   eps: 0.2656516600093718    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 7.26\n","For episode: 1976   the run_score was: 7.0   and mem length: 471249   eps: 0.2649250000093672    steps: 367    lr: 6.400000000000001e-06     eval rl_reward: 7.26\n","For episode: 1977   the run_score was: 4.0   and mem length: 471509   eps: 0.26441020000936394    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 7.21\n","For episode: 1978   the run_score was: 5.0   and mem length: 471835   eps: 0.26376472000935985    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 7.19\n","For episode: 1979   the run_score was: 6.0   and mem length: 472173   eps: 0.2630954800093556    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1980   the run_score was: 6.0   and mem length: 472517   eps: 0.2624143600093513    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 7.18\n","For episode: 1981   the run_score was: 10.0   and mem length: 472998   eps: 0.2614619800093453    steps: 481    lr: 6.400000000000001e-06     eval rl_reward: 7.2\n","For episode: 1982   the run_score was: 10.0   and mem length: 473536   eps: 0.26039674000933855    steps: 538    lr: 6.400000000000001e-06     eval rl_reward: 7.24\n","For episode: 1983   the run_score was: 7.0   and mem length: 473895   eps: 0.25968592000933405    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 7.23\n","For episode: 1984   the run_score was: 7.0   and mem length: 474270   eps: 0.25894342000932935    steps: 375    lr: 6.400000000000001e-06     eval rl_reward: 7.23\n","For episode: 1985   the run_score was: 9.0   and mem length: 474709   eps: 0.25807420000932385    steps: 439    lr: 6.400000000000001e-06     eval rl_reward: 7.25\n","For episode: 1986   the run_score was: 7.0   and mem length: 475101   eps: 0.25729804000931894    steps: 392    lr: 6.400000000000001e-06     eval rl_reward: 7.27\n","For episode: 1987   the run_score was: 12.0   and mem length: 475565   eps: 0.2563793200093131    steps: 464    lr: 6.400000000000001e-06     eval rl_reward: 7.35\n","For episode: 1988   the run_score was: 7.0   and mem length: 475962   eps: 0.25559326000930815    steps: 397    lr: 6.400000000000001e-06     eval rl_reward: 7.39\n","For episode: 1989   the run_score was: 7.0   and mem length: 476355   eps: 0.25481512000930323    steps: 393    lr: 6.400000000000001e-06     eval rl_reward: 7.41\n","For episode: 1990   the run_score was: 7.0   and mem length: 476765   eps: 0.2540033200092981    steps: 410    lr: 6.400000000000001e-06     eval rl_reward: 7.41\n","For episode: 1991   the run_score was: 6.0   and mem length: 477124   eps: 0.2532925000092936    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 7.38\n","For episode: 1992   the run_score was: 8.0   and mem length: 477559   eps: 0.25243120000928815    steps: 435    lr: 6.400000000000001e-06     eval rl_reward: 7.4\n","For episode: 1993   the run_score was: 6.0   and mem length: 477878   eps: 0.25179958000928415    steps: 319    lr: 6.400000000000001e-06     eval rl_reward: 7.35\n","For episode: 1994   the run_score was: 7.0   and mem length: 478238   eps: 0.25108678000927964    steps: 360    lr: 6.400000000000001e-06     eval rl_reward: 7.37\n","For episode: 1995   the run_score was: 8.0   and mem length: 478695   eps: 0.2501819200092739    steps: 457    lr: 6.400000000000001e-06     eval rl_reward: 7.32\n","For episode: 1996   the run_score was: 7.0   and mem length: 479099   eps: 0.24938200000926886    steps: 404    lr: 6.400000000000001e-06     eval rl_reward: 7.27\n","For episode: 1997   the run_score was: 8.0   and mem length: 479531   eps: 0.24852664000926344    steps: 432    lr: 6.400000000000001e-06     eval rl_reward: 7.3\n","For episode: 1998   the run_score was: 4.0   and mem length: 479794   eps: 0.24800590000926015    steps: 263    lr: 6.400000000000001e-06     eval rl_reward: 7.28\n","For episode: 1999   the run_score was: 11.0   and mem length: 480366   eps: 0.24687334000925298    steps: 572    lr: 6.400000000000001e-06     eval rl_reward: 7.33\n","For episode: 2000   the run_score was: 5.0   and mem length: 480674   eps: 0.24626350000924913    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 7.28\n","For episode: 2001   the run_score was: 7.0   and mem length: 481098   eps: 0.24542398000924381    steps: 424    lr: 6.400000000000001e-06     eval rl_reward: 7.3\n","For episode: 2002   the run_score was: 9.0   and mem length: 481558   eps: 0.24451318000923805    steps: 460    lr: 6.400000000000001e-06     eval rl_reward: 7.32\n","For episode: 2003   the run_score was: 10.0   and mem length: 482040   eps: 0.243558820009232    steps: 482    lr: 6.400000000000001e-06     eval rl_reward: 7.33\n","For episode: 2004   the run_score was: 8.0   and mem length: 482475   eps: 0.24269752000922656    steps: 435    lr: 6.400000000000001e-06     eval rl_reward: 7.37\n","For episode: 2005   the run_score was: 14.0   and mem length: 483028   eps: 0.24160258000921964    steps: 553    lr: 6.400000000000001e-06     eval rl_reward: 7.46\n","For episode: 2006   the run_score was: 7.0   and mem length: 483410   eps: 0.24084622000921485    steps: 382    lr: 6.400000000000001e-06     eval rl_reward: 7.42\n","For episode: 2007   the run_score was: 5.0   and mem length: 483703   eps: 0.24026608000921118    steps: 293    lr: 6.400000000000001e-06     eval rl_reward: 7.41\n","For episode: 2008   the run_score was: 13.0   and mem length: 484297   eps: 0.23908996000920374    steps: 594    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2009   the run_score was: 11.0   and mem length: 484852   eps: 0.2379910600091968    steps: 555    lr: 6.400000000000001e-06     eval rl_reward: 7.52\n","For episode: 2010   the run_score was: 11.0   and mem length: 485391   eps: 0.23692384000919003    steps: 539    lr: 6.400000000000001e-06     eval rl_reward: 7.5\n","For episode: 2011   the run_score was: 6.0   and mem length: 485730   eps: 0.2362526200091858    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2012   the run_score was: 4.0   and mem length: 485990   eps: 0.23573782000918253    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 7.43\n","For episode: 2013   the run_score was: 6.0   and mem length: 486297   eps: 0.23512996000917868    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 7.44\n","For episode: 2014   the run_score was: 13.0   and mem length: 486834   eps: 0.23406670000917196    steps: 537    lr: 6.400000000000001e-06     eval rl_reward: 7.52\n","For episode: 2015   the run_score was: 7.0   and mem length: 487227   eps: 0.23328856000916703    steps: 393    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2016   the run_score was: 7.0   and mem length: 487558   eps: 0.2326331800091629    steps: 331    lr: 6.400000000000001e-06     eval rl_reward: 7.4\n","For episode: 2017   the run_score was: 5.0   and mem length: 487867   eps: 0.23202136000915902    steps: 309    lr: 6.400000000000001e-06     eval rl_reward: 7.34\n","For episode: 2018   the run_score was: 9.0   and mem length: 488193   eps: 0.23137588000915493    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 7.38\n","For episode: 2019   the run_score was: 6.0   and mem length: 488532   eps: 0.23070466000915069    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 7.4\n","For episode: 2020   the run_score was: 9.0   and mem length: 488987   eps: 0.229803760009145    steps: 455    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2021   the run_score was: 8.0   and mem length: 489424   eps: 0.2289385000091395    steps: 437    lr: 6.400000000000001e-06     eval rl_reward: 7.41\n","For episode: 2022   the run_score was: 7.0   and mem length: 489794   eps: 0.22820590000913488    steps: 370    lr: 6.400000000000001e-06     eval rl_reward: 7.42\n","For episode: 2023   the run_score was: 11.0   and mem length: 490352   eps: 0.2271010600091279    steps: 558    lr: 6.400000000000001e-06     eval rl_reward: 7.47\n","For episode: 2024   the run_score was: 7.0   and mem length: 490761   eps: 0.22629124000912276    steps: 409    lr: 6.400000000000001e-06     eval rl_reward: 7.49\n","For episode: 2025   the run_score was: 8.0   and mem length: 491214   eps: 0.2253943000091171    steps: 453    lr: 6.400000000000001e-06     eval rl_reward: 7.44\n","For episode: 2026   the run_score was: 4.0   and mem length: 491493   eps: 0.2248418800091136    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 7.35\n","For episode: 2027   the run_score was: 8.0   and mem length: 491950   eps: 0.22393702000910787    steps: 457    lr: 6.400000000000001e-06     eval rl_reward: 7.38\n","For episode: 2028   the run_score was: 5.0   and mem length: 492244   eps: 0.22335490000910418    steps: 294    lr: 6.400000000000001e-06     eval rl_reward: 7.39\n","For episode: 2029   the run_score was: 9.0   and mem length: 492731   eps: 0.22239064000909808    steps: 487    lr: 6.400000000000001e-06     eval rl_reward: 7.42\n","For episode: 2030   the run_score was: 5.0   and mem length: 493041   eps: 0.2217768400090942    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 7.36\n","For episode: 2031   the run_score was: 10.0   and mem length: 493539   eps: 0.22079080000908796    steps: 498    lr: 6.400000000000001e-06     eval rl_reward: 7.42\n","For episode: 2032   the run_score was: 7.0   and mem length: 493936   eps: 0.220004740009083    steps: 397    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2033   the run_score was: 12.0   and mem length: 494520   eps: 0.21884842000907567    steps: 584    lr: 6.400000000000001e-06     eval rl_reward: 7.45\n","For episode: 2034   the run_score was: 5.0   and mem length: 494848   eps: 0.21819898000907156    steps: 328    lr: 6.400000000000001e-06     eval rl_reward: 7.42\n","For episode: 2035   the run_score was: 10.0   and mem length: 495353   eps: 0.21719908000906524    steps: 505    lr: 6.400000000000001e-06     eval rl_reward: 7.46\n","For episode: 2036   the run_score was: 6.0   and mem length: 495690   eps: 0.21653182000906102    steps: 337    lr: 6.400000000000001e-06     eval rl_reward: 7.48\n","For episode: 2037   the run_score was: 10.0   and mem length: 496207   eps: 0.21550816000905454    steps: 517    lr: 6.400000000000001e-06     eval rl_reward: 7.53\n","For episode: 2038   the run_score was: 8.0   and mem length: 496628   eps: 0.21467458000904927    steps: 421    lr: 6.400000000000001e-06     eval rl_reward: 7.56\n","For episode: 2039   the run_score was: 11.0   and mem length: 497181   eps: 0.21357964000904234    steps: 553    lr: 6.400000000000001e-06     eval rl_reward: 7.57\n","For episode: 2040   the run_score was: 9.0   and mem length: 497637   eps: 0.21267676000903663    steps: 456    lr: 6.400000000000001e-06     eval rl_reward: 7.6\n","For episode: 2041   the run_score was: 6.0   and mem length: 497979   eps: 0.21199960000903234    steps: 342    lr: 6.400000000000001e-06     eval rl_reward: 7.6\n","For episode: 2042   the run_score was: 11.0   and mem length: 498490   eps: 0.21098782000902594    steps: 511    lr: 6.400000000000001e-06     eval rl_reward: 7.61\n","For episode: 2043   the run_score was: 5.0   and mem length: 498780   eps: 0.2104136200090223    steps: 290    lr: 6.400000000000001e-06     eval rl_reward: 7.61\n","For episode: 2044   the run_score was: 12.0   and mem length: 499338   eps: 0.20930878000901532    steps: 558    lr: 6.400000000000001e-06     eval rl_reward: 7.65\n","For episode: 2045   the run_score was: 6.0   and mem length: 499676   eps: 0.20863954000901108    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 7.66\n","For episode: 2046   the run_score was: 13.0   and mem length: 500306   eps: 0.2073921400090032    steps: 630    lr: 2.560000000000001e-06     eval rl_reward: 7.75\n","For episode: 2047   the run_score was: 9.0   and mem length: 500760   eps: 0.2064932200089975    steps: 454    lr: 2.560000000000001e-06     eval rl_reward: 7.82\n","For episode: 2048   the run_score was: 10.0   and mem length: 501312   eps: 0.2054002600089906    steps: 552    lr: 2.560000000000001e-06     eval rl_reward: 7.82\n","For episode: 2049   the run_score was: 9.0   and mem length: 501782   eps: 0.2044696600089847    steps: 470    lr: 2.560000000000001e-06     eval rl_reward: 7.83\n","For episode: 2050   the run_score was: 7.0   and mem length: 502208   eps: 0.20362618000897936    steps: 426    lr: 2.560000000000001e-06     eval rl_reward: 7.79\n","For episode: 2051   the run_score was: 10.0   and mem length: 502602   eps: 0.20284606000897443    steps: 394    lr: 2.560000000000001e-06     eval rl_reward: 7.83\n","For episode: 2052   the run_score was: 12.0   and mem length: 503095   eps: 0.20186992000896825    steps: 493    lr: 2.560000000000001e-06     eval rl_reward: 7.84\n","For episode: 2053   the run_score was: 18.0   and mem length: 503763   eps: 0.20054728000895988    steps: 668    lr: 2.560000000000001e-06     eval rl_reward: 7.92\n","For episode: 2054   the run_score was: 11.0   and mem length: 504376   eps: 0.1993335400089522    steps: 613    lr: 2.560000000000001e-06     eval rl_reward: 7.91\n","For episode: 2055   the run_score was: 10.0   and mem length: 504879   eps: 0.1983376000089459    steps: 503    lr: 2.560000000000001e-06     eval rl_reward: 7.97\n","For episode: 2056   the run_score was: 14.0   and mem length: 505392   eps: 0.19732186000893948    steps: 513    lr: 2.560000000000001e-06     eval rl_reward: 8.02\n","For episode: 2057   the run_score was: 9.0   and mem length: 505893   eps: 0.1963298800089332    steps: 501    lr: 2.560000000000001e-06     eval rl_reward: 8.06\n","For episode: 2058   the run_score was: 8.0   and mem length: 506311   eps: 0.19550224000892796    steps: 418    lr: 2.560000000000001e-06     eval rl_reward: 8.08\n","For episode: 2059   the run_score was: 14.0   and mem length: 506987   eps: 0.1941637600089195    steps: 676    lr: 2.560000000000001e-06     eval rl_reward: 8.13\n","For episode: 2060   the run_score was: 6.0   and mem length: 507347   eps: 0.19345096000891498    steps: 360    lr: 2.560000000000001e-06     eval rl_reward: 8.1\n","For episode: 2061   the run_score was: 6.0   and mem length: 507727   eps: 0.19269856000891022    steps: 380    lr: 2.560000000000001e-06     eval rl_reward: 8.07\n","For episode: 2062   the run_score was: 10.0   and mem length: 508233   eps: 0.19169668000890389    steps: 506    lr: 2.560000000000001e-06     eval rl_reward: 8.09\n","For episode: 2063   the run_score was: 10.0   and mem length: 508759   eps: 0.1906552000088973    steps: 526    lr: 2.560000000000001e-06     eval rl_reward: 8.13\n","For episode: 2064   the run_score was: 5.0   and mem length: 509087   eps: 0.1900057600088932    steps: 328    lr: 2.560000000000001e-06     eval rl_reward: 8.09\n","For episode: 2065   the run_score was: 7.0   and mem length: 509494   eps: 0.1891999000088881    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 8.1\n","For episode: 2066   the run_score was: 7.0   and mem length: 509886   eps: 0.18842374000888318    steps: 392    lr: 2.560000000000001e-06     eval rl_reward: 8.13\n","For episode: 2067   the run_score was: 7.0   and mem length: 510295   eps: 0.18761392000887805    steps: 409    lr: 2.560000000000001e-06     eval rl_reward: 8.16\n","For episode: 2068   the run_score was: 7.0   and mem length: 510686   eps: 0.18683974000887316    steps: 391    lr: 2.560000000000001e-06     eval rl_reward: 8.18\n","For episode: 2069   the run_score was: 6.0   and mem length: 511037   eps: 0.18614476000886876    steps: 351    lr: 2.560000000000001e-06     eval rl_reward: 8.15\n","For episode: 2070   the run_score was: 10.0   and mem length: 511508   eps: 0.18521218000886286    steps: 471    lr: 2.560000000000001e-06     eval rl_reward: 8.17\n","For episode: 2071   the run_score was: 11.0   and mem length: 512037   eps: 0.18416476000885623    steps: 529    lr: 2.560000000000001e-06     eval rl_reward: 8.21\n","For episode: 2072   the run_score was: 9.0   and mem length: 512490   eps: 0.18326782000885056    steps: 453    lr: 2.560000000000001e-06     eval rl_reward: 8.21\n","For episode: 2073   the run_score was: 6.0   and mem length: 512831   eps: 0.18259264000884629    steps: 341    lr: 2.560000000000001e-06     eval rl_reward: 8.24\n","For episode: 2074   the run_score was: 9.0   and mem length: 513288   eps: 0.18168778000884056    steps: 457    lr: 2.560000000000001e-06     eval rl_reward: 8.28\n","For episode: 2075   the run_score was: 5.0   and mem length: 513615   eps: 0.18104032000883646    steps: 327    lr: 2.560000000000001e-06     eval rl_reward: 8.23\n","For episode: 2076   the run_score was: 12.0   and mem length: 514124   eps: 0.1800325000088301    steps: 509    lr: 2.560000000000001e-06     eval rl_reward: 8.28\n","For episode: 2077   the run_score was: 7.0   and mem length: 514507   eps: 0.1792741600088253    steps: 383    lr: 2.560000000000001e-06     eval rl_reward: 8.31\n","For episode: 2078   the run_score was: 5.0   and mem length: 514814   eps: 0.17866630000882144    steps: 307    lr: 2.560000000000001e-06     eval rl_reward: 8.31\n","For episode: 2079   the run_score was: 6.0   and mem length: 515172   eps: 0.17795746000881696    steps: 358    lr: 2.560000000000001e-06     eval rl_reward: 8.31\n","For episode: 2080   the run_score was: 12.0   and mem length: 515669   eps: 0.17697340000881073    steps: 497    lr: 2.560000000000001e-06     eval rl_reward: 8.37\n","For episode: 2081   the run_score was: 8.0   and mem length: 516055   eps: 0.1762091200088059    steps: 386    lr: 2.560000000000001e-06     eval rl_reward: 8.35\n","For episode: 2082   the run_score was: 17.0   and mem length: 516774   eps: 0.1747855000087969    steps: 719    lr: 2.560000000000001e-06     eval rl_reward: 8.42\n","For episode: 2083   the run_score was: 15.0   and mem length: 517344   eps: 0.17365690000878975    steps: 570    lr: 2.560000000000001e-06     eval rl_reward: 8.5\n","For episode: 2084   the run_score was: 4.0   and mem length: 517605   eps: 0.17314012000878648    steps: 261    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2085   the run_score was: 11.0   and mem length: 518159   eps: 0.17204320000877954    steps: 554    lr: 2.560000000000001e-06     eval rl_reward: 8.49\n","For episode: 2086   the run_score was: 12.0   and mem length: 518623   eps: 0.17112448000877373    steps: 464    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2087   the run_score was: 10.0   and mem length: 519181   eps: 0.17001964000876674    steps: 558    lr: 2.560000000000001e-06     eval rl_reward: 8.52\n","For episode: 2088   the run_score was: 4.0   and mem length: 519462   eps: 0.16946326000876322    steps: 281    lr: 2.560000000000001e-06     eval rl_reward: 8.49\n","For episode: 2089   the run_score was: 4.0   and mem length: 519722   eps: 0.16894846000875996    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 8.46\n","For episode: 2090   the run_score was: 6.0   and mem length: 520062   eps: 0.1682752600087557    steps: 340    lr: 2.560000000000001e-06     eval rl_reward: 8.45\n","For episode: 2091   the run_score was: 6.0   and mem length: 520425   eps: 0.16755652000875115    steps: 363    lr: 2.560000000000001e-06     eval rl_reward: 8.45\n","For episode: 2092   the run_score was: 10.0   and mem length: 520915   eps: 0.16658632000874501    steps: 490    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2093   the run_score was: 6.0   and mem length: 521289   eps: 0.16584580000874033    steps: 374    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2094   the run_score was: 5.0   and mem length: 521640   eps: 0.16515082000873593    steps: 351    lr: 2.560000000000001e-06     eval rl_reward: 8.45\n","For episode: 2095   the run_score was: 6.0   and mem length: 521966   eps: 0.16450534000873185    steps: 326    lr: 2.560000000000001e-06     eval rl_reward: 8.43\n","For episode: 2096   the run_score was: 8.0   and mem length: 522399   eps: 0.16364800000872642    steps: 433    lr: 2.560000000000001e-06     eval rl_reward: 8.44\n","For episode: 2097   the run_score was: 11.0   and mem length: 522962   eps: 0.16253326000871937    steps: 563    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2098   the run_score was: 11.0   and mem length: 523484   eps: 0.16149970000871283    steps: 522    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2099   the run_score was: 10.0   and mem length: 524001   eps: 0.16047604000870636    steps: 517    lr: 2.560000000000001e-06     eval rl_reward: 8.53\n","For episode: 2100   the run_score was: 9.0   and mem length: 524469   eps: 0.1595494000087005    steps: 468    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2101   the run_score was: 7.0   and mem length: 524803   eps: 0.1588880800086963    steps: 334    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2102   the run_score was: 9.0   and mem length: 525289   eps: 0.15792580000869022    steps: 486    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2103   the run_score was: 8.0   and mem length: 525704   eps: 0.15710410000868502    steps: 415    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2104   the run_score was: 10.0   and mem length: 526171   eps: 0.15617944000867917    steps: 467    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2105   the run_score was: 14.0   and mem length: 526743   eps: 0.155046880008672    steps: 572    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2106   the run_score was: 9.0   and mem length: 527230   eps: 0.1540826200086659    steps: 487    lr: 2.560000000000001e-06     eval rl_reward: 8.59\n","For episode: 2107   the run_score was: 8.0   and mem length: 527638   eps: 0.1532747800086608    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 8.62\n","For episode: 2108   the run_score was: 6.0   and mem length: 528000   eps: 0.15255802000865626    steps: 362    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2109   the run_score was: 11.0   and mem length: 528562   eps: 0.15144526000864922    steps: 562    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2110   the run_score was: 4.0   and mem length: 528807   eps: 0.15096016000864615    steps: 245    lr: 2.560000000000001e-06     eval rl_reward: 8.48\n","For episode: 2111   the run_score was: 11.0   and mem length: 529389   eps: 0.14980780000863886    steps: 582    lr: 2.560000000000001e-06     eval rl_reward: 8.53\n","For episode: 2112   the run_score was: 12.0   and mem length: 529869   eps: 0.14885740000863285    steps: 480    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2113   the run_score was: 9.0   and mem length: 530320   eps: 0.1479644200086272    steps: 451    lr: 2.560000000000001e-06     eval rl_reward: 8.64\n","For episode: 2114   the run_score was: 5.0   and mem length: 530631   eps: 0.1473486400086233    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2115   the run_score was: 7.0   and mem length: 531015   eps: 0.1465883200086185    steps: 384    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2116   the run_score was: 5.0   and mem length: 531304   eps: 0.14601610000861487    steps: 289    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2117   the run_score was: 7.0   and mem length: 531692   eps: 0.14524786000861    steps: 388    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2118   the run_score was: 8.0   and mem length: 532098   eps: 0.14444398000860492    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2119   the run_score was: 7.0   and mem length: 532505   eps: 0.14363812000859982    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2120   the run_score was: 9.0   and mem length: 532960   eps: 0.14273722000859412    steps: 455    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2121   the run_score was: 6.0   and mem length: 533282   eps: 0.1420996600085901    steps: 322    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2122   the run_score was: 7.0   and mem length: 533657   eps: 0.1413571600085854    steps: 375    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2123   the run_score was: 11.0   and mem length: 534186   eps: 0.14030974000857876    steps: 529    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2124   the run_score was: 7.0   and mem length: 534565   eps: 0.13955932000857402    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2125   the run_score was: 10.0   and mem length: 535076   eps: 0.13854754000856762    steps: 511    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2126   the run_score was: 7.0   and mem length: 535478   eps: 0.13775158000856258    steps: 402    lr: 2.560000000000001e-06     eval rl_reward: 8.59\n","For episode: 2127   the run_score was: 9.0   and mem length: 535997   eps: 0.13672396000855608    steps: 519    lr: 2.560000000000001e-06     eval rl_reward: 8.6\n","For episode: 2128   the run_score was: 6.0   and mem length: 536333   eps: 0.13605868000855187    steps: 336    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2129   the run_score was: 9.0   and mem length: 536806   eps: 0.13512214000854594    steps: 473    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2130   the run_score was: 13.0   and mem length: 537326   eps: 0.13409254000853943    steps: 520    lr: 2.560000000000001e-06     eval rl_reward: 8.69\n","For episode: 2131   the run_score was: 8.0   and mem length: 537766   eps: 0.13322134000853392    steps: 440    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2132   the run_score was: 8.0   and mem length: 538204   eps: 0.13235410000852843    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 8.68\n","For episode: 2133   the run_score was: 4.0   and mem length: 538482   eps: 0.13180366000852495    steps: 278    lr: 2.560000000000001e-06     eval rl_reward: 8.6\n","For episode: 2134   the run_score was: 10.0   and mem length: 538966   eps: 0.13084534000851888    steps: 484    lr: 2.560000000000001e-06     eval rl_reward: 8.65\n","For episode: 2135   the run_score was: 9.0   and mem length: 539492   eps: 0.1298038600085123    steps: 526    lr: 2.560000000000001e-06     eval rl_reward: 8.64\n","For episode: 2136   the run_score was: 5.0   and mem length: 539782   eps: 0.12922966000850866    steps: 290    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2137   the run_score was: 15.0   and mem length: 540381   eps: 0.12804364000850116    steps: 599    lr: 2.560000000000001e-06     eval rl_reward: 8.68\n","For episode: 2138   the run_score was: 7.0   and mem length: 540773   eps: 0.12726748000849625    steps: 392    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2139   the run_score was: 5.0   and mem length: 541098   eps: 0.12662398000849218    steps: 325    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2140   the run_score was: 9.0   and mem length: 541584   eps: 0.1256617000084861    steps: 486    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2141   the run_score was: 14.0   and mem length: 542110   eps: 0.12462022000848216    steps: 526    lr: 2.560000000000001e-06     eval rl_reward: 8.69\n","For episode: 2142   the run_score was: 10.0   and mem length: 542602   eps: 0.12364606000848283    steps: 492    lr: 2.560000000000001e-06     eval rl_reward: 8.68\n","For episode: 2143   the run_score was: 9.0   and mem length: 543040   eps: 0.12277882000848342    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2144   the run_score was: 10.0   and mem length: 543564   eps: 0.12174130000848413    steps: 524    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2145   the run_score was: 11.0   and mem length: 544134   eps: 0.1206127000084849    steps: 570    lr: 2.560000000000001e-06     eval rl_reward: 8.75\n","For episode: 2146   the run_score was: 11.0   and mem length: 544692   eps: 0.11950786000848565    steps: 558    lr: 2.560000000000001e-06     eval rl_reward: 8.73\n","For episode: 2147   the run_score was: 7.0   and mem length: 545081   eps: 0.11873764000848618    steps: 389    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2148   the run_score was: 11.0   and mem length: 545571   eps: 0.11776744000848684    steps: 490    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2149   the run_score was: 8.0   and mem length: 545977   eps: 0.11696356000848739    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2150   the run_score was: 8.0   and mem length: 546418   eps: 0.11609038000848798    steps: 441    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2151   the run_score was: 8.0   and mem length: 546831   eps: 0.11527264000848854    steps: 413    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2152   the run_score was: 7.0   and mem length: 547183   eps: 0.11457568000848901    steps: 352    lr: 2.560000000000001e-06     eval rl_reward: 8.65\n","For episode: 2153   the run_score was: 6.0   and mem length: 547535   eps: 0.11387872000848949    steps: 352    lr: 2.560000000000001e-06     eval rl_reward: 8.53\n","For episode: 2154   the run_score was: 15.0   and mem length: 548054   eps: 0.11285110000849019    steps: 519    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2155   the run_score was: 6.0   and mem length: 548376   eps: 0.11221354000849063    steps: 322    lr: 2.560000000000001e-06     eval rl_reward: 8.53\n","For episode: 2156   the run_score was: 5.0   and mem length: 548669   eps: 0.11163340000849102    steps: 293    lr: 2.560000000000001e-06     eval rl_reward: 8.44\n","For episode: 2157   the run_score was: 7.0   and mem length: 549044   eps: 0.11089090000849153    steps: 375    lr: 2.560000000000001e-06     eval rl_reward: 8.42\n","For episode: 2158   the run_score was: 6.0   and mem length: 549367   eps: 0.11025136000849196    steps: 323    lr: 2.560000000000001e-06     eval rl_reward: 8.4\n","For episode: 2159   the run_score was: 8.0   and mem length: 549806   eps: 0.10938214000849256    steps: 439    lr: 2.560000000000001e-06     eval rl_reward: 8.34\n","For episode: 2160   the run_score was: 9.0   and mem length: 550244   eps: 0.10851490000849315    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 8.37\n","For episode: 2161   the run_score was: 7.0   and mem length: 550657   eps: 0.1076971600084937    steps: 413    lr: 2.560000000000001e-06     eval rl_reward: 8.38\n","For episode: 2162   the run_score was: 6.0   and mem length: 551009   eps: 0.10700020000849418    steps: 352    lr: 2.560000000000001e-06     eval rl_reward: 8.34\n","For episode: 2163   the run_score was: 6.0   and mem length: 551350   eps: 0.10632502000849464    steps: 341    lr: 2.560000000000001e-06     eval rl_reward: 8.3\n","For episode: 2164   the run_score was: 7.0   and mem length: 551720   eps: 0.10559242000849514    steps: 370    lr: 2.560000000000001e-06     eval rl_reward: 8.32\n","For episode: 2165   the run_score was: 8.0   and mem length: 552105   eps: 0.10483012000849566    steps: 385    lr: 2.560000000000001e-06     eval rl_reward: 8.33\n","For episode: 2166   the run_score was: 11.0   and mem length: 552490   eps: 0.10406782000849618    steps: 385    lr: 2.560000000000001e-06     eval rl_reward: 8.37\n","For episode: 2167   the run_score was: 9.0   and mem length: 552946   eps: 0.1031649400084968    steps: 456    lr: 2.560000000000001e-06     eval rl_reward: 8.39\n","For episode: 2168   the run_score was: 13.0   and mem length: 553621   eps: 0.10182844000849771    steps: 675    lr: 2.560000000000001e-06     eval rl_reward: 8.45\n","For episode: 2169   the run_score was: 5.0   and mem length: 553894   eps: 0.10128790000849808    steps: 273    lr: 2.560000000000001e-06     eval rl_reward: 8.44\n","For episode: 2170   the run_score was: 15.0   and mem length: 554506   eps: 0.1000761400084989    steps: 612    lr: 2.560000000000001e-06     eval rl_reward: 8.49\n","For episode: 2171   the run_score was: 5.0   and mem length: 554780   eps: 0.09953362000849927    steps: 274    lr: 2.560000000000001e-06     eval rl_reward: 8.43\n","For episode: 2172   the run_score was: 13.0   and mem length: 555413   eps: 0.09828028000850013    steps: 633    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2173   the run_score was: 9.0   and mem length: 555847   eps: 0.09742096000850071    steps: 434    lr: 2.560000000000001e-06     eval rl_reward: 8.5\n","For episode: 2174   the run_score was: 15.0   and mem length: 556429   eps: 0.0962686000085015    steps: 582    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2175   the run_score was: 5.0   and mem length: 556703   eps: 0.09572608000850187    steps: 274    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2176   the run_score was: 5.0   and mem length: 557027   eps: 0.09508456000850231    steps: 324    lr: 2.560000000000001e-06     eval rl_reward: 8.49\n","For episode: 2177   the run_score was: 15.0   and mem length: 557605   eps: 0.09394012000850309    steps: 578    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2178   the run_score was: 9.0   and mem length: 558044   eps: 0.09307090000850368    steps: 439    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2179   the run_score was: 8.0   and mem length: 558466   eps: 0.09223534000850425    steps: 422    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2180   the run_score was: 7.0   and mem length: 558829   eps: 0.09151660000850474    steps: 363    lr: 2.560000000000001e-06     eval rl_reward: 8.58\n","For episode: 2181   the run_score was: 13.0   and mem length: 559472   eps: 0.09024346000850561    steps: 643    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2182   the run_score was: 8.0   and mem length: 559896   eps: 0.08940394000850618    steps: 424    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2183   the run_score was: 5.0   and mem length: 560223   eps: 0.08875648000850662    steps: 327    lr: 2.560000000000001e-06     eval rl_reward: 8.44\n","For episode: 2184   the run_score was: 9.0   and mem length: 560682   eps: 0.08784766000850724    steps: 459    lr: 2.560000000000001e-06     eval rl_reward: 8.49\n","For episode: 2185   the run_score was: 8.0   and mem length: 561134   eps: 0.08695270000850785    steps: 452    lr: 2.560000000000001e-06     eval rl_reward: 8.46\n","For episode: 2186   the run_score was: 7.0   and mem length: 561536   eps: 0.0861567400085084    steps: 402    lr: 2.560000000000001e-06     eval rl_reward: 8.41\n","For episode: 2187   the run_score was: 19.0   and mem length: 562214   eps: 0.08481430000850931    steps: 678    lr: 2.560000000000001e-06     eval rl_reward: 8.5\n","For episode: 2188   the run_score was: 12.0   and mem length: 562695   eps: 0.08386192000850996    steps: 481    lr: 2.560000000000001e-06     eval rl_reward: 8.58\n","For episode: 2189   the run_score was: 17.0   and mem length: 563215   eps: 0.08283232000851067    steps: 520    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2190   the run_score was: 5.0   and mem length: 563544   eps: 0.08218090000851111    steps: 329    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2191   the run_score was: 6.0   and mem length: 563900   eps: 0.08147602000851159    steps: 356    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2192   the run_score was: 12.0   and mem length: 564530   eps: 0.08022862000851244    steps: 630    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2193   the run_score was: 5.0   and mem length: 564859   eps: 0.07957720000851289    steps: 329    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2194   the run_score was: 4.0   and mem length: 565139   eps: 0.07902280000851326    steps: 280    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2195   the run_score was: 11.0   and mem length: 565685   eps: 0.077941720008514    steps: 546    lr: 2.560000000000001e-06     eval rl_reward: 8.75\n","For episode: 2196   the run_score was: 7.0   and mem length: 566059   eps: 0.0772012000085145    steps: 374    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2197   the run_score was: 11.0   and mem length: 566491   eps: 0.07634584000851509    steps: 432    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2198   the run_score was: 12.0   and mem length: 566948   eps: 0.0754409800085157    steps: 457    lr: 2.560000000000001e-06     eval rl_reward: 8.75\n","For episode: 2199   the run_score was: 6.0   and mem length: 567291   eps: 0.07476184000851617    steps: 343    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2200   the run_score was: 19.0   and mem length: 567997   eps: 0.07336396000851712    steps: 706    lr: 2.560000000000001e-06     eval rl_reward: 8.81\n","For episode: 2201   the run_score was: 8.0   and mem length: 568435   eps: 0.07249672000851771    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 8.82\n","For episode: 2202   the run_score was: 5.0   and mem length: 568726   eps: 0.07192054000851811    steps: 291    lr: 2.560000000000001e-06     eval rl_reward: 8.78\n","For episode: 2203   the run_score was: 9.0   and mem length: 569164   eps: 0.0710533000085187    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 8.79\n","For episode: 2204   the run_score was: 5.0   and mem length: 569436   eps: 0.07051474000851907    steps: 272    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2205   the run_score was: 5.0   and mem length: 569747   eps: 0.06989896000851949    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 8.65\n","For episode: 2206   the run_score was: 7.0   and mem length: 570137   eps: 0.06912676000852001    steps: 390    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2207   the run_score was: 8.0   and mem length: 570504   eps: 0.06840010000852051    steps: 367    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2208   the run_score was: 13.0   and mem length: 570992   eps: 0.06743386000852117    steps: 488    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2209   the run_score was: 4.0   and mem length: 571273   eps: 0.06687748000852155    steps: 281    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2210   the run_score was: 8.0   and mem length: 571681   eps: 0.0660696400085221    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2211   the run_score was: 5.0   and mem length: 572009   eps: 0.06542020000852254    steps: 328    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2212   the run_score was: 6.0   and mem length: 572388   eps: 0.06466978000852305    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2213   the run_score was: 14.0   and mem length: 572910   eps: 0.06363622000852376    steps: 522    lr: 2.560000000000001e-06     eval rl_reward: 8.6\n","For episode: 2214   the run_score was: 10.0   and mem length: 573444   eps: 0.06257890000852448    steps: 534    lr: 2.560000000000001e-06     eval rl_reward: 8.65\n","For episode: 2215   the run_score was: 5.0   and mem length: 573755   eps: 0.0619631200085249    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 8.63\n","For episode: 2216   the run_score was: 9.0   and mem length: 574233   eps: 0.061016680008525545    steps: 478    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2217   the run_score was: 4.0   and mem length: 574492   eps: 0.060503860008525895    steps: 259    lr: 2.560000000000001e-06     eval rl_reward: 8.64\n","For episode: 2218   the run_score was: 10.0   and mem length: 574975   eps: 0.05954752000852655    steps: 483    lr: 2.560000000000001e-06     eval rl_reward: 8.66\n","For episode: 2219   the run_score was: 11.0   and mem length: 575478   eps: 0.058551580008527226    steps: 503    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2220   the run_score was: 8.0   and mem length: 575774   eps: 0.057965500008527626    steps: 296    lr: 2.560000000000001e-06     eval rl_reward: 8.69\n","For episode: 2221   the run_score was: 8.0   and mem length: 576175   eps: 0.05717152000852817    steps: 401    lr: 2.560000000000001e-06     eval rl_reward: 8.71\n","For episode: 2222   the run_score was: 12.0   and mem length: 576840   eps: 0.055854820008529066    steps: 665    lr: 2.560000000000001e-06     eval rl_reward: 8.76\n","For episode: 2223   the run_score was: 9.0   and mem length: 577253   eps: 0.055037080008529624    steps: 413    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2224   the run_score was: 7.0   and mem length: 577606   eps: 0.0543381400085301    steps: 353    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2225   the run_score was: 11.0   and mem length: 578135   eps: 0.053290720008530815    steps: 529    lr: 2.560000000000001e-06     eval rl_reward: 8.75\n","For episode: 2226   the run_score was: 6.0   and mem length: 578493   eps: 0.0525818800085313    steps: 358    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2227   the run_score was: 10.0   and mem length: 578827   eps: 0.05192056000853175    steps: 334    lr: 2.560000000000001e-06     eval rl_reward: 8.75\n","For episode: 2228   the run_score was: 9.0   and mem length: 579320   eps: 0.050944420008532415    steps: 493    lr: 2.560000000000001e-06     eval rl_reward: 8.78\n","For episode: 2229   the run_score was: 9.0   and mem length: 579794   eps: 0.050005900008533055    steps: 474    lr: 2.560000000000001e-06     eval rl_reward: 8.78\n","For episode: 2230   the run_score was: 5.0   and mem length: 580121   eps: 0.0493584400085335    steps: 327    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2231   the run_score was: 5.0   and mem length: 580448   eps: 0.04871098000853394    steps: 327    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2232   the run_score was: 7.0   and mem length: 580803   eps: 0.04800808000853442    steps: 355    lr: 2.560000000000001e-06     eval rl_reward: 8.66\n","For episode: 2233   the run_score was: 8.0   and mem length: 581262   eps: 0.04709926000853504    steps: 459    lr: 2.560000000000001e-06     eval rl_reward: 8.7\n","For episode: 2234   the run_score was: 9.0   and mem length: 581755   eps: 0.046123120008535703    steps: 493    lr: 2.560000000000001e-06     eval rl_reward: 8.69\n","For episode: 2235   the run_score was: 6.0   and mem length: 582076   eps: 0.04548754000853614    steps: 321    lr: 2.560000000000001e-06     eval rl_reward: 8.66\n","For episode: 2236   the run_score was: 5.0   and mem length: 582382   eps: 0.04488166000853655    steps: 306    lr: 2.560000000000001e-06     eval rl_reward: 8.66\n","For episode: 2237   the run_score was: 5.0   and mem length: 582693   eps: 0.04426588000853697    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 8.56\n","For episode: 2238   the run_score was: 12.0   and mem length: 583136   eps: 0.04338874000853757    steps: 443    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2239   the run_score was: 5.0   and mem length: 583429   eps: 0.042808600008537964    steps: 293    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2240   the run_score was: 13.0   and mem length: 584065   eps: 0.04154932000853882    steps: 636    lr: 2.560000000000001e-06     eval rl_reward: 8.65\n","For episode: 2241   the run_score was: 11.0   and mem length: 584599   eps: 0.040492000008539544    steps: 534    lr: 2.560000000000001e-06     eval rl_reward: 8.62\n","For episode: 2242   the run_score was: 6.0   and mem length: 584978   eps: 0.039741580008540056    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 8.58\n","For episode: 2243   the run_score was: 8.0   and mem length: 585411   eps: 0.03888424000854064    steps: 433    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2244   the run_score was: 5.0   and mem length: 585683   eps: 0.03834568000854101    steps: 272    lr: 2.560000000000001e-06     eval rl_reward: 8.52\n","For episode: 2245   the run_score was: 12.0   and mem length: 586222   eps: 0.037278460008541736    steps: 539    lr: 2.560000000000001e-06     eval rl_reward: 8.53\n","For episode: 2246   the run_score was: 6.0   and mem length: 586542   eps: 0.03664486000854217    steps: 320    lr: 2.560000000000001e-06     eval rl_reward: 8.48\n","For episode: 2247   the run_score was: 7.0   and mem length: 586929   eps: 0.03587860000854269    steps: 387    lr: 2.560000000000001e-06     eval rl_reward: 8.48\n","For episode: 2248   the run_score was: 10.0   and mem length: 587402   eps: 0.03494206000854333    steps: 473    lr: 2.560000000000001e-06     eval rl_reward: 8.47\n","For episode: 2249   the run_score was: 11.0   and mem length: 587968   eps: 0.033821380008544094    steps: 566    lr: 2.560000000000001e-06     eval rl_reward: 8.5\n","For episode: 2250   the run_score was: 4.0   and mem length: 588228   eps: 0.033306580008544445    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 8.46\n","For episode: 2251   the run_score was: 6.0   and mem length: 588607   eps: 0.03255616000854496    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 8.44\n","For episode: 2252   the run_score was: 15.0   and mem length: 589257   eps: 0.031269160008545835    steps: 650    lr: 2.560000000000001e-06     eval rl_reward: 8.52\n","For episode: 2253   the run_score was: 9.0   and mem length: 589731   eps: 0.030330640008546475    steps: 474    lr: 2.560000000000001e-06     eval rl_reward: 8.55\n","For episode: 2254   the run_score was: 11.0   and mem length: 590261   eps: 0.02928124000854719    steps: 530    lr: 2.560000000000001e-06     eval rl_reward: 8.51\n","For episode: 2255   the run_score was: 9.0   and mem length: 590727   eps: 0.02835856000854782    steps: 466    lr: 2.560000000000001e-06     eval rl_reward: 8.54\n","For episode: 2256   the run_score was: 8.0   and mem length: 591166   eps: 0.027489340008548413    steps: 439    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2257   the run_score was: 8.0   and mem length: 591566   eps: 0.026697340008548953    steps: 400    lr: 2.560000000000001e-06     eval rl_reward: 8.58\n","For episode: 2258   the run_score was: 7.0   and mem length: 591973   eps: 0.025891480008549503    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 8.59\n","For episode: 2259   the run_score was: 6.0   and mem length: 592352   eps: 0.025141060008550015    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2260   the run_score was: 13.0   and mem length: 592811   eps: 0.024232240008550635    steps: 459    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2261   the run_score was: 15.0   and mem length: 593380   eps: 0.023105620008551403    steps: 569    lr: 2.560000000000001e-06     eval rl_reward: 8.69\n","For episode: 2262   the run_score was: 9.0   and mem length: 593832   eps: 0.022210660008552013    steps: 452    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2263   the run_score was: 8.0   and mem length: 594267   eps: 0.0213493600085526    steps: 435    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2264   the run_score was: 6.0   and mem length: 594587   eps: 0.020715760008553033    steps: 320    lr: 2.560000000000001e-06     eval rl_reward: 8.73\n","For episode: 2265   the run_score was: 7.0   and mem length: 594989   eps: 0.019919800008553576    steps: 402    lr: 2.560000000000001e-06     eval rl_reward: 8.72\n","For episode: 2266   the run_score was: 16.0   and mem length: 595657   eps: 0.018597160008554478    steps: 668    lr: 2.560000000000001e-06     eval rl_reward: 8.77\n","For episode: 2267   the run_score was: 9.0   and mem length: 596079   eps: 0.017761600008555048    steps: 422    lr: 2.560000000000001e-06     eval rl_reward: 8.77\n","For episode: 2268   the run_score was: 10.0   and mem length: 596585   eps: 0.01675972000855573    steps: 506    lr: 2.560000000000001e-06     eval rl_reward: 8.74\n","For episode: 2269   the run_score was: 9.0   and mem length: 597018   eps: 0.015902380008556316    steps: 433    lr: 2.560000000000001e-06     eval rl_reward: 8.78\n","For episode: 2270   the run_score was: 5.0   and mem length: 597348   eps: 0.015248980008556432    steps: 330    lr: 2.560000000000001e-06     eval rl_reward: 8.68\n","For episode: 2271   the run_score was: 10.0   and mem length: 597825   eps: 0.014304520008556249    steps: 477    lr: 2.560000000000001e-06     eval rl_reward: 8.73\n","For episode: 2272   the run_score was: 8.0   and mem length: 598207   eps: 0.013548160008556102    steps: 382    lr: 2.560000000000001e-06     eval rl_reward: 8.68\n","For episode: 2273   the run_score was: 8.0   and mem length: 598633   eps: 0.012704680008555938    steps: 426    lr: 2.560000000000001e-06     eval rl_reward: 8.67\n","For episode: 2274   the run_score was: 5.0   and mem length: 598926   eps: 0.012124540008555826    steps: 293    lr: 2.560000000000001e-06     eval rl_reward: 8.57\n","For episode: 2275   the run_score was: 9.0   and mem length: 599361   eps: 0.011263240008555659    steps: 435    lr: 2.560000000000001e-06     eval rl_reward: 8.61\n","For episode: 2276   the run_score was: 8.0   and mem length: 599749   eps: 0.01049500000855551    steps: 388    lr: 2.560000000000001e-06     eval rl_reward: 8.64\n","For episode: 2277   the run_score was: 11.0   and mem length: 600282   eps: 0.009998020008555413    steps: 533    lr: 1.0240000000000005e-06     eval rl_reward: 8.6\n","For episode: 2278   the run_score was: 5.0   and mem length: 600588   eps: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2279   the run_score was: 9.0   and mem length: 601029   eps: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     eval rl_reward: 8.57\n","For episode: 2280   the run_score was: 5.0   and mem length: 601339   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 8.55\n","For episode: 2281   the run_score was: 5.0   and mem length: 601612   eps: 0.009998020008555413    steps: 273    lr: 1.0240000000000005e-06     eval rl_reward: 8.47\n","For episode: 2282   the run_score was: 9.0   and mem length: 602077   eps: 0.009998020008555413    steps: 465    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2283   the run_score was: 5.0   and mem length: 602368   eps: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2284   the run_score was: 6.0   and mem length: 602671   eps: 0.009998020008555413    steps: 303    lr: 1.0240000000000005e-06     eval rl_reward: 8.45\n","For episode: 2285   the run_score was: 8.0   and mem length: 603087   eps: 0.009998020008555413    steps: 416    lr: 1.0240000000000005e-06     eval rl_reward: 8.45\n","For episode: 2286   the run_score was: 7.0   and mem length: 603458   eps: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     eval rl_reward: 8.45\n","For episode: 2287   the run_score was: 15.0   and mem length: 604050   eps: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     eval rl_reward: 8.41\n","For episode: 2288   the run_score was: 19.0   and mem length: 604695   eps: 0.009998020008555413    steps: 645    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2289   the run_score was: 8.0   and mem length: 605108   eps: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     eval rl_reward: 8.39\n","For episode: 2290   the run_score was: 9.0   and mem length: 605530   eps: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2291   the run_score was: 10.0   and mem length: 606051   eps: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     eval rl_reward: 8.47\n","For episode: 2292   the run_score was: 7.0   and mem length: 606387   eps: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     eval rl_reward: 8.42\n","For episode: 2293   the run_score was: 6.0   and mem length: 606766   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2294   the run_score was: 9.0   and mem length: 607181   eps: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2295   the run_score was: 6.0   and mem length: 607560   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2296   the run_score was: 11.0   and mem length: 608119   eps: 0.009998020008555413    steps: 559    lr: 1.0240000000000005e-06     eval rl_reward: 8.47\n","For episode: 2297   the run_score was: 7.0   and mem length: 608486   eps: 0.009998020008555413    steps: 367    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2298   the run_score was: 8.0   and mem length: 608921   eps: 0.009998020008555413    steps: 435    lr: 1.0240000000000005e-06     eval rl_reward: 8.39\n","For episode: 2299   the run_score was: 10.0   and mem length: 609369   eps: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2300   the run_score was: 12.0   and mem length: 609961   eps: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     eval rl_reward: 8.36\n","For episode: 2301   the run_score was: 8.0   and mem length: 610371   eps: 0.009998020008555413    steps: 410    lr: 1.0240000000000005e-06     eval rl_reward: 8.36\n","For episode: 2302   the run_score was: 11.0   and mem length: 610923   eps: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     eval rl_reward: 8.42\n","For episode: 2303   the run_score was: 7.0   and mem length: 611311   eps: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     eval rl_reward: 8.4\n","For episode: 2304   the run_score was: 6.0   and mem length: 611690   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.41\n","For episode: 2305   the run_score was: 12.0   and mem length: 612295   eps: 0.009998020008555413    steps: 605    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2306   the run_score was: 7.0   and mem length: 612637   eps: 0.009998020008555413    steps: 342    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2307   the run_score was: 8.0   and mem length: 613071   eps: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     eval rl_reward: 8.48\n","For episode: 2308   the run_score was: 10.0   and mem length: 613532   eps: 0.009998020008555413    steps: 461    lr: 1.0240000000000005e-06     eval rl_reward: 8.45\n","For episode: 2309   the run_score was: 10.0   and mem length: 613944   eps: 0.009998020008555413    steps: 412    lr: 1.0240000000000005e-06     eval rl_reward: 8.51\n","For episode: 2310   the run_score was: 6.0   and mem length: 614340   eps: 0.009998020008555413    steps: 396    lr: 1.0240000000000005e-06     eval rl_reward: 8.49\n","For episode: 2311   the run_score was: 8.0   and mem length: 614735   eps: 0.009998020008555413    steps: 395    lr: 1.0240000000000005e-06     eval rl_reward: 8.52\n","For episode: 2312   the run_score was: 6.0   and mem length: 615092   eps: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     eval rl_reward: 8.52\n","For episode: 2313   the run_score was: 5.0   and mem length: 615417   eps: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     eval rl_reward: 8.43\n","For episode: 2314   the run_score was: 8.0   and mem length: 615805   eps: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     eval rl_reward: 8.41\n","For episode: 2315   the run_score was: 5.0   and mem length: 616114   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 8.41\n","For episode: 2316   the run_score was: 15.0   and mem length: 616778   eps: 0.009998020008555413    steps: 664    lr: 1.0240000000000005e-06     eval rl_reward: 8.47\n","For episode: 2317   the run_score was: 10.0   and mem length: 617320   eps: 0.009998020008555413    steps: 542    lr: 1.0240000000000005e-06     eval rl_reward: 8.53\n","For episode: 2318   the run_score was: 16.0   and mem length: 617926   eps: 0.009998020008555413    steps: 606    lr: 1.0240000000000005e-06     eval rl_reward: 8.59\n","For episode: 2319   the run_score was: 10.0   and mem length: 618408   eps: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     eval rl_reward: 8.58\n","For episode: 2320   the run_score was: 9.0   and mem length: 618843   eps: 0.009998020008555413    steps: 435    lr: 1.0240000000000005e-06     eval rl_reward: 8.59\n","For episode: 2321   the run_score was: 8.0   and mem length: 619225   eps: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     eval rl_reward: 8.59\n","For episode: 2322   the run_score was: 7.0   and mem length: 619595   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 8.54\n","For episode: 2323   the run_score was: 8.0   and mem length: 620037   eps: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     eval rl_reward: 8.53\n","For episode: 2324   the run_score was: 6.0   and mem length: 620412   eps: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     eval rl_reward: 8.52\n","For episode: 2325   the run_score was: 8.0   and mem length: 620850   eps: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     eval rl_reward: 8.49\n","For episode: 2326   the run_score was: 10.0   and mem length: 621326   eps: 0.009998020008555413    steps: 476    lr: 1.0240000000000005e-06     eval rl_reward: 8.53\n","For episode: 2327   the run_score was: 9.0   and mem length: 621794   eps: 0.009998020008555413    steps: 468    lr: 1.0240000000000005e-06     eval rl_reward: 8.52\n","For episode: 2328   the run_score was: 6.0   and mem length: 622173   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.49\n","For episode: 2329   the run_score was: 11.0   and mem length: 622688   eps: 0.009998020008555413    steps: 515    lr: 1.0240000000000005e-06     eval rl_reward: 8.51\n","For episode: 2330   the run_score was: 9.0   and mem length: 623165   eps: 0.009998020008555413    steps: 477    lr: 1.0240000000000005e-06     eval rl_reward: 8.55\n","For episode: 2331   the run_score was: 6.0   and mem length: 623521   eps: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2332   the run_score was: 8.0   and mem length: 623969   eps: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     eval rl_reward: 8.57\n","For episode: 2333   the run_score was: 10.0   and mem length: 624452   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 8.59\n","For episode: 2334   the run_score was: 5.0   and mem length: 624724   eps: 0.009998020008555413    steps: 272    lr: 1.0240000000000005e-06     eval rl_reward: 8.55\n","For episode: 2335   the run_score was: 5.0   and mem length: 625033   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 8.54\n","For episode: 2336   the run_score was: 7.0   and mem length: 625424   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2337   the run_score was: 11.0   and mem length: 625968   eps: 0.009998020008555413    steps: 544    lr: 1.0240000000000005e-06     eval rl_reward: 8.62\n","For episode: 2338   the run_score was: 6.0   and mem length: 626347   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2339   the run_score was: 6.0   and mem length: 626707   eps: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     eval rl_reward: 8.57\n","For episode: 2340   the run_score was: 12.0   and mem length: 627282   eps: 0.009998020008555413    steps: 575    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2341   the run_score was: 8.0   and mem length: 627720   eps: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     eval rl_reward: 8.53\n","For episode: 2342   the run_score was: 9.0   and mem length: 628195   eps: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     eval rl_reward: 8.56\n","For episode: 2343   the run_score was: 14.0   and mem length: 628849   eps: 0.009998020008555413    steps: 654    lr: 1.0240000000000005e-06     eval rl_reward: 8.62\n","For episode: 2344   the run_score was: 8.0   and mem length: 629269   eps: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     eval rl_reward: 8.65\n","For episode: 2345   the run_score was: 9.0   and mem length: 629701   eps: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     eval rl_reward: 8.62\n","For episode: 2346   the run_score was: 15.0   and mem length: 630277   eps: 0.009998020008555413    steps: 576    lr: 1.0240000000000005e-06     eval rl_reward: 8.71\n","For episode: 2347   the run_score was: 6.0   and mem length: 630599   eps: 0.009998020008555413    steps: 322    lr: 1.0240000000000005e-06     eval rl_reward: 8.7\n","For episode: 2348   the run_score was: 20.0   and mem length: 631254   eps: 0.009998020008555413    steps: 655    lr: 1.0240000000000005e-06     eval rl_reward: 8.8\n","For episode: 2349   the run_score was: 6.0   and mem length: 631557   eps: 0.009998020008555413    steps: 303    lr: 1.0240000000000005e-06     eval rl_reward: 8.75\n","For episode: 2350   the run_score was: 13.0   and mem length: 632166   eps: 0.009998020008555413    steps: 609    lr: 1.0240000000000005e-06     eval rl_reward: 8.84\n","For episode: 2351   the run_score was: 9.0   and mem length: 632605   eps: 0.009998020008555413    steps: 439    lr: 1.0240000000000005e-06     eval rl_reward: 8.87\n","For episode: 2352   the run_score was: 10.0   and mem length: 633088   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 8.82\n","For episode: 2353   the run_score was: 6.0   and mem length: 633422   eps: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     eval rl_reward: 8.79\n","For episode: 2354   the run_score was: 14.0   and mem length: 634012   eps: 0.009998020008555413    steps: 590    lr: 1.0240000000000005e-06     eval rl_reward: 8.82\n","For episode: 2355   the run_score was: 7.0   and mem length: 634364   eps: 0.009998020008555413    steps: 352    lr: 1.0240000000000005e-06     eval rl_reward: 8.8\n","For episode: 2356   the run_score was: 9.0   and mem length: 634808   eps: 0.009998020008555413    steps: 444    lr: 1.0240000000000005e-06     eval rl_reward: 8.81\n","For episode: 2357   the run_score was: 9.0   and mem length: 635246   eps: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     eval rl_reward: 8.82\n","For episode: 2358   the run_score was: 16.0   and mem length: 635852   eps: 0.009998020008555413    steps: 606    lr: 1.0240000000000005e-06     eval rl_reward: 8.91\n","For episode: 2359   the run_score was: 7.0   and mem length: 636243   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 8.92\n","For episode: 2360   the run_score was: 9.0   and mem length: 636648   eps: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     eval rl_reward: 8.88\n","For episode: 2361   the run_score was: 15.0   and mem length: 637273   eps: 0.009998020008555413    steps: 625    lr: 1.0240000000000005e-06     eval rl_reward: 8.88\n","For episode: 2362   the run_score was: 6.0   and mem length: 637652   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.85\n","For episode: 2363   the run_score was: 9.0   and mem length: 638142   eps: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     eval rl_reward: 8.86\n","For episode: 2364   the run_score was: 12.0   and mem length: 638716   eps: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     eval rl_reward: 8.92\n","For episode: 2365   the run_score was: 11.0   and mem length: 639276   eps: 0.009998020008555413    steps: 560    lr: 1.0240000000000005e-06     eval rl_reward: 8.96\n","For episode: 2366   the run_score was: 7.0   and mem length: 639643   eps: 0.009998020008555413    steps: 367    lr: 1.0240000000000005e-06     eval rl_reward: 8.87\n","For episode: 2367   the run_score was: 12.0   and mem length: 640229   eps: 0.009998020008555413    steps: 586    lr: 1.0240000000000005e-06     eval rl_reward: 8.9\n","For episode: 2368   the run_score was: 10.0   and mem length: 640767   eps: 0.009998020008555413    steps: 538    lr: 1.0240000000000005e-06     eval rl_reward: 8.9\n","For episode: 2369   the run_score was: 9.0   and mem length: 641255   eps: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     eval rl_reward: 8.9\n","For episode: 2370   the run_score was: 13.0   and mem length: 641745   eps: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     eval rl_reward: 8.98\n","For episode: 2371   the run_score was: 10.0   and mem length: 642233   eps: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     eval rl_reward: 8.98\n","For episode: 2372   the run_score was: 6.0   and mem length: 642612   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 8.96\n","For episode: 2373   the run_score was: 14.0   and mem length: 643211   eps: 0.009998020008555413    steps: 599    lr: 1.0240000000000005e-06     eval rl_reward: 9.02\n","For episode: 2374   the run_score was: 16.0   and mem length: 643817   eps: 0.009998020008555413    steps: 606    lr: 1.0240000000000005e-06     eval rl_reward: 9.13\n","For episode: 2375   the run_score was: 9.0   and mem length: 644253   eps: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     eval rl_reward: 9.13\n","For episode: 2376   the run_score was: 10.0   and mem length: 644736   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 9.15\n","For episode: 2377   the run_score was: 12.0   and mem length: 645311   eps: 0.009998020008555413    steps: 575    lr: 1.0240000000000005e-06     eval rl_reward: 9.16\n","For episode: 2378   the run_score was: 9.0   and mem length: 645728   eps: 0.009998020008555413    steps: 417    lr: 1.0240000000000005e-06     eval rl_reward: 9.2\n","For episode: 2379   the run_score was: 7.0   and mem length: 646081   eps: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     eval rl_reward: 9.18\n","For episode: 2380   the run_score was: 12.0   and mem length: 646538   eps: 0.009998020008555413    steps: 457    lr: 1.0240000000000005e-06     eval rl_reward: 9.25\n","For episode: 2381   the run_score was: 14.0   and mem length: 647198   eps: 0.009998020008555413    steps: 660    lr: 1.0240000000000005e-06     eval rl_reward: 9.34\n","For episode: 2382   the run_score was: 9.0   and mem length: 647669   eps: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     eval rl_reward: 9.34\n","For episode: 2383   the run_score was: 9.0   and mem length: 648166   eps: 0.009998020008555413    steps: 497    lr: 1.0240000000000005e-06     eval rl_reward: 9.38\n","For episode: 2384   the run_score was: 7.0   and mem length: 648568   eps: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     eval rl_reward: 9.39\n","For episode: 2385   the run_score was: 20.0   and mem length: 649193   eps: 0.009998020008555413    steps: 625    lr: 1.0240000000000005e-06     eval rl_reward: 9.51\n","For episode: 2386   the run_score was: 8.0   and mem length: 649635   eps: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     eval rl_reward: 9.52\n","For episode: 2387   the run_score was: 14.0   and mem length: 650281   eps: 0.009998020008555413    steps: 646    lr: 1.0240000000000005e-06     eval rl_reward: 9.51\n","For episode: 2388   the run_score was: 7.0   and mem length: 650634   eps: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     eval rl_reward: 9.39\n","For episode: 2389   the run_score was: 7.0   and mem length: 651004   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 9.38\n","For episode: 2390   the run_score was: 10.0   and mem length: 651515   eps: 0.009998020008555413    steps: 511    lr: 1.0240000000000005e-06     eval rl_reward: 9.39\n","For episode: 2391   the run_score was: 10.0   and mem length: 651998   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 9.39\n","For episode: 2392   the run_score was: 17.0   and mem length: 652680   eps: 0.009998020008555413    steps: 682    lr: 1.0240000000000005e-06     eval rl_reward: 9.49\n","For episode: 2393   the run_score was: 14.0   and mem length: 653227   eps: 0.009998020008555413    steps: 547    lr: 1.0240000000000005e-06     eval rl_reward: 9.57\n","For episode: 2394   the run_score was: 18.0   and mem length: 653890   eps: 0.009998020008555413    steps: 663    lr: 1.0240000000000005e-06     eval rl_reward: 9.66\n","For episode: 2395   the run_score was: 10.0   and mem length: 654372   eps: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     eval rl_reward: 9.7\n","For episode: 2396   the run_score was: 11.0   and mem length: 654875   eps: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     eval rl_reward: 9.7\n","For episode: 2397   the run_score was: 21.0   and mem length: 655534   eps: 0.009998020008555413    steps: 659    lr: 1.0240000000000005e-06     eval rl_reward: 9.84\n","For episode: 2398   the run_score was: 10.0   and mem length: 656040   eps: 0.009998020008555413    steps: 506    lr: 1.0240000000000005e-06     eval rl_reward: 9.86\n","For episode: 2399   the run_score was: 10.0   and mem length: 656545   eps: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     eval rl_reward: 9.86\n","For episode: 2400   the run_score was: 5.0   and mem length: 656854   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 9.79\n","For episode: 2401   the run_score was: 14.0   and mem length: 657421   eps: 0.009998020008555413    steps: 567    lr: 1.0240000000000005e-06     eval rl_reward: 9.85\n","For episode: 2402   the run_score was: 12.0   and mem length: 657998   eps: 0.009998020008555413    steps: 577    lr: 1.0240000000000005e-06     eval rl_reward: 9.86\n","For episode: 2403   the run_score was: 7.0   and mem length: 658387   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 9.86\n","For episode: 2404   the run_score was: 5.0   and mem length: 658696   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 9.85\n","For episode: 2405   the run_score was: 7.0   and mem length: 659124   eps: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     eval rl_reward: 9.8\n","For episode: 2406   the run_score was: 7.0   and mem length: 659515   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 9.8\n","For episode: 2407   the run_score was: 10.0   and mem length: 660070   eps: 0.009998020008555413    steps: 555    lr: 1.0240000000000005e-06     eval rl_reward: 9.82\n","For episode: 2408   the run_score was: 10.0   and mem length: 660575   eps: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     eval rl_reward: 9.82\n","For episode: 2409   the run_score was: 6.0   and mem length: 660895   eps: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     eval rl_reward: 9.78\n","For episode: 2410   the run_score was: 6.0   and mem length: 661214   eps: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     eval rl_reward: 9.78\n","For episode: 2411   the run_score was: 14.0   and mem length: 661865   eps: 0.009998020008555413    steps: 651    lr: 1.0240000000000005e-06     eval rl_reward: 9.84\n","For episode: 2412   the run_score was: 13.0   and mem length: 662431   eps: 0.009998020008555413    steps: 566    lr: 1.0240000000000005e-06     eval rl_reward: 9.91\n","For episode: 2413   the run_score was: 7.0   and mem length: 662822   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 9.93\n","For episode: 2414   the run_score was: 8.0   and mem length: 663231   eps: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     eval rl_reward: 9.93\n","For episode: 2415   the run_score was: 11.0   and mem length: 663804   eps: 0.009998020008555413    steps: 573    lr: 1.0240000000000005e-06     eval rl_reward: 9.99\n","For episode: 2416   the run_score was: 7.0   and mem length: 664178   eps: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     eval rl_reward: 9.91\n","For episode: 2417   the run_score was: 12.0   and mem length: 664769   eps: 0.009998020008555413    steps: 591    lr: 1.0240000000000005e-06     eval rl_reward: 9.93\n","For episode: 2418   the run_score was: 16.0   and mem length: 665415   eps: 0.009998020008555413    steps: 646    lr: 1.0240000000000005e-06     eval rl_reward: 9.93\n","For episode: 2419   the run_score was: 8.0   and mem length: 665857   eps: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     eval rl_reward: 9.91\n","For episode: 2420   the run_score was: 15.0   and mem length: 666560   eps: 0.009998020008555413    steps: 703    lr: 1.0240000000000005e-06     eval rl_reward: 9.97\n","For episode: 2421   the run_score was: 9.0   and mem length: 667064   eps: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     eval rl_reward: 9.98\n","For episode: 2422   the run_score was: 11.0   and mem length: 667590   eps: 0.009998020008555413    steps: 526    lr: 1.0240000000000005e-06     eval rl_reward: 10.02\n","For episode: 2423   the run_score was: 10.0   and mem length: 668120   eps: 0.009998020008555413    steps: 530    lr: 1.0240000000000005e-06     eval rl_reward: 10.04\n","For episode: 2424   the run_score was: 15.0   and mem length: 668799   eps: 0.009998020008555413    steps: 679    lr: 1.0240000000000005e-06     eval rl_reward: 10.13\n","For episode: 2425   the run_score was: 10.0   and mem length: 669322   eps: 0.009998020008555413    steps: 523    lr: 1.0240000000000005e-06     eval rl_reward: 10.15\n","For episode: 2426   the run_score was: 7.0   and mem length: 669696   eps: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     eval rl_reward: 10.12\n","For episode: 2427   the run_score was: 12.0   and mem length: 670271   eps: 0.009998020008555413    steps: 575    lr: 1.0240000000000005e-06     eval rl_reward: 10.15\n","For episode: 2428   the run_score was: 9.0   and mem length: 670746   eps: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     eval rl_reward: 10.18\n","For episode: 2429   the run_score was: 6.0   and mem length: 671125   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 10.13\n","For episode: 2430   the run_score was: 13.0   and mem length: 671733   eps: 0.009998020008555413    steps: 608    lr: 1.0240000000000005e-06     eval rl_reward: 10.17\n","For episode: 2431   the run_score was: 8.0   and mem length: 672191   eps: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     eval rl_reward: 10.19\n","For episode: 2432   the run_score was: 7.0   and mem length: 672576   eps: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     eval rl_reward: 10.18\n","For episode: 2433   the run_score was: 6.0   and mem length: 672896   eps: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     eval rl_reward: 10.14\n","For episode: 2434   the run_score was: 6.0   and mem length: 673216   eps: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     eval rl_reward: 10.15\n","For episode: 2435   the run_score was: 9.0   and mem length: 673675   eps: 0.009998020008555413    steps: 459    lr: 1.0240000000000005e-06     eval rl_reward: 10.19\n","For episode: 2436   the run_score was: 6.0   and mem length: 674033   eps: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     eval rl_reward: 10.18\n","For episode: 2437   the run_score was: 11.0   and mem length: 674543   eps: 0.009998020008555413    steps: 510    lr: 1.0240000000000005e-06     eval rl_reward: 10.18\n","For episode: 2438   the run_score was: 9.0   and mem length: 675033   eps: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     eval rl_reward: 10.21\n","For episode: 2439   the run_score was: 8.0   and mem length: 675417   eps: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     eval rl_reward: 10.23\n","For episode: 2440   the run_score was: 6.0   and mem length: 675796   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 10.17\n","For episode: 2441   the run_score was: 9.0   and mem length: 676286   eps: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     eval rl_reward: 10.18\n","For episode: 2442   the run_score was: 6.0   and mem length: 676665   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 10.15\n","For episode: 2443   the run_score was: 7.0   and mem length: 677096   eps: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     eval rl_reward: 10.08\n","For episode: 2444   the run_score was: 6.0   and mem length: 677475   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 10.06\n","For episode: 2445   the run_score was: 6.0   and mem length: 677854   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 10.03\n","For episode: 2446   the run_score was: 12.0   and mem length: 678430   eps: 0.009998020008555413    steps: 576    lr: 1.0240000000000005e-06     eval rl_reward: 10.0\n","For episode: 2447   the run_score was: 11.0   and mem length: 678836   eps: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     eval rl_reward: 10.05\n","For episode: 2448   the run_score was: 5.0   and mem length: 679142   eps: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     eval rl_reward: 9.9\n","For episode: 2449   the run_score was: 6.0   and mem length: 679521   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 9.9\n","For episode: 2450   the run_score was: 6.0   and mem length: 679900   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 9.83\n","For episode: 2451   the run_score was: 13.0   and mem length: 680401   eps: 0.009998020008555413    steps: 501    lr: 1.0240000000000005e-06     eval rl_reward: 9.87\n","For episode: 2452   the run_score was: 18.0   and mem length: 681081   eps: 0.009998020008555413    steps: 680    lr: 1.0240000000000005e-06     eval rl_reward: 9.95\n","For episode: 2453   the run_score was: 11.0   and mem length: 681605   eps: 0.009998020008555413    steps: 524    lr: 1.0240000000000005e-06     eval rl_reward: 10.0\n","For episode: 2454   the run_score was: 7.0   and mem length: 682036   eps: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     eval rl_reward: 9.93\n","For episode: 2455   the run_score was: 6.0   and mem length: 682415   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 9.92\n","For episode: 2456   the run_score was: 11.0   and mem length: 682937   eps: 0.009998020008555413    steps: 522    lr: 1.0240000000000005e-06     eval rl_reward: 9.94\n","For episode: 2457   the run_score was: 9.0   and mem length: 683425   eps: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     eval rl_reward: 9.94\n","For episode: 2458   the run_score was: 7.0   and mem length: 683780   eps: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     eval rl_reward: 9.85\n","For episode: 2459   the run_score was: 6.0   and mem length: 684159   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 9.84\n","For episode: 2460   the run_score was: 8.0   and mem length: 684601   eps: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     eval rl_reward: 9.83\n","For episode: 2461   the run_score was: 9.0   and mem length: 685074   eps: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     eval rl_reward: 9.77\n","For episode: 2462   the run_score was: 10.0   and mem length: 685578   eps: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     eval rl_reward: 9.81\n","For episode: 2463   the run_score was: 6.0   and mem length: 685881   eps: 0.009998020008555413    steps: 303    lr: 1.0240000000000005e-06     eval rl_reward: 9.78\n","For episode: 2464   the run_score was: 10.0   and mem length: 686391   eps: 0.009998020008555413    steps: 510    lr: 1.0240000000000005e-06     eval rl_reward: 9.76\n","For episode: 2465   the run_score was: 7.0   and mem length: 686744   eps: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     eval rl_reward: 9.72\n","For episode: 2466   the run_score was: 14.0   and mem length: 687301   eps: 0.009998020008555413    steps: 557    lr: 1.0240000000000005e-06     eval rl_reward: 9.79\n","For episode: 2467   the run_score was: 11.0   and mem length: 687733   eps: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     eval rl_reward: 9.78\n","For episode: 2468   the run_score was: 5.0   and mem length: 688040   eps: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     eval rl_reward: 9.73\n","For episode: 2469   the run_score was: 6.0   and mem length: 688361   eps: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     eval rl_reward: 9.7\n","For episode: 2470   the run_score was: 11.0   and mem length: 688897   eps: 0.009998020008555413    steps: 536    lr: 1.0240000000000005e-06     eval rl_reward: 9.68\n","For episode: 2471   the run_score was: 11.0   and mem length: 689418   eps: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     eval rl_reward: 9.69\n","For episode: 2472   the run_score was: 6.0   and mem length: 689738   eps: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     eval rl_reward: 9.69\n","For episode: 2473   the run_score was: 13.0   and mem length: 690347   eps: 0.009998020008555413    steps: 609    lr: 1.0240000000000005e-06     eval rl_reward: 9.68\n","For episode: 2474   the run_score was: 13.0   and mem length: 691002   eps: 0.009998020008555413    steps: 655    lr: 1.0240000000000005e-06     eval rl_reward: 9.65\n","For episode: 2475   the run_score was: 15.0   and mem length: 691543   eps: 0.009998020008555413    steps: 541    lr: 1.0240000000000005e-06     eval rl_reward: 9.71\n","For episode: 2476   the run_score was: 9.0   and mem length: 692016   eps: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     eval rl_reward: 9.7\n","For episode: 2477   the run_score was: 5.0   and mem length: 692309   eps: 0.009998020008555413    steps: 293    lr: 1.0240000000000005e-06     eval rl_reward: 9.63\n","For episode: 2478   the run_score was: 9.0   and mem length: 692782   eps: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     eval rl_reward: 9.63\n","For episode: 2479   the run_score was: 12.0   and mem length: 693356   eps: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     eval rl_reward: 9.68\n","For episode: 2480   the run_score was: 11.0   and mem length: 693859   eps: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     eval rl_reward: 9.67\n","For episode: 2481   the run_score was: 10.0   and mem length: 694342   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 9.63\n","For episode: 2482   the run_score was: 10.0   and mem length: 694825   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 9.64\n","For episode: 2483   the run_score was: 5.0   and mem length: 695118   eps: 0.009998020008555413    steps: 293    lr: 1.0240000000000005e-06     eval rl_reward: 9.6\n","For episode: 2484   the run_score was: 11.0   and mem length: 695640   eps: 0.009998020008555413    steps: 522    lr: 1.0240000000000005e-06     eval rl_reward: 9.64\n","For episode: 2485   the run_score was: 10.0   and mem length: 696117   eps: 0.009998020008555413    steps: 477    lr: 1.0240000000000005e-06     eval rl_reward: 9.54\n","For episode: 2486   the run_score was: 12.0   and mem length: 696694   eps: 0.009998020008555413    steps: 577    lr: 1.0240000000000005e-06     eval rl_reward: 9.58\n","For episode: 2487   the run_score was: 9.0   and mem length: 697167   eps: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     eval rl_reward: 9.53\n","For episode: 2488   the run_score was: 14.0   and mem length: 697731   eps: 0.009998020008555413    steps: 564    lr: 1.0240000000000005e-06     eval rl_reward: 9.6\n","For episode: 2489   the run_score was: 10.0   and mem length: 698123   eps: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     eval rl_reward: 9.63\n","For episode: 2490   the run_score was: 9.0   and mem length: 698575   eps: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     eval rl_reward: 9.62\n","For episode: 2491   the run_score was: 9.0   and mem length: 699035   eps: 0.009998020008555413    steps: 460    lr: 1.0240000000000005e-06     eval rl_reward: 9.61\n","For episode: 2492   the run_score was: 11.0   and mem length: 699597   eps: 0.009998020008555413    steps: 562    lr: 1.0240000000000005e-06     eval rl_reward: 9.55\n","For episode: 2493   the run_score was: 12.0   and mem length: 700181   eps: 0.009998020008555413    steps: 584    lr: 4.0960000000000023e-07     eval rl_reward: 9.53\n","For episode: 2494   the run_score was: 11.0   and mem length: 700743   eps: 0.009998020008555413    steps: 562    lr: 4.0960000000000023e-07     eval rl_reward: 9.46\n","For episode: 2495   the run_score was: 10.0   and mem length: 701268   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.46\n","For episode: 2496   the run_score was: 6.0   and mem length: 701609   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 9.41\n","For episode: 2497   the run_score was: 14.0   and mem length: 702173   eps: 0.009998020008555413    steps: 564    lr: 4.0960000000000023e-07     eval rl_reward: 9.34\n","For episode: 2498   the run_score was: 9.0   and mem length: 702648   eps: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     eval rl_reward: 9.33\n","For episode: 2499   the run_score was: 13.0   and mem length: 703247   eps: 0.009998020008555413    steps: 599    lr: 4.0960000000000023e-07     eval rl_reward: 9.36\n","For episode: 2500   the run_score was: 14.0   and mem length: 703811   eps: 0.009998020008555413    steps: 564    lr: 4.0960000000000023e-07     eval rl_reward: 9.45\n","For episode: 2501   the run_score was: 18.0   and mem length: 704403   eps: 0.009998020008555413    steps: 592    lr: 4.0960000000000023e-07     eval rl_reward: 9.49\n","For episode: 2502   the run_score was: 11.0   and mem length: 704925   eps: 0.009998020008555413    steps: 522    lr: 4.0960000000000023e-07     eval rl_reward: 9.48\n","For episode: 2503   the run_score was: 7.0   and mem length: 705316   eps: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     eval rl_reward: 9.48\n","For episode: 2504   the run_score was: 14.0   and mem length: 705880   eps: 0.009998020008555413    steps: 564    lr: 4.0960000000000023e-07     eval rl_reward: 9.57\n","For episode: 2505   the run_score was: 17.0   and mem length: 706557   eps: 0.009998020008555413    steps: 677    lr: 4.0960000000000023e-07     eval rl_reward: 9.67\n","For episode: 2506   the run_score was: 11.0   and mem length: 707157   eps: 0.009998020008555413    steps: 600    lr: 4.0960000000000023e-07     eval rl_reward: 9.71\n","For episode: 2507   the run_score was: 18.0   and mem length: 707749   eps: 0.009998020008555413    steps: 592    lr: 4.0960000000000023e-07     eval rl_reward: 9.79\n","For episode: 2508   the run_score was: 5.0   and mem length: 708076   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.74\n","For episode: 2509   the run_score was: 5.0   and mem length: 708403   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.73\n","For episode: 2510   the run_score was: 14.0   and mem length: 708967   eps: 0.009998020008555413    steps: 564    lr: 4.0960000000000023e-07     eval rl_reward: 9.81\n","For episode: 2511   the run_score was: 11.0   and mem length: 709529   eps: 0.009998020008555413    steps: 562    lr: 4.0960000000000023e-07     eval rl_reward: 9.78\n","For episode: 2512   the run_score was: 9.0   and mem length: 710026   eps: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     eval rl_reward: 9.74\n","For episode: 2513   the run_score was: 11.0   and mem length: 710605   eps: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     eval rl_reward: 9.78\n","For episode: 2514   the run_score was: 15.0   and mem length: 711146   eps: 0.009998020008555413    steps: 541    lr: 4.0960000000000023e-07     eval rl_reward: 9.85\n","For episode: 2515   the run_score was: 13.0   and mem length: 711745   eps: 0.009998020008555413    steps: 599    lr: 4.0960000000000023e-07     eval rl_reward: 9.87\n","For episode: 2516   the run_score was: 9.0   and mem length: 712220   eps: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     eval rl_reward: 9.89\n","For episode: 2517   the run_score was: 9.0   and mem length: 712693   eps: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     eval rl_reward: 9.86\n","For episode: 2518   the run_score was: 6.0   and mem length: 713034   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 9.76\n","For episode: 2519   the run_score was: 6.0   and mem length: 713410   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.74\n","For episode: 2520   the run_score was: 5.0   and mem length: 713700   eps: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     eval rl_reward: 9.64\n","For episode: 2521   the run_score was: 8.0   and mem length: 714120   eps: 0.009998020008555413    steps: 420    lr: 4.0960000000000023e-07     eval rl_reward: 9.63\n","For episode: 2522   the run_score was: 15.0   and mem length: 714657   eps: 0.009998020008555413    steps: 537    lr: 4.0960000000000023e-07     eval rl_reward: 9.67\n","For episode: 2523   the run_score was: 7.0   and mem length: 715038   eps: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     eval rl_reward: 9.64\n","For episode: 2524   the run_score was: 11.0   and mem length: 715600   eps: 0.009998020008555413    steps: 562    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2525   the run_score was: 9.0   and mem length: 716063   eps: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     eval rl_reward: 9.59\n","For episode: 2526   the run_score was: 13.0   and mem length: 716679   eps: 0.009998020008555413    steps: 616    lr: 4.0960000000000023e-07     eval rl_reward: 9.65\n","For episode: 2527   the run_score was: 5.0   and mem length: 717004   eps: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     eval rl_reward: 9.58\n","For episode: 2528   the run_score was: 12.0   and mem length: 717605   eps: 0.009998020008555413    steps: 601    lr: 4.0960000000000023e-07     eval rl_reward: 9.61\n","For episode: 2529   the run_score was: 8.0   and mem length: 718047   eps: 0.009998020008555413    steps: 442    lr: 4.0960000000000023e-07     eval rl_reward: 9.63\n","For episode: 2530   the run_score was: 4.0   and mem length: 718324   eps: 0.009998020008555413    steps: 277    lr: 4.0960000000000023e-07     eval rl_reward: 9.54\n","For episode: 2531   the run_score was: 6.0   and mem length: 718700   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.52\n","For episode: 2532   the run_score was: 6.0   and mem length: 719079   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.51\n","For episode: 2533   the run_score was: 10.0   and mem length: 719562   eps: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     eval rl_reward: 9.55\n","For episode: 2534   the run_score was: 11.0   and mem length: 720114   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2535   the run_score was: 10.0   and mem length: 720635   eps: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     eval rl_reward: 9.61\n","For episode: 2536   the run_score was: 6.0   and mem length: 721014   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.61\n","For episode: 2537   the run_score was: 6.0   and mem length: 721390   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.56\n","For episode: 2538   the run_score was: 13.0   and mem length: 721917   eps: 0.009998020008555413    steps: 527    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2539   the run_score was: 9.0   and mem length: 722418   eps: 0.009998020008555413    steps: 501    lr: 4.0960000000000023e-07     eval rl_reward: 9.61\n","For episode: 2540   the run_score was: 8.0   and mem length: 722819   eps: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     eval rl_reward: 9.63\n","For episode: 2541   the run_score was: 6.0   and mem length: 723195   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2542   the run_score was: 9.0   and mem length: 723690   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 9.63\n","For episode: 2543   the run_score was: 9.0   and mem length: 724153   eps: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     eval rl_reward: 9.65\n","For episode: 2544   the run_score was: 7.0   and mem length: 724544   eps: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     eval rl_reward: 9.66\n","For episode: 2545   the run_score was: 15.0   and mem length: 725151   eps: 0.009998020008555413    steps: 607    lr: 4.0960000000000023e-07     eval rl_reward: 9.75\n","For episode: 2546   the run_score was: 6.0   and mem length: 725527   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.69\n","For episode: 2547   the run_score was: 13.0   and mem length: 726054   eps: 0.009998020008555413    steps: 527    lr: 4.0960000000000023e-07     eval rl_reward: 9.71\n","For episode: 2548   the run_score was: 8.0   and mem length: 726500   eps: 0.009998020008555413    steps: 446    lr: 4.0960000000000023e-07     eval rl_reward: 9.74\n","For episode: 2549   the run_score was: 5.0   and mem length: 726827   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.73\n","For episode: 2550   the run_score was: 11.0   and mem length: 727308   eps: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     eval rl_reward: 9.78\n","For episode: 2551   the run_score was: 7.0   and mem length: 727707   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.72\n","For episode: 2552   the run_score was: 7.0   and mem length: 728135   eps: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     eval rl_reward: 9.61\n","For episode: 2553   the run_score was: 12.0   and mem length: 728714   eps: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     eval rl_reward: 9.62\n","For episode: 2554   the run_score was: 10.0   and mem length: 729242   eps: 0.009998020008555413    steps: 528    lr: 4.0960000000000023e-07     eval rl_reward: 9.65\n","For episode: 2555   the run_score was: 13.0   and mem length: 729790   eps: 0.009998020008555413    steps: 548    lr: 4.0960000000000023e-07     eval rl_reward: 9.72\n","For episode: 2556   the run_score was: 6.0   and mem length: 730169   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.67\n","For episode: 2557   the run_score was: 10.0   and mem length: 730665   eps: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     eval rl_reward: 9.68\n","For episode: 2558   the run_score was: 7.0   and mem length: 731064   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.68\n","For episode: 2559   the run_score was: 8.0   and mem length: 731499   eps: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     eval rl_reward: 9.7\n","For episode: 2560   the run_score was: 9.0   and mem length: 731949   eps: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     eval rl_reward: 9.71\n","For episode: 2561   the run_score was: 8.0   and mem length: 732384   eps: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     eval rl_reward: 9.7\n","For episode: 2562   the run_score was: 7.0   and mem length: 732783   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.67\n","For episode: 2563   the run_score was: 7.0   and mem length: 733182   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.68\n","For episode: 2564   the run_score was: 7.0   and mem length: 733581   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.65\n","For episode: 2565   the run_score was: 9.0   and mem length: 734044   eps: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     eval rl_reward: 9.67\n","For episode: 2566   the run_score was: 6.0   and mem length: 734420   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 9.59\n","For episode: 2567   the run_score was: 12.0   and mem length: 734895   eps: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2568   the run_score was: 11.0   and mem length: 735376   eps: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     eval rl_reward: 9.66\n","For episode: 2569   the run_score was: 5.0   and mem length: 735703   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.65\n","For episode: 2570   the run_score was: 8.0   and mem length: 736138   eps: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     eval rl_reward: 9.62\n","For episode: 2571   the run_score was: 5.0   and mem length: 736463   eps: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     eval rl_reward: 9.56\n","For episode: 2572   the run_score was: 13.0   and mem length: 736959   eps: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     eval rl_reward: 9.63\n","For episode: 2573   the run_score was: 7.0   and mem length: 737349   eps: 0.009998020008555413    steps: 390    lr: 4.0960000000000023e-07     eval rl_reward: 9.57\n","For episode: 2574   the run_score was: 15.0   and mem length: 738052   eps: 0.009998020008555413    steps: 703    lr: 4.0960000000000023e-07     eval rl_reward: 9.59\n","For episode: 2575   the run_score was: 6.0   and mem length: 738431   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.5\n","For episode: 2576   the run_score was: 14.0   and mem length: 738975   eps: 0.009998020008555413    steps: 544    lr: 4.0960000000000023e-07     eval rl_reward: 9.55\n","For episode: 2577   the run_score was: 7.0   and mem length: 739374   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.57\n","For episode: 2578   the run_score was: 6.0   and mem length: 739753   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.54\n","For episode: 2579   the run_score was: 11.0   and mem length: 740301   eps: 0.009998020008555413    steps: 548    lr: 4.0960000000000023e-07     eval rl_reward: 9.53\n","For episode: 2580   the run_score was: 7.0   and mem length: 740700   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.49\n","For episode: 2581   the run_score was: 7.0   and mem length: 741099   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.46\n","For episode: 2582   the run_score was: 5.0   and mem length: 741426   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.41\n","For episode: 2583   the run_score was: 5.0   and mem length: 741753   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.41\n","For episode: 2584   the run_score was: 6.0   and mem length: 742132   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.36\n","For episode: 2585   the run_score was: 12.0   and mem length: 742710   eps: 0.009998020008555413    steps: 578    lr: 4.0960000000000023e-07     eval rl_reward: 9.38\n","For episode: 2586   the run_score was: 13.0   and mem length: 743310   eps: 0.009998020008555413    steps: 600    lr: 4.0960000000000023e-07     eval rl_reward: 9.39\n","For episode: 2587   the run_score was: 11.0   and mem length: 743798   eps: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     eval rl_reward: 9.41\n","For episode: 2588   the run_score was: 6.0   and mem length: 744177   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.33\n","For episode: 2589   the run_score was: 10.0   and mem length: 744673   eps: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     eval rl_reward: 9.33\n","For episode: 2590   the run_score was: 7.0   and mem length: 745072   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.31\n","For episode: 2591   the run_score was: 9.0   and mem length: 745571   eps: 0.009998020008555413    steps: 499    lr: 4.0960000000000023e-07     eval rl_reward: 9.31\n","For episode: 2592   the run_score was: 5.0   and mem length: 745898   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.25\n","For episode: 2593   the run_score was: 12.0   and mem length: 746477   eps: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     eval rl_reward: 9.25\n","For episode: 2594   the run_score was: 10.0   and mem length: 746973   eps: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     eval rl_reward: 9.24\n","For episode: 2595   the run_score was: 5.0   and mem length: 747266   eps: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     eval rl_reward: 9.19\n","For episode: 2596   the run_score was: 11.0   and mem length: 747818   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.24\n","For episode: 2597   the run_score was: 5.0   and mem length: 748145   eps: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     eval rl_reward: 9.15\n","For episode: 2598   the run_score was: 11.0   and mem length: 748698   eps: 0.009998020008555413    steps: 553    lr: 4.0960000000000023e-07     eval rl_reward: 9.17\n","For episode: 2599   the run_score was: 12.0   and mem length: 749266   eps: 0.009998020008555413    steps: 568    lr: 4.0960000000000023e-07     eval rl_reward: 9.16\n","For episode: 2600   the run_score was: 6.0   and mem length: 749624   eps: 0.009998020008555413    steps: 358    lr: 4.0960000000000023e-07     eval rl_reward: 9.08\n","For episode: 2601   the run_score was: 6.0   and mem length: 750000   eps: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     eval rl_reward: 8.96\n","For episode: 2602   the run_score was: 7.0   and mem length: 750372   eps: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     eval rl_reward: 8.92\n","For episode: 2603   the run_score was: 6.0   and mem length: 750751   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.91\n","For episode: 2604   the run_score was: 12.0   and mem length: 751295   eps: 0.009998020008555413    steps: 544    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2605   the run_score was: 9.0   and mem length: 751792   eps: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     eval rl_reward: 8.81\n","For episode: 2606   the run_score was: 16.0   and mem length: 752418   eps: 0.009998020008555413    steps: 626    lr: 4.0960000000000023e-07     eval rl_reward: 8.86\n","For episode: 2607   the run_score was: 8.0   and mem length: 752853   eps: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     eval rl_reward: 8.76\n","For episode: 2608   the run_score was: 10.0   and mem length: 753331   eps: 0.009998020008555413    steps: 478    lr: 4.0960000000000023e-07     eval rl_reward: 8.81\n","For episode: 2609   the run_score was: 15.0   and mem length: 753868   eps: 0.009998020008555413    steps: 537    lr: 4.0960000000000023e-07     eval rl_reward: 8.91\n","For episode: 2610   the run_score was: 14.0   and mem length: 754424   eps: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     eval rl_reward: 8.91\n","For episode: 2611   the run_score was: 10.0   and mem length: 754913   eps: 0.009998020008555413    steps: 489    lr: 4.0960000000000023e-07     eval rl_reward: 8.9\n","For episode: 2612   the run_score was: 6.0   and mem length: 755292   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.87\n","For episode: 2613   the run_score was: 12.0   and mem length: 755902   eps: 0.009998020008555413    steps: 610    lr: 4.0960000000000023e-07     eval rl_reward: 8.88\n","For episode: 2614   the run_score was: 11.0   and mem length: 756454   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 8.84\n","For episode: 2615   the run_score was: 12.0   and mem length: 757010   eps: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     eval rl_reward: 8.83\n","For episode: 2616   the run_score was: 11.0   and mem length: 757562   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 8.85\n","For episode: 2617   the run_score was: 13.0   and mem length: 758152   eps: 0.009998020008555413    steps: 590    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2618   the run_score was: 6.0   and mem length: 758531   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2619   the run_score was: 11.0   and mem length: 759083   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 8.94\n","For episode: 2620   the run_score was: 8.0   and mem length: 759533   eps: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     eval rl_reward: 8.97\n","For episode: 2621   the run_score was: 9.0   and mem length: 759996   eps: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     eval rl_reward: 8.98\n","For episode: 2622   the run_score was: 6.0   and mem length: 760375   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2623   the run_score was: 6.0   and mem length: 760754   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.88\n","For episode: 2624   the run_score was: 12.0   and mem length: 761368   eps: 0.009998020008555413    steps: 614    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2625   the run_score was: 6.0   and mem length: 761747   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 8.86\n","For episode: 2626   the run_score was: 16.0   and mem length: 762373   eps: 0.009998020008555413    steps: 626    lr: 4.0960000000000023e-07     eval rl_reward: 8.89\n","For episode: 2627   the run_score was: 11.0   and mem length: 762925   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 8.95\n","For episode: 2628   the run_score was: 11.0   and mem length: 763497   eps: 0.009998020008555413    steps: 572    lr: 4.0960000000000023e-07     eval rl_reward: 8.94\n","For episode: 2629   the run_score was: 10.0   and mem length: 764022   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 8.96\n","For episode: 2630   the run_score was: 10.0   and mem length: 764547   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.02\n","For episode: 2631   the run_score was: 9.0   and mem length: 765022   eps: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     eval rl_reward: 9.05\n","For episode: 2632   the run_score was: 6.0   and mem length: 765401   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.05\n","For episode: 2633   the run_score was: 10.0   and mem length: 765929   eps: 0.009998020008555413    steps: 528    lr: 4.0960000000000023e-07     eval rl_reward: 9.05\n","For episode: 2634   the run_score was: 11.0   and mem length: 766484   eps: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     eval rl_reward: 9.05\n","For episode: 2635   the run_score was: 8.0   and mem length: 766876   eps: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     eval rl_reward: 9.03\n","For episode: 2636   the run_score was: 11.0   and mem length: 767419   eps: 0.009998020008555413    steps: 543    lr: 4.0960000000000023e-07     eval rl_reward: 9.08\n","For episode: 2637   the run_score was: 19.0   and mem length: 768175   eps: 0.009998020008555413    steps: 756    lr: 4.0960000000000023e-07     eval rl_reward: 9.21\n","For episode: 2638   the run_score was: 14.0   and mem length: 768716   eps: 0.009998020008555413    steps: 541    lr: 4.0960000000000023e-07     eval rl_reward: 9.22\n","For episode: 2639   the run_score was: 12.0   and mem length: 769295   eps: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     eval rl_reward: 9.25\n","For episode: 2640   the run_score was: 13.0   and mem length: 769776   eps: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     eval rl_reward: 9.3\n","For episode: 2641   the run_score was: 10.0   and mem length: 770326   eps: 0.009998020008555413    steps: 550    lr: 4.0960000000000023e-07     eval rl_reward: 9.34\n","For episode: 2642   the run_score was: 11.0   and mem length: 770878   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.36\n","For episode: 2643   the run_score was: 9.0   and mem length: 771331   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 9.36\n","For episode: 2644   the run_score was: 9.0   and mem length: 771784   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 9.38\n","For episode: 2645   the run_score was: 11.0   and mem length: 772336   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.34\n","For episode: 2646   the run_score was: 10.0   and mem length: 772832   eps: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     eval rl_reward: 9.38\n","For episode: 2647   the run_score was: 6.0   and mem length: 773211   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.31\n","For episode: 2648   the run_score was: 11.0   and mem length: 773763   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.34\n","For episode: 2649   the run_score was: 11.0   and mem length: 774314   eps: 0.009998020008555413    steps: 551    lr: 4.0960000000000023e-07     eval rl_reward: 9.4\n","For episode: 2650   the run_score was: 10.0   and mem length: 774839   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.39\n","For episode: 2651   the run_score was: 10.0   and mem length: 775364   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.42\n","For episode: 2652   the run_score was: 7.0   and mem length: 775763   eps: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     eval rl_reward: 9.42\n","For episode: 2653   the run_score was: 6.0   and mem length: 776142   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 9.36\n","For episode: 2654   the run_score was: 21.0   and mem length: 776909   eps: 0.009998020008555413    steps: 767    lr: 4.0960000000000023e-07     eval rl_reward: 9.47\n","For episode: 2655   the run_score was: 8.0   and mem length: 777368   eps: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     eval rl_reward: 9.42\n","For episode: 2656   the run_score was: 9.0   and mem length: 777821   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 9.45\n","For episode: 2657   the run_score was: 10.0   and mem length: 778346   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.45\n","For episode: 2658   the run_score was: 9.0   and mem length: 778843   eps: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     eval rl_reward: 9.47\n","For episode: 2659   the run_score was: 11.0   and mem length: 779395   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 9.5\n","For episode: 2660   the run_score was: 6.0   and mem length: 779749   eps: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     eval rl_reward: 9.47\n","For episode: 2661   the run_score was: 10.0   and mem length: 780291   eps: 0.009998020008555413    steps: 542    lr: 4.0960000000000023e-07     eval rl_reward: 9.49\n","For episode: 2662   the run_score was: 9.0   and mem length: 780752   eps: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     eval rl_reward: 9.51\n","For episode: 2663   the run_score was: 9.0   and mem length: 781256   eps: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     eval rl_reward: 9.53\n","For episode: 2664   the run_score was: 12.0   and mem length: 781751   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 9.58\n","For episode: 2665   the run_score was: 11.0   and mem length: 782302   eps: 0.009998020008555413    steps: 551    lr: 4.0960000000000023e-07     eval rl_reward: 9.6\n","For episode: 2666   the run_score was: 10.0   and mem length: 782779   eps: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     eval rl_reward: 9.64\n","For episode: 2667   the run_score was: 19.0   and mem length: 783535   eps: 0.009998020008555413    steps: 756    lr: 4.0960000000000023e-07     eval rl_reward: 9.71\n","For episode: 2668   the run_score was: 15.0   and mem length: 784150   eps: 0.009998020008555413    steps: 615    lr: 4.0960000000000023e-07     eval rl_reward: 9.75\n","For episode: 2669   the run_score was: 9.0   and mem length: 784627   eps: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     eval rl_reward: 9.79\n","For episode: 2670   the run_score was: 14.0   and mem length: 785171   eps: 0.009998020008555413    steps: 544    lr: 4.0960000000000023e-07     eval rl_reward: 9.85\n","For episode: 2671   the run_score was: 13.0   and mem length: 785778   eps: 0.009998020008555413    steps: 607    lr: 4.0960000000000023e-07     eval rl_reward: 9.93\n","For episode: 2672   the run_score was: 10.0   and mem length: 786303   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 9.9\n","For episode: 2673   the run_score was: 11.0   and mem length: 786836   eps: 0.009998020008555413    steps: 533    lr: 4.0960000000000023e-07     eval rl_reward: 9.94\n","For episode: 2674   the run_score was: 11.0   and mem length: 787382   eps: 0.009998020008555413    steps: 546    lr: 4.0960000000000023e-07     eval rl_reward: 9.9\n","For episode: 2675   the run_score was: 12.0   and mem length: 787877   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 9.96\n","For episode: 2676   the run_score was: 8.0   and mem length: 788313   eps: 0.009998020008555413    steps: 436    lr: 4.0960000000000023e-07     eval rl_reward: 9.9\n","For episode: 2677   the run_score was: 10.0   and mem length: 788834   eps: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     eval rl_reward: 9.93\n","For episode: 2678   the run_score was: 10.0   and mem length: 789311   eps: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     eval rl_reward: 9.97\n","For episode: 2679   the run_score was: 14.0   and mem length: 789867   eps: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     eval rl_reward: 10.0\n","For episode: 2680   the run_score was: 10.0   and mem length: 790392   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 10.03\n","For episode: 2681   the run_score was: 16.0   and mem length: 791018   eps: 0.009998020008555413    steps: 626    lr: 4.0960000000000023e-07     eval rl_reward: 10.12\n","For episode: 2682   the run_score was: 19.0   and mem length: 791761   eps: 0.009998020008555413    steps: 743    lr: 4.0960000000000023e-07     eval rl_reward: 10.26\n","For episode: 2683   the run_score was: 12.0   and mem length: 792256   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 10.33\n","For episode: 2684   the run_score was: 10.0   and mem length: 792781   eps: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     eval rl_reward: 10.37\n","For episode: 2685   the run_score was: 10.0   and mem length: 793258   eps: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     eval rl_reward: 10.35\n","For episode: 2686   the run_score was: 13.0   and mem length: 793868   eps: 0.009998020008555413    steps: 610    lr: 4.0960000000000023e-07     eval rl_reward: 10.35\n","For episode: 2687   the run_score was: 7.0   and mem length: 794298   eps: 0.009998020008555413    steps: 430    lr: 4.0960000000000023e-07     eval rl_reward: 10.31\n","For episode: 2688   the run_score was: 9.0   and mem length: 794797   eps: 0.009998020008555413    steps: 499    lr: 4.0960000000000023e-07     eval rl_reward: 10.34\n","For episode: 2689   the run_score was: 4.0   and mem length: 795057   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 10.28\n","For episode: 2690   the run_score was: 12.0   and mem length: 795626   eps: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     eval rl_reward: 10.33\n","For episode: 2691   the run_score was: 12.0   and mem length: 796121   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 10.36\n","For episode: 2692   the run_score was: 9.0   and mem length: 796597   eps: 0.009998020008555413    steps: 476    lr: 4.0960000000000023e-07     eval rl_reward: 10.4\n","For episode: 2693   the run_score was: 13.0   and mem length: 797106   eps: 0.009998020008555413    steps: 509    lr: 4.0960000000000023e-07     eval rl_reward: 10.41\n","For episode: 2694   the run_score was: 9.0   and mem length: 797559   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 10.4\n","For episode: 2695   the run_score was: 11.0   and mem length: 798111   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 10.46\n","For episode: 2696   the run_score was: 17.0   and mem length: 798696   eps: 0.009998020008555413    steps: 585    lr: 4.0960000000000023e-07     eval rl_reward: 10.52\n","For episode: 2697   the run_score was: 10.0   and mem length: 799179   eps: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     eval rl_reward: 10.57\n","For episode: 2698   the run_score was: 11.0   and mem length: 799731   eps: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     eval rl_reward: 10.57\n","For episode: 2699   the run_score was: 10.0   and mem length: 800208   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.55\n","For episode: 2700   the run_score was: 12.0   and mem length: 800703   eps: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     eval rl_reward: 10.61\n","For episode: 2701   the run_score was: 10.0   and mem length: 801180   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.65\n","For episode: 2702   the run_score was: 10.0   and mem length: 801657   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.68\n","For episode: 2703   the run_score was: 10.0   and mem length: 802182   eps: 0.009998020008555413    steps: 525    lr: 1.638400000000001e-07     eval rl_reward: 10.72\n","For episode: 2704   the run_score was: 12.0   and mem length: 802677   eps: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     eval rl_reward: 10.72\n","For episode: 2705   the run_score was: 9.0   and mem length: 803135   eps: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     eval rl_reward: 10.72\n","For episode: 2706   the run_score was: 7.0   and mem length: 803526   eps: 0.009998020008555413    steps: 391    lr: 1.638400000000001e-07     eval rl_reward: 10.63\n","For episode: 2707   the run_score was: 12.0   and mem length: 804048   eps: 0.009998020008555413    steps: 522    lr: 1.638400000000001e-07     eval rl_reward: 10.67\n","For episode: 2708   the run_score was: 10.0   and mem length: 804531   eps: 0.009998020008555413    steps: 483    lr: 1.638400000000001e-07     eval rl_reward: 10.67\n","For episode: 2709   the run_score was: 11.0   and mem length: 805083   eps: 0.009998020008555413    steps: 552    lr: 1.638400000000001e-07     eval rl_reward: 10.63\n","For episode: 2710   the run_score was: 6.0   and mem length: 805424   eps: 0.009998020008555413    steps: 341    lr: 1.638400000000001e-07     eval rl_reward: 10.55\n","For episode: 2711   the run_score was: 10.0   and mem length: 805901   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.55\n","For episode: 2712   the run_score was: 10.0   and mem length: 806378   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.59\n","For episode: 2713   the run_score was: 10.0   and mem length: 806855   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.57\n","For episode: 2714   the run_score was: 12.0   and mem length: 807350   eps: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     eval rl_reward: 10.58\n","For episode: 2715   the run_score was: 17.0   and mem length: 807935   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 10.63\n","For episode: 2716   the run_score was: 18.0   and mem length: 808645   eps: 0.009998020008555413    steps: 710    lr: 1.638400000000001e-07     eval rl_reward: 10.7\n","For episode: 2717   the run_score was: 14.0   and mem length: 809308   eps: 0.009998020008555413    steps: 663    lr: 1.638400000000001e-07     eval rl_reward: 10.71\n","For episode: 2718   the run_score was: 17.0   and mem length: 809962   eps: 0.009998020008555413    steps: 654    lr: 1.638400000000001e-07     eval rl_reward: 10.82\n","For episode: 2719   the run_score was: 10.0   and mem length: 810439   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.81\n","For episode: 2720   the run_score was: 10.0   and mem length: 810916   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 10.83\n","For episode: 2721   the run_score was: 6.0   and mem length: 811255   eps: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     eval rl_reward: 10.8\n","For episode: 2722   the run_score was: 17.0   and mem length: 811840   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 10.91\n","For episode: 2723   the run_score was: 12.0   and mem length: 812335   eps: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     eval rl_reward: 10.97\n","For episode: 2724   the run_score was: 11.0   and mem length: 812874   eps: 0.009998020008555413    steps: 539    lr: 1.638400000000001e-07     eval rl_reward: 10.96\n","For episode: 2725   the run_score was: 10.0   and mem length: 813402   eps: 0.009998020008555413    steps: 528    lr: 1.638400000000001e-07     eval rl_reward: 11.0\n","For episode: 2726   the run_score was: 10.0   and mem length: 813904   eps: 0.009998020008555413    steps: 502    lr: 1.638400000000001e-07     eval rl_reward: 10.94\n","For episode: 2727   the run_score was: 14.0   and mem length: 814543   eps: 0.009998020008555413    steps: 639    lr: 1.638400000000001e-07     eval rl_reward: 10.97\n","For episode: 2728   the run_score was: 14.0   and mem length: 815206   eps: 0.009998020008555413    steps: 663    lr: 1.638400000000001e-07     eval rl_reward: 11.0\n","For episode: 2729   the run_score was: 10.0   and mem length: 815769   eps: 0.009998020008555413    steps: 563    lr: 1.638400000000001e-07     eval rl_reward: 11.0\n","For episode: 2730   the run_score was: 13.0   and mem length: 816278   eps: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     eval rl_reward: 11.03\n","For episode: 2731   the run_score was: 11.0   and mem length: 816830   eps: 0.009998020008555413    steps: 552    lr: 1.638400000000001e-07     eval rl_reward: 11.05\n","For episode: 2732   the run_score was: 9.0   and mem length: 817282   eps: 0.009998020008555413    steps: 452    lr: 1.638400000000001e-07     eval rl_reward: 11.08\n","For episode: 2733   the run_score was: 11.0   and mem length: 817834   eps: 0.009998020008555413    steps: 552    lr: 1.638400000000001e-07     eval rl_reward: 11.09\n","For episode: 2734   the run_score was: 11.0   and mem length: 818386   eps: 0.009998020008555413    steps: 552    lr: 1.638400000000001e-07     eval rl_reward: 11.09\n","For episode: 2735   the run_score was: 11.0   and mem length: 818938   eps: 0.009998020008555413    steps: 552    lr: 1.638400000000001e-07     eval rl_reward: 11.12\n","For episode: 2736   the run_score was: 11.0   and mem length: 819511   eps: 0.009998020008555413    steps: 573    lr: 1.638400000000001e-07     eval rl_reward: 11.12\n","For episode: 2737   the run_score was: 9.0   and mem length: 819963   eps: 0.009998020008555413    steps: 452    lr: 1.638400000000001e-07     eval rl_reward: 11.02\n","For episode: 2738   the run_score was: 11.0   and mem length: 820536   eps: 0.009998020008555413    steps: 573    lr: 1.638400000000001e-07     eval rl_reward: 10.99\n","For episode: 2739   the run_score was: 17.0   and mem length: 821121   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 11.04\n","For episode: 2740   the run_score was: 17.0   and mem length: 821706   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 11.08\n","For episode: 2741   the run_score was: 17.0   and mem length: 822291   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 11.15\n","For episode: 2742   the run_score was: 17.0   and mem length: 822876   eps: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     eval rl_reward: 11.21\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-0a44f4a02be3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# only train when ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0mtraining_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_net_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdouble_d\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mtarget_update_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_to_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/DQN/your_double_agent.py\u001b[0m in \u001b[0;36mp_net_training\u001b[0;34m(self, current_step)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Sampling from replay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msys_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/DQN/memory.py\u001b[0m in \u001b[0;36mget_mini_batch\u001b[0;34m(self, current_step)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["rl_rewards, episodes = [], []\n","best_rl_reward_from_eval = 0\n","for e in range(num_episodes):\n","    done = False\n","    run_score = 0\n","\n","    state_history = np.zeros([5, 84, 84], dtype=np.uint8) # 5 x 84 x 84\n","    step = 0\n","    state = env.reset() # reset the environment for new episode\n","    subsequent_state = state\n","    life = max_number_of_lives_in_game # resetting life count - new game\n","\n","    get_initialization_state(state_history, state, history_length) # set up the states\n","\n","    while not done:\n","        step += 1\n","        cnt_frame+= 1\n","\n","        if step > 1 and len(np.unique(subsequent_state[:189] == state[:189])) < 2:\n","            action = 0  # This is going to \"fire\"  - this is checking to see if you need to start the game\n","        else:\n","            action = agent.select_action(np.float32(state_history[:4, :, :]) / 255.) # converting imgs to 0-1\n","        state = subsequent_state\n","        subsequent_state, rl_reward, done, info_dictionary = env.step(action + 1)\n","\n","        frame_counter_subsequent_state = process_frame(subsequent_state)\n","        state_history[4, :, :] = frame_counter_subsequent_state\n","        last_state = check_if_live(life, info_dictionary['lives'])\n","\n","        life = info_dictionary['lives']\n","        r = rl_reward\n","\n","        agent.sys_memory.record(deepcopy(frame_counter_subsequent_state), action, r, last_state)\n","\n","        # only train when ready\n","        if(cnt_frame>= training_frames):\n","            agent.p_net_training(cnt_frame)\n","            if double_d and (cnt_frame% target_update_frequency)== 0:\n","                agent.target_to_policy()\n","        run_score += rl_reward\n","        state_history[:4, :, :] = state_history[1:, :, :] # cut off last\n","\n","        if done:\n","            rl_reward_from_eval.append(run_score)\n","            rl_rewards.append(np.mean(rl_reward_from_eval))\n","            episodes.append(e)\n","            pylab.plot(episodes, rl_rewards, 'b')\n","            pylab.xlabel('Number of Episodes')\n","            pylab.ylabel('Amount of Rewards')\n","            pylab.title('Plot of Episodes and Rewards')\n","            pylab.savefig(\"./deep_q.png\")\n","\n","            print(\"For episode:\", e, \"  the run_score was:\", run_score, \"  and mem length:\",\n","                  len(agent.sys_memory), \"  eps:\", agent.eps, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    eval rl_reward:\", np.mean(rl_reward_from_eval))\n","\n","            ### You can change this to whatever you want\n","            if np.mean(rl_reward_from_eval) > 5 and np.mean(rl_reward_from_eval) > best_rl_reward_from_eval:\n","                torch.save(agent.policy_network, \"./dqn.pth\")\n","                best_rl_reward_from_eval = np.mean(rl_reward_from_eval)\n"]},{"cell_type":"markdown","metadata":{"id":"Q4otfIYf8-82"},"source":["## Visualizing the Game"]},{"cell_type":"markdown","metadata":{"id":"7zaP8GUo8-82"},"source":["Be careful - you don't want to run this twice in the same kernel or it will crash. Recommend you save your model before making visualization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5In0r_Bx8-82"},"outputs":[],"source":["torch.save(agent.policy_network, \"./dqn_last.pth\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"aUtQ6Eev8-83","executionInfo":{"status":"ok","timestamp":1714702167763,"user_tz":240,"elapsed":187,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["# from gym.wrappers import Monitor # `\n","from gym.wrappers import RecordVideo\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","import glob\n","import io\n","import base64\n","from pyvirtualdisplay import Display\n","\n","def vis_curr(env, step=0, info_dictionary=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Curr Step: %d %s\" % (\"Game\",step, info_dictionary))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True) # for jupyter notebook\n","    ipythondisplay.display(plt.gcf()) # for jupyter\n","\n","# Making a video of the jupyter\n","def make_video_of_jupyter():\n","    videos_from_glob = glob.glob('video.mp4')\n","    if len(videos_from_glob) > 0:\n","        mp4 = videos_from_glob[0] # video path\n","        video = io.open(mp4, 'r+b').read() # load in the video\n","        encoded = base64.b64encode(video) # encode in base 64  # this code below creates html for the video in jupyter\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"No video\")\n","\n","\n","def environment_writer(env):\n","    env = RecordVideo(env, './video')\n","    return env"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"aso2A7m68-83","executionInfo":{"status":"ok","timestamp":1714702267515,"user_tz":240,"elapsed":96188,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"colab":{"base_uri":"https://localhost:8080/","height":1261},"outputId":"d06097a4-046c-4a7e-df2e-73a18967b169"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7af418064a60>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["display = Display(visible=0, size=(300, 200))\n","display.start()\n","\n","# Load agent\n","# might need to write code to load the agent if you are resuming here:\n","#load here\n","#############\n","# agent.eps = 0.0 # Why would we want this?\n","agent = EnvironmentAgent(action_to_take_size)\n","agent.load_policy_network(\"/content/drive/My Drive/DQN/dqn_last.pth\")\n","agent.eps = 0.0 # Why would we want this?\n","\n","env = gym.make('BreakoutDeterministic-v4',render_mode='rgb_array')\n","env = environment_writer(env)\n","\n","done = False\n","run_score = 0\n","step = 0\n","state = env.reset()\n","subsequent_state = state\n","life = max_number_of_lives_in_game # this stuff is all same as above\n","state_history = np.zeros([5, 84, 84], dtype=np.uint8)\n","# get_initialization_state(state_history, state)\n","\n","while not done:\n","\n","    # env.render()\n","    vis_curr(env,step)\n","\n","    step += 1\n","    cnt_frame+= 1\n","\n","    if step > 1 and len(np.unique(subsequent_state[:189] == state[:189])) < 2:\n","        action = 0  # This is going to \"fire\"  - this is checking to see if you need to start the game\n","    else:\n","        action = agent.select_action(np.float32(state_history[:4, :, :]) / 255.) # converting imgs to 0-1\n","    state = subsequent_state\n","\n","    # subsequent_state, rl_reward, done, info_dictionary = env.step(action_to_take + 1)\n","    subsequent_state, rl_reward, done, info_dictionary = env.step(action + 1)\n","\n","    frame_counter_subsequent_state = process_frame(subsequent_state)\n","    state_history[4, :, :] = frame_counter_subsequent_state\n","    last_state = check_if_live(life, info_dictionary['lives'])\n","\n","    life = info_dictionary['lives'] # lives in gym\n","    r = np.clip(rl_reward, -1, 1)  # clipping reward between -1 and 1\n","    r = rl_reward\n","\n","    agent.sys_memory.record(deepcopy(frame_counter_subsequent_state), action, r, last_state)\n","\n","    run_score += rl_reward\n","\n","    state_history[:4, :, :] = state_history[1:, :, :]\n","\n","env.close()\n","make_video_of_jupyter()\n","display.stop()"]},{"cell_type":"markdown","source":["**Analysis of Graphs**\n","\n","\n","# *Normal DQN Training Progress:*\n","\n","The graph displays a general upward trend in the rewards over episodes, indicating improvement in the agent's performance as training progresses.\n","The graph shows some fluctuations, but these tend to decrease as the number of episodes increases, suggesting some degree of learning stabilization.\n","\n","*Double DQN Training Progress:*\n","The Double DQN also shows an improvement in rewards over time, which is typical as the agent explores and exploits the environment.\n","The rewards seem to stabilize earlier than in the normal DQN setup, and the peaks of rewards are generally higher, indicating potentially more effective learning and better policy stabilization.\n","\n","**Comparative Insights:**\n","\n","*Stability and Performance:* The Double DQN appears to achieve a more stable and higher reward faster than the normal DQN. This could be attributed to the reduced overestimation of Q-values inherent in the Double DQN method.\n","Consistency: Double DQN shows less variance in rewards towards the later episodes compared to normal DQN, suggesting that Double DQN might be more consistent in its performance across different states of the environment."],"metadata":{"id":"yiImnJUGQJoR"}},{"cell_type":"markdown","source":["**We also see Double DQ is a better player and has a better score overall.**"],"metadata":{"id":"xsDdOcIjTG6Y"}},{"cell_type":"markdown","source":["## **Please check the video in my ipynb for both double DQ and normal DQ.**"],"metadata":{"id":"MAclGvgATcEv"}},{"cell_type":"code","source":["print('Thanks for taking the effort to grade folks. As a Graduate Student myself I understand the pain juggling courses, grades and life. Cya on the other side. Cheers!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Q6YvHcS6W31Q","executionInfo":{"status":"ok","timestamp":1714704633225,"user_tz":240,"elapsed":183,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"e2dbe629-7414-4631-b776-ada880b86491"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Thanks for taking the effort to grade folks. As a Graduate Student myself I understand the pain juggling courses, grades and life. Cya on the other side. Cheers!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6o-mh8fSXEtr"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}