{"cells":[{"cell_type":"markdown","metadata":{"id":"_vk6J8-b8-8v"},"source":["# CS 5814 Homework 4, Part 2: Deep Q-Learning"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"csIfanhh8-8y","executionInfo":{"status":"ok","timestamp":1714696378783,"user_tz":240,"elapsed":27533,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"7eb9fbab-f062-48fa-a771-cc0e79d3c170"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xvfbwrapper in /usr/local/lib/python3.10/dist-packages (0.2.9)\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n","Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (3.1.7)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n"]}],"source":["#!pip3 install gym pyvirtualdisplay # gym is the OpenAI gym: https://github.com/openai/gym\n","!pip3 install xvfbwrapper pyvirtualdisplay\n","!pip3 install pyopengl\n","!pip3 install ffmpeg-python"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"OeVYmUL98-8z","executionInfo":{"status":"ok","timestamp":1714696346290,"user_tz":240,"elapsed":20640,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"64c344a1-3b7e-44dc-c4c3-b8232010dd2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (65.5.0)\n","Collecting setuptools\n","  Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n","Installing collected packages: setuptools\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","pip-tools 6.13.0 requires pip>=22.2, but you have pip 21.0 which is incompatible.\u001b[0m\n","Successfully installed setuptools-69.5.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","pkg_resources","setuptools"]},"id":"ed8cd3912c1e4377ac92a634e06f6844"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ez_setup in /usr/local/lib/python3.10/dist-packages (0.9)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"]}],"source":["!pip3 install --upgrade setuptools --user\n","!pip3 install ez_setup\n","# !pip3 install gym[atari] # Atari games\n","# !pip3 install gym[accept-rom-license] # accept the license agreement"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"I0zHcZ4K-wx8","executionInfo":{"status":"ok","timestamp":1714696379739,"user_tz":240,"elapsed":968,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"5cd5e65b-acd7-45f9-a86a-f1d6be50f3fd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","datadir = \"/content/drive/My Drive/part2/\" # path to the homework\n","if not os.path.exists(datadir):\n","  !ln -s \"\" $datadir # path to the homework\n","os.chdir(datadir)\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Vek6KXew-2Ld","executionInfo":{"status":"ok","timestamp":1714696382728,"user_tz":240,"elapsed":209,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"3008bd5b-9ab7-46a8-ae1a-f2af862febc1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/part2\n"]}]},{"cell_type":"markdown","metadata":{"id":"QdBhchT-8-8z"},"source":["You should take a look at [this paper](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) before beginning. You'll be playing the game of __Breakout__."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nHPyjEBP8-80","executionInfo":{"status":"ok","timestamp":1714696396517,"user_tz":240,"elapsed":4117,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from model import Model\n","from utils import count_max_lives, check_if_live, process_frame, get_initialization_state\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["!pip show gym"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0wlLy1u0_aQc","executionInfo":{"status":"ok","timestamp":1714696401742,"user_tz":240,"elapsed":4710,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"81b268a9-3a31-4758-cb9b-f0ccffaadb7f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: gym\n","Version: 0.21.0\n","Summary: Gym: A universal API for reinforcement learning environments.\n","Home-page: https://github.com/openai/gym\n","Author: OpenAI\n","Author-email: jkterry@umd.edu\n","License: None\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: numpy, cloudpickle\n","Required-by: dopamine-rl\n"]}]},{"cell_type":"markdown","metadata":{"id":"ngqM8KFL8-80"},"source":["## Initialize env"]},{"cell_type":"markdown","metadata":{"id":"0aN7BReV8-80"},"source":["Refer to the Gym [documentation](https://www.gymlibrary.dev/environments/atari/breakout/) for more details on the environment. There are three action_to_takes in this game - \"left\", \"right\" (to move the paddle) and \"fire\" (this releases the ball)."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZoIYfNV38-80","executionInfo":{"status":"ok","timestamp":1714696407881,"user_tz":240,"elapsed":709,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["env = gym.make('BreakoutDeterministic-v4')\n","# v0 vs v4: v0 has repeat_action_to_take_probability of 0.25 (meaning 25% of the time the previous action_to_take will be used instead of the new action_to_take), while v4 has 0 (always follow your issued action_to_take)\n","# Deterministic: a fixed frame_counterskip of 4, while for the env without Deterministic, frame_counterskip is sampled from (2,5)\n","# https://github.com/openai/gym/issues/1280\n","state = env.reset()"]},{"cell_type":"code","source":["env.step(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"4SJErCSK0SKr","executionInfo":{"status":"ok","timestamp":1714696411338,"user_tz":240,"elapsed":155,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"175c068b-a9d0-4d36-9ee0-0e8e8b1e6d56"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]],\n"," \n","        [[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]],\n"," \n","        [[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]],\n"," \n","        ...,\n"," \n","        [[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]],\n"," \n","        [[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]],\n"," \n","        [[0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         ...,\n","         [0, 0, 0],\n","         [0, 0, 0],\n","         [0, 0, 0]]], dtype=uint8),\n"," 0.0,\n"," False,\n"," {'lives': 5, 'episode_frame_number': 4, 'frame_number': 4})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"laaMFU-M8-81","executionInfo":{"status":"ok","timestamp":1714696427003,"user_tz":240,"elapsed":173,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["max_number_of_lives_in_game = count_max_lives(env)\n","state_size = env.observation_space.shape\n","action_to_take_size = 3"]},{"cell_type":"markdown","metadata":{"id":"7tZvi_rz8-81"},"source":["## Create your agent"]},{"cell_type":"markdown","metadata":{"id":"JBXFKv-k8-81"},"source":["The agent is defined in the __your_agent.py__ file. We have coded a network for you already in the __model.py__ file. You shouldn't change the implementation we have there for fairness.\n","\n","Once you get that working, you'll need to then create a double agent (see [this paper](https://arxiv.org/pdf/1509.06461.pdf)) in the __your_double_agent.py__ file. We have a switch below which determines which to train."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"gJZWSV9B8-81","executionInfo":{"status":"ok","timestamp":1714696432512,"user_tz":240,"elapsed":2169,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["double_d = False # switch\n","\n","if double_d:\n","    from your_double_agent import EnvironmentAgent\n","else:\n","    from your_agent import EnvironmentAgent\n","\n","agent = EnvironmentAgent(action_to_take_size) # buff size\n","rl_reward_from_eval = deque(maxlen=evaluation_reward_window) # This is avg rl_reward from 100 games\n","cnt_frame= 0\n","memory_size = 0"]},{"cell_type":"markdown","metadata":{"id":"kqQKFWWC8-82"},"source":["### Training"]},{"cell_type":"code","execution_count":10,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":70873},"id":"131uuRy48-82","executionInfo":{"status":"error","timestamp":1714689142591,"user_tz":240,"elapsed":65471,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"ccd0b57d-be94-4954-8ca3-8e8eeb25d3c3"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["For episode: 0   the run_score was: 3.0   and mem length: 228   eps: 1.0    steps: 228    lr: 0.0001     eval rl_reward: 3.0\n","For episode: 1   the run_score was: 3.0   and mem length: 495   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 3.0\n","For episode: 2   the run_score was: 0.0   and mem length: 618   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 3   the run_score was: 3.0   and mem length: 865   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 4   the run_score was: 4.0   and mem length: 1181   eps: 1.0    steps: 316    lr: 0.0001     eval rl_reward: 2.6\n","For episode: 5   the run_score was: 1.0   and mem length: 1333   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 2.3333333333333335\n","For episode: 6   the run_score was: 1.0   and mem length: 1505   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 2.142857142857143\n","For episode: 7   the run_score was: 0.0   and mem length: 1629   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.875\n","For episode: 8   the run_score was: 0.0   and mem length: 1752   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.6666666666666667\n","For episode: 9   the run_score was: 3.0   and mem length: 1999   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.8\n","For episode: 10   the run_score was: 1.0   and mem length: 2151   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.7272727272727273\n","For episode: 11   the run_score was: 2.0   and mem length: 2350   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 12   the run_score was: 4.0   and mem length: 2626   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.9230769230769231\n","For episode: 13   the run_score was: 1.0   and mem length: 2796   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.8571428571428572\n","For episode: 14   the run_score was: 8.0   and mem length: 3165   eps: 1.0    steps: 369    lr: 0.0001     eval rl_reward: 2.2666666666666666\n","For episode: 15   the run_score was: 2.0   and mem length: 3384   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 2.25\n","For episode: 16   the run_score was: 3.0   and mem length: 3610   eps: 1.0    steps: 226    lr: 0.0001     eval rl_reward: 2.2941176470588234\n","For episode: 17   the run_score was: 1.0   and mem length: 3780   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 2.2222222222222223\n","For episode: 18   the run_score was: 2.0   and mem length: 3979   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 2.210526315789474\n","For episode: 19   the run_score was: 2.0   and mem length: 4177   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 20   the run_score was: 2.0   and mem length: 4377   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 2.1904761904761907\n","For episode: 21   the run_score was: 3.0   and mem length: 4644   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 2.227272727272727\n","For episode: 22   the run_score was: 0.0   and mem length: 4767   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 2.130434782608696\n","For episode: 23   the run_score was: 1.0   and mem length: 4919   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 2.0833333333333335\n","For episode: 24   the run_score was: 2.0   and mem length: 5118   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 2.08\n","For episode: 25   the run_score was: 1.0   and mem length: 5288   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 2.0384615384615383\n","For episode: 26   the run_score was: 3.0   and mem length: 5537   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 2.074074074074074\n","For episode: 27   the run_score was: 2.0   and mem length: 5756   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 2.0714285714285716\n","For episode: 28   the run_score was: 3.0   and mem length: 5983   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 2.103448275862069\n","For episode: 29   the run_score was: 5.0   and mem length: 6275   eps: 1.0    steps: 292    lr: 0.0001     eval rl_reward: 2.2\n","For episode: 30   the run_score was: 1.0   and mem length: 6426   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 2.161290322580645\n","For episode: 31   the run_score was: 1.0   and mem length: 6596   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 2.125\n","For episode: 32   the run_score was: 2.0   and mem length: 6816   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 2.121212121212121\n","For episode: 33   the run_score was: 2.0   and mem length: 7035   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 2.1176470588235294\n","For episode: 34   the run_score was: 2.0   and mem length: 7233   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 2.1142857142857143\n","For episode: 35   the run_score was: 0.0   and mem length: 7357   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 2.0555555555555554\n","For episode: 36   the run_score was: 2.0   and mem length: 7556   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 2.054054054054054\n","For episode: 37   the run_score was: 3.0   and mem length: 7783   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 2.0789473684210527\n","For episode: 38   the run_score was: 1.0   and mem length: 7953   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 2.051282051282051\n","For episode: 39   the run_score was: 2.0   and mem length: 8151   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 2.05\n","For episode: 40   the run_score was: 1.0   and mem length: 8303   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 2.024390243902439\n","For episode: 41   the run_score was: 2.0   and mem length: 8502   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 2.0238095238095237\n","For episode: 42   the run_score was: 2.0   and mem length: 8724   eps: 1.0    steps: 222    lr: 0.0001     eval rl_reward: 2.0232558139534884\n","For episode: 43   the run_score was: 1.0   and mem length: 8893   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 2.0\n","For episode: 44   the run_score was: 1.0   and mem length: 9064   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.9777777777777779\n","For episode: 45   the run_score was: 1.0   and mem length: 9216   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.9565217391304348\n","For episode: 46   the run_score was: 2.0   and mem length: 9417   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.9574468085106382\n","For episode: 47   the run_score was: 2.0   and mem length: 9618   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.9583333333333333\n","For episode: 48   the run_score was: 3.0   and mem length: 9845   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.9795918367346939\n","For episode: 49   the run_score was: 2.0   and mem length: 10044   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.98\n","For episode: 50   the run_score was: 0.0   and mem length: 10167   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.9411764705882353\n","For episode: 51   the run_score was: 0.0   and mem length: 10291   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.9038461538461537\n","For episode: 52   the run_score was: 1.0   and mem length: 10442   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.8867924528301887\n","For episode: 53   the run_score was: 1.0   and mem length: 10613   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.8703703703703705\n","For episode: 54   the run_score was: 0.0   and mem length: 10737   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.8363636363636364\n","For episode: 55   the run_score was: 1.0   and mem length: 10888   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.8214285714285714\n","For episode: 56   the run_score was: 0.0   and mem length: 11012   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.7894736842105263\n","For episode: 57   the run_score was: 2.0   and mem length: 11210   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.793103448275862\n","For episode: 58   the run_score was: 2.0   and mem length: 11432   eps: 1.0    steps: 222    lr: 0.0001     eval rl_reward: 1.7966101694915255\n","For episode: 59   the run_score was: 0.0   and mem length: 11555   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.7666666666666666\n","For episode: 60   the run_score was: 0.0   and mem length: 11679   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.7377049180327868\n","For episode: 61   the run_score was: 2.0   and mem length: 11878   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.7419354838709677\n","For episode: 62   the run_score was: 3.0   and mem length: 12125   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.7619047619047619\n","For episode: 63   the run_score was: 1.0   and mem length: 12297   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 64   the run_score was: 2.0   and mem length: 12496   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.7538461538461538\n","For episode: 65   the run_score was: 1.0   and mem length: 12648   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.7424242424242424\n","For episode: 66   the run_score was: 2.0   and mem length: 12846   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.7462686567164178\n","For episode: 67   the run_score was: 1.0   and mem length: 13018   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.7352941176470589\n","For episode: 68   the run_score was: 0.0   and mem length: 13142   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.710144927536232\n","For episode: 69   the run_score was: 5.0   and mem length: 13446   eps: 1.0    steps: 304    lr: 0.0001     eval rl_reward: 1.7571428571428571\n","For episode: 70   the run_score was: 5.0   and mem length: 13776   eps: 1.0    steps: 330    lr: 0.0001     eval rl_reward: 1.8028169014084507\n","For episode: 71   the run_score was: 0.0   and mem length: 13900   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.7777777777777777\n","For episode: 72   the run_score was: 1.0   and mem length: 14070   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.7671232876712328\n","For episode: 73   the run_score was: 1.0   and mem length: 14240   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.7567567567567568\n","For episode: 74   the run_score was: 1.0   and mem length: 14411   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.7466666666666666\n","For episode: 75   the run_score was: 1.0   and mem length: 14563   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.736842105263158\n","For episode: 76   the run_score was: 1.0   and mem length: 14734   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.7272727272727273\n","For episode: 77   the run_score was: 2.0   and mem length: 14955   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.7307692307692308\n","For episode: 78   the run_score was: 3.0   and mem length: 15203   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.7468354430379747\n","For episode: 79   the run_score was: 2.0   and mem length: 15422   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 80   the run_score was: 1.0   and mem length: 15592   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.7407407407407407\n","For episode: 81   the run_score was: 1.0   and mem length: 15761   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.7317073170731707\n","For episode: 82   the run_score was: 0.0   and mem length: 15885   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.7108433734939759\n","For episode: 83   the run_score was: 1.0   and mem length: 16054   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.7023809523809523\n","For episode: 84   the run_score was: 3.0   and mem length: 16283   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.7176470588235293\n","For episode: 85   the run_score was: 1.0   and mem length: 16434   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.7093023255813953\n","For episode: 86   the run_score was: 3.0   and mem length: 16660   eps: 1.0    steps: 226    lr: 0.0001     eval rl_reward: 1.7241379310344827\n","For episode: 87   the run_score was: 0.0   and mem length: 16784   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.7045454545454546\n","For episode: 88   the run_score was: 6.0   and mem length: 17110   eps: 1.0    steps: 326    lr: 0.0001     eval rl_reward: 1.752808988764045\n","For episode: 89   the run_score was: 2.0   and mem length: 17291   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.7555555555555555\n","For episode: 90   the run_score was: 1.0   and mem length: 17462   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.7472527472527473\n","For episode: 91   the run_score was: 2.0   and mem length: 17661   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 92   the run_score was: 2.0   and mem length: 17880   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.7526881720430108\n","For episode: 93   the run_score was: 0.0   and mem length: 18003   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.7340425531914894\n","For episode: 94   the run_score was: 2.0   and mem length: 18202   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.736842105263158\n","For episode: 95   the run_score was: 3.0   and mem length: 18448   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.75\n","For episode: 96   the run_score was: 1.0   and mem length: 18617   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.7422680412371134\n","For episode: 97   the run_score was: 1.0   and mem length: 18787   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.7346938775510203\n","For episode: 98   the run_score was: 2.0   and mem length: 18988   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.7373737373737375\n","For episode: 99   the run_score was: 1.0   and mem length: 19159   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 100   the run_score was: 2.0   and mem length: 19380   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.72\n","For episode: 101   the run_score was: 2.0   and mem length: 19599   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 102   the run_score was: 0.0   and mem length: 19722   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 103   the run_score was: 3.0   and mem length: 19970   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 104   the run_score was: 2.0   and mem length: 20151   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.69\n","For episode: 105   the run_score was: 9.0   and mem length: 20524   eps: 1.0    steps: 373    lr: 0.0001     eval rl_reward: 1.77\n","For episode: 106   the run_score was: 0.0   and mem length: 20647   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.76\n","For episode: 107   the run_score was: 1.0   and mem length: 20818   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.77\n","For episode: 108   the run_score was: 3.0   and mem length: 21066   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.8\n","For episode: 109   the run_score was: 1.0   and mem length: 21236   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.78\n","For episode: 110   the run_score was: 0.0   and mem length: 21360   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.77\n","For episode: 111   the run_score was: 1.0   and mem length: 21512   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.76\n","For episode: 112   the run_score was: 2.0   and mem length: 21710   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.74\n","For episode: 113   the run_score was: 0.0   and mem length: 21833   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.73\n","For episode: 114   the run_score was: 1.0   and mem length: 22006   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 115   the run_score was: 2.0   and mem length: 22225   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 116   the run_score was: 2.0   and mem length: 22423   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 117   the run_score was: 3.0   and mem length: 22691   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.67\n","For episode: 118   the run_score was: 1.0   and mem length: 22862   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 119   the run_score was: 0.0   and mem length: 22986   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 120   the run_score was: 3.0   and mem length: 23234   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 121   the run_score was: 1.0   and mem length: 23404   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 122   the run_score was: 2.0   and mem length: 23621   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 123   the run_score was: 2.0   and mem length: 23819   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 124   the run_score was: 2.0   and mem length: 24002   eps: 1.0    steps: 183    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 125   the run_score was: 0.0   and mem length: 24126   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 126   the run_score was: 3.0   and mem length: 24372   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 127   the run_score was: 0.0   and mem length: 24496   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 128   the run_score was: 1.0   and mem length: 24648   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 129   the run_score was: 0.0   and mem length: 24772   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 130   the run_score was: 0.0   and mem length: 24896   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 131   the run_score was: 3.0   and mem length: 25144   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 132   the run_score was: 2.0   and mem length: 25343   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 133   the run_score was: 1.0   and mem length: 25495   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 134   the run_score was: 5.0   and mem length: 25819   eps: 1.0    steps: 324    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 135   the run_score was: 0.0   and mem length: 25942   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 136   the run_score was: 2.0   and mem length: 26164   eps: 1.0    steps: 222    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 137   the run_score was: 0.0   and mem length: 26288   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 138   the run_score was: 1.0   and mem length: 26440   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 139   the run_score was: 0.0   and mem length: 26563   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 140   the run_score was: 1.0   and mem length: 26733   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 141   the run_score was: 3.0   and mem length: 26980   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 142   the run_score was: 2.0   and mem length: 27179   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 143   the run_score was: 1.0   and mem length: 27331   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 144   the run_score was: 1.0   and mem length: 27500   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 145   the run_score was: 2.0   and mem length: 27719   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 146   the run_score was: 4.0   and mem length: 28015   eps: 1.0    steps: 296    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 147   the run_score was: 1.0   and mem length: 28185   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 148   the run_score was: 2.0   and mem length: 28385   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 149   the run_score was: 2.0   and mem length: 28604   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 150   the run_score was: 0.0   and mem length: 28727   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 151   the run_score was: 1.0   and mem length: 28896   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 152   the run_score was: 2.0   and mem length: 29097   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 153   the run_score was: 1.0   and mem length: 29267   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 154   the run_score was: 0.0   and mem length: 29390   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 155   the run_score was: 3.0   and mem length: 29637   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 156   the run_score was: 0.0   and mem length: 29760   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 157   the run_score was: 0.0   and mem length: 29884   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 158   the run_score was: 0.0   and mem length: 30008   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 159   the run_score was: 1.0   and mem length: 30178   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 160   the run_score was: 1.0   and mem length: 30330   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 161   the run_score was: 1.0   and mem length: 30500   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 162   the run_score was: 0.0   and mem length: 30624   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 163   the run_score was: 0.0   and mem length: 30748   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 164   the run_score was: 0.0   and mem length: 30872   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 165   the run_score was: 1.0   and mem length: 31045   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 166   the run_score was: 5.0   and mem length: 31353   eps: 1.0    steps: 308    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 167   the run_score was: 2.0   and mem length: 31574   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 168   the run_score was: 2.0   and mem length: 31755   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 169   the run_score was: 4.0   and mem length: 32035   eps: 1.0    steps: 280    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 170   the run_score was: 1.0   and mem length: 32187   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 171   the run_score was: 2.0   and mem length: 32385   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 172   the run_score was: 4.0   and mem length: 32679   eps: 1.0    steps: 294    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 173   the run_score was: 1.0   and mem length: 32831   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 174   the run_score was: 2.0   and mem length: 33049   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 175   the run_score was: 4.0   and mem length: 33364   eps: 1.0    steps: 315    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 176   the run_score was: 3.0   and mem length: 33612   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 177   the run_score was: 0.0   and mem length: 33736   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 178   the run_score was: 1.0   and mem length: 33887   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 179   the run_score was: 1.0   and mem length: 34057   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 180   the run_score was: 3.0   and mem length: 34284   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 181   the run_score was: 1.0   and mem length: 34436   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 182   the run_score was: 0.0   and mem length: 34559   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 183   the run_score was: 2.0   and mem length: 34758   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 184   the run_score was: 2.0   and mem length: 34977   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 185   the run_score was: 0.0   and mem length: 35101   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 186   the run_score was: 1.0   and mem length: 35271   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 187   the run_score was: 0.0   and mem length: 35395   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 188   the run_score was: 1.0   and mem length: 35565   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 189   the run_score was: 3.0   and mem length: 35832   eps: 1.0    steps: 267    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 190   the run_score was: 3.0   and mem length: 36101   eps: 1.0    steps: 269    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 191   the run_score was: 1.0   and mem length: 36253   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 192   the run_score was: 6.0   and mem length: 36630   eps: 1.0    steps: 377    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 193   the run_score was: 2.0   and mem length: 36829   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 194   the run_score was: 0.0   and mem length: 36953   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 195   the run_score was: 1.0   and mem length: 37104   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 196   the run_score was: 3.0   and mem length: 37368   eps: 1.0    steps: 264    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 197   the run_score was: 1.0   and mem length: 37519   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 198   the run_score was: 3.0   and mem length: 37787   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 199   the run_score was: 6.0   and mem length: 38175   eps: 1.0    steps: 388    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 200   the run_score was: 0.0   and mem length: 38299   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 201   the run_score was: 1.0   and mem length: 38468   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 202   the run_score was: 1.0   and mem length: 38620   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 203   the run_score was: 1.0   and mem length: 38789   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 204   the run_score was: 1.0   and mem length: 38941   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 205   the run_score was: 1.0   and mem length: 39112   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 206   the run_score was: 0.0   and mem length: 39236   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 207   the run_score was: 0.0   and mem length: 39359   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 208   the run_score was: 1.0   and mem length: 39511   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 209   the run_score was: 1.0   and mem length: 39683   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 210   the run_score was: 1.0   and mem length: 39852   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 211   the run_score was: 2.0   and mem length: 40052   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 212   the run_score was: 2.0   and mem length: 40250   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 213   the run_score was: 2.0   and mem length: 40449   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 214   the run_score was: 1.0   and mem length: 40620   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 215   the run_score was: 2.0   and mem length: 40843   eps: 1.0    steps: 223    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 216   the run_score was: 0.0   and mem length: 40967   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 217   the run_score was: 2.0   and mem length: 41186   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 218   the run_score was: 3.0   and mem length: 41456   eps: 1.0    steps: 270    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 219   the run_score was: 0.0   and mem length: 41580   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 220   the run_score was: 0.0   and mem length: 41704   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 221   the run_score was: 2.0   and mem length: 41886   eps: 1.0    steps: 182    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 222   the run_score was: 0.0   and mem length: 42009   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 223   the run_score was: 3.0   and mem length: 42273   eps: 1.0    steps: 264    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 224   the run_score was: 0.0   and mem length: 42397   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 225   the run_score was: 2.0   and mem length: 42579   eps: 1.0    steps: 182    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 226   the run_score was: 3.0   and mem length: 42828   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 227   the run_score was: 3.0   and mem length: 43076   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 228   the run_score was: 8.0   and mem length: 43390   eps: 1.0    steps: 314    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 229   the run_score was: 2.0   and mem length: 43612   eps: 1.0    steps: 222    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 230   the run_score was: 2.0   and mem length: 43811   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 231   the run_score was: 2.0   and mem length: 44030   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 232   the run_score was: 1.0   and mem length: 44201   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 233   the run_score was: 2.0   and mem length: 44419   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 234   the run_score was: 2.0   and mem length: 44619   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 235   the run_score was: 2.0   and mem length: 44817   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 236   the run_score was: 5.0   and mem length: 45161   eps: 1.0    steps: 344    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 237   the run_score was: 2.0   and mem length: 45378   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 238   the run_score was: 2.0   and mem length: 45577   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 239   the run_score was: 2.0   and mem length: 45795   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.68\n","For episode: 240   the run_score was: 4.0   and mem length: 46071   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 241   the run_score was: 0.0   and mem length: 46195   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.68\n","For episode: 242   the run_score was: 0.0   and mem length: 46318   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 243   the run_score was: 0.0   and mem length: 46442   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 244   the run_score was: 0.0   and mem length: 46566   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 245   the run_score was: 4.0   and mem length: 46865   eps: 1.0    steps: 299    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 246   the run_score was: 0.0   and mem length: 46989   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 247   the run_score was: 0.0   and mem length: 47112   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 248   the run_score was: 2.0   and mem length: 47332   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 249   the run_score was: 2.0   and mem length: 47549   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 250   the run_score was: 0.0   and mem length: 47673   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 251   the run_score was: 0.0   and mem length: 47797   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 252   the run_score was: 1.0   and mem length: 47948   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 253   the run_score was: 0.0   and mem length: 48071   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 254   the run_score was: 0.0   and mem length: 48194   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 255   the run_score was: 1.0   and mem length: 48365   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 256   the run_score was: 1.0   and mem length: 48538   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 257   the run_score was: 1.0   and mem length: 48711   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 258   the run_score was: 1.0   and mem length: 48881   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 259   the run_score was: 2.0   and mem length: 49064   eps: 1.0    steps: 183    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 260   the run_score was: 2.0   and mem length: 49282   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 261   the run_score was: 1.0   and mem length: 49434   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 262   the run_score was: 2.0   and mem length: 49633   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 263   the run_score was: 2.0   and mem length: 49834   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 264   the run_score was: 2.0   and mem length: 50033   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.67\n","For episode: 265   the run_score was: 2.0   and mem length: 50232   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.68\n","For episode: 266   the run_score was: 2.0   and mem length: 50431   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 267   the run_score was: 3.0   and mem length: 50678   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 268   the run_score was: 1.0   and mem length: 50847   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 269   the run_score was: 1.0   and mem length: 51016   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 270   the run_score was: 1.0   and mem length: 51168   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 271   the run_score was: 0.0   and mem length: 51292   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 272   the run_score was: 4.0   and mem length: 51573   eps: 1.0    steps: 281    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 273   the run_score was: 0.0   and mem length: 51697   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 274   the run_score was: 0.0   and mem length: 51820   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 275   the run_score was: 3.0   and mem length: 52066   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 276   the run_score was: 1.0   and mem length: 52236   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 277   the run_score was: 3.0   and mem length: 52483   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 278   the run_score was: 2.0   and mem length: 52681   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 279   the run_score was: 0.0   and mem length: 52804   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 280   the run_score was: 2.0   and mem length: 53023   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 281   the run_score was: 0.0   and mem length: 53147   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 282   the run_score was: 3.0   and mem length: 53419   eps: 1.0    steps: 272    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 283   the run_score was: 0.0   and mem length: 53542   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 284   the run_score was: 2.0   and mem length: 53741   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 285   the run_score was: 0.0   and mem length: 53865   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 286   the run_score was: 0.0   and mem length: 53988   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 287   the run_score was: 0.0   and mem length: 54112   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 288   the run_score was: 3.0   and mem length: 54359   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 289   the run_score was: 1.0   and mem length: 54528   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 290   the run_score was: 1.0   and mem length: 54697   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 291   the run_score was: 0.0   and mem length: 54821   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 292   the run_score was: 3.0   and mem length: 55090   eps: 1.0    steps: 269    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 293   the run_score was: 3.0   and mem length: 55318   eps: 1.0    steps: 228    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 294   the run_score was: 0.0   and mem length: 55441   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 295   the run_score was: 2.0   and mem length: 55665   eps: 1.0    steps: 224    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 296   the run_score was: 3.0   and mem length: 55892   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 297   the run_score was: 1.0   and mem length: 56062   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 298   the run_score was: 2.0   and mem length: 56281   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 299   the run_score was: 3.0   and mem length: 56529   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 300   the run_score was: 1.0   and mem length: 56680   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 301   the run_score was: 1.0   and mem length: 56852   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 302   the run_score was: 0.0   and mem length: 56976   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 303   the run_score was: 1.0   and mem length: 57148   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 304   the run_score was: 1.0   and mem length: 57320   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 305   the run_score was: 2.0   and mem length: 57518   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 306   the run_score was: 2.0   and mem length: 57719   eps: 1.0    steps: 201    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 307   the run_score was: 2.0   and mem length: 57900   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 308   the run_score was: 1.0   and mem length: 58070   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 309   the run_score was: 4.0   and mem length: 58367   eps: 1.0    steps: 297    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 310   the run_score was: 1.0   and mem length: 58518   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 311   the run_score was: 4.0   and mem length: 58807   eps: 1.0    steps: 289    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 312   the run_score was: 0.0   and mem length: 58931   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 313   the run_score was: 0.0   and mem length: 59054   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 314   the run_score was: 1.0   and mem length: 59206   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 315   the run_score was: 1.0   and mem length: 59358   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 316   the run_score was: 2.0   and mem length: 59557   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 317   the run_score was: 2.0   and mem length: 59776   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 318   the run_score was: 3.0   and mem length: 60048   eps: 1.0    steps: 272    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 319   the run_score was: 1.0   and mem length: 60217   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 320   the run_score was: 0.0   and mem length: 60341   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 321   the run_score was: 1.0   and mem length: 60512   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 322   the run_score was: 2.0   and mem length: 60693   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 323   the run_score was: 0.0   and mem length: 60817   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 324   the run_score was: 1.0   and mem length: 60969   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 325   the run_score was: 1.0   and mem length: 61139   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 326   the run_score was: 0.0   and mem length: 61262   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 327   the run_score was: 1.0   and mem length: 61431   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 328   the run_score was: 0.0   and mem length: 61554   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 329   the run_score was: 0.0   and mem length: 61678   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 330   the run_score was: 1.0   and mem length: 61848   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 331   the run_score was: 0.0   and mem length: 61971   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 332   the run_score was: 2.0   and mem length: 62171   eps: 1.0    steps: 200    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 333   the run_score was: 4.0   and mem length: 62447   eps: 1.0    steps: 276    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 334   the run_score was: 0.0   and mem length: 62571   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 335   the run_score was: 2.0   and mem length: 62773   eps: 1.0    steps: 202    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 336   the run_score was: 3.0   and mem length: 63003   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 337   the run_score was: 1.0   and mem length: 63173   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 338   the run_score was: 0.0   and mem length: 63297   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 339   the run_score was: 3.0   and mem length: 63567   eps: 1.0    steps: 270    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 340   the run_score was: 3.0   and mem length: 63833   eps: 1.0    steps: 266    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 341   the run_score was: 4.0   and mem length: 64151   eps: 1.0    steps: 318    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 342   the run_score was: 1.0   and mem length: 64302   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 343   the run_score was: 0.0   and mem length: 64426   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 344   the run_score was: 0.0   and mem length: 64550   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 345   the run_score was: 0.0   and mem length: 64673   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 346   the run_score was: 3.0   and mem length: 64921   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 347   the run_score was: 2.0   and mem length: 65145   eps: 1.0    steps: 224    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 348   the run_score was: 2.0   and mem length: 65343   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 349   the run_score was: 0.0   and mem length: 65466   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 350   the run_score was: 1.0   and mem length: 65636   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 351   the run_score was: 1.0   and mem length: 65788   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 352   the run_score was: 1.0   and mem length: 65960   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 353   the run_score was: 0.0   and mem length: 66084   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 354   the run_score was: 2.0   and mem length: 66282   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 355   the run_score was: 0.0   and mem length: 66406   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 356   the run_score was: 2.0   and mem length: 66626   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 357   the run_score was: 1.0   and mem length: 66778   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 358   the run_score was: 3.0   and mem length: 67027   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 359   the run_score was: 1.0   and mem length: 67199   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 360   the run_score was: 2.0   and mem length: 67397   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 361   the run_score was: 0.0   and mem length: 67521   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 362   the run_score was: 1.0   and mem length: 67694   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 363   the run_score was: 3.0   and mem length: 67962   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 364   the run_score was: 0.0   and mem length: 68085   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 365   the run_score was: 1.0   and mem length: 68237   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 366   the run_score was: 0.0   and mem length: 68360   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 367   the run_score was: 1.0   and mem length: 68531   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 368   the run_score was: 1.0   and mem length: 68701   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 369   the run_score was: 0.0   and mem length: 68824   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 370   the run_score was: 1.0   and mem length: 68994   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 371   the run_score was: 1.0   and mem length: 69165   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 372   the run_score was: 0.0   and mem length: 69289   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 373   the run_score was: 0.0   and mem length: 69412   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.28\n","For episode: 374   the run_score was: 1.0   and mem length: 69582   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.29\n","For episode: 375   the run_score was: 0.0   and mem length: 69706   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 376   the run_score was: 0.0   and mem length: 69830   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 377   the run_score was: 0.0   and mem length: 69954   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 378   the run_score was: 2.0   and mem length: 70174   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.22\n","For episode: 379   the run_score was: 1.0   and mem length: 70344   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 380   the run_score was: 0.0   and mem length: 70468   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 381   the run_score was: 0.0   and mem length: 70591   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.21\n","For episode: 382   the run_score was: 0.0   and mem length: 70715   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.18\n","For episode: 383   the run_score was: 0.0   and mem length: 70838   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.18\n","For episode: 384   the run_score was: 2.0   and mem length: 71037   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.18\n","For episode: 385   the run_score was: 5.0   and mem length: 71365   eps: 1.0    steps: 328    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 386   the run_score was: 0.0   and mem length: 71489   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.23\n","For episode: 387   the run_score was: 3.0   and mem length: 71734   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 388   the run_score was: 1.0   and mem length: 71885   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.24\n","For episode: 389   the run_score was: 3.0   and mem length: 72117   eps: 1.0    steps: 232    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 390   the run_score was: 1.0   and mem length: 72288   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 391   the run_score was: 0.0   and mem length: 72411   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 392   the run_score was: 2.0   and mem length: 72632   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 393   the run_score was: 4.0   and mem length: 72888   eps: 1.0    steps: 256    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 394   the run_score was: 0.0   and mem length: 73012   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 395   the run_score was: 2.0   and mem length: 73211   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 396   the run_score was: 2.0   and mem length: 73409   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.25\n","For episode: 397   the run_score was: 2.0   and mem length: 73608   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 398   the run_score was: 2.0   and mem length: 73825   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.26\n","For episode: 399   the run_score was: 4.0   and mem length: 74140   eps: 1.0    steps: 315    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 400   the run_score was: 1.0   and mem length: 74310   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.27\n","For episode: 401   the run_score was: 9.0   and mem length: 74682   eps: 1.0    steps: 372    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 402   the run_score was: 1.0   and mem length: 74834   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 403   the run_score was: 2.0   and mem length: 75015   eps: 1.0    steps: 181    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 404   the run_score was: 0.0   and mem length: 75139   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 405   the run_score was: 0.0   and mem length: 75263   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 406   the run_score was: 6.0   and mem length: 75620   eps: 1.0    steps: 357    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 407   the run_score was: 1.0   and mem length: 75772   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 408   the run_score was: 3.0   and mem length: 76003   eps: 1.0    steps: 231    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 409   the run_score was: 3.0   and mem length: 76250   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 410   the run_score was: 0.0   and mem length: 76374   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 411   the run_score was: 3.0   and mem length: 76603   eps: 1.0    steps: 229    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 412   the run_score was: 0.0   and mem length: 76727   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 413   the run_score was: 0.0   and mem length: 76851   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 414   the run_score was: 1.0   and mem length: 77021   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 415   the run_score was: 1.0   and mem length: 77172   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 416   the run_score was: 2.0   and mem length: 77391   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 417   the run_score was: 0.0   and mem length: 77515   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 418   the run_score was: 1.0   and mem length: 77685   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 419   the run_score was: 6.0   and mem length: 78054   eps: 1.0    steps: 369    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 420   the run_score was: 5.0   and mem length: 78381   eps: 1.0    steps: 327    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 421   the run_score was: 1.0   and mem length: 78532   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 422   the run_score was: 1.0   and mem length: 78704   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 423   the run_score was: 2.0   and mem length: 78886   eps: 1.0    steps: 182    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 424   the run_score was: 0.0   and mem length: 79009   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 425   the run_score was: 0.0   and mem length: 79133   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 426   the run_score was: 1.0   and mem length: 79302   eps: 1.0    steps: 169    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 427   the run_score was: 3.0   and mem length: 79529   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 428   the run_score was: 1.0   and mem length: 79699   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 429   the run_score was: 0.0   and mem length: 79823   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 430   the run_score was: 0.0   and mem length: 79947   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 431   the run_score was: 2.0   and mem length: 80145   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 432   the run_score was: 2.0   and mem length: 80325   eps: 1.0    steps: 180    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 433   the run_score was: 2.0   and mem length: 80544   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 434   the run_score was: 6.0   and mem length: 80939   eps: 1.0    steps: 395    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 435   the run_score was: 0.0   and mem length: 81063   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 436   the run_score was: 1.0   and mem length: 81235   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 437   the run_score was: 1.0   and mem length: 81387   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 438   the run_score was: 0.0   and mem length: 81511   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 439   the run_score was: 3.0   and mem length: 81757   eps: 1.0    steps: 246    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 440   the run_score was: 0.0   and mem length: 81880   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 441   the run_score was: 2.0   and mem length: 82078   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 442   the run_score was: 0.0   and mem length: 82201   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 443   the run_score was: 2.0   and mem length: 82400   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 444   the run_score was: 0.0   and mem length: 82524   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 445   the run_score was: 2.0   and mem length: 82723   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 446   the run_score was: 2.0   and mem length: 82922   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 447   the run_score was: 0.0   and mem length: 83046   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 448   the run_score was: 1.0   and mem length: 83219   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 449   the run_score was: 3.0   and mem length: 83487   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 450   the run_score was: 0.0   and mem length: 83611   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 451   the run_score was: 2.0   and mem length: 83830   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 452   the run_score was: 4.0   and mem length: 84126   eps: 1.0    steps: 296    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 453   the run_score was: 2.0   and mem length: 84325   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 454   the run_score was: 0.0   and mem length: 84449   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 455   the run_score was: 0.0   and mem length: 84572   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 456   the run_score was: 3.0   and mem length: 84799   eps: 1.0    steps: 227    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 457   the run_score was: 2.0   and mem length: 85018   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 458   the run_score was: 1.0   and mem length: 85169   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 459   the run_score was: 1.0   and mem length: 85321   eps: 1.0    steps: 152    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 460   the run_score was: 3.0   and mem length: 85570   eps: 1.0    steps: 249    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 461   the run_score was: 1.0   and mem length: 85723   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 462   the run_score was: 1.0   and mem length: 85874   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 463   the run_score was: 2.0   and mem length: 86073   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 464   the run_score was: 1.0   and mem length: 86244   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 465   the run_score was: 3.0   and mem length: 86510   eps: 1.0    steps: 266    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 466   the run_score was: 3.0   and mem length: 86757   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 467   the run_score was: 2.0   and mem length: 86976   eps: 1.0    steps: 219    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 468   the run_score was: 0.0   and mem length: 87100   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 469   the run_score was: 2.0   and mem length: 87317   eps: 1.0    steps: 217    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 470   the run_score was: 2.0   and mem length: 87516   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 471   the run_score was: 3.0   and mem length: 87746   eps: 1.0    steps: 230    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 472   the run_score was: 1.0   and mem length: 87916   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 473   the run_score was: 3.0   and mem length: 88142   eps: 1.0    steps: 226    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 474   the run_score was: 0.0   and mem length: 88265   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 475   the run_score was: 0.0   and mem length: 88388   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 476   the run_score was: 0.0   and mem length: 88512   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 477   the run_score was: 4.0   and mem length: 88805   eps: 1.0    steps: 293    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 478   the run_score was: 0.0   and mem length: 88929   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 479   the run_score was: 2.0   and mem length: 89127   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 480   the run_score was: 0.0   and mem length: 89251   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 481   the run_score was: 0.0   and mem length: 89375   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 482   the run_score was: 2.0   and mem length: 89574   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 483   the run_score was: 5.0   and mem length: 89898   eps: 1.0    steps: 324    lr: 0.0001     eval rl_reward: 1.71\n","For episode: 484   the run_score was: 0.0   and mem length: 90022   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.69\n","For episode: 485   the run_score was: 0.0   and mem length: 90146   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 486   the run_score was: 2.0   and mem length: 90345   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 487   the run_score was: 0.0   and mem length: 90469   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 488   the run_score was: 0.0   and mem length: 90592   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 489   the run_score was: 1.0   and mem length: 90743   eps: 1.0    steps: 151    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 490   the run_score was: 4.0   and mem length: 91002   eps: 1.0    steps: 259    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 491   the run_score was: 0.0   and mem length: 91126   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 492   the run_score was: 1.0   and mem length: 91297   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 493   the run_score was: 2.0   and mem length: 91496   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 494   the run_score was: 2.0   and mem length: 91714   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 495   the run_score was: 2.0   and mem length: 91913   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 496   the run_score was: 1.0   and mem length: 92085   eps: 1.0    steps: 172    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 497   the run_score was: 0.0   and mem length: 92209   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 498   the run_score was: 0.0   and mem length: 92332   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 499   the run_score was: 1.0   and mem length: 92485   eps: 1.0    steps: 153    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 500   the run_score was: 3.0   and mem length: 92732   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 501   the run_score was: 1.0   and mem length: 92902   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 502   the run_score was: 2.0   and mem length: 93101   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 503   the run_score was: 2.0   and mem length: 93299   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 504   the run_score was: 2.0   and mem length: 93498   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 505   the run_score was: 1.0   and mem length: 93671   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 506   the run_score was: 3.0   and mem length: 93937   eps: 1.0    steps: 266    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 507   the run_score was: 2.0   and mem length: 94157   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 508   the run_score was: 2.0   and mem length: 94375   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 509   the run_score was: 0.0   and mem length: 94499   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 510   the run_score was: 0.0   and mem length: 94622   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 511   the run_score was: 2.0   and mem length: 94821   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 512   the run_score was: 3.0   and mem length: 95066   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 513   the run_score was: 0.0   and mem length: 95190   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 514   the run_score was: 2.0   and mem length: 95410   eps: 1.0    steps: 220    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 515   the run_score was: 1.0   and mem length: 95583   eps: 1.0    steps: 173    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 516   the run_score was: 3.0   and mem length: 95830   eps: 1.0    steps: 247    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 517   the run_score was: 2.0   and mem length: 96028   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 518   the run_score was: 1.0   and mem length: 96198   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 519   the run_score was: 0.0   and mem length: 96322   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 520   the run_score was: 2.0   and mem length: 96543   eps: 1.0    steps: 221    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 521   the run_score was: 0.0   and mem length: 96667   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 522   the run_score was: 0.0   and mem length: 96791   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 523   the run_score was: 0.0   and mem length: 96914   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 524   the run_score was: 2.0   and mem length: 97112   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 525   the run_score was: 0.0   and mem length: 97235   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 526   the run_score was: 3.0   and mem length: 97480   eps: 1.0    steps: 245    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 527   the run_score was: 1.0   and mem length: 97650   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 528   the run_score was: 3.0   and mem length: 97898   eps: 1.0    steps: 248    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 529   the run_score was: 0.0   and mem length: 98022   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 530   the run_score was: 2.0   and mem length: 98220   eps: 1.0    steps: 198    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 531   the run_score was: 2.0   and mem length: 98438   eps: 1.0    steps: 218    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 532   the run_score was: 1.0   and mem length: 98609   eps: 1.0    steps: 171    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 533   the run_score was: 2.0   and mem length: 98808   eps: 1.0    steps: 199    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 534   the run_score was: 0.0   and mem length: 98931   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 535   the run_score was: 0.0   and mem length: 99055   eps: 1.0    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 536   the run_score was: 1.0   and mem length: 99225   eps: 1.0    steps: 170    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 537   the run_score was: 5.0   and mem length: 99573   eps: 1.0    steps: 348    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 538   the run_score was: 0.0   and mem length: 99696   eps: 1.0    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 539   the run_score was: 3.0   and mem length: 99964   eps: 1.0    steps: 268    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 540   the run_score was: 1.0   and mem length: 100116   eps: 0.999768340000005    steps: 152    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 541   the run_score was: 1.0   and mem length: 100268   eps: 0.9994673800000116    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 542   the run_score was: 2.0   and mem length: 100448   eps: 0.9991109800000193    steps: 180    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 543   the run_score was: 1.0   and mem length: 100619   eps: 0.9987724000000266    steps: 171    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 544   the run_score was: 0.0   and mem length: 100743   eps: 0.998526880000032    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 545   the run_score was: 0.0   and mem length: 100866   eps: 0.9982833400000373    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 546   the run_score was: 3.0   and mem length: 101112   eps: 0.9977962600000478    steps: 246    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 547   the run_score was: 0.0   and mem length: 101236   eps: 0.9975507400000532    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 548   the run_score was: 0.0   and mem length: 101359   eps: 0.9973072000000585    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 549   the run_score was: 1.0   and mem length: 101529   eps: 0.9969706000000658    steps: 170    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 550   the run_score was: 0.0   and mem length: 101652   eps: 0.996727060000071    steps: 123    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 551   the run_score was: 2.0   and mem length: 101870   eps: 0.9962954200000804    steps: 218    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 552   the run_score was: 0.0   and mem length: 101994   eps: 0.9960499000000858    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 553   the run_score was: 3.0   and mem length: 102242   eps: 0.9955588600000964    steps: 248    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 554   the run_score was: 2.0   and mem length: 102459   eps: 0.9951292000001057    steps: 217    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 555   the run_score was: 2.0   and mem length: 102640   eps: 0.9947708200001135    steps: 181    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 556   the run_score was: 2.0   and mem length: 102861   eps: 0.994333240000123    steps: 221    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 557   the run_score was: 2.0   and mem length: 103059   eps: 0.9939412000001315    steps: 198    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 558   the run_score was: 2.0   and mem length: 103277   eps: 0.9935095600001409    steps: 218    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 559   the run_score was: 3.0   and mem length: 103506   eps: 0.9930561400001507    steps: 229    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 560   the run_score was: 1.0   and mem length: 103658   eps: 0.9927551800001573    steps: 152    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 561   the run_score was: 1.0   and mem length: 103830   eps: 0.9924146200001647    steps: 172    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 562   the run_score was: 3.0   and mem length: 104075   eps: 0.9919295200001752    steps: 245    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 563   the run_score was: 2.0   and mem length: 104261   eps: 0.9915612400001832    steps: 186    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 564   the run_score was: 1.0   and mem length: 104434   eps: 0.9912187000001906    steps: 173    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 565   the run_score was: 1.0   and mem length: 104586   eps: 0.9909177400001972    steps: 152    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 566   the run_score was: 2.0   and mem length: 104805   eps: 0.9904841200002066    steps: 219    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 567   the run_score was: 0.0   and mem length: 104929   eps: 0.9902386000002119    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 568   the run_score was: 2.0   and mem length: 105128   eps: 0.9898445800002205    steps: 199    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 569   the run_score was: 0.0   and mem length: 105251   eps: 0.9896010400002258    steps: 123    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 570   the run_score was: 6.0   and mem length: 105620   eps: 0.9888704200002416    steps: 369    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 571   the run_score was: 2.0   and mem length: 105819   eps: 0.9884764000002502    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 572   the run_score was: 0.0   and mem length: 105943   eps: 0.9882308800002555    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 573   the run_score was: 0.0   and mem length: 106067   eps: 0.9879853600002608    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 574   the run_score was: 1.0   and mem length: 106238   eps: 0.9876467800002682    steps: 171    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 575   the run_score was: 2.0   and mem length: 106419   eps: 0.987288400000276    steps: 181    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 576   the run_score was: 3.0   and mem length: 106664   eps: 0.9868033000002865    steps: 245    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 577   the run_score was: 1.0   and mem length: 106834   eps: 0.9864667000002938    steps: 170    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 578   the run_score was: 1.0   and mem length: 106985   eps: 0.9861677200003003    steps: 151    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 579   the run_score was: 3.0   and mem length: 107235   eps: 0.985672720000311    steps: 250    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 580   the run_score was: 5.0   and mem length: 107578   eps: 0.9849935800003258    steps: 343    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 581   the run_score was: 1.0   and mem length: 107730   eps: 0.9846926200003323    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 582   the run_score was: 0.0   and mem length: 107854   eps: 0.9844471000003376    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 583   the run_score was: 2.0   and mem length: 108070   eps: 0.9840194200003469    steps: 216    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 584   the run_score was: 3.0   and mem length: 108300   eps: 0.9835640200003568    steps: 230    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 585   the run_score was: 1.0   and mem length: 108452   eps: 0.9832630600003633    steps: 152    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 586   the run_score was: 1.0   and mem length: 108621   eps: 0.9829284400003706    steps: 169    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 587   the run_score was: 2.0   and mem length: 108820   eps: 0.9825344200003792    steps: 199    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 588   the run_score was: 2.0   and mem length: 109036   eps: 0.9821067400003884    steps: 216    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 589   the run_score was: 2.0   and mem length: 109222   eps: 0.9817384600003964    steps: 186    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 590   the run_score was: 0.0   and mem length: 109346   eps: 0.9814929400004018    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 591   the run_score was: 0.0   and mem length: 109470   eps: 0.9812474200004071    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 592   the run_score was: 2.0   and mem length: 109672   eps: 0.9808474600004158    steps: 202    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 593   the run_score was: 0.0   and mem length: 109795   eps: 0.9806039200004211    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 594   the run_score was: 1.0   and mem length: 109965   eps: 0.9802673200004284    steps: 170    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 595   the run_score was: 0.0   and mem length: 110089   eps: 0.9800218000004337    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 596   the run_score was: 3.0   and mem length: 110337   eps: 0.9795307600004444    steps: 248    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 597   the run_score was: 2.0   and mem length: 110554   eps: 0.9791011000004537    steps: 217    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 598   the run_score was: 0.0   and mem length: 110678   eps: 0.978855580000459    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 599   the run_score was: 3.0   and mem length: 110925   eps: 0.9783665200004696    steps: 247    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 600   the run_score was: 4.0   and mem length: 111205   eps: 0.9778121200004817    steps: 280    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 601   the run_score was: 3.0   and mem length: 111473   eps: 0.9772814800004932    steps: 268    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 602   the run_score was: 0.0   and mem length: 111596   eps: 0.9770379400004985    steps: 123    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 603   the run_score was: 1.0   and mem length: 111766   eps: 0.9767013400005058    steps: 170    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 604   the run_score was: 2.0   and mem length: 111986   eps: 0.9762657400005152    steps: 220    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 605   the run_score was: 2.0   and mem length: 112187   eps: 0.9758677600005239    steps: 201    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 606   the run_score was: 2.0   and mem length: 112370   eps: 0.9755054200005318    steps: 183    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 607   the run_score was: 1.0   and mem length: 112540   eps: 0.9751688200005391    steps: 170    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 608   the run_score was: 3.0   and mem length: 112769   eps: 0.9747154000005489    steps: 229    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 609   the run_score was: 0.0   and mem length: 112892   eps: 0.9744718600005542    steps: 123    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 610   the run_score was: 0.0   and mem length: 113016   eps: 0.9742263400005595    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 611   the run_score was: 3.0   and mem length: 113243   eps: 0.9737768800005693    steps: 227    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 612   the run_score was: 4.0   and mem length: 113541   eps: 0.9731868400005821    steps: 298    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 613   the run_score was: 0.0   and mem length: 113665   eps: 0.9729413200005874    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 614   the run_score was: 2.0   and mem length: 113885   eps: 0.9725057200005969    steps: 220    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 615   the run_score was: 4.0   and mem length: 114187   eps: 0.9719077600006099    steps: 302    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 616   the run_score was: 3.0   and mem length: 114417   eps: 0.9714523600006197    steps: 230    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 617   the run_score was: 2.0   and mem length: 114618   eps: 0.9710543800006284    steps: 201    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 618   the run_score was: 0.0   and mem length: 114741   eps: 0.9708108400006337    steps: 123    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 619   the run_score was: 2.0   and mem length: 114924   eps: 0.9704485000006415    steps: 183    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 620   the run_score was: 0.0   and mem length: 115048   eps: 0.9702029800006469    steps: 124    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 621   the run_score was: 3.0   and mem length: 115297   eps: 0.9697099600006576    steps: 249    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 622   the run_score was: 1.0   and mem length: 115449   eps: 0.9694090000006641    steps: 152    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 623   the run_score was: 3.0   and mem length: 115675   eps: 0.9689615200006738    steps: 226    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 624   the run_score was: 1.0   and mem length: 115848   eps: 0.9686189800006813    steps: 173    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 625   the run_score was: 7.0   and mem length: 116204   eps: 0.9679141000006966    steps: 356    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 626   the run_score was: 2.0   and mem length: 116403   eps: 0.9675200800007051    steps: 199    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 627   the run_score was: 1.0   and mem length: 116575   eps: 0.9671795200007125    steps: 172    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 628   the run_score was: 0.0   and mem length: 116699   eps: 0.9669340000007178    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 629   the run_score was: 1.0   and mem length: 116868   eps: 0.9665993800007251    steps: 169    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 630   the run_score was: 0.0   and mem length: 116991   eps: 0.9663558400007304    steps: 123    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 631   the run_score was: 2.0   and mem length: 117208   eps: 0.9659261800007397    steps: 217    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 632   the run_score was: 1.0   and mem length: 117360   eps: 0.9656252200007462    steps: 152    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 633   the run_score was: 3.0   and mem length: 117609   eps: 0.965132200000757    steps: 249    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 634   the run_score was: 0.0   and mem length: 117733   eps: 0.9648866800007623    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 635   the run_score was: 2.0   and mem length: 117931   eps: 0.9644946400007708    steps: 198    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 636   the run_score was: 4.0   and mem length: 118228   eps: 0.9639065800007836    steps: 297    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 637   the run_score was: 0.0   and mem length: 118352   eps: 0.9636610600007889    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 638   the run_score was: 1.0   and mem length: 118524   eps: 0.9633205000007963    steps: 172    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 639   the run_score was: 1.0   and mem length: 118695   eps: 0.9629819200008036    steps: 171    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 640   the run_score was: 2.0   and mem length: 118914   eps: 0.962548300000813    steps: 219    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 641   the run_score was: 3.0   and mem length: 119160   eps: 0.9620612200008236    steps: 246    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 642   the run_score was: 2.0   and mem length: 119379   eps: 0.961627600000833    steps: 219    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 643   the run_score was: 0.0   and mem length: 119503   eps: 0.9613820800008384    steps: 124    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 644   the run_score was: 3.0   and mem length: 119716   eps: 0.9609603400008475    steps: 213    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 645   the run_score was: 2.0   and mem length: 119914   eps: 0.960568300000856    steps: 198    lr: 0.0001     eval rl_reward: 1.67\n","For episode: 646   the run_score was: 0.0   and mem length: 120037   eps: 0.9603247600008613    steps: 123    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 647   the run_score was: 0.0   and mem length: 120160   eps: 0.9600812200008666    steps: 123    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 648   the run_score was: 0.0   and mem length: 120284   eps: 0.9598357000008719    steps: 124    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 649   the run_score was: 1.0   and mem length: 120436   eps: 0.9595347400008785    steps: 152    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 650   the run_score was: 4.0   and mem length: 120712   eps: 0.9589882600008903    steps: 276    lr: 0.0001     eval rl_reward: 1.68\n","For episode: 651   the run_score was: 0.0   and mem length: 120835   eps: 0.9587447200008956    steps: 123    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 652   the run_score was: 2.0   and mem length: 121054   eps: 0.958311100000905    steps: 219    lr: 0.0001     eval rl_reward: 1.68\n","For episode: 653   the run_score was: 1.0   and mem length: 121206   eps: 0.9580101400009116    steps: 152    lr: 0.0001     eval rl_reward: 1.66\n","For episode: 654   the run_score was: 1.0   and mem length: 121379   eps: 0.957667600000919    steps: 173    lr: 0.0001     eval rl_reward: 1.65\n","For episode: 655   the run_score was: 1.0   and mem length: 121530   eps: 0.9573686200009255    steps: 151    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 656   the run_score was: 0.0   and mem length: 121654   eps: 0.9571231000009308    steps: 124    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 657   the run_score was: 2.0   and mem length: 121873   eps: 0.9566894800009402    steps: 219    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 658   the run_score was: 1.0   and mem length: 122043   eps: 0.9563528800009475    steps: 170    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 659   the run_score was: 1.0   and mem length: 122215   eps: 0.9560123200009549    steps: 172    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 660   the run_score was: 3.0   and mem length: 122444   eps: 0.9555589000009648    steps: 229    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 661   the run_score was: 3.0   and mem length: 122671   eps: 0.9551094400009745    steps: 227    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 662   the run_score was: 0.0   and mem length: 122795   eps: 0.9548639200009799    steps: 124    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 663   the run_score was: 2.0   and mem length: 123013   eps: 0.9544322800009892    steps: 218    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 664   the run_score was: 2.0   and mem length: 123233   eps: 0.9539966800009987    steps: 220    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 665   the run_score was: 3.0   and mem length: 123477   eps: 0.9535135600010092    steps: 244    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 666   the run_score was: 1.0   and mem length: 123629   eps: 0.9532126000010157    steps: 152    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 667   the run_score was: 2.0   and mem length: 123847   eps: 0.9527809600010251    steps: 218    lr: 0.0001     eval rl_reward: 1.64\n","For episode: 668   the run_score was: 0.0   and mem length: 123970   eps: 0.9525374200010304    steps: 123    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 669   the run_score was: 1.0   and mem length: 124142   eps: 0.9521968600010378    steps: 172    lr: 0.0001     eval rl_reward: 1.63\n","For episode: 670   the run_score was: 0.0   and mem length: 124265   eps: 0.951953320001043    steps: 123    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 671   the run_score was: 2.0   and mem length: 124463   eps: 0.9515612800010516    steps: 198    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 672   the run_score was: 0.0   and mem length: 124587   eps: 0.9513157600010569    steps: 124    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 673   the run_score was: 4.0   and mem length: 124884   eps: 0.9507277000010697    steps: 297    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 674   the run_score was: 0.0   and mem length: 125007   eps: 0.9504841600010749    steps: 123    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 675   the run_score was: 3.0   and mem length: 125234   eps: 0.9500347000010847    steps: 227    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 676   the run_score was: 2.0   and mem length: 125433   eps: 0.9496406800010933    steps: 199    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 677   the run_score was: 3.0   and mem length: 125701   eps: 0.9491100400011048    steps: 268    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 678   the run_score was: 0.0   and mem length: 125825   eps: 0.9488645200011101    steps: 124    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 679   the run_score was: 1.0   and mem length: 125976   eps: 0.9485655400011166    steps: 151    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 680   the run_score was: 0.0   and mem length: 126100   eps: 0.9483200200011219    steps: 124    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 681   the run_score was: 0.0   and mem length: 126224   eps: 0.9480745000011273    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 682   the run_score was: 0.0   and mem length: 126348   eps: 0.9478289800011326    steps: 124    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 683   the run_score was: 3.0   and mem length: 126574   eps: 0.9473815000011423    steps: 226    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 684   the run_score was: 0.0   and mem length: 126698   eps: 0.9471359800011476    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 685   the run_score was: 6.0   and mem length: 127074   eps: 0.9463915000011638    steps: 376    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 686   the run_score was: 1.0   and mem length: 127226   eps: 0.9460905400011703    steps: 152    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 687   the run_score was: 3.0   and mem length: 127474   eps: 0.945599500001181    steps: 248    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 688   the run_score was: 1.0   and mem length: 127645   eps: 0.9452609200011883    steps: 171    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 689   the run_score was: 2.0   and mem length: 127867   eps: 0.9448213600011979    steps: 222    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 690   the run_score was: 1.0   and mem length: 128039   eps: 0.9444808000012053    steps: 172    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 691   the run_score was: 2.0   and mem length: 128257   eps: 0.9440491600012146    steps: 218    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 692   the run_score was: 2.0   and mem length: 128478   eps: 0.9436115800012241    steps: 221    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 693   the run_score was: 2.0   and mem length: 128677   eps: 0.9432175600012327    steps: 199    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 694   the run_score was: 1.0   and mem length: 128847   eps: 0.94288096000124    steps: 170    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 695   the run_score was: 1.0   and mem length: 129016   eps: 0.9425463400012473    steps: 169    lr: 0.0001     eval rl_reward: 1.62\n","For episode: 696   the run_score was: 1.0   and mem length: 129186   eps: 0.9422097400012546    steps: 170    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 697   the run_score was: 1.0   and mem length: 129356   eps: 0.9418731400012619    steps: 170    lr: 0.0001     eval rl_reward: 1.59\n","For episode: 698   the run_score was: 1.0   and mem length: 129527   eps: 0.9415345600012692    steps: 171    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 699   the run_score was: 1.0   and mem length: 129700   eps: 0.9411920200012767    steps: 173    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 700   the run_score was: 2.0   and mem length: 129917   eps: 0.940762360001286    steps: 217    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 701   the run_score was: 1.0   and mem length: 130089   eps: 0.9404218000012934    steps: 172    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 702   the run_score was: 3.0   and mem length: 130356   eps: 0.9398931400013049    steps: 267    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 703   the run_score was: 1.0   and mem length: 130528   eps: 0.9395525800013123    steps: 172    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 704   the run_score was: 1.0   and mem length: 130680   eps: 0.9392516200013188    steps: 152    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 705   the run_score was: 4.0   and mem length: 130994   eps: 0.9386299000013323    steps: 314    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 706   the run_score was: 1.0   and mem length: 131164   eps: 0.9382933000013396    steps: 170    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 707   the run_score was: 2.0   and mem length: 131383   eps: 0.937859680001349    steps: 219    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 708   the run_score was: 1.0   and mem length: 131553   eps: 0.9375230800013563    steps: 170    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 709   the run_score was: 1.0   and mem length: 131705   eps: 0.9372221200013628    steps: 152    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 710   the run_score was: 0.0   and mem length: 131829   eps: 0.9369766000013682    steps: 124    lr: 0.0001     eval rl_reward: 1.57\n","For episode: 711   the run_score was: 2.0   and mem length: 132028   eps: 0.9365825800013767    steps: 199    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 712   the run_score was: 1.0   and mem length: 132180   eps: 0.9362816200013833    steps: 152    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 713   the run_score was: 2.0   and mem length: 132379   eps: 0.9358876000013918    steps: 199    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 714   the run_score was: 2.0   and mem length: 132580   eps: 0.9354896200014005    steps: 201    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 715   the run_score was: 0.0   and mem length: 132703   eps: 0.9352460800014057    steps: 123    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 716   the run_score was: 0.0   and mem length: 132827   eps: 0.9350005600014111    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 717   the run_score was: 1.0   and mem length: 132978   eps: 0.9347015800014176    steps: 151    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 718   the run_score was: 3.0   and mem length: 133229   eps: 0.9342046000014284    steps: 251    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 719   the run_score was: 1.0   and mem length: 133402   eps: 0.9338620600014358    steps: 173    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 720   the run_score was: 2.0   and mem length: 133601   eps: 0.9334680400014443    steps: 199    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 721   the run_score was: 1.0   and mem length: 133752   eps: 0.9331690600014508    steps: 151    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 722   the run_score was: 2.0   and mem length: 133953   eps: 0.9327710800014595    steps: 201    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 723   the run_score was: 1.0   and mem length: 134104   eps: 0.932472100001466    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 724   the run_score was: 2.0   and mem length: 134302   eps: 0.9320800600014745    steps: 198    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 725   the run_score was: 2.0   and mem length: 134504   eps: 0.9316801000014832    steps: 202    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 726   the run_score was: 1.0   and mem length: 134673   eps: 0.9313454800014904    steps: 169    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 727   the run_score was: 0.0   and mem length: 134797   eps: 0.9310999600014958    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 728   the run_score was: 3.0   and mem length: 135048   eps: 0.9306029800015065    steps: 251    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 729   the run_score was: 2.0   and mem length: 135267   eps: 0.930169360001516    steps: 219    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 730   the run_score was: 3.0   and mem length: 135496   eps: 0.9297159400015258    steps: 229    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 731   the run_score was: 0.0   and mem length: 135620   eps: 0.9294704200015311    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 732   the run_score was: 1.0   and mem length: 135772   eps: 0.9291694600015377    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 733   the run_score was: 0.0   and mem length: 135896   eps: 0.928923940001543    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 734   the run_score was: 0.0   and mem length: 136020   eps: 0.9286784200015483    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 735   the run_score was: 1.0   and mem length: 136191   eps: 0.9283398400015557    steps: 171    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 736   the run_score was: 1.0   and mem length: 136361   eps: 0.928003240001563    steps: 170    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 737   the run_score was: 1.0   and mem length: 136531   eps: 0.9276666400015703    steps: 170    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 738   the run_score was: 2.0   and mem length: 136749   eps: 0.9272350000015797    steps: 218    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 739   the run_score was: 2.0   and mem length: 136948   eps: 0.9268409800015882    steps: 199    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 740   the run_score was: 2.0   and mem length: 137152   eps: 0.926437060001597    steps: 204    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 741   the run_score was: 0.0   and mem length: 137276   eps: 0.9261915400016023    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 742   the run_score was: 3.0   and mem length: 137504   eps: 0.9257401000016121    steps: 228    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 743   the run_score was: 3.0   and mem length: 137731   eps: 0.9252906400016219    steps: 227    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 744   the run_score was: 1.0   and mem length: 137884   eps: 0.9249877000016284    steps: 153    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 745   the run_score was: 1.0   and mem length: 138036   eps: 0.924686740001635    steps: 152    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 746   the run_score was: 0.0   and mem length: 138159   eps: 0.9244432000016403    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 747   the run_score was: 5.0   and mem length: 138450   eps: 0.9238670200016528    steps: 291    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 748   the run_score was: 4.0   and mem length: 138768   eps: 0.9232373800016664    steps: 318    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 749   the run_score was: 2.0   and mem length: 138985   eps: 0.9228077200016758    steps: 217    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 750   the run_score was: 0.0   and mem length: 139109   eps: 0.9225622000016811    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 751   the run_score was: 3.0   and mem length: 139356   eps: 0.9220731400016917    steps: 247    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 752   the run_score was: 3.0   and mem length: 139604   eps: 0.9215821000017024    steps: 248    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 753   the run_score was: 0.0   and mem length: 139728   eps: 0.9213365800017077    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 754   the run_score was: 2.0   and mem length: 139927   eps: 0.9209425600017163    steps: 199    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 755   the run_score was: 0.0   and mem length: 140051   eps: 0.9206970400017216    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 756   the run_score was: 0.0   and mem length: 140174   eps: 0.9204535000017269    steps: 123    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 757   the run_score was: 0.0   and mem length: 140298   eps: 0.9202079800017322    steps: 124    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 758   the run_score was: 0.0   and mem length: 140422   eps: 0.9199624600017375    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 759   the run_score was: 1.0   and mem length: 140574   eps: 0.9196615000017441    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 760   the run_score was: 1.0   and mem length: 140747   eps: 0.9193189600017515    steps: 173    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 761   the run_score was: 1.0   and mem length: 140916   eps: 0.9189843400017588    steps: 169    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 762   the run_score was: 0.0   and mem length: 141040   eps: 0.9187388200017641    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 763   the run_score was: 1.0   and mem length: 141192   eps: 0.9184378600017706    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 764   the run_score was: 1.0   and mem length: 141362   eps: 0.9181012600017779    steps: 170    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 765   the run_score was: 1.0   and mem length: 141532   eps: 0.9177646600017852    steps: 170    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 766   the run_score was: 1.0   and mem length: 141705   eps: 0.9174221200017927    steps: 173    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 767   the run_score was: 1.0   and mem length: 141878   eps: 0.9170795800018001    steps: 173    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 768   the run_score was: 0.0   and mem length: 142002   eps: 0.9168340600018055    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 769   the run_score was: 5.0   and mem length: 142335   eps: 0.9161747200018198    steps: 333    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 770   the run_score was: 4.0   and mem length: 142630   eps: 0.9155906200018324    steps: 295    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 771   the run_score was: 2.0   and mem length: 142829   eps: 0.915196600001841    steps: 199    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 772   the run_score was: 3.0   and mem length: 143078   eps: 0.9147035800018517    steps: 249    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 773   the run_score was: 2.0   and mem length: 143277   eps: 0.9143095600018603    steps: 199    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 774   the run_score was: 4.0   and mem length: 143535   eps: 0.9137987200018713    steps: 258    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 775   the run_score was: 1.0   and mem length: 143687   eps: 0.9134977600018779    steps: 152    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 776   the run_score was: 1.0   and mem length: 143858   eps: 0.9131591800018852    steps: 171    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 777   the run_score was: 0.0   and mem length: 143981   eps: 0.9129156400018905    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 778   the run_score was: 0.0   and mem length: 144104   eps: 0.9126721000018958    steps: 123    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 779   the run_score was: 2.0   and mem length: 144322   eps: 0.9122404600019052    steps: 218    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 780   the run_score was: 0.0   and mem length: 144446   eps: 0.9119949400019105    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 781   the run_score was: 2.0   and mem length: 144665   eps: 0.9115613200019199    steps: 219    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 782   the run_score was: 1.0   and mem length: 144836   eps: 0.9112227400019273    steps: 171    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 783   the run_score was: 0.0   and mem length: 144960   eps: 0.9109772200019326    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 784   the run_score was: 0.0   and mem length: 145084   eps: 0.9107317000019379    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 785   the run_score was: 3.0   and mem length: 145333   eps: 0.9102386800019486    steps: 249    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 786   the run_score was: 2.0   and mem length: 145532   eps: 0.9098446600019572    steps: 199    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 787   the run_score was: 3.0   and mem length: 145801   eps: 0.9093120400019687    steps: 269    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 788   the run_score was: 1.0   and mem length: 145971   eps: 0.908975440001976    steps: 170    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 789   the run_score was: 6.0   and mem length: 146325   eps: 0.9082745200019913    steps: 354    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 790   the run_score was: 1.0   and mem length: 146476   eps: 0.9079755400019978    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 791   the run_score was: 0.0   and mem length: 146599   eps: 0.907732000002003    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 792   the run_score was: 0.0   and mem length: 146723   eps: 0.9074864800020084    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 793   the run_score was: 1.0   and mem length: 146894   eps: 0.9071479000020157    steps: 171    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 794   the run_score was: 2.0   and mem length: 147093   eps: 0.9067538800020243    steps: 199    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 795   the run_score was: 3.0   and mem length: 147321   eps: 0.9063024400020341    steps: 228    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 796   the run_score was: 2.0   and mem length: 147541   eps: 0.9058668400020435    steps: 220    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 797   the run_score was: 1.0   and mem length: 147693   eps: 0.9055658800020501    steps: 152    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 798   the run_score was: 1.0   and mem length: 147863   eps: 0.9052292800020574    steps: 170    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 799   the run_score was: 2.0   and mem length: 148045   eps: 0.9048689200020652    steps: 182    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 800   the run_score was: 3.0   and mem length: 148294   eps: 0.9043759000020759    steps: 249    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 801   the run_score was: 2.0   and mem length: 148513   eps: 0.9039422800020853    steps: 219    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 802   the run_score was: 0.0   and mem length: 148636   eps: 0.9036987400020906    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 803   the run_score was: 0.0   and mem length: 148760   eps: 0.9034532200020959    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 804   the run_score was: 0.0   and mem length: 148884   eps: 0.9032077000021013    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 805   the run_score was: 1.0   and mem length: 149035   eps: 0.9029087200021078    steps: 151    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 806   the run_score was: 4.0   and mem length: 149311   eps: 0.9023622400021196    steps: 276    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 807   the run_score was: 1.0   and mem length: 149480   eps: 0.9020276200021269    steps: 169    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 808   the run_score was: 1.0   and mem length: 149651   eps: 0.9016890400021342    steps: 171    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 809   the run_score was: 2.0   and mem length: 149850   eps: 0.9012950200021428    steps: 199    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 810   the run_score was: 3.0   and mem length: 150099   eps: 0.9008020000021535    steps: 249    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 811   the run_score was: 0.0   and mem length: 150223   eps: 0.9005564800021588    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 812   the run_score was: 0.0   and mem length: 150347   eps: 0.9003109600021642    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 813   the run_score was: 0.0   and mem length: 150471   eps: 0.9000654400021695    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 814   the run_score was: 1.0   and mem length: 150643   eps: 0.8997248800021769    steps: 172    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 815   the run_score was: 3.0   and mem length: 150890   eps: 0.8992358200021875    steps: 247    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 816   the run_score was: 2.0   and mem length: 151109   eps: 0.8988022000021969    steps: 219    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 817   the run_score was: 0.0   and mem length: 151233   eps: 0.8985566800022022    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 818   the run_score was: 0.0   and mem length: 151357   eps: 0.8983111600022076    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 819   the run_score was: 3.0   and mem length: 151585   eps: 0.8978597200022174    steps: 228    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 820   the run_score was: 3.0   and mem length: 151811   eps: 0.8974122400022271    steps: 226    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 821   the run_score was: 1.0   and mem length: 151980   eps: 0.8970776200022343    steps: 169    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 822   the run_score was: 2.0   and mem length: 152199   eps: 0.8966440000022438    steps: 219    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 823   the run_score was: 3.0   and mem length: 152446   eps: 0.8961549400022544    steps: 247    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 824   the run_score was: 5.0   and mem length: 152791   eps: 0.8954718400022692    steps: 345    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 825   the run_score was: 1.0   and mem length: 152942   eps: 0.8951728600022757    steps: 151    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 826   the run_score was: 0.0   and mem length: 153066   eps: 0.894927340002281    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 827   the run_score was: 0.0   and mem length: 153190   eps: 0.8946818200022864    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 828   the run_score was: 0.0   and mem length: 153313   eps: 0.8944382800022916    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 829   the run_score was: 1.0   and mem length: 153482   eps: 0.8941036600022989    steps: 169    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 830   the run_score was: 1.0   and mem length: 153652   eps: 0.8937670600023062    steps: 170    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 831   the run_score was: 1.0   and mem length: 153823   eps: 0.8934284800023136    steps: 171    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 832   the run_score was: 3.0   and mem length: 154071   eps: 0.8929374400023242    steps: 248    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 833   the run_score was: 1.0   and mem length: 154241   eps: 0.8926008400023315    steps: 170    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 834   the run_score was: 1.0   and mem length: 154392   eps: 0.892301860002338    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 835   the run_score was: 1.0   and mem length: 154563   eps: 0.8919632800023454    steps: 171    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 836   the run_score was: 0.0   and mem length: 154687   eps: 0.8917177600023507    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 837   the run_score was: 2.0   and mem length: 154886   eps: 0.8913237400023593    steps: 199    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 838   the run_score was: 0.0   and mem length: 155010   eps: 0.8910782200023646    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 839   the run_score was: 3.0   and mem length: 155277   eps: 0.8905495600023761    steps: 267    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 840   the run_score was: 3.0   and mem length: 155542   eps: 0.8900248600023875    steps: 265    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 841   the run_score was: 1.0   and mem length: 155714   eps: 0.8896843000023948    steps: 172    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 842   the run_score was: 0.0   and mem length: 155837   eps: 0.8894407600024001    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 843   the run_score was: 1.0   and mem length: 156007   eps: 0.8891041600024074    steps: 170    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 844   the run_score was: 2.0   and mem length: 156226   eps: 0.8886705400024169    steps: 219    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 845   the run_score was: 3.0   and mem length: 156473   eps: 0.8881814800024275    steps: 247    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 846   the run_score was: 0.0   and mem length: 156596   eps: 0.8879379400024328    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 847   the run_score was: 0.0   and mem length: 156720   eps: 0.8876924200024381    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 848   the run_score was: 0.0   and mem length: 156844   eps: 0.8874469000024434    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 849   the run_score was: 2.0   and mem length: 157045   eps: 0.8870489200024521    steps: 201    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 850   the run_score was: 4.0   and mem length: 157365   eps: 0.8864153200024658    steps: 320    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 851   the run_score was: 1.0   and mem length: 157538   eps: 0.8860727800024732    steps: 173    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 852   the run_score was: 3.0   and mem length: 157768   eps: 0.8856173800024831    steps: 230    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 853   the run_score was: 0.0   and mem length: 157892   eps: 0.8853718600024885    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 854   the run_score was: 0.0   and mem length: 158016   eps: 0.8851263400024938    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 855   the run_score was: 2.0   and mem length: 158217   eps: 0.8847283600025024    steps: 201    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 856   the run_score was: 4.0   and mem length: 158514   eps: 0.8841403000025152    steps: 297    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 857   the run_score was: 0.0   and mem length: 158638   eps: 0.8838947800025205    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 858   the run_score was: 0.0   and mem length: 158761   eps: 0.8836512400025258    steps: 123    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 859   the run_score was: 1.0   and mem length: 158930   eps: 0.8833166200025331    steps: 169    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 860   the run_score was: 0.0   and mem length: 159054   eps: 0.8830711000025384    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 861   the run_score was: 4.0   and mem length: 159329   eps: 0.8825266000025502    steps: 275    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 862   the run_score was: 0.0   and mem length: 159453   eps: 0.8822810800025556    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 863   the run_score was: 3.0   and mem length: 159679   eps: 0.8818336000025653    steps: 226    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 864   the run_score was: 1.0   and mem length: 159831   eps: 0.8815326400025718    steps: 152    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 865   the run_score was: 1.0   and mem length: 159982   eps: 0.8812336600025783    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 866   the run_score was: 5.0   and mem length: 160291   eps: 0.8806218400025916    steps: 309    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 867   the run_score was: 0.0   and mem length: 160415   eps: 0.8803763200025969    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 868   the run_score was: 2.0   and mem length: 160617   eps: 0.8799763600026056    steps: 202    lr: 0.0001     eval rl_reward: 1.53\n","For episode: 869   the run_score was: 0.0   and mem length: 160740   eps: 0.8797328200026109    steps: 123    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 870   the run_score was: 0.0   and mem length: 160864   eps: 0.8794873000026162    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 871   the run_score was: 1.0   and mem length: 161034   eps: 0.8791507000026235    steps: 170    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 872   the run_score was: 3.0   and mem length: 161282   eps: 0.8786596600026342    steps: 248    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 873   the run_score was: 2.0   and mem length: 161501   eps: 0.8782260400026436    steps: 219    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 874   the run_score was: 3.0   and mem length: 161749   eps: 0.8777350000026543    steps: 248    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 875   the run_score was: 3.0   and mem length: 161976   eps: 0.877285540002664    steps: 227    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 876   the run_score was: 0.0   and mem length: 162100   eps: 0.8770400200026693    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 877   the run_score was: 0.0   and mem length: 162224   eps: 0.8767945000026747    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 878   the run_score was: 1.0   and mem length: 162396   eps: 0.8764539400026821    steps: 172    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 879   the run_score was: 1.0   and mem length: 162548   eps: 0.8761529800026886    steps: 152    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 880   the run_score was: 1.0   and mem length: 162700   eps: 0.8758520200026951    steps: 152    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 881   the run_score was: 1.0   and mem length: 162872   eps: 0.8755114600027025    steps: 172    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 882   the run_score was: 0.0   and mem length: 162996   eps: 0.8752659400027079    steps: 124    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 883   the run_score was: 0.0   and mem length: 163119   eps: 0.8750224000027131    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 884   the run_score was: 3.0   and mem length: 163364   eps: 0.8745373000027237    steps: 245    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 885   the run_score was: 0.0   and mem length: 163487   eps: 0.874293760002729    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 886   the run_score was: 2.0   and mem length: 163688   eps: 0.8738957800027376    steps: 201    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 887   the run_score was: 3.0   and mem length: 163915   eps: 0.8734463200027474    steps: 227    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 888   the run_score was: 0.0   and mem length: 164038   eps: 0.8732027800027526    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 889   the run_score was: 0.0   and mem length: 164162   eps: 0.872957260002758    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 890   the run_score was: 1.0   and mem length: 164314   eps: 0.8726563000027645    steps: 152    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 891   the run_score was: 1.0   and mem length: 164484   eps: 0.8723197000027718    steps: 170    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 892   the run_score was: 0.0   and mem length: 164608   eps: 0.8720741800027771    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 893   the run_score was: 3.0   and mem length: 164853   eps: 0.8715890800027877    steps: 245    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 894   the run_score was: 1.0   and mem length: 165004   eps: 0.8712901000027942    steps: 151    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 895   the run_score was: 4.0   and mem length: 165301   eps: 0.8707020400028069    steps: 297    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 896   the run_score was: 2.0   and mem length: 165500   eps: 0.8703080200028155    steps: 199    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 897   the run_score was: 2.0   and mem length: 165719   eps: 0.8698744000028249    steps: 219    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 898   the run_score was: 0.0   and mem length: 165843   eps: 0.8696288800028302    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 899   the run_score was: 0.0   and mem length: 165966   eps: 0.8693853400028355    steps: 123    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 900   the run_score was: 0.0   and mem length: 166089   eps: 0.8691418000028408    steps: 123    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 901   the run_score was: 0.0   and mem length: 166213   eps: 0.8688962800028461    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 902   the run_score was: 0.0   and mem length: 166336   eps: 0.8686527400028514    steps: 123    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 903   the run_score was: 3.0   and mem length: 166587   eps: 0.8681557600028622    steps: 251    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 904   the run_score was: 2.0   and mem length: 166786   eps: 0.8677617400028708    steps: 199    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 905   the run_score was: 0.0   and mem length: 166910   eps: 0.8675162200028761    steps: 124    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 906   the run_score was: 0.0   and mem length: 167034   eps: 0.8672707000028814    steps: 124    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 907   the run_score was: 0.0   and mem length: 167157   eps: 0.8670271600028867    steps: 123    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 908   the run_score was: 1.0   and mem length: 167309   eps: 0.8667262000028932    steps: 152    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 909   the run_score was: 4.0   and mem length: 167605   eps: 0.866140120002906    steps: 296    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 910   the run_score was: 2.0   and mem length: 167805   eps: 0.8657441200029146    steps: 200    lr: 0.0001     eval rl_reward: 1.31\n","For episode: 911   the run_score was: 2.0   and mem length: 168003   eps: 0.8653520800029231    steps: 198    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 912   the run_score was: 0.0   and mem length: 168127   eps: 0.8651065600029284    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 913   the run_score was: 3.0   and mem length: 168357   eps: 0.8646511600029383    steps: 230    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 914   the run_score was: 5.0   and mem length: 168702   eps: 0.8639680600029531    steps: 345    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 915   the run_score was: 1.0   and mem length: 168871   eps: 0.8636334400029604    steps: 169    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 916   the run_score was: 0.0   and mem length: 168995   eps: 0.8633879200029657    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 917   the run_score was: 2.0   and mem length: 169194   eps: 0.8629939000029743    steps: 199    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 918   the run_score was: 1.0   and mem length: 169367   eps: 0.8626513600029817    steps: 173    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 919   the run_score was: 0.0   and mem length: 169491   eps: 0.862405840002987    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 920   the run_score was: 0.0   and mem length: 169615   eps: 0.8621603200029924    steps: 124    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 921   the run_score was: 0.0   and mem length: 169738   eps: 0.8619167800029977    steps: 123    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 922   the run_score was: 3.0   and mem length: 169965   eps: 0.8614673200030074    steps: 227    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 923   the run_score was: 2.0   and mem length: 170166   eps: 0.861069340003016    steps: 201    lr: 0.0001     eval rl_reward: 1.32\n","For episode: 924   the run_score was: 3.0   and mem length: 170394   eps: 0.8606179000030258    steps: 228    lr: 0.0001     eval rl_reward: 1.3\n","For episode: 925   the run_score was: 4.0   and mem length: 170654   eps: 0.860103100003037    steps: 260    lr: 0.0001     eval rl_reward: 1.33\n","For episode: 926   the run_score was: 1.0   and mem length: 170825   eps: 0.8597645200030444    steps: 171    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 927   the run_score was: 2.0   and mem length: 171006   eps: 0.8594061400030522    steps: 181    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 928   the run_score was: 1.0   and mem length: 171158   eps: 0.8591051800030587    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 929   the run_score was: 1.0   and mem length: 171310   eps: 0.8588042200030652    steps: 152    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 930   the run_score was: 1.0   and mem length: 171483   eps: 0.8584616800030727    steps: 173    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 931   the run_score was: 5.0   and mem length: 171808   eps: 0.8578181800030866    steps: 325    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 932   the run_score was: 0.0   and mem length: 171932   eps: 0.857572660003092    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 933   the run_score was: 2.0   and mem length: 172130   eps: 0.8571806200031005    steps: 198    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 934   the run_score was: 1.0   and mem length: 172282   eps: 0.856879660003107    steps: 152    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 935   the run_score was: 2.0   and mem length: 172481   eps: 0.8564856400031156    steps: 199    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 936   the run_score was: 1.0   and mem length: 172653   eps: 0.856145080003123    steps: 172    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 937   the run_score was: 2.0   and mem length: 172851   eps: 0.8557530400031315    steps: 198    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 938   the run_score was: 1.0   and mem length: 173003   eps: 0.855452080003138    steps: 152    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 939   the run_score was: 0.0   and mem length: 173127   eps: 0.8552065600031433    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 940   the run_score was: 1.0   and mem length: 173297   eps: 0.8548699600031506    steps: 170    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 941   the run_score was: 0.0   and mem length: 173421   eps: 0.854624440003156    steps: 124    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 942   the run_score was: 2.0   and mem length: 173622   eps: 0.8542264600031646    steps: 201    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 943   the run_score was: 2.0   and mem length: 173840   eps: 0.853794820003174    steps: 218    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 944   the run_score was: 0.0   and mem length: 173964   eps: 0.8535493000031793    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 945   the run_score was: 2.0   and mem length: 174163   eps: 0.8531552800031879    steps: 199    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 946   the run_score was: 3.0   and mem length: 174410   eps: 0.8526662200031985    steps: 247    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 947   the run_score was: 0.0   and mem length: 174534   eps: 0.8524207000032038    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 948   the run_score was: 0.0   and mem length: 174658   eps: 0.8521751800032091    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 949   the run_score was: 0.0   and mem length: 174782   eps: 0.8519296600032145    steps: 124    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 950   the run_score was: 2.0   and mem length: 174980   eps: 0.851537620003223    steps: 198    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 951   the run_score was: 1.0   and mem length: 175150   eps: 0.8512010200032303    steps: 170    lr: 0.0001     eval rl_reward: 1.35\n","For episode: 952   the run_score was: 5.0   and mem length: 175496   eps: 0.8505159400032452    steps: 346    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 953   the run_score was: 3.0   and mem length: 175723   eps: 0.8500664800032549    steps: 227    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 954   the run_score was: 6.0   and mem length: 176095   eps: 0.8493299200032709    steps: 372    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 955   the run_score was: 2.0   and mem length: 176315   eps: 0.8488943200032804    steps: 220    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 956   the run_score was: 5.0   and mem length: 176639   eps: 0.8482528000032943    steps: 324    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 957   the run_score was: 2.0   and mem length: 176838   eps: 0.8478587800033028    steps: 199    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 958   the run_score was: 2.0   and mem length: 177036   eps: 0.8474667400033113    steps: 198    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 959   the run_score was: 0.0   and mem length: 177160   eps: 0.8472212200033167    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 960   the run_score was: 0.0   and mem length: 177284   eps: 0.846975700003322    steps: 124    lr: 0.0001     eval rl_reward: 1.5\n","For episode: 961   the run_score was: 1.0   and mem length: 177453   eps: 0.8466410800033293    steps: 169    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 962   the run_score was: 1.0   and mem length: 177624   eps: 0.8463025000033366    steps: 171    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 963   the run_score was: 0.0   and mem length: 177748   eps: 0.846056980003342    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 964   the run_score was: 3.0   and mem length: 177976   eps: 0.8456055400033518    steps: 228    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 965   the run_score was: 0.0   and mem length: 178100   eps: 0.8453600200033571    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 966   the run_score was: 0.0   and mem length: 178224   eps: 0.8451145000033624    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 967   the run_score was: 0.0   and mem length: 178347   eps: 0.8448709600033677    steps: 123    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 968   the run_score was: 0.0   and mem length: 178471   eps: 0.844625440003373    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 969   the run_score was: 0.0   and mem length: 178595   eps: 0.8443799200033784    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 970   the run_score was: 0.0   and mem length: 178719   eps: 0.8441344000033837    steps: 124    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 971   the run_score was: 0.0   and mem length: 178843   eps: 0.843888880003389    steps: 124    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 972   the run_score was: 2.0   and mem length: 179042   eps: 0.8434948600033976    steps: 199    lr: 0.0001     eval rl_reward: 1.37\n","For episode: 973   the run_score was: 1.0   and mem length: 179194   eps: 0.8431939000034041    steps: 152    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 974   the run_score was: 1.0   and mem length: 179364   eps: 0.8428573000034114    steps: 170    lr: 0.0001     eval rl_reward: 1.34\n","For episode: 975   the run_score was: 5.0   and mem length: 179710   eps: 0.8421722200034263    steps: 346    lr: 0.0001     eval rl_reward: 1.36\n","For episode: 976   the run_score was: 3.0   and mem length: 179959   eps: 0.841679200003437    steps: 249    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 977   the run_score was: 2.0   and mem length: 180158   eps: 0.8412851800034455    steps: 199    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 978   the run_score was: 2.0   and mem length: 180381   eps: 0.8408436400034551    steps: 223    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 979   the run_score was: 1.0   and mem length: 180550   eps: 0.8405090200034624    steps: 169    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 980   the run_score was: 2.0   and mem length: 180751   eps: 0.840111040003471    steps: 201    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 981   the run_score was: 1.0   and mem length: 180924   eps: 0.8397685000034785    steps: 173    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 982   the run_score was: 3.0   and mem length: 181171   eps: 0.8392794400034891    steps: 247    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 983   the run_score was: 3.0   and mem length: 181441   eps: 0.8387448400035007    steps: 270    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 984   the run_score was: 2.0   and mem length: 181640   eps: 0.8383508200035092    steps: 199    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 985   the run_score was: 3.0   and mem length: 181885   eps: 0.8378657200035198    steps: 245    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 986   the run_score was: 0.0   and mem length: 182008   eps: 0.8376221800035251    steps: 123    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 987   the run_score was: 0.0   and mem length: 182131   eps: 0.8373786400035304    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 988   the run_score was: 0.0   and mem length: 182254   eps: 0.8371351000035356    steps: 123    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 989   the run_score was: 1.0   and mem length: 182424   eps: 0.8367985000035429    steps: 170    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 990   the run_score was: 2.0   and mem length: 182623   eps: 0.8364044800035515    steps: 199    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 991   the run_score was: 0.0   and mem length: 182746   eps: 0.8361609400035568    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 992   the run_score was: 1.0   and mem length: 182917   eps: 0.8358223600035641    steps: 171    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 993   the run_score was: 1.0   and mem length: 183090   eps: 0.8354798200035716    steps: 173    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 994   the run_score was: 1.0   and mem length: 183260   eps: 0.8351432200035789    steps: 170    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 995   the run_score was: 0.0   and mem length: 183383   eps: 0.8348996800035842    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 996   the run_score was: 2.0   and mem length: 183582   eps: 0.8345056600035927    steps: 199    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 997   the run_score was: 0.0   and mem length: 183706   eps: 0.834260140003598    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 998   the run_score was: 0.0   and mem length: 183830   eps: 0.8340146200036034    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 999   the run_score was: 0.0   and mem length: 183954   eps: 0.8337691000036087    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 1000   the run_score was: 0.0   and mem length: 184078   eps: 0.833523580003614    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 1001   the run_score was: 3.0   and mem length: 184349   eps: 0.8329870000036257    steps: 271    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 1002   the run_score was: 2.0   and mem length: 184568   eps: 0.8325533800036351    steps: 219    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1003   the run_score was: 0.0   and mem length: 184691   eps: 0.8323098400036404    steps: 123    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 1004   the run_score was: 0.0   and mem length: 184815   eps: 0.8320643200036457    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 1005   the run_score was: 4.0   and mem length: 185131   eps: 0.8314386400036593    steps: 316    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1006   the run_score was: 0.0   and mem length: 185255   eps: 0.8311931200036646    steps: 124    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1007   the run_score was: 0.0   and mem length: 185378   eps: 0.8309495800036699    steps: 123    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1008   the run_score was: 1.0   and mem length: 185530   eps: 0.8306486200036765    steps: 152    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1009   the run_score was: 2.0   and mem length: 185749   eps: 0.8302150000036859    steps: 219    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 1010   the run_score was: 0.0   and mem length: 185873   eps: 0.8299694800036912    steps: 124    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 1011   the run_score was: 2.0   and mem length: 186071   eps: 0.8295774400036997    steps: 198    lr: 0.0001     eval rl_reward: 1.4\n","For episode: 1012   the run_score was: 4.0   and mem length: 186387   eps: 0.8289517600037133    steps: 316    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1013   the run_score was: 0.0   and mem length: 186511   eps: 0.8287062400037186    steps: 124    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 1014   the run_score was: 2.0   and mem length: 186730   eps: 0.828272620003728    steps: 219    lr: 0.0001     eval rl_reward: 1.38\n","For episode: 1015   the run_score was: 2.0   and mem length: 186949   eps: 0.8278390000037374    steps: 219    lr: 0.0001     eval rl_reward: 1.39\n","For episode: 1016   the run_score was: 2.0   and mem length: 187151   eps: 0.8274390400037461    steps: 202    lr: 0.0001     eval rl_reward: 1.41\n","For episode: 1017   the run_score was: 3.0   and mem length: 187378   eps: 0.8269895800037559    steps: 227    lr: 0.0001     eval rl_reward: 1.42\n","For episode: 1018   the run_score was: 3.0   and mem length: 187647   eps: 0.8264569600037674    steps: 269    lr: 0.0001     eval rl_reward: 1.44\n","For episode: 1019   the run_score was: 1.0   and mem length: 187817   eps: 0.8261203600037748    steps: 170    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1020   the run_score was: 3.0   and mem length: 188086   eps: 0.8255877400037863    steps: 269    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 1021   the run_score was: 4.0   and mem length: 188362   eps: 0.8250412600037982    steps: 276    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1022   the run_score was: 0.0   and mem length: 188486   eps: 0.8247957400038035    steps: 124    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1023   the run_score was: 2.0   and mem length: 188708   eps: 0.824356180003813    steps: 222    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1024   the run_score was: 0.0   and mem length: 188832   eps: 0.8241106600038184    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1025   the run_score was: 3.0   and mem length: 189102   eps: 0.82357606000383    steps: 270    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1026   the run_score was: 2.0   and mem length: 189283   eps: 0.8232176800038378    steps: 181    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1027   the run_score was: 1.0   and mem length: 189435   eps: 0.8229167200038443    steps: 152    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1028   the run_score was: 4.0   and mem length: 189715   eps: 0.8223623200038563    steps: 280    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 1029   the run_score was: 4.0   and mem length: 189990   eps: 0.8218178200038682    steps: 275    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 1030   the run_score was: 2.0   and mem length: 190189   eps: 0.8214238000038767    steps: 199    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1031   the run_score was: 2.0   and mem length: 190389   eps: 0.8210278000038853    steps: 200    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1032   the run_score was: 0.0   and mem length: 190512   eps: 0.8207842600038906    steps: 123    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1033   the run_score was: 1.0   and mem length: 190664   eps: 0.8204833000038971    steps: 152    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 1034   the run_score was: 0.0   and mem length: 190788   eps: 0.8202377800039025    steps: 124    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1035   the run_score was: 0.0   and mem length: 190912   eps: 0.8199922600039078    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1036   the run_score was: 1.0   and mem length: 191064   eps: 0.8196913000039143    steps: 152    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1037   the run_score was: 2.0   and mem length: 191281   eps: 0.8192616400039237    steps: 217    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1038   the run_score was: 3.0   and mem length: 191530   eps: 0.8187686200039344    steps: 249    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1039   the run_score was: 1.0   and mem length: 191681   eps: 0.8184696400039408    steps: 151    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 1040   the run_score was: 0.0   and mem length: 191804   eps: 0.8182261000039461    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1041   the run_score was: 2.0   and mem length: 192006   eps: 0.8178261400039548    steps: 202    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1042   the run_score was: 0.0   and mem length: 192129   eps: 0.8175826000039601    steps: 123    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1043   the run_score was: 1.0   and mem length: 192299   eps: 0.8172460000039674    steps: 170    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1044   the run_score was: 3.0   and mem length: 192547   eps: 0.8167549600039781    steps: 248    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1045   the run_score was: 1.0   and mem length: 192720   eps: 0.8164124200039855    steps: 173    lr: 0.0001     eval rl_reward: 1.48\n","For episode: 1046   the run_score was: 2.0   and mem length: 192937   eps: 0.8159827600039948    steps: 217    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1047   the run_score was: 2.0   and mem length: 193154   eps: 0.8155531000040042    steps: 217    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1048   the run_score was: 3.0   and mem length: 193402   eps: 0.8150620600040148    steps: 248    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1049   the run_score was: 2.0   and mem length: 193601   eps: 0.8146680400040234    steps: 199    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 1050   the run_score was: 0.0   and mem length: 193725   eps: 0.8144225200040287    steps: 124    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1051   the run_score was: 4.0   and mem length: 194001   eps: 0.8138760400040406    steps: 276    lr: 0.0001     eval rl_reward: 1.55\n","For episode: 1052   the run_score was: 1.0   and mem length: 194152   eps: 0.8135770600040471    steps: 151    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 1053   the run_score was: 3.0   and mem length: 194401   eps: 0.8130840400040578    steps: 249    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 1054   the run_score was: 0.0   and mem length: 194525   eps: 0.8128385200040631    steps: 124    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1055   the run_score was: 3.0   and mem length: 194773   eps: 0.8123474800040738    steps: 248    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1056   the run_score was: 4.0   and mem length: 195051   eps: 0.8117970400040857    steps: 278    lr: 0.0001     eval rl_reward: 1.45\n","For episode: 1057   the run_score was: 0.0   and mem length: 195175   eps: 0.811551520004091    steps: 124    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 1058   the run_score was: 2.0   and mem length: 195373   eps: 0.8111594800040995    steps: 198    lr: 0.0001     eval rl_reward: 1.43\n","For episode: 1059   the run_score was: 3.0   and mem length: 195642   eps: 0.8106268600041111    steps: 269    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1060   the run_score was: 1.0   and mem length: 195812   eps: 0.8102902600041184    steps: 170    lr: 0.0001     eval rl_reward: 1.47\n","For episode: 1061   the run_score was: 0.0   and mem length: 195936   eps: 0.8100447400041237    steps: 124    lr: 0.0001     eval rl_reward: 1.46\n","For episode: 1062   the run_score was: 4.0   and mem length: 196214   eps: 0.8094943000041357    steps: 278    lr: 0.0001     eval rl_reward: 1.49\n","For episode: 1063   the run_score was: 5.0   and mem length: 196560   eps: 0.8088092200041506    steps: 346    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 1064   the run_score was: 0.0   and mem length: 196684   eps: 0.8085637000041559    steps: 124    lr: 0.0001     eval rl_reward: 1.51\n","For episode: 1065   the run_score was: 1.0   and mem length: 196854   eps: 0.8082271000041632    steps: 170    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1066   the run_score was: 0.0   and mem length: 196977   eps: 0.8079835600041685    steps: 123    lr: 0.0001     eval rl_reward: 1.52\n","For episode: 1067   the run_score was: 2.0   and mem length: 197178   eps: 0.8075855800041771    steps: 201    lr: 0.0001     eval rl_reward: 1.54\n","For episode: 1068   the run_score was: 2.0   and mem length: 197377   eps: 0.8071915600041857    steps: 199    lr: 0.0001     eval rl_reward: 1.56\n","For episode: 1069   the run_score was: 2.0   and mem length: 197559   eps: 0.8068312000041935    steps: 182    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 1070   the run_score was: 0.0   and mem length: 197683   eps: 0.8065856800041988    steps: 124    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 1071   the run_score was: 3.0   and mem length: 197928   eps: 0.8061005800042094    steps: 245    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1072   the run_score was: 2.0   and mem length: 198127   eps: 0.8057065600042179    steps: 199    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1073   the run_score was: 1.0   and mem length: 198300   eps: 0.8053640200042254    steps: 173    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1074   the run_score was: 1.0   and mem length: 198470   eps: 0.8050274200042327    steps: 170    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1075   the run_score was: 2.0   and mem length: 198668   eps: 0.8046353800042412    steps: 198    lr: 0.0001     eval rl_reward: 1.58\n","For episode: 1076   the run_score was: 6.0   and mem length: 199063   eps: 0.8038532800042582    steps: 395    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1077   the run_score was: 1.0   and mem length: 199217   eps: 0.8035483600042648    steps: 154    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 1078   the run_score was: 2.0   and mem length: 199415   eps: 0.8031563200042733    steps: 198    lr: 0.0001     eval rl_reward: 1.6\n","For episode: 1079   the run_score was: 2.0   and mem length: 199632   eps: 0.8027266600042826    steps: 217    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1080   the run_score was: 2.0   and mem length: 199852   eps: 0.8022910600042921    steps: 220    lr: 0.0001     eval rl_reward: 1.61\n","For episode: 1081   the run_score was: 3.0   and mem length: 200117   eps: 0.8017663600043035    steps: 265    lr: 4e-05     eval rl_reward: 1.63\n","For episode: 1082   the run_score was: 2.0   and mem length: 200316   eps: 0.801372340004312    steps: 199    lr: 4e-05     eval rl_reward: 1.62\n","For episode: 1083   the run_score was: 2.0   and mem length: 200515   eps: 0.8009783200043206    steps: 199    lr: 4e-05     eval rl_reward: 1.61\n","For episode: 1084   the run_score was: 0.0   and mem length: 200639   eps: 0.8007328000043259    steps: 124    lr: 4e-05     eval rl_reward: 1.59\n","For episode: 1085   the run_score was: 2.0   and mem length: 200838   eps: 0.8003387800043344    steps: 199    lr: 4e-05     eval rl_reward: 1.58\n","For episode: 1086   the run_score was: 4.0   and mem length: 201130   eps: 0.799760620004347    steps: 292    lr: 4e-05     eval rl_reward: 1.62\n","For episode: 1087   the run_score was: 2.0   and mem length: 201329   eps: 0.7993666000043556    steps: 199    lr: 4e-05     eval rl_reward: 1.64\n","For episode: 1088   the run_score was: 5.0   and mem length: 201672   eps: 0.7986874600043703    steps: 343    lr: 4e-05     eval rl_reward: 1.69\n","For episode: 1089   the run_score was: 0.0   and mem length: 201795   eps: 0.7984439200043756    steps: 123    lr: 4e-05     eval rl_reward: 1.68\n","For episode: 1090   the run_score was: 5.0   and mem length: 202141   eps: 0.7977588400043905    steps: 346    lr: 4e-05     eval rl_reward: 1.71\n","For episode: 1091   the run_score was: 1.0   and mem length: 202311   eps: 0.7974222400043978    steps: 170    lr: 4e-05     eval rl_reward: 1.72\n","For episode: 1092   the run_score was: 4.0   and mem length: 202569   eps: 0.7969114000044089    steps: 258    lr: 4e-05     eval rl_reward: 1.75\n","For episode: 1093   the run_score was: 1.0   and mem length: 202739   eps: 0.7965748000044162    steps: 170    lr: 4e-05     eval rl_reward: 1.75\n","For episode: 1094   the run_score was: 2.0   and mem length: 202938   eps: 0.7961807800044247    steps: 199    lr: 4e-05     eval rl_reward: 1.76\n","For episode: 1095   the run_score was: 4.0   and mem length: 203214   eps: 0.7956343000044366    steps: 276    lr: 4e-05     eval rl_reward: 1.8\n","For episode: 1096   the run_score was: 3.0   and mem length: 203480   eps: 0.795107620004448    steps: 266    lr: 4e-05     eval rl_reward: 1.81\n","For episode: 1097   the run_score was: 2.0   and mem length: 203678   eps: 0.7947155800044565    steps: 198    lr: 4e-05     eval rl_reward: 1.83\n","For episode: 1098   the run_score was: 2.0   and mem length: 203877   eps: 0.7943215600044651    steps: 199    lr: 4e-05     eval rl_reward: 1.85\n","For episode: 1099   the run_score was: 2.0   and mem length: 204075   eps: 0.7939295200044736    steps: 198    lr: 4e-05     eval rl_reward: 1.87\n","For episode: 1100   the run_score was: 1.0   and mem length: 204245   eps: 0.7935929200044809    steps: 170    lr: 4e-05     eval rl_reward: 1.88\n","For episode: 1101   the run_score was: 2.0   and mem length: 204444   eps: 0.7931989000044894    steps: 199    lr: 4e-05     eval rl_reward: 1.87\n","For episode: 1102   the run_score was: 1.0   and mem length: 204615   eps: 0.7928603200044968    steps: 171    lr: 4e-05     eval rl_reward: 1.86\n","For episode: 1103   the run_score was: 2.0   and mem length: 204817   eps: 0.7924603600045055    steps: 202    lr: 4e-05     eval rl_reward: 1.88\n","For episode: 1104   the run_score was: 2.0   and mem length: 205015   eps: 0.792068320004514    steps: 198    lr: 4e-05     eval rl_reward: 1.9\n","For episode: 1105   the run_score was: 2.0   and mem length: 205214   eps: 0.7916743000045225    steps: 199    lr: 4e-05     eval rl_reward: 1.88\n","For episode: 1106   the run_score was: 1.0   and mem length: 205383   eps: 0.7913396800045298    steps: 169    lr: 4e-05     eval rl_reward: 1.89\n","For episode: 1107   the run_score was: 3.0   and mem length: 205627   eps: 0.7908565600045403    steps: 244    lr: 4e-05     eval rl_reward: 1.92\n","For episode: 1108   the run_score was: 2.0   and mem length: 205826   eps: 0.7904625400045489    steps: 199    lr: 4e-05     eval rl_reward: 1.93\n","For episode: 1109   the run_score was: 3.0   and mem length: 206053   eps: 0.7900130800045586    steps: 227    lr: 4e-05     eval rl_reward: 1.94\n","For episode: 1110   the run_score was: 2.0   and mem length: 206251   eps: 0.7896210400045671    steps: 198    lr: 4e-05     eval rl_reward: 1.96\n","For episode: 1111   the run_score was: 4.0   and mem length: 206549   eps: 0.7890310000045799    steps: 298    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1112   the run_score was: 1.0   and mem length: 206700   eps: 0.7887320200045864    steps: 151    lr: 4e-05     eval rl_reward: 1.95\n","For episode: 1113   the run_score was: 3.0   and mem length: 206945   eps: 0.788246920004597    steps: 245    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1114   the run_score was: 5.0   and mem length: 207290   eps: 0.7875638200046118    steps: 345    lr: 4e-05     eval rl_reward: 2.01\n","For episode: 1115   the run_score was: 0.0   and mem length: 207414   eps: 0.7873183000046171    steps: 124    lr: 4e-05     eval rl_reward: 1.99\n","For episode: 1116   the run_score was: 1.0   and mem length: 207584   eps: 0.7869817000046244    steps: 170    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1117   the run_score was: 1.0   and mem length: 207756   eps: 0.7866411400046318    steps: 172    lr: 4e-05     eval rl_reward: 1.96\n","For episode: 1118   the run_score was: 3.0   and mem length: 208003   eps: 0.7861520800046424    steps: 247    lr: 4e-05     eval rl_reward: 1.96\n","For episode: 1119   the run_score was: 2.0   and mem length: 208202   eps: 0.785758060004651    steps: 199    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1120   the run_score was: 3.0   and mem length: 208432   eps: 0.7853026600046609    steps: 230    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1121   the run_score was: 1.0   and mem length: 208583   eps: 0.7850036800046674    steps: 151    lr: 4e-05     eval rl_reward: 1.94\n","For episode: 1122   the run_score was: 2.0   and mem length: 208782   eps: 0.7846096600046759    steps: 199    lr: 4e-05     eval rl_reward: 1.96\n","For episode: 1123   the run_score was: 2.0   and mem length: 208981   eps: 0.7842156400046845    steps: 199    lr: 4e-05     eval rl_reward: 1.96\n","For episode: 1124   the run_score was: 2.0   and mem length: 209179   eps: 0.783823600004693    steps: 198    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1125   the run_score was: 0.0   and mem length: 209302   eps: 0.7835800600046983    steps: 123    lr: 4e-05     eval rl_reward: 1.95\n","For episode: 1126   the run_score was: 4.0   and mem length: 209580   eps: 0.7830296200047102    steps: 278    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1127   the run_score was: 2.0   and mem length: 209802   eps: 0.7825900600047198    steps: 222    lr: 4e-05     eval rl_reward: 1.98\n","For episode: 1128   the run_score was: 0.0   and mem length: 209925   eps: 0.782346520004725    steps: 123    lr: 4e-05     eval rl_reward: 1.94\n","For episode: 1129   the run_score was: 2.0   and mem length: 210123   eps: 0.7819544800047336    steps: 198    lr: 4e-05     eval rl_reward: 1.92\n","For episode: 1130   the run_score was: 0.0   and mem length: 210247   eps: 0.7817089600047389    steps: 124    lr: 4e-05     eval rl_reward: 1.9\n","For episode: 1131   the run_score was: 3.0   and mem length: 210493   eps: 0.7812218800047495    steps: 246    lr: 4e-05     eval rl_reward: 1.91\n","For episode: 1132   the run_score was: 2.0   and mem length: 210692   eps: 0.780827860004758    steps: 199    lr: 4e-05     eval rl_reward: 1.93\n","For episode: 1133   the run_score was: 2.0   and mem length: 210890   eps: 0.7804358200047665    steps: 198    lr: 4e-05     eval rl_reward: 1.94\n","For episode: 1134   the run_score was: 3.0   and mem length: 211117   eps: 0.7799863600047763    steps: 227    lr: 4e-05     eval rl_reward: 1.97\n","For episode: 1135   the run_score was: 3.0   and mem length: 211363   eps: 0.7794992800047869    steps: 246    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1136   the run_score was: 3.0   and mem length: 211591   eps: 0.7790478400047967    steps: 228    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1137   the run_score was: 2.0   and mem length: 211789   eps: 0.7786558000048052    steps: 198    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1138   the run_score was: 1.0   and mem length: 211962   eps: 0.7783132600048126    steps: 173    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1139   the run_score was: 1.0   and mem length: 212132   eps: 0.7779766600048199    steps: 170    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1140   the run_score was: 2.0   and mem length: 212351   eps: 0.7775430400048293    steps: 219    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1141   the run_score was: 4.0   and mem length: 212626   eps: 0.7769985400048411    steps: 275    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1142   the run_score was: 0.0   and mem length: 212749   eps: 0.7767550000048464    steps: 123    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1143   the run_score was: 2.0   and mem length: 212948   eps: 0.776360980004855    steps: 199    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1144   the run_score was: 2.0   and mem length: 213169   eps: 0.7759234000048645    steps: 221    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1145   the run_score was: 3.0   and mem length: 213418   eps: 0.7754303800048752    steps: 249    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1146   the run_score was: 2.0   and mem length: 213616   eps: 0.7750383400048837    steps: 198    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1147   the run_score was: 3.0   and mem length: 213884   eps: 0.7745077000048952    steps: 268    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1148   the run_score was: 3.0   and mem length: 214129   eps: 0.7740226000049057    steps: 245    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1149   the run_score was: 2.0   and mem length: 214328   eps: 0.7736285800049143    steps: 199    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1150   the run_score was: 2.0   and mem length: 214547   eps: 0.7731949600049237    steps: 219    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1151   the run_score was: 3.0   and mem length: 214777   eps: 0.7727395600049336    steps: 230    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1152   the run_score was: 3.0   and mem length: 215005   eps: 0.7722881200049434    steps: 228    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1153   the run_score was: 2.0   and mem length: 215203   eps: 0.7718960800049519    steps: 198    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1154   the run_score was: 3.0   and mem length: 215450   eps: 0.7714070200049625    steps: 247    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1155   the run_score was: 2.0   and mem length: 215648   eps: 0.771014980004971    steps: 198    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1156   the run_score was: 3.0   and mem length: 215877   eps: 0.7705615600049809    steps: 229    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1157   the run_score was: 2.0   and mem length: 216096   eps: 0.7701279400049903    steps: 219    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1158   the run_score was: 3.0   and mem length: 216325   eps: 0.7696745200050001    steps: 229    lr: 4e-05     eval rl_reward: 2.13\n","For episode: 1159   the run_score was: 2.0   and mem length: 216524   eps: 0.7692805000050087    steps: 199    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1160   the run_score was: 0.0   and mem length: 216647   eps: 0.769036960005014    steps: 123    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1161   the run_score was: 0.0   and mem length: 216770   eps: 0.7687934200050193    steps: 123    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1162   the run_score was: 3.0   and mem length: 216979   eps: 0.7683796000050283    steps: 209    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1163   the run_score was: 0.0   and mem length: 217103   eps: 0.7681340800050336    steps: 124    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1164   the run_score was: 1.0   and mem length: 217273   eps: 0.7677974800050409    steps: 170    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1165   the run_score was: 4.0   and mem length: 217534   eps: 0.7672807000050521    steps: 261    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1166   the run_score was: 3.0   and mem length: 217803   eps: 0.7667480800050637    steps: 269    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1167   the run_score was: 2.0   and mem length: 218005   eps: 0.7663481200050724    steps: 202    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1168   the run_score was: 2.0   and mem length: 218204   eps: 0.7659541000050809    steps: 199    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1169   the run_score was: 2.0   and mem length: 218403   eps: 0.7655600800050895    steps: 199    lr: 4e-05     eval rl_reward: 2.12\n","For episode: 1170   the run_score was: 3.0   and mem length: 218648   eps: 0.7650749800051    steps: 245    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1171   the run_score was: 3.0   and mem length: 218895   eps: 0.7645859200051106    steps: 247    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1172   the run_score was: 2.0   and mem length: 219114   eps: 0.76415230000512    steps: 219    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1173   the run_score was: 0.0   and mem length: 219238   eps: 0.7639067800051254    steps: 124    lr: 4e-05     eval rl_reward: 2.14\n","For episode: 1174   the run_score was: 2.0   and mem length: 219436   eps: 0.7635147400051339    steps: 198    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1175   the run_score was: 1.0   and mem length: 219605   eps: 0.7631801200051411    steps: 169    lr: 4e-05     eval rl_reward: 2.14\n","For episode: 1176   the run_score was: 2.0   and mem length: 219785   eps: 0.7628237200051489    steps: 180    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1177   the run_score was: 0.0   and mem length: 219908   eps: 0.7625801800051542    steps: 123    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1178   the run_score was: 1.0   and mem length: 220060   eps: 0.7622792200051607    steps: 152    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1179   the run_score was: 4.0   and mem length: 220338   eps: 0.7617287800051726    steps: 278    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1180   the run_score was: 2.0   and mem length: 220537   eps: 0.7613347600051812    steps: 199    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1181   the run_score was: 3.0   and mem length: 220787   eps: 0.7608397600051919    steps: 250    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1182   the run_score was: 0.0   and mem length: 220911   eps: 0.7605942400051973    steps: 124    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1183   the run_score was: 2.0   and mem length: 221127   eps: 0.7601665600052065    steps: 216    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1184   the run_score was: 3.0   and mem length: 221374   eps: 0.7596775000052172    steps: 247    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1185   the run_score was: 2.0   and mem length: 221572   eps: 0.7592854600052257    steps: 198    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1186   the run_score was: 3.0   and mem length: 221819   eps: 0.7587964000052363    steps: 247    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1187   the run_score was: 3.0   and mem length: 222064   eps: 0.7583113000052468    steps: 245    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1188   the run_score was: 2.0   and mem length: 222262   eps: 0.7579192600052553    steps: 198    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1189   the run_score was: 0.0   and mem length: 222386   eps: 0.7576737400052607    steps: 124    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1190   the run_score was: 3.0   and mem length: 222634   eps: 0.7571827000052713    steps: 248    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1191   the run_score was: 2.0   and mem length: 222832   eps: 0.7567906600052798    steps: 198    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1192   the run_score was: 2.0   and mem length: 223032   eps: 0.7563946600052884    steps: 200    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1193   the run_score was: 2.0   and mem length: 223230   eps: 0.7560026200052969    steps: 198    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1194   the run_score was: 5.0   and mem length: 223520   eps: 0.7554284200053094    steps: 290    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1195   the run_score was: 2.0   and mem length: 223719   eps: 0.755034400005318    steps: 199    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1196   the run_score was: 2.0   and mem length: 223918   eps: 0.7546403800053265    steps: 199    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1197   the run_score was: 2.0   and mem length: 224117   eps: 0.7542463600053351    steps: 199    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1198   the run_score was: 3.0   and mem length: 224362   eps: 0.7537612600053456    steps: 245    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1199   the run_score was: 1.0   and mem length: 224514   eps: 0.7534603000053521    steps: 152    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1200   the run_score was: 0.0   and mem length: 224637   eps: 0.7532167600053574    steps: 123    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1201   the run_score was: 3.0   and mem length: 224867   eps: 0.7527613600053673    steps: 230    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1202   the run_score was: 1.0   and mem length: 225019   eps: 0.7524604000053738    steps: 152    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1203   the run_score was: 2.0   and mem length: 225218   eps: 0.7520663800053824    steps: 199    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1204   the run_score was: 1.0   and mem length: 225389   eps: 0.7517278000053897    steps: 171    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1205   the run_score was: 0.0   and mem length: 225513   eps: 0.7514822800053951    steps: 124    lr: 4e-05     eval rl_reward: 2.03\n","For episode: 1206   the run_score was: 0.0   and mem length: 225636   eps: 0.7512387400054004    steps: 123    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1207   the run_score was: 6.0   and mem length: 225977   eps: 0.750563560005415    steps: 341    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1208   the run_score was: 3.0   and mem length: 226204   eps: 0.7501141000054248    steps: 227    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1209   the run_score was: 1.0   and mem length: 226377   eps: 0.7497715600054322    steps: 173    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1210   the run_score was: 2.0   and mem length: 226575   eps: 0.7493795200054407    steps: 198    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1211   the run_score was: 3.0   and mem length: 226839   eps: 0.7488568000054521    steps: 264    lr: 4e-05     eval rl_reward: 2.03\n","For episode: 1212   the run_score was: 2.0   and mem length: 227058   eps: 0.7484231800054615    steps: 219    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1213   the run_score was: 2.0   and mem length: 227261   eps: 0.7480212400054702    steps: 203    lr: 4e-05     eval rl_reward: 2.03\n","For episode: 1214   the run_score was: 2.0   and mem length: 227480   eps: 0.7475876200054796    steps: 219    lr: 4e-05     eval rl_reward: 2.0\n","For episode: 1215   the run_score was: 5.0   and mem length: 227826   eps: 0.7469025400054945    steps: 346    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1216   the run_score was: 0.0   and mem length: 227949   eps: 0.7466590000054998    steps: 123    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1217   the run_score was: 2.0   and mem length: 228166   eps: 0.7462293400055091    steps: 217    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1218   the run_score was: 2.0   and mem length: 228364   eps: 0.7458373000055176    steps: 198    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1219   the run_score was: 3.0   and mem length: 228613   eps: 0.7453442800055283    steps: 249    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1220   the run_score was: 4.0   and mem length: 228888   eps: 0.7447997800055401    steps: 275    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1221   the run_score was: 2.0   and mem length: 229086   eps: 0.7444077400055487    steps: 198    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1222   the run_score was: 1.0   and mem length: 229256   eps: 0.744071140005556    steps: 170    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1223   the run_score was: 2.0   and mem length: 229474   eps: 0.7436395000055653    steps: 218    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1224   the run_score was: 2.0   and mem length: 229672   eps: 0.7432474600055738    steps: 198    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1225   the run_score was: 3.0   and mem length: 229940   eps: 0.7427168200055854    steps: 268    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1226   the run_score was: 2.0   and mem length: 230139   eps: 0.7423228000055939    steps: 199    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1227   the run_score was: 4.0   and mem length: 230436   eps: 0.7417347400056067    steps: 297    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1228   the run_score was: 0.0   and mem length: 230559   eps: 0.741491200005612    steps: 123    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1229   the run_score was: 2.0   and mem length: 230758   eps: 0.7410971800056205    steps: 199    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1230   the run_score was: 2.0   and mem length: 230976   eps: 0.7406655400056299    steps: 218    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1231   the run_score was: 2.0   and mem length: 231174   eps: 0.7402735000056384    steps: 198    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1232   the run_score was: 0.0   and mem length: 231297   eps: 0.7400299600056437    steps: 123    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1233   the run_score was: 0.0   and mem length: 231420   eps: 0.739786420005649    steps: 123    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1234   the run_score was: 2.0   and mem length: 231641   eps: 0.7393488400056585    steps: 221    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1235   the run_score was: 3.0   and mem length: 231887   eps: 0.738861760005669    steps: 246    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1236   the run_score was: 1.0   and mem length: 232056   eps: 0.7385271400056763    steps: 169    lr: 4e-05     eval rl_reward: 2.03\n","For episode: 1237   the run_score was: 1.0   and mem length: 232226   eps: 0.7381905400056836    steps: 170    lr: 4e-05     eval rl_reward: 2.02\n","For episode: 1238   the run_score was: 3.0   and mem length: 232471   eps: 0.7377054400056942    steps: 245    lr: 4e-05     eval rl_reward: 2.04\n","For episode: 1239   the run_score was: 4.0   and mem length: 232747   eps: 0.737158960005706    steps: 276    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1240   the run_score was: 2.0   and mem length: 232945   eps: 0.7367669200057145    steps: 198    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1241   the run_score was: 3.0   and mem length: 233213   eps: 0.736236280005726    steps: 268    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1242   the run_score was: 0.0   and mem length: 233337   eps: 0.7359907600057314    steps: 124    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1243   the run_score was: 3.0   and mem length: 233584   eps: 0.735501700005742    steps: 247    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1244   the run_score was: 2.0   and mem length: 233803   eps: 0.7350680800057514    steps: 219    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1245   the run_score was: 2.0   and mem length: 234002   eps: 0.73467406000576    steps: 199    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1246   the run_score was: 1.0   and mem length: 234172   eps: 0.7343374600057673    steps: 170    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1247   the run_score was: 4.0   and mem length: 234449   eps: 0.7337890000057792    steps: 277    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1248   the run_score was: 3.0   and mem length: 234697   eps: 0.7332979600057898    steps: 248    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1249   the run_score was: 3.0   and mem length: 234910   eps: 0.732876220005799    steps: 213    lr: 4e-05     eval rl_reward: 2.07\n","For episode: 1250   the run_score was: 4.0   and mem length: 235207   eps: 0.7322881600058118    steps: 297    lr: 4e-05     eval rl_reward: 2.09\n","For episode: 1251   the run_score was: 0.0   and mem length: 235331   eps: 0.7320426400058171    steps: 124    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1252   the run_score was: 2.0   and mem length: 235529   eps: 0.7316506000058256    steps: 198    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1253   the run_score was: 2.0   and mem length: 235728   eps: 0.7312565800058342    steps: 199    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1254   the run_score was: 3.0   and mem length: 235954   eps: 0.7308091000058439    steps: 226    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1255   the run_score was: 3.0   and mem length: 236181   eps: 0.7303596400058536    steps: 227    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1256   the run_score was: 2.0   and mem length: 236380   eps: 0.7299656200058622    steps: 199    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1257   the run_score was: 3.0   and mem length: 236624   eps: 0.7294825000058727    steps: 244    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1258   the run_score was: 2.0   and mem length: 236843   eps: 0.7290488800058821    steps: 219    lr: 4e-05     eval rl_reward: 2.05\n","For episode: 1259   the run_score was: 3.0   and mem length: 237069   eps: 0.7286014000058918    steps: 226    lr: 4e-05     eval rl_reward: 2.06\n","For episode: 1260   the run_score was: 2.0   and mem length: 237268   eps: 0.7282073800059004    steps: 199    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1261   the run_score was: 3.0   and mem length: 237516   eps: 0.727716340005911    steps: 248    lr: 4e-05     eval rl_reward: 2.11\n","For episode: 1262   the run_score was: 0.0   and mem length: 237639   eps: 0.7274728000059163    steps: 123    lr: 4e-05     eval rl_reward: 2.08\n","For episode: 1263   the run_score was: 2.0   and mem length: 237837   eps: 0.7270807600059248    steps: 198    lr: 4e-05     eval rl_reward: 2.1\n","For episode: 1264   the run_score was: 4.0   and mem length: 238114   eps: 0.7265323000059367    steps: 277    lr: 4e-05     eval rl_reward: 2.13\n","For episode: 1265   the run_score was: 10.0   and mem length: 238483   eps: 0.7258016800059526    steps: 369    lr: 4e-05     eval rl_reward: 2.19\n","For episode: 1266   the run_score was: 2.0   and mem length: 238701   eps: 0.725370040005962    steps: 218    lr: 4e-05     eval rl_reward: 2.18\n","For episode: 1267   the run_score was: 2.0   and mem length: 238900   eps: 0.7249760200059705    steps: 199    lr: 4e-05     eval rl_reward: 2.18\n","For episode: 1268   the run_score was: 1.0   and mem length: 239070   eps: 0.7246394200059778    steps: 170    lr: 4e-05     eval rl_reward: 2.17\n","For episode: 1269   the run_score was: 2.0   and mem length: 239269   eps: 0.7242454000059864    steps: 199    lr: 4e-05     eval rl_reward: 2.17\n","For episode: 1270   the run_score was: 3.0   and mem length: 239537   eps: 0.7237147600059979    steps: 268    lr: 4e-05     eval rl_reward: 2.17\n","For episode: 1271   the run_score was: 0.0   and mem length: 239661   eps: 0.7234692400060032    steps: 124    lr: 4e-05     eval rl_reward: 2.14\n","For episode: 1272   the run_score was: 3.0   and mem length: 239907   eps: 0.7229821600060138    steps: 246    lr: 4e-05     eval rl_reward: 2.15\n","For episode: 1273   the run_score was: 4.0   and mem length: 240185   eps: 0.7224317200060257    steps: 278    lr: 4e-05     eval rl_reward: 2.19\n","For episode: 1274   the run_score was: 3.0   and mem length: 240411   eps: 0.7219842400060354    steps: 226    lr: 4e-05     eval rl_reward: 2.2\n","For episode: 1275   the run_score was: 0.0   and mem length: 240535   eps: 0.7217387200060408    steps: 124    lr: 4e-05     eval rl_reward: 2.19\n","For episode: 1276   the run_score was: 3.0   and mem length: 240782   eps: 0.7212496600060514    steps: 247    lr: 4e-05     eval rl_reward: 2.2\n","For episode: 1277   the run_score was: 2.0   and mem length: 240981   eps: 0.72085564000606    steps: 199    lr: 4e-05     eval rl_reward: 2.22\n","For episode: 1278   the run_score was: 3.0   and mem length: 241226   eps: 0.7203705400060705    steps: 245    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1279   the run_score was: 2.0   and mem length: 241445   eps: 0.7199369200060799    steps: 219    lr: 4e-05     eval rl_reward: 2.22\n","For episode: 1280   the run_score was: 2.0   and mem length: 241644   eps: 0.7195429000060884    steps: 199    lr: 4e-05     eval rl_reward: 2.22\n","For episode: 1281   the run_score was: 2.0   and mem length: 241842   eps: 0.719150860006097    steps: 198    lr: 4e-05     eval rl_reward: 2.21\n","For episode: 1282   the run_score was: 3.0   and mem length: 242089   eps: 0.7186618000061076    steps: 247    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1283   the run_score was: 2.0   and mem length: 242287   eps: 0.7182697600061161    steps: 198    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1284   the run_score was: 2.0   and mem length: 242489   eps: 0.7178698000061248    steps: 202    lr: 4e-05     eval rl_reward: 2.23\n","For episode: 1285   the run_score was: 0.0   and mem length: 242613   eps: 0.7176242800061301    steps: 124    lr: 4e-05     eval rl_reward: 2.21\n","For episode: 1286   the run_score was: 6.0   and mem length: 242949   eps: 0.7169590000061445    steps: 336    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1287   the run_score was: 3.0   and mem length: 243198   eps: 0.7164659800061552    steps: 249    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1288   the run_score was: 3.0   and mem length: 243444   eps: 0.7159789000061658    steps: 246    lr: 4e-05     eval rl_reward: 2.25\n","For episode: 1289   the run_score was: 2.0   and mem length: 243663   eps: 0.7155452800061752    steps: 219    lr: 4e-05     eval rl_reward: 2.27\n","For episode: 1290   the run_score was: 2.0   and mem length: 243881   eps: 0.7151136400061846    steps: 218    lr: 4e-05     eval rl_reward: 2.26\n","For episode: 1291   the run_score was: 3.0   and mem length: 244128   eps: 0.7146245800061952    steps: 247    lr: 4e-05     eval rl_reward: 2.27\n","For episode: 1292   the run_score was: 4.0   and mem length: 244425   eps: 0.714036520006208    steps: 297    lr: 4e-05     eval rl_reward: 2.29\n","For episode: 1293   the run_score was: 0.0   and mem length: 244548   eps: 0.7137929800062133    steps: 123    lr: 4e-05     eval rl_reward: 2.27\n","For episode: 1294   the run_score was: 3.0   and mem length: 244774   eps: 0.713345500006223    steps: 226    lr: 4e-05     eval rl_reward: 2.25\n","For episode: 1295   the run_score was: 1.0   and mem length: 244944   eps: 0.7130089000062303    steps: 170    lr: 4e-05     eval rl_reward: 2.24\n","For episode: 1296   the run_score was: 3.0   and mem length: 245189   eps: 0.7125238000062408    steps: 245    lr: 4e-05     eval rl_reward: 2.25\n","For episode: 1297   the run_score was: 3.0   and mem length: 245435   eps: 0.7120367200062514    steps: 246    lr: 4e-05     eval rl_reward: 2.26\n","For episode: 1298   the run_score was: 2.0   and mem length: 245634   eps: 0.71164270000626    steps: 199    lr: 4e-05     eval rl_reward: 2.25\n","For episode: 1299   the run_score was: 2.0   and mem length: 245833   eps: 0.7112486800062685    steps: 199    lr: 4e-05     eval rl_reward: 2.26\n","For episode: 1300   the run_score was: 2.0   and mem length: 246032   eps: 0.7108546600062771    steps: 199    lr: 4e-05     eval rl_reward: 2.28\n","For episode: 1301   the run_score was: 1.0   and mem length: 246184   eps: 0.7105537000062836    steps: 152    lr: 4e-05     eval rl_reward: 2.26\n","For episode: 1302   the run_score was: 3.0   and mem length: 246451   eps: 0.7100250400062951    steps: 267    lr: 4e-05     eval rl_reward: 2.28\n","For episode: 1303   the run_score was: 8.0   and mem length: 246912   eps: 0.7091122600063149    steps: 461    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1304   the run_score was: 2.0   and mem length: 247110   eps: 0.7087202200063234    steps: 198    lr: 4e-05     eval rl_reward: 2.35\n","For episode: 1305   the run_score was: 2.0   and mem length: 247292   eps: 0.7083598600063312    steps: 182    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1306   the run_score was: 1.0   and mem length: 247462   eps: 0.7080232600063385    steps: 170    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1307   the run_score was: 2.0   and mem length: 247661   eps: 0.7076292400063471    steps: 199    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1308   the run_score was: 2.0   and mem length: 247879   eps: 0.7071976000063565    steps: 218    lr: 4e-05     eval rl_reward: 2.33\n","For episode: 1309   the run_score was: 2.0   and mem length: 248077   eps: 0.706805560006365    steps: 198    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1310   the run_score was: 2.0   and mem length: 248276   eps: 0.7064115400063735    steps: 199    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1311   the run_score was: 4.0   and mem length: 248553   eps: 0.7058630800063854    steps: 277    lr: 4e-05     eval rl_reward: 2.35\n","For episode: 1312   the run_score was: 8.0   and mem length: 249010   eps: 0.7049582200064051    steps: 457    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1313   the run_score was: 2.0   and mem length: 249208   eps: 0.7045661800064136    steps: 198    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1314   the run_score was: 0.0   and mem length: 249331   eps: 0.7043226400064189    steps: 123    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1315   the run_score was: 3.0   and mem length: 249599   eps: 0.7037920000064304    steps: 268    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1316   the run_score was: 1.0   and mem length: 249770   eps: 0.7034534200064377    steps: 171    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1317   the run_score was: 1.0   and mem length: 249940   eps: 0.703116820006445    steps: 170    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1318   the run_score was: 2.0   and mem length: 250140   eps: 0.7027208200064536    steps: 200    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1319   the run_score was: 3.0   and mem length: 250388   eps: 0.7022297800064643    steps: 248    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1320   the run_score was: 3.0   and mem length: 250614   eps: 0.701782300006474    steps: 226    lr: 4e-05     eval rl_reward: 2.36\n","For episode: 1321   the run_score was: 5.0   and mem length: 250981   eps: 0.7010556400064898    steps: 367    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1322   the run_score was: 1.0   and mem length: 251133   eps: 0.7007546800064963    steps: 152    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1323   the run_score was: 2.0   and mem length: 251332   eps: 0.7003606600065049    steps: 199    lr: 4e-05     eval rl_reward: 2.39\n","For episode: 1324   the run_score was: 0.0   and mem length: 251455   eps: 0.7001171200065102    steps: 123    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1325   the run_score was: 0.0   and mem length: 251578   eps: 0.6998735800065154    steps: 123    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1326   the run_score was: 2.0   and mem length: 251781   eps: 0.6994716400065242    steps: 203    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1327   the run_score was: 0.0   and mem length: 251904   eps: 0.6992281000065295    steps: 123    lr: 4e-05     eval rl_reward: 2.3\n","For episode: 1328   the run_score was: 1.0   and mem length: 252074   eps: 0.6988915000065368    steps: 170    lr: 4e-05     eval rl_reward: 2.31\n","For episode: 1329   the run_score was: 3.0   and mem length: 252338   eps: 0.6983687800065481    steps: 264    lr: 4e-05     eval rl_reward: 2.32\n","For episode: 1330   the run_score was: 3.0   and mem length: 252585   eps: 0.6978797200065587    steps: 247    lr: 4e-05     eval rl_reward: 2.33\n","For episode: 1331   the run_score was: 2.0   and mem length: 252787   eps: 0.6974797600065674    steps: 202    lr: 4e-05     eval rl_reward: 2.33\n","For episode: 1332   the run_score was: 1.0   and mem length: 252939   eps: 0.697178800006574    steps: 152    lr: 4e-05     eval rl_reward: 2.34\n","For episode: 1333   the run_score was: 3.0   and mem length: 253166   eps: 0.6967293400065837    steps: 227    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1334   the run_score was: 3.0   and mem length: 253435   eps: 0.6961967200065953    steps: 269    lr: 4e-05     eval rl_reward: 2.38\n","For episode: 1335   the run_score was: 2.0   and mem length: 253633   eps: 0.6958046800066038    steps: 198    lr: 4e-05     eval rl_reward: 2.37\n","For episode: 1336   the run_score was: 4.0   and mem length: 253912   eps: 0.6952522600066158    steps: 279    lr: 4e-05     eval rl_reward: 2.4\n","For episode: 1337   the run_score was: 1.0   and mem length: 254063   eps: 0.6949532800066223    steps: 151    lr: 4e-05     eval rl_reward: 2.4\n","For episode: 1338   the run_score was: 3.0   and mem length: 254290   eps: 0.694503820006632    steps: 227    lr: 4e-05     eval rl_reward: 2.4\n","For episode: 1339   the run_score was: 6.0   and mem length: 254646   eps: 0.6937989400066473    steps: 356    lr: 4e-05     eval rl_reward: 2.42\n","For episode: 1340   the run_score was: 1.0   and mem length: 254798   eps: 0.6934979800066539    steps: 152    lr: 4e-05     eval rl_reward: 2.41\n","For episode: 1341   the run_score was: 6.0   and mem length: 255137   eps: 0.6928267600066684    steps: 339    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1342   the run_score was: 4.0   and mem length: 255414   eps: 0.6922783000066803    steps: 277    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1343   the run_score was: 3.0   and mem length: 255680   eps: 0.6917516200066918    steps: 266    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1344   the run_score was: 3.0   and mem length: 255906   eps: 0.6913041400067015    steps: 226    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1345   the run_score was: 0.0   and mem length: 256030   eps: 0.6910586200067068    steps: 124    lr: 4e-05     eval rl_reward: 2.47\n","For episode: 1346   the run_score was: 3.0   and mem length: 256258   eps: 0.6906071800067166    steps: 228    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1347   the run_score was: 3.0   and mem length: 256507   eps: 0.6901141600067273    steps: 249    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1348   the run_score was: 1.0   and mem length: 256659   eps: 0.6898132000067339    steps: 152    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1349   the run_score was: 3.0   and mem length: 256887   eps: 0.6893617600067437    steps: 228    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1350   the run_score was: 3.0   and mem length: 257131   eps: 0.6888786400067541    steps: 244    lr: 4e-05     eval rl_reward: 2.45\n","For episode: 1351   the run_score was: 3.0   and mem length: 257381   eps: 0.6883836400067649    steps: 250    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1352   the run_score was: 1.0   and mem length: 257533   eps: 0.6880826800067714    steps: 152    lr: 4e-05     eval rl_reward: 2.47\n","For episode: 1353   the run_score was: 2.0   and mem length: 257731   eps: 0.6876906400067799    steps: 198    lr: 4e-05     eval rl_reward: 2.47\n","For episode: 1354   the run_score was: 1.0   and mem length: 257903   eps: 0.6873500800067873    steps: 172    lr: 4e-05     eval rl_reward: 2.45\n","For episode: 1355   the run_score was: 2.0   and mem length: 258102   eps: 0.6869560600067959    steps: 199    lr: 4e-05     eval rl_reward: 2.44\n","For episode: 1356   the run_score was: 4.0   and mem length: 258384   eps: 0.686397700006808    steps: 282    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1357   the run_score was: 3.0   and mem length: 258653   eps: 0.6858650800068196    steps: 269    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1358   the run_score was: 2.0   and mem length: 258852   eps: 0.6854710600068281    steps: 199    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1359   the run_score was: 3.0   and mem length: 259078   eps: 0.6850235800068378    steps: 226    lr: 4e-05     eval rl_reward: 2.46\n","For episode: 1360   the run_score was: 7.0   and mem length: 259377   eps: 0.6844315600068507    steps: 299    lr: 4e-05     eval rl_reward: 2.51\n","For episode: 1361   the run_score was: 2.0   and mem length: 259578   eps: 0.6840335800068593    steps: 201    lr: 4e-05     eval rl_reward: 2.5\n","For episode: 1362   the run_score was: 4.0   and mem length: 259836   eps: 0.6835227400068704    steps: 258    lr: 4e-05     eval rl_reward: 2.54\n","For episode: 1363   the run_score was: 5.0   and mem length: 260166   eps: 0.6828693400068846    steps: 330    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1364   the run_score was: 4.0   and mem length: 260443   eps: 0.6823208800068965    steps: 277    lr: 4e-05     eval rl_reward: 2.57\n","For episode: 1365   the run_score was: 2.0   and mem length: 260661   eps: 0.6818892400069059    steps: 218    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1366   the run_score was: 0.0   and mem length: 260785   eps: 0.6816437200069112    steps: 124    lr: 4e-05     eval rl_reward: 2.47\n","For episode: 1367   the run_score was: 2.0   and mem length: 260984   eps: 0.6812497000069198    steps: 199    lr: 4e-05     eval rl_reward: 2.47\n","For episode: 1368   the run_score was: 2.0   and mem length: 261164   eps: 0.6808933000069275    steps: 180    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1369   the run_score was: 3.0   and mem length: 261394   eps: 0.6804379000069374    steps: 230    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1370   the run_score was: 2.0   and mem length: 261593   eps: 0.6800438800069459    steps: 199    lr: 4e-05     eval rl_reward: 2.48\n","For episode: 1371   the run_score was: 3.0   and mem length: 261841   eps: 0.6795528400069566    steps: 248    lr: 4e-05     eval rl_reward: 2.51\n","For episode: 1372   the run_score was: 2.0   and mem length: 262040   eps: 0.6791588200069651    steps: 199    lr: 4e-05     eval rl_reward: 2.5\n","For episode: 1373   the run_score was: 3.0   and mem length: 262269   eps: 0.678705400006975    steps: 229    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1374   the run_score was: 3.0   and mem length: 262514   eps: 0.6782203000069855    steps: 245    lr: 4e-05     eval rl_reward: 2.49\n","For episode: 1375   the run_score was: 2.0   and mem length: 262713   eps: 0.6778262800069941    steps: 199    lr: 4e-05     eval rl_reward: 2.51\n","For episode: 1376   the run_score was: 2.0   and mem length: 262932   eps: 0.6773926600070035    steps: 219    lr: 4e-05     eval rl_reward: 2.5\n","For episode: 1377   the run_score was: 4.0   and mem length: 263201   eps: 0.676860040007015    steps: 269    lr: 4e-05     eval rl_reward: 2.52\n","For episode: 1378   the run_score was: 3.0   and mem length: 263427   eps: 0.6764125600070248    steps: 226    lr: 4e-05     eval rl_reward: 2.52\n","For episode: 1379   the run_score was: 5.0   and mem length: 263753   eps: 0.6757670800070388    steps: 326    lr: 4e-05     eval rl_reward: 2.55\n","For episode: 1380   the run_score was: 3.0   and mem length: 263980   eps: 0.6753176200070485    steps: 227    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1381   the run_score was: 0.0   and mem length: 264104   eps: 0.6750721000070539    steps: 124    lr: 4e-05     eval rl_reward: 2.54\n","For episode: 1382   the run_score was: 5.0   and mem length: 264412   eps: 0.6744622600070671    steps: 308    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1383   the run_score was: 2.0   and mem length: 264630   eps: 0.6740306200070765    steps: 218    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1384   the run_score was: 2.0   and mem length: 264829   eps: 0.673636600007085    steps: 199    lr: 4e-05     eval rl_reward: 2.56\n","For episode: 1385   the run_score was: 5.0   and mem length: 265155   eps: 0.672991120007099    steps: 326    lr: 4e-05     eval rl_reward: 2.61\n","For episode: 1386   the run_score was: 3.0   and mem length: 265381   eps: 0.6725436400071088    steps: 226    lr: 4e-05     eval rl_reward: 2.58\n","For episode: 1387   the run_score was: 4.0   and mem length: 265668   eps: 0.6719753800071211    steps: 287    lr: 4e-05     eval rl_reward: 2.59\n","For episode: 1388   the run_score was: 6.0   and mem length: 266029   eps: 0.6712606000071366    steps: 361    lr: 4e-05     eval rl_reward: 2.62\n","For episode: 1389   the run_score was: 2.0   and mem length: 266227   eps: 0.6708685600071451    steps: 198    lr: 4e-05     eval rl_reward: 2.62\n","For episode: 1390   the run_score was: 3.0   and mem length: 266455   eps: 0.6704171200071549    steps: 228    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1391   the run_score was: 5.0   and mem length: 266779   eps: 0.6697756000071688    steps: 324    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1392   the run_score was: 4.0   and mem length: 267097   eps: 0.6691459600071825    steps: 318    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1393   the run_score was: 3.0   and mem length: 267341   eps: 0.668662840007193    steps: 244    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1394   the run_score was: 3.0   and mem length: 267552   eps: 0.6682450600072021    steps: 211    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1395   the run_score was: 2.0   and mem length: 267750   eps: 0.6678530200072106    steps: 198    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1396   the run_score was: 3.0   and mem length: 267995   eps: 0.6673679200072211    steps: 245    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1397   the run_score was: 2.0   and mem length: 268194   eps: 0.6669739000072297    steps: 199    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1398   the run_score was: 3.0   and mem length: 268460   eps: 0.6664472200072411    steps: 266    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1399   the run_score was: 1.0   and mem length: 268630   eps: 0.6661106200072484    steps: 170    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1400   the run_score was: 2.0   and mem length: 268829   eps: 0.665716600007257    steps: 199    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1401   the run_score was: 4.0   and mem length: 269127   eps: 0.6651265600072698    steps: 298    lr: 4e-05     eval rl_reward: 2.71\n","For episode: 1402   the run_score was: 2.0   and mem length: 269326   eps: 0.6647325400072783    steps: 199    lr: 4e-05     eval rl_reward: 2.7\n","For episode: 1403   the run_score was: 1.0   and mem length: 269478   eps: 0.6644315800072849    steps: 152    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1404   the run_score was: 2.0   and mem length: 269676   eps: 0.6640395400072934    steps: 198    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1405   the run_score was: 3.0   and mem length: 269924   eps: 0.663548500007304    steps: 248    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1406   the run_score was: 0.0   and mem length: 270048   eps: 0.6633029800073094    steps: 124    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1407   the run_score was: 1.0   and mem length: 270199   eps: 0.6630040000073159    steps: 151    lr: 4e-05     eval rl_reward: 2.62\n","For episode: 1408   the run_score was: 3.0   and mem length: 270426   eps: 0.6625545400073256    steps: 227    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1409   the run_score was: 7.0   and mem length: 270849   eps: 0.6617170000073438    steps: 423    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1410   the run_score was: 2.0   and mem length: 271066   eps: 0.6612873400073531    steps: 217    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1411   the run_score was: 4.0   and mem length: 271342   eps: 0.660740860007365    steps: 276    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1412   the run_score was: 3.0   and mem length: 271569   eps: 0.6602914000073747    steps: 227    lr: 4e-05     eval rl_reward: 2.63\n","For episode: 1413   the run_score was: 3.0   and mem length: 271796   eps: 0.6598419400073845    steps: 227    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1414   the run_score was: 1.0   and mem length: 271948   eps: 0.659540980007391    steps: 152    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1415   the run_score was: 3.0   and mem length: 272177   eps: 0.6590875600074009    steps: 229    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1416   the run_score was: 1.0   and mem length: 272329   eps: 0.6587866000074074    steps: 152    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1417   the run_score was: 4.0   and mem length: 272627   eps: 0.6581965600074202    steps: 298    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1418   the run_score was: 3.0   and mem length: 272895   eps: 0.6576659200074317    steps: 268    lr: 4e-05     eval rl_reward: 2.69\n","For episode: 1419   the run_score was: 2.0   and mem length: 273093   eps: 0.6572738800074402    steps: 198    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1420   the run_score was: 0.0   and mem length: 273217   eps: 0.6570283600074456    steps: 124    lr: 4e-05     eval rl_reward: 2.65\n","For episode: 1421   the run_score was: 4.0   and mem length: 273493   eps: 0.6564818800074574    steps: 276    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1422   the run_score was: 1.0   and mem length: 273644   eps: 0.6561829000074639    steps: 151    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1423   the run_score was: 0.0   and mem length: 273767   eps: 0.6559393600074692    steps: 123    lr: 4e-05     eval rl_reward: 2.62\n","For episode: 1424   the run_score was: 2.0   and mem length: 273966   eps: 0.6555453400074778    steps: 199    lr: 4e-05     eval rl_reward: 2.64\n","For episode: 1425   the run_score was: 2.0   and mem length: 274165   eps: 0.6551513200074863    steps: 199    lr: 4e-05     eval rl_reward: 2.66\n","For episode: 1426   the run_score was: 4.0   and mem length: 274424   eps: 0.6546385000074975    steps: 259    lr: 4e-05     eval rl_reward: 2.68\n","For episode: 1427   the run_score was: 6.0   and mem length: 274799   eps: 0.6538960000075136    steps: 375    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1428   the run_score was: 4.0   and mem length: 275074   eps: 0.6533515000075254    steps: 275    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1429   the run_score was: 3.0   and mem length: 275321   eps: 0.652862440007536    steps: 247    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1430   the run_score was: 1.0   and mem length: 275472   eps: 0.6525634600075425    steps: 151    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1431   the run_score was: 3.0   and mem length: 275701   eps: 0.6521100400075523    steps: 229    lr: 4e-05     eval rl_reward: 2.76\n","For episode: 1432   the run_score was: 3.0   and mem length: 275948   eps: 0.651620980007563    steps: 247    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1433   the run_score was: 3.0   and mem length: 276219   eps: 0.6510844000075746    steps: 271    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1434   the run_score was: 2.0   and mem length: 276436   eps: 0.6506547400075839    steps: 217    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1435   the run_score was: 3.0   and mem length: 276681   eps: 0.6501696400075945    steps: 245    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1436   the run_score was: 2.0   and mem length: 276880   eps: 0.649775620007603    steps: 199    lr: 4e-05     eval rl_reward: 2.76\n","For episode: 1437   the run_score was: 4.0   and mem length: 277157   eps: 0.6492271600076149    steps: 277    lr: 4e-05     eval rl_reward: 2.79\n","For episode: 1438   the run_score was: 2.0   and mem length: 277339   eps: 0.6488668000076228    steps: 182    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1439   the run_score was: 3.0   and mem length: 277587   eps: 0.6483757600076334    steps: 248    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1440   the run_score was: 3.0   and mem length: 277835   eps: 0.6478847200076441    steps: 248    lr: 4e-05     eval rl_reward: 2.77\n","For episode: 1441   the run_score was: 3.0   and mem length: 278081   eps: 0.6473976400076547    steps: 246    lr: 4e-05     eval rl_reward: 2.74\n","For episode: 1442   the run_score was: 3.0   and mem length: 278331   eps: 0.6469026400076654    steps: 250    lr: 4e-05     eval rl_reward: 2.73\n","For episode: 1443   the run_score was: 2.0   and mem length: 278532   eps: 0.646504660007674    steps: 201    lr: 4e-05     eval rl_reward: 2.72\n","For episode: 1444   the run_score was: 3.0   and mem length: 278758   eps: 0.6460571800076838    steps: 226    lr: 4e-05     eval rl_reward: 2.72\n","For episode: 1445   the run_score was: 3.0   and mem length: 278984   eps: 0.6456097000076935    steps: 226    lr: 4e-05     eval rl_reward: 2.75\n","For episode: 1446   the run_score was: 4.0   and mem length: 279260   eps: 0.6450632200077053    steps: 276    lr: 4e-05     eval rl_reward: 2.76\n","For episode: 1447   the run_score was: 8.0   and mem length: 279704   eps: 0.6441841000077244    steps: 444    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1448   the run_score was: 1.0   and mem length: 279876   eps: 0.6438435400077318    steps: 172    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1449   the run_score was: 3.0   and mem length: 280090   eps: 0.643419820007741    steps: 214    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1450   the run_score was: 1.0   and mem length: 280242   eps: 0.6431188600077475    steps: 152    lr: 4e-05     eval rl_reward: 2.79\n","For episode: 1451   the run_score was: 3.0   and mem length: 280471   eps: 0.6426654400077574    steps: 229    lr: 4e-05     eval rl_reward: 2.79\n","For episode: 1452   the run_score was: 3.0   and mem length: 280718   eps: 0.642176380007768    steps: 247    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1453   the run_score was: 4.0   and mem length: 281015   eps: 0.6415883200077808    steps: 297    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1454   the run_score was: 3.0   and mem length: 281244   eps: 0.6411349000077906    steps: 229    lr: 4e-05     eval rl_reward: 2.85\n","For episode: 1455   the run_score was: 7.0   and mem length: 281612   eps: 0.6404062600078064    steps: 368    lr: 4e-05     eval rl_reward: 2.9\n","For episode: 1456   the run_score was: 3.0   and mem length: 281824   eps: 0.6399865000078155    steps: 212    lr: 4e-05     eval rl_reward: 2.89\n","For episode: 1457   the run_score was: 2.0   and mem length: 282022   eps: 0.639594460007824    steps: 198    lr: 4e-05     eval rl_reward: 2.88\n","For episode: 1458   the run_score was: 1.0   and mem length: 282192   eps: 0.6392578600078314    steps: 170    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1459   the run_score was: 1.0   and mem length: 282345   eps: 0.6389549200078379    steps: 153    lr: 4e-05     eval rl_reward: 2.85\n","For episode: 1460   the run_score was: 5.0   and mem length: 282689   eps: 0.6382738000078527    steps: 344    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1461   the run_score was: 3.0   and mem length: 282916   eps: 0.6378243400078625    steps: 227    lr: 4e-05     eval rl_reward: 2.84\n","For episode: 1462   the run_score was: 3.0   and mem length: 283164   eps: 0.6373333000078731    steps: 248    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1463   the run_score was: 2.0   and mem length: 283344   eps: 0.6369769000078809    steps: 180    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1464   the run_score was: 2.0   and mem length: 283543   eps: 0.6365828800078894    steps: 199    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1465   the run_score was: 0.0   and mem length: 283666   eps: 0.6363393400078947    steps: 123    lr: 4e-05     eval rl_reward: 2.76\n","For episode: 1466   the run_score was: 2.0   and mem length: 283868   eps: 0.6359393800079034    steps: 202    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1467   the run_score was: 3.0   and mem length: 284095   eps: 0.6354899200079132    steps: 227    lr: 4e-05     eval rl_reward: 2.79\n","For episode: 1468   the run_score was: 4.0   and mem length: 284355   eps: 0.6349751200079243    steps: 260    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1469   the run_score was: 0.0   and mem length: 284478   eps: 0.6347315800079296    steps: 123    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1470   the run_score was: 4.0   and mem length: 284777   eps: 0.6341395600079425    steps: 299    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1471   the run_score was: 4.0   and mem length: 285072   eps: 0.6335554600079552    steps: 295    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1472   the run_score was: 3.0   and mem length: 285320   eps: 0.6330644200079658    steps: 248    lr: 4e-05     eval rl_reward: 2.82\n","For episode: 1473   the run_score was: 2.0   and mem length: 285543   eps: 0.6326228800079754    steps: 223    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1474   the run_score was: 2.0   and mem length: 285760   eps: 0.6321932200079847    steps: 217    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1475   the run_score was: 3.0   and mem length: 286008   eps: 0.6317021800079954    steps: 248    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1476   the run_score was: 3.0   and mem length: 286235   eps: 0.6312527200080051    steps: 227    lr: 4e-05     eval rl_reward: 2.82\n","For episode: 1477   the run_score was: 3.0   and mem length: 286462   eps: 0.6308032600080149    steps: 227    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1478   the run_score was: 3.0   and mem length: 286689   eps: 0.6303538000080247    steps: 227    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1479   the run_score was: 2.0   and mem length: 286888   eps: 0.6299597800080332    steps: 199    lr: 4e-05     eval rl_reward: 2.78\n","For episode: 1480   the run_score was: 4.0   and mem length: 287164   eps: 0.6294133000080451    steps: 276    lr: 4e-05     eval rl_reward: 2.79\n","For episode: 1481   the run_score was: 2.0   and mem length: 287383   eps: 0.6289796800080545    steps: 219    lr: 4e-05     eval rl_reward: 2.81\n","For episode: 1482   the run_score was: 4.0   and mem length: 287659   eps: 0.6284332000080664    steps: 276    lr: 4e-05     eval rl_reward: 2.8\n","For episode: 1483   the run_score was: 4.0   and mem length: 287935   eps: 0.6278867200080782    steps: 276    lr: 4e-05     eval rl_reward: 2.82\n","For episode: 1484   the run_score was: 7.0   and mem length: 288319   eps: 0.6271264000080947    steps: 384    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1485   the run_score was: 7.0   and mem length: 288740   eps: 0.6262928200081128    steps: 421    lr: 4e-05     eval rl_reward: 2.89\n","For episode: 1486   the run_score was: 1.0   and mem length: 288910   eps: 0.6259562200081201    steps: 170    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1487   the run_score was: 2.0   and mem length: 289109   eps: 0.6255622000081287    steps: 199    lr: 4e-05     eval rl_reward: 2.85\n","For episode: 1488   the run_score was: 3.0   and mem length: 289339   eps: 0.6251068000081386    steps: 230    lr: 4e-05     eval rl_reward: 2.82\n","For episode: 1489   the run_score was: 3.0   and mem length: 289566   eps: 0.6246573400081483    steps: 227    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1490   the run_score was: 7.0   and mem length: 289973   eps: 0.6238514800081658    steps: 407    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1491   the run_score was: 4.0   and mem length: 290253   eps: 0.6232970800081779    steps: 280    lr: 4e-05     eval rl_reward: 2.86\n","For episode: 1492   the run_score was: 2.0   and mem length: 290435   eps: 0.6229367200081857    steps: 182    lr: 4e-05     eval rl_reward: 2.84\n","For episode: 1493   the run_score was: 2.0   and mem length: 290634   eps: 0.6225427000081942    steps: 199    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1494   the run_score was: 3.0   and mem length: 290848   eps: 0.6221189800082034    steps: 214    lr: 4e-05     eval rl_reward: 2.83\n","For episode: 1495   the run_score was: 5.0   and mem length: 291177   eps: 0.6214675600082176    steps: 329    lr: 4e-05     eval rl_reward: 2.86\n","For episode: 1496   the run_score was: 1.0   and mem length: 291329   eps: 0.6211666000082241    steps: 152    lr: 4e-05     eval rl_reward: 2.84\n","For episode: 1497   the run_score was: 3.0   and mem length: 291556   eps: 0.6207171400082339    steps: 227    lr: 4e-05     eval rl_reward: 2.85\n","For episode: 1498   the run_score was: 5.0   and mem length: 291896   eps: 0.6200439400082485    steps: 340    lr: 4e-05     eval rl_reward: 2.87\n","For episode: 1499   the run_score was: 5.0   and mem length: 292222   eps: 0.6193984600082625    steps: 326    lr: 4e-05     eval rl_reward: 2.91\n","For episode: 1500   the run_score was: 4.0   and mem length: 292463   eps: 0.6189212800082728    steps: 241    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1501   the run_score was: 4.0   and mem length: 292740   eps: 0.6183728200082848    steps: 277    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1502   the run_score was: 2.0   and mem length: 292920   eps: 0.6180164200082925    steps: 180    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1503   the run_score was: 1.0   and mem length: 293090   eps: 0.6176798200082998    steps: 170    lr: 4e-05     eval rl_reward: 2.93\n","For episode: 1504   the run_score was: 4.0   and mem length: 293367   eps: 0.6171313600083117    steps: 277    lr: 4e-05     eval rl_reward: 2.95\n","For episode: 1505   the run_score was: 6.0   and mem length: 293731   eps: 0.6164106400083273    steps: 364    lr: 4e-05     eval rl_reward: 2.98\n","For episode: 1506   the run_score was: 6.0   and mem length: 294075   eps: 0.6157295200083421    steps: 344    lr: 4e-05     eval rl_reward: 3.04\n","For episode: 1507   the run_score was: 2.0   and mem length: 294276   eps: 0.6153315400083508    steps: 201    lr: 4e-05     eval rl_reward: 3.05\n","For episode: 1508   the run_score was: 4.0   and mem length: 294553   eps: 0.6147830800083627    steps: 277    lr: 4e-05     eval rl_reward: 3.06\n","For episode: 1509   the run_score was: 2.0   and mem length: 294735   eps: 0.6144227200083705    steps: 182    lr: 4e-05     eval rl_reward: 3.01\n","For episode: 1510   the run_score was: 3.0   and mem length: 294962   eps: 0.6139732600083803    steps: 227    lr: 4e-05     eval rl_reward: 3.02\n","For episode: 1511   the run_score was: 3.0   and mem length: 295189   eps: 0.61352380000839    steps: 227    lr: 4e-05     eval rl_reward: 3.01\n","For episode: 1512   the run_score was: 1.0   and mem length: 295341   eps: 0.6132228400083966    steps: 152    lr: 4e-05     eval rl_reward: 2.99\n","For episode: 1513   the run_score was: 4.0   and mem length: 295604   eps: 0.6127021000084079    steps: 263    lr: 4e-05     eval rl_reward: 3.0\n","For episode: 1514   the run_score was: 3.0   and mem length: 295816   eps: 0.612282340008417    steps: 212    lr: 4e-05     eval rl_reward: 3.02\n","For episode: 1515   the run_score was: 4.0   and mem length: 296094   eps: 0.6117319000084289    steps: 278    lr: 4e-05     eval rl_reward: 3.03\n","For episode: 1516   the run_score was: 7.0   and mem length: 296479   eps: 0.6109696000084455    steps: 385    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1517   the run_score was: 3.0   and mem length: 296706   eps: 0.6105201400084552    steps: 227    lr: 4e-05     eval rl_reward: 3.08\n","For episode: 1518   the run_score was: 4.0   and mem length: 296988   eps: 0.6099617800084673    steps: 282    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1519   the run_score was: 2.0   and mem length: 297170   eps: 0.6096014200084752    steps: 182    lr: 4e-05     eval rl_reward: 3.09\n","For episode: 1520   the run_score was: 2.0   and mem length: 297389   eps: 0.6091678000084846    steps: 219    lr: 4e-05     eval rl_reward: 3.11\n","For episode: 1521   the run_score was: 5.0   and mem length: 297694   eps: 0.6085639000084977    steps: 305    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1522   the run_score was: 1.0   and mem length: 297846   eps: 0.6082629400085042    steps: 152    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1523   the run_score was: 2.0   and mem length: 298029   eps: 0.6079006000085121    steps: 183    lr: 4e-05     eval rl_reward: 3.14\n","For episode: 1524   the run_score was: 3.0   and mem length: 298256   eps: 0.6074511400085219    steps: 227    lr: 4e-05     eval rl_reward: 3.15\n","For episode: 1525   the run_score was: 3.0   and mem length: 298483   eps: 0.6070016800085316    steps: 227    lr: 4e-05     eval rl_reward: 3.16\n","For episode: 1526   the run_score was: 3.0   and mem length: 298696   eps: 0.6065799400085408    steps: 213    lr: 4e-05     eval rl_reward: 3.15\n","For episode: 1527   the run_score was: 3.0   and mem length: 298908   eps: 0.6061601800085499    steps: 212    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1528   the run_score was: 4.0   and mem length: 299207   eps: 0.6055681600085627    steps: 299    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1529   the run_score was: 3.0   and mem length: 299454   eps: 0.6050791000085733    steps: 247    lr: 4e-05     eval rl_reward: 3.12\n","For episode: 1530   the run_score was: 3.0   and mem length: 299703   eps: 0.604586080008584    steps: 249    lr: 4e-05     eval rl_reward: 3.14\n","For episode: 1531   the run_score was: 4.0   and mem length: 300000   eps: 0.6039980200085968    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 3.15\n","For episode: 1532   the run_score was: 3.0   and mem length: 300226   eps: 0.6035505400086065    steps: 226    lr: 1.6000000000000003e-05     eval rl_reward: 3.15\n","For episode: 1533   the run_score was: 5.0   and mem length: 300523   eps: 0.6029624800086193    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 3.17\n","For episode: 1534   the run_score was: 5.0   and mem length: 300815   eps: 0.6023843200086318    steps: 292    lr: 1.6000000000000003e-05     eval rl_reward: 3.2\n","For episode: 1535   the run_score was: 5.0   and mem length: 301143   eps: 0.601734880008646    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 3.22\n","For episode: 1536   the run_score was: 3.0   and mem length: 301370   eps: 0.6012854200086557    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.23\n","For episode: 1537   the run_score was: 2.0   and mem length: 301569   eps: 0.6008914000086643    steps: 199    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1538   the run_score was: 1.0   and mem length: 301721   eps: 0.6005904400086708    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.2\n","For episode: 1539   the run_score was: 2.0   and mem length: 301922   eps: 0.6001924600086794    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 3.19\n","For episode: 1540   the run_score was: 4.0   and mem length: 302197   eps: 0.5996479600086912    steps: 275    lr: 1.6000000000000003e-05     eval rl_reward: 3.2\n","For episode: 1541   the run_score was: 2.0   and mem length: 302380   eps: 0.5992856200086991    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 3.19\n","For episode: 1542   the run_score was: 4.0   and mem length: 302641   eps: 0.5987688400087103    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 3.2\n","For episode: 1543   the run_score was: 3.0   and mem length: 302867   eps: 0.59832136000872    steps: 226    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1544   the run_score was: 3.0   and mem length: 303094   eps: 0.5978719000087298    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1545   the run_score was: 3.0   and mem length: 303327   eps: 0.5974105600087398    steps: 233    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1546   the run_score was: 3.0   and mem length: 303575   eps: 0.5969195200087505    steps: 248    lr: 1.6000000000000003e-05     eval rl_reward: 3.2\n","For episode: 1547   the run_score was: 4.0   and mem length: 303842   eps: 0.596390860008762    steps: 267    lr: 1.6000000000000003e-05     eval rl_reward: 3.16\n","For episode: 1548   the run_score was: 2.0   and mem length: 304042   eps: 0.5959948600087706    steps: 200    lr: 1.6000000000000003e-05     eval rl_reward: 3.17\n","For episode: 1549   the run_score was: 5.0   and mem length: 304366   eps: 0.5953533400087845    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 3.19\n","For episode: 1550   the run_score was: 3.0   and mem length: 304592   eps: 0.5949058600087942    steps: 226    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1551   the run_score was: 5.0   and mem length: 304894   eps: 0.5943079000088072    steps: 302    lr: 1.6000000000000003e-05     eval rl_reward: 3.23\n","For episode: 1552   the run_score was: 3.0   and mem length: 305164   eps: 0.5937733000088188    steps: 270    lr: 1.6000000000000003e-05     eval rl_reward: 3.23\n","For episode: 1553   the run_score was: 5.0   and mem length: 305474   eps: 0.5931595000088321    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.24\n","For episode: 1554   the run_score was: 5.0   and mem length: 305763   eps: 0.5925872800088445    steps: 289    lr: 1.6000000000000003e-05     eval rl_reward: 3.26\n","For episode: 1555   the run_score was: 2.0   and mem length: 305982   eps: 0.5921536600088539    steps: 219    lr: 1.6000000000000003e-05     eval rl_reward: 3.21\n","For episode: 1556   the run_score was: 6.0   and mem length: 306338   eps: 0.5914487800088692    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 3.24\n","For episode: 1557   the run_score was: 2.0   and mem length: 306539   eps: 0.5910508000088779    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 3.24\n","For episode: 1558   the run_score was: 1.0   and mem length: 306692   eps: 0.5907478600088845    steps: 153    lr: 1.6000000000000003e-05     eval rl_reward: 3.24\n","For episode: 1559   the run_score was: 3.0   and mem length: 306918   eps: 0.5903003800088942    steps: 226    lr: 1.6000000000000003e-05     eval rl_reward: 3.26\n","For episode: 1560   the run_score was: 4.0   and mem length: 307194   eps: 0.589753900008906    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.25\n","For episode: 1561   the run_score was: 6.0   and mem length: 307521   eps: 0.5891064400089201    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 3.28\n","For episode: 1562   the run_score was: 5.0   and mem length: 307869   eps: 0.588417400008935    steps: 348    lr: 1.6000000000000003e-05     eval rl_reward: 3.3\n","For episode: 1563   the run_score was: 3.0   and mem length: 308135   eps: 0.5878907200089465    steps: 266    lr: 1.6000000000000003e-05     eval rl_reward: 3.31\n","For episode: 1564   the run_score was: 4.0   and mem length: 308403   eps: 0.587360080008958    steps: 268    lr: 1.6000000000000003e-05     eval rl_reward: 3.33\n","For episode: 1565   the run_score was: 3.0   and mem length: 308649   eps: 0.5868730000089686    steps: 246    lr: 1.6000000000000003e-05     eval rl_reward: 3.36\n","For episode: 1566   the run_score was: 3.0   and mem length: 308916   eps: 0.5863443400089801    steps: 267    lr: 1.6000000000000003e-05     eval rl_reward: 3.37\n","For episode: 1567   the run_score was: 3.0   and mem length: 309130   eps: 0.5859206200089893    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.37\n","For episode: 1568   the run_score was: 4.0   and mem length: 309389   eps: 0.5854078000090004    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 3.37\n","For episode: 1569   the run_score was: 3.0   and mem length: 309601   eps: 0.5849880400090095    steps: 212    lr: 1.6000000000000003e-05     eval rl_reward: 3.4\n","For episode: 1570   the run_score was: 10.0   and mem length: 309998   eps: 0.5842019800090266    steps: 397    lr: 1.6000000000000003e-05     eval rl_reward: 3.46\n","For episode: 1571   the run_score was: 3.0   and mem length: 310224   eps: 0.5837545000090363    steps: 226    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1572   the run_score was: 2.0   and mem length: 310423   eps: 0.5833604800090448    steps: 199    lr: 1.6000000000000003e-05     eval rl_reward: 3.44\n","For episode: 1573   the run_score was: 1.0   and mem length: 310593   eps: 0.5830238800090521    steps: 170    lr: 1.6000000000000003e-05     eval rl_reward: 3.43\n","For episode: 1574   the run_score was: 2.0   and mem length: 310778   eps: 0.5826575800090601    steps: 185    lr: 1.6000000000000003e-05     eval rl_reward: 3.43\n","For episode: 1575   the run_score was: 3.0   and mem length: 311005   eps: 0.5822081200090699    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.43\n","For episode: 1576   the run_score was: 5.0   and mem length: 311315   eps: 0.5815943200090832    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1577   the run_score was: 3.0   and mem length: 311544   eps: 0.581140900009093    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1578   the run_score was: 3.0   and mem length: 311771   eps: 0.5806914400091028    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1579   the run_score was: 4.0   and mem length: 312031   eps: 0.580176640009114    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.47\n","For episode: 1580   the run_score was: 4.0   and mem length: 312308   eps: 0.5796281800091259    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.47\n","For episode: 1581   the run_score was: 3.0   and mem length: 312535   eps: 0.5791787200091356    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.48\n","For episode: 1582   the run_score was: 2.0   and mem length: 312718   eps: 0.5788163800091435    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 3.46\n","For episode: 1583   the run_score was: 6.0   and mem length: 313096   eps: 0.5780679400091597    steps: 378    lr: 1.6000000000000003e-05     eval rl_reward: 3.48\n","For episode: 1584   the run_score was: 2.0   and mem length: 313296   eps: 0.5776719400091683    steps: 200    lr: 1.6000000000000003e-05     eval rl_reward: 3.43\n","For episode: 1585   the run_score was: 3.0   and mem length: 313528   eps: 0.5772125800091783    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 3.39\n","For episode: 1586   the run_score was: 3.0   and mem length: 313742   eps: 0.5767888600091875    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.41\n","For episode: 1587   the run_score was: 3.0   and mem length: 314009   eps: 0.576260200009199    steps: 267    lr: 1.6000000000000003e-05     eval rl_reward: 3.42\n","For episode: 1588   the run_score was: 6.0   and mem length: 314349   eps: 0.5755870000092136    steps: 340    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1589   the run_score was: 4.0   and mem length: 314608   eps: 0.5750741800092247    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 3.46\n","For episode: 1590   the run_score was: 3.0   and mem length: 314835   eps: 0.5746247200092345    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.42\n","For episode: 1591   the run_score was: 6.0   and mem length: 315182   eps: 0.5739376600092494    steps: 347    lr: 1.6000000000000003e-05     eval rl_reward: 3.44\n","For episode: 1592   the run_score was: 3.0   and mem length: 315411   eps: 0.5734842400092592    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1593   the run_score was: 2.0   and mem length: 315613   eps: 0.5730842800092679    steps: 202    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1594   the run_score was: 5.0   and mem length: 315920   eps: 0.5724764200092811    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 3.47\n","For episode: 1595   the run_score was: 3.0   and mem length: 316147   eps: 0.5720269600092909    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.45\n","For episode: 1596   the run_score was: 4.0   and mem length: 316405   eps: 0.571516120009302    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 3.48\n","For episode: 1597   the run_score was: 3.0   and mem length: 316616   eps: 0.571098340009311    steps: 211    lr: 1.6000000000000003e-05     eval rl_reward: 3.48\n","For episode: 1598   the run_score was: 4.0   and mem length: 316876   eps: 0.5705835400093222    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.47\n","For episode: 1599   the run_score was: 5.0   and mem length: 317200   eps: 0.5699420200093361    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 3.47\n","For episode: 1600   the run_score was: 5.0   and mem length: 317510   eps: 0.5693282200093495    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.48\n","For episode: 1601   the run_score was: 5.0   and mem length: 317856   eps: 0.5686431400093643    steps: 346    lr: 1.6000000000000003e-05     eval rl_reward: 3.49\n","For episode: 1602   the run_score was: 5.0   and mem length: 318181   eps: 0.5679996400093783    steps: 325    lr: 1.6000000000000003e-05     eval rl_reward: 3.52\n","For episode: 1603   the run_score was: 4.0   and mem length: 318457   eps: 0.5674531600093902    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.55\n","For episode: 1604   the run_score was: 6.0   and mem length: 318802   eps: 0.566770060009405    steps: 345    lr: 1.6000000000000003e-05     eval rl_reward: 3.57\n","For episode: 1605   the run_score was: 6.0   and mem length: 319157   eps: 0.5660671600094203    steps: 355    lr: 1.6000000000000003e-05     eval rl_reward: 3.57\n","For episode: 1606   the run_score was: 3.0   and mem length: 319369   eps: 0.5656474000094294    steps: 212    lr: 1.6000000000000003e-05     eval rl_reward: 3.54\n","For episode: 1607   the run_score was: 3.0   and mem length: 319583   eps: 0.5652236800094386    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.55\n","For episode: 1608   the run_score was: 8.0   and mem length: 320028   eps: 0.5643425800094577    steps: 445    lr: 1.6000000000000003e-05     eval rl_reward: 3.59\n","For episode: 1609   the run_score was: 5.0   and mem length: 320354   eps: 0.5636971000094717    steps: 326    lr: 1.6000000000000003e-05     eval rl_reward: 3.62\n","For episode: 1610   the run_score was: 8.0   and mem length: 320798   eps: 0.5628179800094908    steps: 444    lr: 1.6000000000000003e-05     eval rl_reward: 3.67\n","For episode: 1611   the run_score was: 5.0   and mem length: 321103   eps: 0.5622140800095039    steps: 305    lr: 1.6000000000000003e-05     eval rl_reward: 3.69\n","For episode: 1612   the run_score was: 3.0   and mem length: 321317   eps: 0.5617903600095131    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.71\n","For episode: 1613   the run_score was: 4.0   and mem length: 321594   eps: 0.561241900009525    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.71\n","For episode: 1614   the run_score was: 7.0   and mem length: 321988   eps: 0.5604617800095419    steps: 394    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1615   the run_score was: 4.0   and mem length: 322264   eps: 0.5599153000095538    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1616   the run_score was: 0.0   and mem length: 322388   eps: 0.5596697800095591    steps: 124    lr: 1.6000000000000003e-05     eval rl_reward: 3.68\n","For episode: 1617   the run_score was: 4.0   and mem length: 322648   eps: 0.5591549800095703    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.69\n","For episode: 1618   the run_score was: 4.0   and mem length: 322947   eps: 0.5585629600095832    steps: 299    lr: 1.6000000000000003e-05     eval rl_reward: 3.69\n","For episode: 1619   the run_score was: 2.0   and mem length: 323145   eps: 0.5581709200095917    steps: 198    lr: 1.6000000000000003e-05     eval rl_reward: 3.69\n","For episode: 1620   the run_score was: 3.0   and mem length: 323359   eps: 0.5577472000096009    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.7\n","For episode: 1621   the run_score was: 2.0   and mem length: 323542   eps: 0.5573848600096087    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 3.67\n","For episode: 1622   the run_score was: 6.0   and mem length: 323883   eps: 0.5567096800096234    steps: 341    lr: 1.6000000000000003e-05     eval rl_reward: 3.72\n","For episode: 1623   the run_score was: 3.0   and mem length: 324134   eps: 0.5562127000096342    steps: 251    lr: 1.6000000000000003e-05     eval rl_reward: 3.73\n","For episode: 1624   the run_score was: 2.0   and mem length: 324355   eps: 0.5557751200096437    steps: 221    lr: 1.6000000000000003e-05     eval rl_reward: 3.72\n","For episode: 1625   the run_score was: 6.0   and mem length: 324692   eps: 0.5551078600096582    steps: 337    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1626   the run_score was: 2.0   and mem length: 324910   eps: 0.5546762200096675    steps: 218    lr: 1.6000000000000003e-05     eval rl_reward: 3.74\n","For episode: 1627   the run_score was: 3.0   and mem length: 325122   eps: 0.5542564600096767    steps: 212    lr: 1.6000000000000003e-05     eval rl_reward: 3.74\n","For episode: 1628   the run_score was: 4.0   and mem length: 325398   eps: 0.5537099800096885    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.74\n","For episode: 1629   the run_score was: 5.0   and mem length: 325708   eps: 0.5530961800097018    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1630   the run_score was: 2.0   and mem length: 325907   eps: 0.5527021600097104    steps: 199    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1631   the run_score was: 3.0   and mem length: 326154   eps: 0.552213100009721    steps: 247    lr: 1.6000000000000003e-05     eval rl_reward: 3.74\n","For episode: 1632   the run_score was: 4.0   and mem length: 326430   eps: 0.5516666200097329    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1633   the run_score was: 4.0   and mem length: 326710   eps: 0.5511122200097449    steps: 280    lr: 1.6000000000000003e-05     eval rl_reward: 3.74\n","For episode: 1634   the run_score was: 6.0   and mem length: 327061   eps: 0.55041724000976    steps: 351    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1635   the run_score was: 6.0   and mem length: 327457   eps: 0.549633160009777    steps: 396    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1636   the run_score was: 2.0   and mem length: 327637   eps: 0.5492767600097848    steps: 180    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1637   the run_score was: 3.0   and mem length: 327851   eps: 0.548853040009794    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1638   the run_score was: 4.0   and mem length: 328128   eps: 0.5483045800098059    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1639   the run_score was: 5.0   and mem length: 328438   eps: 0.5476907800098192    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1640   the run_score was: 4.0   and mem length: 328715   eps: 0.5471423200098311    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1641   the run_score was: 3.0   and mem length: 328945   eps: 0.546686920009841    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1642   the run_score was: 4.0   and mem length: 329204   eps: 0.5461741000098521    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1643   the run_score was: 2.0   and mem length: 329405   eps: 0.5457761200098608    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1644   the run_score was: 4.0   and mem length: 329665   eps: 0.5452613200098719    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1645   the run_score was: 3.0   and mem length: 329916   eps: 0.5447643400098827    steps: 251    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1646   the run_score was: 4.0   and mem length: 330208   eps: 0.5441861800098953    steps: 292    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1647   the run_score was: 3.0   and mem length: 330456   eps: 0.5436951400099059    steps: 248    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1648   the run_score was: 2.0   and mem length: 330657   eps: 0.5432971600099146    steps: 201    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1649   the run_score was: 5.0   and mem length: 330967   eps: 0.5426833600099279    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1650   the run_score was: 1.0   and mem length: 331119   eps: 0.5423824000099344    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1651   the run_score was: 6.0   and mem length: 331491   eps: 0.5416458400099504    steps: 372    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1652   the run_score was: 3.0   and mem length: 331718   eps: 0.5411963800099602    steps: 227    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1653   the run_score was: 4.0   and mem length: 332014   eps: 0.5406103000099729    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1654   the run_score was: 7.0   and mem length: 332435   eps: 0.539776720009991    steps: 421    lr: 1.6000000000000003e-05     eval rl_reward: 3.83\n","For episode: 1655   the run_score was: 3.0   and mem length: 332649   eps: 0.5393530000100002    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1656   the run_score was: 3.0   and mem length: 332879   eps: 0.5388976000100101    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1657   the run_score was: 5.0   and mem length: 333187   eps: 0.5382877600100233    steps: 308    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1658   the run_score was: 4.0   and mem length: 333430   eps: 0.5378066200100338    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 3.87\n","For episode: 1659   the run_score was: 6.0   and mem length: 333808   eps: 0.53705818001005    steps: 378    lr: 1.6000000000000003e-05     eval rl_reward: 3.9\n","For episode: 1660   the run_score was: 2.0   and mem length: 334006   eps: 0.5366661400100585    steps: 198    lr: 1.6000000000000003e-05     eval rl_reward: 3.88\n","For episode: 1661   the run_score was: 3.0   and mem length: 334237   eps: 0.5362087600100685    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 3.85\n","For episode: 1662   the run_score was: 4.0   and mem length: 334514   eps: 0.5356603000100804    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1663   the run_score was: 3.0   and mem length: 334743   eps: 0.5352068800100902    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1664   the run_score was: 5.0   and mem length: 335015   eps: 0.5346683200101019    steps: 272    lr: 1.6000000000000003e-05     eval rl_reward: 3.85\n","For episode: 1665   the run_score was: 2.0   and mem length: 335234   eps: 0.5342347000101113    steps: 219    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1666   the run_score was: 4.0   and mem length: 335477   eps: 0.5337535600101218    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 3.85\n","For episode: 1667   the run_score was: 2.0   and mem length: 335659   eps: 0.5333932000101296    steps: 182    lr: 1.6000000000000003e-05     eval rl_reward: 3.84\n","For episode: 1668   the run_score was: 1.0   and mem length: 335811   eps: 0.5330922400101361    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1669   the run_score was: 1.0   and mem length: 335963   eps: 0.5327912800101426    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1670   the run_score was: 3.0   and mem length: 336191   eps: 0.5323398400101524    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 3.72\n","For episode: 1671   the run_score was: 1.0   and mem length: 336342   eps: 0.5320408600101589    steps: 151    lr: 1.6000000000000003e-05     eval rl_reward: 3.7\n","For episode: 1672   the run_score was: 7.0   and mem length: 336742   eps: 0.5312488600101761    steps: 400    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1673   the run_score was: 5.0   and mem length: 337052   eps: 0.5306350600101895    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1674   the run_score was: 3.0   and mem length: 337266   eps: 0.5302113400101987    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1675   the run_score was: 4.0   and mem length: 337587   eps: 0.5295757600102124    steps: 321    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1676   the run_score was: 5.0   and mem length: 337894   eps: 0.5289679000102256    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1677   the run_score was: 4.0   and mem length: 338172   eps: 0.5284174600102376    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1678   the run_score was: 3.0   and mem length: 338400   eps: 0.5279660200102474    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1679   the run_score was: 1.0   and mem length: 338552   eps: 0.5276650600102539    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1680   the run_score was: 4.0   and mem length: 338812   eps: 0.5271502600102651    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1681   the run_score was: 4.0   and mem length: 339072   eps: 0.5266354600102763    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1682   the run_score was: 4.0   and mem length: 339315   eps: 0.5261543200102867    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1683   the run_score was: 3.0   and mem length: 339545   eps: 0.5256989200102966    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1684   the run_score was: 3.0   and mem length: 339775   eps: 0.5252435200103065    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1685   the run_score was: 2.0   and mem length: 339955   eps: 0.5248871200103142    steps: 180    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1686   the run_score was: 4.0   and mem length: 340233   eps: 0.5243366800103262    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1687   the run_score was: 4.0   and mem length: 340509   eps: 0.523790200010338    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1688   the run_score was: 2.0   and mem length: 340709   eps: 0.5233942000103466    steps: 200    lr: 1.6000000000000003e-05     eval rl_reward: 3.77\n","For episode: 1689   the run_score was: 7.0   and mem length: 341057   eps: 0.5227051600103616    steps: 348    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1690   the run_score was: 1.0   and mem length: 341227   eps: 0.5223685600103689    steps: 170    lr: 1.6000000000000003e-05     eval rl_reward: 3.78\n","For episode: 1691   the run_score was: 3.0   and mem length: 341456   eps: 0.5219151400103788    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1692   the run_score was: 5.0   and mem length: 341763   eps: 0.521307280010392    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 3.77\n","For episode: 1693   the run_score was: 4.0   and mem length: 342059   eps: 0.5207212000104047    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1694   the run_score was: 3.0   and mem length: 342288   eps: 0.5202677800104145    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.77\n","For episode: 1695   the run_score was: 8.0   and mem length: 342727   eps: 0.5193985600104334    steps: 439    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1696   the run_score was: 9.0   and mem length: 343122   eps: 0.5186164600104504    steps: 395    lr: 1.6000000000000003e-05     eval rl_reward: 3.87\n","For episode: 1697   the run_score was: 1.0   and mem length: 343274   eps: 0.5183155000104569    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.85\n","For episode: 1698   the run_score was: 5.0   and mem length: 343603   eps: 0.517664080010471    steps: 329    lr: 1.6000000000000003e-05     eval rl_reward: 3.86\n","For episode: 1699   the run_score was: 1.0   and mem length: 343775   eps: 0.5173235200104784    steps: 172    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1700   the run_score was: 1.0   and mem length: 343927   eps: 0.517022560010485    steps: 152    lr: 1.6000000000000003e-05     eval rl_reward: 3.78\n","For episode: 1701   the run_score was: 7.0   and mem length: 344283   eps: 0.5163176800105003    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1702   the run_score was: 3.0   and mem length: 344496   eps: 0.5158959400105094    steps: 213    lr: 1.6000000000000003e-05     eval rl_reward: 3.78\n","For episode: 1703   the run_score was: 4.0   and mem length: 344737   eps: 0.5154187600105198    steps: 241    lr: 1.6000000000000003e-05     eval rl_reward: 3.78\n","For episode: 1704   the run_score was: 3.0   and mem length: 344966   eps: 0.5149653400105296    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1705   the run_score was: 7.0   and mem length: 345368   eps: 0.5141693800105469    steps: 402    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1706   the run_score was: 5.0   and mem length: 345690   eps: 0.5135318200105607    steps: 322    lr: 1.6000000000000003e-05     eval rl_reward: 3.78\n","For episode: 1707   the run_score was: 4.0   and mem length: 345971   eps: 0.5129754400105728    steps: 281    lr: 1.6000000000000003e-05     eval rl_reward: 3.79\n","For episode: 1708   the run_score was: 5.0   and mem length: 346281   eps: 0.5123616400105862    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1709   the run_score was: 4.0   and mem length: 346560   eps: 0.5118092200105981    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1710   the run_score was: 3.0   and mem length: 346774   eps: 0.5113855000106073    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.7\n","For episode: 1711   the run_score was: 3.0   and mem length: 346988   eps: 0.5109617800106165    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.68\n","For episode: 1712   the run_score was: 5.0   and mem length: 347297   eps: 0.5103499600106298    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 3.7\n","For episode: 1713   the run_score was: 5.0   and mem length: 347614   eps: 0.5097223000106434    steps: 317    lr: 1.6000000000000003e-05     eval rl_reward: 3.71\n","For episode: 1714   the run_score was: 4.0   and mem length: 347891   eps: 0.5091738400106554    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.68\n","For episode: 1715   the run_score was: 6.0   and mem length: 348251   eps: 0.5084610400106708    steps: 360    lr: 1.6000000000000003e-05     eval rl_reward: 3.7\n","For episode: 1716   the run_score was: 6.0   and mem length: 348605   eps: 0.507760120010686    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1717   the run_score was: 4.0   and mem length: 348866   eps: 0.5072433400106973    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 3.76\n","For episode: 1718   the run_score was: 3.0   and mem length: 349078   eps: 0.5068235800107064    steps: 212    lr: 1.6000000000000003e-05     eval rl_reward: 3.75\n","For episode: 1719   the run_score was: 7.0   and mem length: 349504   eps: 0.5059801000107247    steps: 426    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1720   the run_score was: 4.0   and mem length: 349785   eps: 0.5054237200107368    steps: 281    lr: 1.6000000000000003e-05     eval rl_reward: 3.81\n","For episode: 1721   the run_score was: 3.0   and mem length: 349999   eps: 0.505000000010746    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1722   the run_score was: 4.0   and mem length: 350259   eps: 0.5044852000107571    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1723   the run_score was: 3.0   and mem length: 350490   eps: 0.5040278200107671    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 3.8\n","For episode: 1724   the run_score was: 4.0   and mem length: 350751   eps: 0.5035110400107783    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1725   the run_score was: 6.0   and mem length: 351113   eps: 0.5027942800107938    steps: 362    lr: 1.6000000000000003e-05     eval rl_reward: 3.82\n","For episode: 1726   the run_score was: 6.0   and mem length: 351507   eps: 0.5020141600108108    steps: 394    lr: 1.6000000000000003e-05     eval rl_reward: 3.86\n","For episode: 1727   the run_score was: 3.0   and mem length: 351736   eps: 0.5015607400108206    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.86\n","For episode: 1728   the run_score was: 5.0   and mem length: 352025   eps: 0.500988520010833    steps: 289    lr: 1.6000000000000003e-05     eval rl_reward: 3.87\n","For episode: 1729   the run_score was: 3.0   and mem length: 352255   eps: 0.5005331200108429    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.85\n","For episode: 1730   the run_score was: 7.0   and mem length: 352687   eps: 0.49967776001085246    steps: 432    lr: 1.6000000000000003e-05     eval rl_reward: 3.9\n","For episode: 1731   the run_score was: 4.0   and mem length: 352954   eps: 0.4991491000108491    steps: 267    lr: 1.6000000000000003e-05     eval rl_reward: 3.91\n","For episode: 1732   the run_score was: 4.0   and mem length: 353211   eps: 0.4986402400108459    steps: 257    lr: 1.6000000000000003e-05     eval rl_reward: 3.91\n","For episode: 1733   the run_score was: 6.0   and mem length: 353567   eps: 0.49793536001084143    steps: 356    lr: 1.6000000000000003e-05     eval rl_reward: 3.93\n","For episode: 1734   the run_score was: 4.0   and mem length: 353861   eps: 0.49735324001083775    steps: 294    lr: 1.6000000000000003e-05     eval rl_reward: 3.91\n","For episode: 1735   the run_score was: 4.0   and mem length: 354122   eps: 0.4968364600108345    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 3.89\n","For episode: 1736   the run_score was: 2.0   and mem length: 354322   eps: 0.496440460010832    steps: 200    lr: 1.6000000000000003e-05     eval rl_reward: 3.89\n","For episode: 1737   the run_score was: 4.0   and mem length: 354598   eps: 0.4958939800108285    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.9\n","For episode: 1738   the run_score was: 4.0   and mem length: 354841   eps: 0.4954128400108255    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 3.9\n","For episode: 1739   the run_score was: 4.0   and mem length: 355099   eps: 0.49490200001082224    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 3.89\n","For episode: 1740   the run_score was: 2.0   and mem length: 355318   eps: 0.4944683800108195    steps: 219    lr: 1.6000000000000003e-05     eval rl_reward: 3.87\n","For episode: 1741   the run_score was: 4.0   and mem length: 355595   eps: 0.493919920010816    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 3.88\n","For episode: 1742   the run_score was: 6.0   and mem length: 355937   eps: 0.49324276001081174    steps: 342    lr: 1.6000000000000003e-05     eval rl_reward: 3.9\n","For episode: 1743   the run_score was: 5.0   and mem length: 356260   eps: 0.4926032200108077    steps: 323    lr: 1.6000000000000003e-05     eval rl_reward: 3.93\n","For episode: 1744   the run_score was: 4.0   and mem length: 356502   eps: 0.49212406001080466    steps: 242    lr: 1.6000000000000003e-05     eval rl_reward: 3.93\n","For episode: 1745   the run_score was: 3.0   and mem length: 356731   eps: 0.4916706400108018    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.93\n","For episode: 1746   the run_score was: 3.0   and mem length: 356961   eps: 0.4912152400107989    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 3.92\n","For episode: 1747   the run_score was: 4.0   and mem length: 357240   eps: 0.4906628200107954    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 3.93\n","For episode: 1748   the run_score was: 5.0   and mem length: 357533   eps: 0.49008268001079175    steps: 293    lr: 1.6000000000000003e-05     eval rl_reward: 3.96\n","For episode: 1749   the run_score was: 3.0   and mem length: 357747   eps: 0.48965896001078907    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1750   the run_score was: 4.0   and mem length: 358043   eps: 0.48907288001078536    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 3.97\n","For episode: 1751   the run_score was: 3.0   and mem length: 358257   eps: 0.4886491600107827    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1752   the run_score was: 6.0   and mem length: 358618   eps: 0.48793438001077816    steps: 361    lr: 1.6000000000000003e-05     eval rl_reward: 3.97\n","For episode: 1753   the run_score was: 3.0   and mem length: 358865   eps: 0.48744532001077506    steps: 247    lr: 1.6000000000000003e-05     eval rl_reward: 3.96\n","For episode: 1754   the run_score was: 5.0   and mem length: 359154   eps: 0.48687310001077144    steps: 289    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1755   the run_score was: 3.0   and mem length: 359383   eps: 0.4864196800107686    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1756   the run_score was: 5.0   and mem length: 359679   eps: 0.48583360001076487    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 3.96\n","For episode: 1757   the run_score was: 3.0   and mem length: 359893   eps: 0.4854098800107622    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1758   the run_score was: 4.0   and mem length: 360153   eps: 0.4848950800107589    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1759   the run_score was: 4.0   and mem length: 360396   eps: 0.4844139400107559    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 3.92\n","For episode: 1760   the run_score was: 4.0   and mem length: 360656   eps: 0.4838991400107526    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 3.94\n","For episode: 1761   the run_score was: 6.0   and mem length: 361007   eps: 0.48320416001074823    steps: 351    lr: 1.6000000000000003e-05     eval rl_reward: 3.97\n","For episode: 1762   the run_score was: 5.0   and mem length: 361333   eps: 0.48255868001074415    steps: 326    lr: 1.6000000000000003e-05     eval rl_reward: 3.98\n","For episode: 1763   the run_score was: 4.0   and mem length: 361612   eps: 0.48200626001074065    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 3.99\n","For episode: 1764   the run_score was: 4.0   and mem length: 361888   eps: 0.4814597800107372    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 3.98\n","For episode: 1765   the run_score was: 4.0   and mem length: 362149   eps: 0.4809430000107339    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 4.0\n","For episode: 1766   the run_score was: 7.0   and mem length: 362523   eps: 0.48020248001072924    steps: 374    lr: 1.6000000000000003e-05     eval rl_reward: 4.03\n","For episode: 1767   the run_score was: 5.0   and mem length: 362832   eps: 0.47959066001072537    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 4.06\n","For episode: 1768   the run_score was: 3.0   and mem length: 363061   eps: 0.4791372400107225    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.08\n","For episode: 1769   the run_score was: 4.0   and mem length: 363338   eps: 0.47858878001071903    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 4.11\n","For episode: 1770   the run_score was: 3.0   and mem length: 363569   eps: 0.47813140001071613    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.11\n","For episode: 1771   the run_score was: 6.0   and mem length: 363905   eps: 0.4774661200107119    steps: 336    lr: 1.6000000000000003e-05     eval rl_reward: 4.16\n","For episode: 1772   the run_score was: 4.0   and mem length: 364144   eps: 0.47699290001070893    steps: 239    lr: 1.6000000000000003e-05     eval rl_reward: 4.13\n","For episode: 1773   the run_score was: 5.0   and mem length: 364471   eps: 0.47634544001070483    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 4.13\n","For episode: 1774   the run_score was: 7.0   and mem length: 364878   eps: 0.47553958001069974    steps: 407    lr: 1.6000000000000003e-05     eval rl_reward: 4.17\n","For episode: 1775   the run_score was: 5.0   and mem length: 365204   eps: 0.47489410001069565    steps: 326    lr: 1.6000000000000003e-05     eval rl_reward: 4.18\n","For episode: 1776   the run_score was: 6.0   and mem length: 365558   eps: 0.4741931800106912    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 4.19\n","For episode: 1777   the run_score was: 6.0   and mem length: 365934   eps: 0.4734487000106865    steps: 376    lr: 1.6000000000000003e-05     eval rl_reward: 4.21\n","For episode: 1778   the run_score was: 3.0   and mem length: 366146   eps: 0.47302894001068385    steps: 212    lr: 1.6000000000000003e-05     eval rl_reward: 4.21\n","For episode: 1779   the run_score was: 5.0   and mem length: 366455   eps: 0.47241712001068    steps: 309    lr: 1.6000000000000003e-05     eval rl_reward: 4.25\n","For episode: 1780   the run_score was: 4.0   and mem length: 366715   eps: 0.4719023200106767    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.25\n","For episode: 1781   the run_score was: 4.0   and mem length: 366993   eps: 0.47135188001067324    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 4.25\n","For episode: 1782   the run_score was: 5.0   and mem length: 367303   eps: 0.47073808001066936    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 4.26\n","For episode: 1783   the run_score was: 5.0   and mem length: 367591   eps: 0.47016784001066575    steps: 288    lr: 1.6000000000000003e-05     eval rl_reward: 4.28\n","For episode: 1784   the run_score was: 8.0   and mem length: 368070   eps: 0.46921942001065975    steps: 479    lr: 1.6000000000000003e-05     eval rl_reward: 4.33\n","For episode: 1785   the run_score was: 4.0   and mem length: 368342   eps: 0.46868086001065634    steps: 272    lr: 1.6000000000000003e-05     eval rl_reward: 4.35\n","For episode: 1786   the run_score was: 5.0   and mem length: 368632   eps: 0.4681066600106527    steps: 290    lr: 1.6000000000000003e-05     eval rl_reward: 4.36\n","For episode: 1787   the run_score was: 6.0   and mem length: 369004   eps: 0.46737010001064805    steps: 372    lr: 1.6000000000000003e-05     eval rl_reward: 4.38\n","For episode: 1788   the run_score was: 3.0   and mem length: 369233   eps: 0.4669166800106452    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.39\n","For episode: 1789   the run_score was: 5.0   and mem length: 369526   eps: 0.4663365400106415    steps: 293    lr: 1.6000000000000003e-05     eval rl_reward: 4.37\n","For episode: 1790   the run_score was: 4.0   and mem length: 369769   eps: 0.46585540001063847    steps: 243    lr: 1.6000000000000003e-05     eval rl_reward: 4.4\n","For episode: 1791   the run_score was: 3.0   and mem length: 370020   eps: 0.4653584200106353    steps: 251    lr: 1.6000000000000003e-05     eval rl_reward: 4.4\n","For episode: 1792   the run_score was: 3.0   and mem length: 370248   eps: 0.46490698001063246    steps: 228    lr: 1.6000000000000003e-05     eval rl_reward: 4.38\n","For episode: 1793   the run_score was: 4.0   and mem length: 370507   eps: 0.4643941600106292    steps: 259    lr: 1.6000000000000003e-05     eval rl_reward: 4.38\n","For episode: 1794   the run_score was: 7.0   and mem length: 370897   eps: 0.46362196001062433    steps: 390    lr: 1.6000000000000003e-05     eval rl_reward: 4.42\n","For episode: 1795   the run_score was: 10.0   and mem length: 371382   eps: 0.46266166001061826    steps: 485    lr: 1.6000000000000003e-05     eval rl_reward: 4.44\n","For episode: 1796   the run_score was: 5.0   and mem length: 371689   eps: 0.4620538000106144    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.4\n","For episode: 1797   the run_score was: 5.0   and mem length: 372033   eps: 0.4613726800106101    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 4.44\n","For episode: 1798   the run_score was: 4.0   and mem length: 372291   eps: 0.46086184001060687    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 4.43\n","For episode: 1799   the run_score was: 4.0   and mem length: 372531   eps: 0.46038664001060386    steps: 240    lr: 1.6000000000000003e-05     eval rl_reward: 4.46\n","For episode: 1800   the run_score was: 2.0   and mem length: 372714   eps: 0.4600243000106016    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 4.47\n","For episode: 1801   the run_score was: 5.0   and mem length: 373042   eps: 0.45937486001059746    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 4.45\n","For episode: 1802   the run_score was: 4.0   and mem length: 373318   eps: 0.458828380010594    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.46\n","For episode: 1803   the run_score was: 6.0   and mem length: 373677   eps: 0.4581175600105895    steps: 359    lr: 1.6000000000000003e-05     eval rl_reward: 4.48\n","For episode: 1804   the run_score was: 4.0   and mem length: 373938   eps: 0.45760078001058624    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 4.49\n","For episode: 1805   the run_score was: 5.0   and mem length: 374282   eps: 0.45691966001058193    steps: 344    lr: 1.6000000000000003e-05     eval rl_reward: 4.47\n","For episode: 1806   the run_score was: 4.0   and mem length: 374558   eps: 0.45637318001057847    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.46\n","For episode: 1807   the run_score was: 3.0   and mem length: 374789   eps: 0.4559158000105756    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.45\n","For episode: 1808   the run_score was: 3.0   and mem length: 375021   eps: 0.45545644001057267    steps: 232    lr: 1.6000000000000003e-05     eval rl_reward: 4.43\n","For episode: 1809   the run_score was: 6.0   and mem length: 375364   eps: 0.4547773000105684    steps: 343    lr: 1.6000000000000003e-05     eval rl_reward: 4.45\n","For episode: 1810   the run_score was: 5.0   and mem length: 375670   eps: 0.45417142001056454    steps: 306    lr: 1.6000000000000003e-05     eval rl_reward: 4.47\n","For episode: 1811   the run_score was: 4.0   and mem length: 375930   eps: 0.4536566200105613    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.48\n","For episode: 1812   the run_score was: 4.0   and mem length: 376191   eps: 0.453139840010558    steps: 261    lr: 1.6000000000000003e-05     eval rl_reward: 4.47\n","For episode: 1813   the run_score was: 15.0   and mem length: 376717   eps: 0.4520983600105514    steps: 526    lr: 1.6000000000000003e-05     eval rl_reward: 4.57\n","For episode: 1814   the run_score was: 5.0   and mem length: 377013   eps: 0.4515122800105477    steps: 296    lr: 1.6000000000000003e-05     eval rl_reward: 4.58\n","For episode: 1815   the run_score was: 2.0   and mem length: 377194   eps: 0.45115390001054545    steps: 181    lr: 1.6000000000000003e-05     eval rl_reward: 4.54\n","For episode: 1816   the run_score was: 3.0   and mem length: 377462   eps: 0.4506232600105421    steps: 268    lr: 1.6000000000000003e-05     eval rl_reward: 4.51\n","For episode: 1817   the run_score was: 5.0   and mem length: 377811   eps: 0.4499322400105377    steps: 349    lr: 1.6000000000000003e-05     eval rl_reward: 4.52\n","For episode: 1818   the run_score was: 5.0   and mem length: 378156   eps: 0.4492491400105334    steps: 345    lr: 1.6000000000000003e-05     eval rl_reward: 4.54\n","For episode: 1819   the run_score was: 3.0   and mem length: 378385   eps: 0.44879572001053053    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.5\n","For episode: 1820   the run_score was: 6.0   and mem length: 378737   eps: 0.4480987600105261    steps: 352    lr: 1.6000000000000003e-05     eval rl_reward: 4.52\n","For episode: 1821   the run_score was: 9.0   and mem length: 379064   eps: 0.447451300010522    steps: 327    lr: 1.6000000000000003e-05     eval rl_reward: 4.58\n","For episode: 1822   the run_score was: 8.0   and mem length: 379359   eps: 0.44686720001051833    steps: 295    lr: 1.6000000000000003e-05     eval rl_reward: 4.62\n","For episode: 1823   the run_score was: 5.0   and mem length: 379663   eps: 0.4462652800105145    steps: 304    lr: 1.6000000000000003e-05     eval rl_reward: 4.64\n","For episode: 1824   the run_score was: 4.0   and mem length: 379930   eps: 0.4457366200105112    steps: 267    lr: 1.6000000000000003e-05     eval rl_reward: 4.64\n","For episode: 1825   the run_score was: 7.0   and mem length: 380360   eps: 0.4448852200105058    steps: 430    lr: 1.6000000000000003e-05     eval rl_reward: 4.65\n","For episode: 1826   the run_score was: 4.0   and mem length: 380620   eps: 0.44437042001050253    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.63\n","For episode: 1827   the run_score was: 4.0   and mem length: 380896   eps: 0.4438239400104991    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.64\n","For episode: 1828   the run_score was: 7.0   and mem length: 381301   eps: 0.443022040010494    steps: 405    lr: 1.6000000000000003e-05     eval rl_reward: 4.66\n","For episode: 1829   the run_score was: 3.0   and mem length: 381515   eps: 0.4425983200104913    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 4.66\n","For episode: 1830   the run_score was: 5.0   and mem length: 381828   eps: 0.4419785800104874    steps: 313    lr: 1.6000000000000003e-05     eval rl_reward: 4.64\n","For episode: 1831   the run_score was: 8.0   and mem length: 382223   eps: 0.44119648001048245    steps: 395    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1832   the run_score was: 4.0   and mem length: 382499   eps: 0.440650000010479    steps: 276    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1833   the run_score was: 4.0   and mem length: 382759   eps: 0.44013520001047574    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.66\n","For episode: 1834   the run_score was: 6.0   and mem length: 383125   eps: 0.43941052001047115    steps: 366    lr: 1.6000000000000003e-05     eval rl_reward: 4.68\n","For episode: 1835   the run_score was: 6.0   and mem length: 383479   eps: 0.4387096000104667    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 4.7\n","For episode: 1836   the run_score was: 3.0   and mem length: 383693   eps: 0.43828588001046404    steps: 214    lr: 1.6000000000000003e-05     eval rl_reward: 4.71\n","For episode: 1837   the run_score was: 5.0   and mem length: 384021   eps: 0.4376364400104599    steps: 328    lr: 1.6000000000000003e-05     eval rl_reward: 4.72\n","For episode: 1838   the run_score was: 5.0   and mem length: 384328   eps: 0.4370285800104561    steps: 307    lr: 1.6000000000000003e-05     eval rl_reward: 4.73\n","For episode: 1839   the run_score was: 3.0   and mem length: 384558   eps: 0.4365731800104532    steps: 230    lr: 1.6000000000000003e-05     eval rl_reward: 4.72\n","For episode: 1840   the run_score was: 3.0   and mem length: 384787   eps: 0.43611976001045033    steps: 229    lr: 1.6000000000000003e-05     eval rl_reward: 4.73\n","For episode: 1841   the run_score was: 6.0   and mem length: 385144   eps: 0.43541290001044586    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 4.75\n","For episode: 1842   the run_score was: 6.0   and mem length: 385507   eps: 0.4346941600104413    steps: 363    lr: 1.6000000000000003e-05     eval rl_reward: 4.75\n","For episode: 1843   the run_score was: 2.0   and mem length: 385690   eps: 0.434331820010439    steps: 183    lr: 1.6000000000000003e-05     eval rl_reward: 4.72\n","For episode: 1844   the run_score was: 3.0   and mem length: 385921   eps: 0.4338744400104361    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.71\n","For episode: 1845   the run_score was: 8.0   and mem length: 386388   eps: 0.4329497800104303    steps: 467    lr: 1.6000000000000003e-05     eval rl_reward: 4.76\n","For episode: 1846   the run_score was: 6.0   and mem length: 386768   eps: 0.4321973800104255    steps: 380    lr: 1.6000000000000003e-05     eval rl_reward: 4.79\n","For episode: 1847   the run_score was: 2.0   and mem length: 386950   eps: 0.43183702001042323    steps: 182    lr: 1.6000000000000003e-05     eval rl_reward: 4.77\n","For episode: 1848   the run_score was: 6.0   and mem length: 387303   eps: 0.4311380800104188    steps: 353    lr: 1.6000000000000003e-05     eval rl_reward: 4.78\n","For episode: 1849   the run_score was: 4.0   and mem length: 387583   eps: 0.4305836800104153    steps: 280    lr: 1.6000000000000003e-05     eval rl_reward: 4.79\n","For episode: 1850   the run_score was: 3.0   and mem length: 387814   eps: 0.4301263000104124    steps: 231    lr: 1.6000000000000003e-05     eval rl_reward: 4.78\n","For episode: 1851   the run_score was: 6.0   and mem length: 388187   eps: 0.42938776001040774    steps: 373    lr: 1.6000000000000003e-05     eval rl_reward: 4.81\n","For episode: 1852   the run_score was: 6.0   and mem length: 388544   eps: 0.42868090001040327    steps: 357    lr: 1.6000000000000003e-05     eval rl_reward: 4.81\n","For episode: 1853   the run_score was: 5.0   and mem length: 388831   eps: 0.42811264001039967    steps: 287    lr: 1.6000000000000003e-05     eval rl_reward: 4.83\n","For episode: 1854   the run_score was: 4.0   and mem length: 389091   eps: 0.4275978400103964    steps: 260    lr: 1.6000000000000003e-05     eval rl_reward: 4.82\n","For episode: 1855   the run_score was: 10.0   and mem length: 389619   eps: 0.4265524000103898    steps: 528    lr: 1.6000000000000003e-05     eval rl_reward: 4.89\n","For episode: 1856   the run_score was: 6.0   and mem length: 389974   eps: 0.42584950001038535    steps: 355    lr: 1.6000000000000003e-05     eval rl_reward: 4.9\n","For episode: 1857   the run_score was: 5.0   and mem length: 390296   eps: 0.4252119400103813    steps: 322    lr: 1.6000000000000003e-05     eval rl_reward: 4.92\n","For episode: 1858   the run_score was: 5.0   and mem length: 390589   eps: 0.42463180001037765    steps: 293    lr: 1.6000000000000003e-05     eval rl_reward: 4.93\n","For episode: 1859   the run_score was: 6.0   and mem length: 390928   eps: 0.4239605800103734    steps: 339    lr: 1.6000000000000003e-05     eval rl_reward: 4.95\n","For episode: 1860   the run_score was: 5.0   and mem length: 391252   eps: 0.42331906001036934    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 4.96\n","For episode: 1861   the run_score was: 4.0   and mem length: 391529   eps: 0.42277060001036587    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 4.94\n","For episode: 1862   the run_score was: 4.0   and mem length: 391787   eps: 0.42225976001036264    steps: 258    lr: 1.6000000000000003e-05     eval rl_reward: 4.93\n","For episode: 1863   the run_score was: 6.0   and mem length: 392126   eps: 0.4215885400103584    steps: 339    lr: 1.6000000000000003e-05     eval rl_reward: 4.95\n","For episode: 1864   the run_score was: 5.0   and mem length: 392450   eps: 0.42094702001035433    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 4.96\n","For episode: 1865   the run_score was: 7.0   and mem length: 392813   eps: 0.4202282800103498    steps: 363    lr: 1.6000000000000003e-05     eval rl_reward: 4.99\n","For episode: 1866   the run_score was: 6.0   and mem length: 393171   eps: 0.4195194400103453    steps: 358    lr: 1.6000000000000003e-05     eval rl_reward: 4.98\n","For episode: 1867   the run_score was: 4.0   and mem length: 393466   eps: 0.4189353400103416    steps: 295    lr: 1.6000000000000003e-05     eval rl_reward: 4.97\n","For episode: 1868   the run_score was: 5.0   and mem length: 393776   eps: 0.4183215400103377    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 4.99\n","For episode: 1869   the run_score was: 4.0   and mem length: 394053   eps: 0.41777308001033425    steps: 277    lr: 1.6000000000000003e-05     eval rl_reward: 4.99\n","For episode: 1870   the run_score was: 4.0   and mem length: 394331   eps: 0.41722264001033077    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 5.0\n","For episode: 1871   the run_score was: 6.0   and mem length: 394685   eps: 0.41652172001032634    steps: 354    lr: 1.6000000000000003e-05     eval rl_reward: 5.0\n","For episode: 1872   the run_score was: 5.0   and mem length: 394995   eps: 0.41590792001032245    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 5.01\n","For episode: 1873   the run_score was: 7.0   and mem length: 395392   eps: 0.4151218600103175    steps: 397    lr: 1.6000000000000003e-05     eval rl_reward: 5.03\n","For episode: 1874   the run_score was: 3.0   and mem length: 395603   eps: 0.41470408001031484    steps: 211    lr: 1.6000000000000003e-05     eval rl_reward: 4.99\n","For episode: 1875   the run_score was: 4.0   and mem length: 395881   eps: 0.41415364001031135    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 4.98\n","For episode: 1876   the run_score was: 11.0   and mem length: 396324   eps: 0.4132765000103058    steps: 443    lr: 1.6000000000000003e-05     eval rl_reward: 5.03\n","For episode: 1877   the run_score was: 7.0   and mem length: 396733   eps: 0.4124666800103007    steps: 409    lr: 1.6000000000000003e-05     eval rl_reward: 5.04\n","For episode: 1878   the run_score was: 5.0   and mem length: 397057   eps: 0.4118251600102966    steps: 324    lr: 1.6000000000000003e-05     eval rl_reward: 5.06\n","For episode: 1879   the run_score was: 7.0   and mem length: 397480   eps: 0.4109876200102913    steps: 423    lr: 1.6000000000000003e-05     eval rl_reward: 5.08\n","For episode: 1880   the run_score was: 4.0   and mem length: 397758   eps: 0.41043718001028784    steps: 278    lr: 1.6000000000000003e-05     eval rl_reward: 5.08\n","For episode: 1881   the run_score was: 4.0   and mem length: 398038   eps: 0.40988278001028433    steps: 280    lr: 1.6000000000000003e-05     eval rl_reward: 5.08\n","For episode: 1882   the run_score was: 7.0   and mem length: 398422   eps: 0.4091224600102795    steps: 384    lr: 1.6000000000000003e-05     eval rl_reward: 5.1\n","For episode: 1883   the run_score was: 6.0   and mem length: 398765   eps: 0.4084433200102752    steps: 343    lr: 1.6000000000000003e-05     eval rl_reward: 5.11\n","For episode: 1884   the run_score was: 4.0   and mem length: 399064   eps: 0.4078513000102715    steps: 299    lr: 1.6000000000000003e-05     eval rl_reward: 5.07\n","For episode: 1885   the run_score was: 5.0   and mem length: 399374   eps: 0.4072375000102676    steps: 310    lr: 1.6000000000000003e-05     eval rl_reward: 5.08\n","For episode: 1886   the run_score was: 4.0   and mem length: 399671   eps: 0.4066494400102639    steps: 297    lr: 1.6000000000000003e-05     eval rl_reward: 5.07\n","For episode: 1887   the run_score was: 4.0   and mem length: 399950   eps: 0.4060970200102604    steps: 279    lr: 1.6000000000000003e-05     eval rl_reward: 5.05\n","For episode: 1888   the run_score was: 3.0   and mem length: 400181   eps: 0.4056396400102575    steps: 231    lr: 6.400000000000001e-06     eval rl_reward: 5.05\n","For episode: 1889   the run_score was: 5.0   and mem length: 400488   eps: 0.40503178001025364    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.05\n","For episode: 1890   the run_score was: 5.0   and mem length: 400784   eps: 0.40444570001024993    steps: 296    lr: 6.400000000000001e-06     eval rl_reward: 5.06\n","For episode: 1891   the run_score was: 4.0   and mem length: 401043   eps: 0.4039328800102467    steps: 259    lr: 6.400000000000001e-06     eval rl_reward: 5.07\n","For episode: 1892   the run_score was: 9.0   and mem length: 401407   eps: 0.4032121600102421    steps: 364    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1893   the run_score was: 4.0   and mem length: 401650   eps: 0.4027310200102391    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1894   the run_score was: 9.0   and mem length: 402010   eps: 0.4020182200102346    steps: 360    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1895   the run_score was: 4.0   and mem length: 402271   eps: 0.4015014400102313    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.09\n","For episode: 1896   the run_score was: 5.0   and mem length: 402578   eps: 0.40089358001022746    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.09\n","For episode: 1897   the run_score was: 5.0   and mem length: 402885   eps: 0.4002857200102236    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.09\n","For episode: 1898   the run_score was: 3.0   and mem length: 403114   eps: 0.39983230001022074    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.08\n","For episode: 1899   the run_score was: 4.0   and mem length: 403375   eps: 0.3993155200102175    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.08\n","For episode: 1900   the run_score was: 4.0   and mem length: 403652   eps: 0.398767060010214    steps: 277    lr: 6.400000000000001e-06     eval rl_reward: 5.1\n","For episode: 1901   the run_score was: 8.0   and mem length: 404086   eps: 0.39790774001020857    steps: 434    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1902   the run_score was: 5.0   and mem length: 404414   eps: 0.39725830001020446    steps: 328    lr: 6.400000000000001e-06     eval rl_reward: 5.14\n","For episode: 1903   the run_score was: 7.0   and mem length: 404794   eps: 0.3965059000101997    steps: 380    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1904   the run_score was: 4.0   and mem length: 405074   eps: 0.3959515000101962    steps: 280    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1905   the run_score was: 6.0   and mem length: 405433   eps: 0.3952406800101917    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1906   the run_score was: 4.0   and mem length: 405724   eps: 0.39466450001018805    steps: 291    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1907   the run_score was: 6.0   and mem length: 406100   eps: 0.39392002001018334    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 5.19\n","For episode: 1908   the run_score was: 4.0   and mem length: 406361   eps: 0.39340324001018007    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.2\n","For episode: 1909   the run_score was: 4.0   and mem length: 406621   eps: 0.3928884400101768    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.18\n","For episode: 1910   the run_score was: 3.0   and mem length: 406850   eps: 0.39243502001017394    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1911   the run_score was: 3.0   and mem length: 407064   eps: 0.39201130001017126    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1912   the run_score was: 4.0   and mem length: 407323   eps: 0.391498480010168    steps: 259    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1913   the run_score was: 7.0   and mem length: 407745   eps: 0.39066292001016273    steps: 422    lr: 6.400000000000001e-06     eval rl_reward: 5.07\n","For episode: 1914   the run_score was: 11.0   and mem length: 408283   eps: 0.389597680010156    steps: 538    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1915   the run_score was: 4.0   and mem length: 408523   eps: 0.389122480010153    steps: 240    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1916   the run_score was: 4.0   and mem length: 408784   eps: 0.3886057000101497    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1917   the run_score was: 3.0   and mem length: 409031   eps: 0.3881166400101466    steps: 247    lr: 6.400000000000001e-06     eval rl_reward: 5.14\n","For episode: 1918   the run_score was: 4.0   and mem length: 409276   eps: 0.38763154001014355    steps: 245    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1919   the run_score was: 4.0   and mem length: 409554   eps: 0.38708110001014007    steps: 278    lr: 6.400000000000001e-06     eval rl_reward: 5.14\n","For episode: 1920   the run_score was: 3.0   and mem length: 409764   eps: 0.38666530001013744    steps: 210    lr: 6.400000000000001e-06     eval rl_reward: 5.11\n","For episode: 1921   the run_score was: 4.0   and mem length: 410007   eps: 0.3861841600101344    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.06\n","For episode: 1922   the run_score was: 6.0   and mem length: 410363   eps: 0.38547928001012993    steps: 356    lr: 6.400000000000001e-06     eval rl_reward: 5.04\n","For episode: 1923   the run_score was: 4.0   and mem length: 410603   eps: 0.3850040800101269    steps: 240    lr: 6.400000000000001e-06     eval rl_reward: 5.03\n","For episode: 1924   the run_score was: 9.0   and mem length: 411028   eps: 0.3841625800101216    steps: 425    lr: 6.400000000000001e-06     eval rl_reward: 5.08\n","For episode: 1925   the run_score was: 5.0   and mem length: 411334   eps: 0.38355670001011777    steps: 306    lr: 6.400000000000001e-06     eval rl_reward: 5.06\n","For episode: 1926   the run_score was: 4.0   and mem length: 411594   eps: 0.3830419000101145    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.06\n","For episode: 1927   the run_score was: 5.0   and mem length: 411902   eps: 0.38243206001011065    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.07\n","For episode: 1928   the run_score was: 12.0   and mem length: 412339   eps: 0.3815668000101052    steps: 437    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1929   the run_score was: 4.0   and mem length: 412599   eps: 0.3810520000101019    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.13\n","For episode: 1930   the run_score was: 6.0   and mem length: 412920   eps: 0.3804164200100979    steps: 321    lr: 6.400000000000001e-06     eval rl_reward: 5.14\n","For episode: 1931   the run_score was: 6.0   and mem length: 413281   eps: 0.3797016400100934    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1932   the run_score was: 4.0   and mem length: 413524   eps: 0.37922050001009033    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1933   the run_score was: 4.0   and mem length: 413785   eps: 0.37870372001008706    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1934   the run_score was: 5.0   and mem length: 414077   eps: 0.3781255600100834    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.11\n","For episode: 1935   the run_score was: 5.0   and mem length: 414403   eps: 0.3774800800100793    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 5.1\n","For episode: 1936   the run_score was: 3.0   and mem length: 414652   eps: 0.3769870600100762    steps: 249    lr: 6.400000000000001e-06     eval rl_reward: 5.1\n","For episode: 1937   the run_score was: 6.0   and mem length: 414988   eps: 0.376321780010072    steps: 336    lr: 6.400000000000001e-06     eval rl_reward: 5.11\n","For episode: 1938   the run_score was: 4.0   and mem length: 415245   eps: 0.3758129200100688    steps: 257    lr: 6.400000000000001e-06     eval rl_reward: 5.1\n","For episode: 1939   the run_score was: 5.0   and mem length: 415556   eps: 0.3751971400100649    steps: 311    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1940   the run_score was: 3.0   and mem length: 415770   eps: 0.3747734200100622    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1941   the run_score was: 9.0   and mem length: 416184   eps: 0.373953700010057    steps: 414    lr: 6.400000000000001e-06     eval rl_reward: 5.15\n","For episode: 1942   the run_score was: 3.0   and mem length: 416394   eps: 0.3735379000100544    steps: 210    lr: 6.400000000000001e-06     eval rl_reward: 5.12\n","For episode: 1943   the run_score was: 6.0   and mem length: 416737   eps: 0.3728587600100501    steps: 343    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1944   the run_score was: 6.0   and mem length: 417074   eps: 0.37219150001004586    steps: 337    lr: 6.400000000000001e-06     eval rl_reward: 5.19\n","For episode: 1945   the run_score was: 7.0   and mem length: 417482   eps: 0.37138366001004075    steps: 408    lr: 6.400000000000001e-06     eval rl_reward: 5.18\n","For episode: 1946   the run_score was: 4.0   and mem length: 417742   eps: 0.3708688600100375    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.16\n","For episode: 1947   the run_score was: 3.0   and mem length: 417972   eps: 0.3704134600100346    steps: 230    lr: 6.400000000000001e-06     eval rl_reward: 5.17\n","For episode: 1948   the run_score was: 7.0   and mem length: 418338   eps: 0.36968878001003    steps: 366    lr: 6.400000000000001e-06     eval rl_reward: 5.18\n","For episode: 1949   the run_score was: 8.0   and mem length: 418744   eps: 0.36888490001002494    steps: 406    lr: 6.400000000000001e-06     eval rl_reward: 5.22\n","For episode: 1950   the run_score was: 10.0   and mem length: 419085   eps: 0.36820972001002067    steps: 341    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1951   the run_score was: 9.0   and mem length: 419538   eps: 0.367312780010015    steps: 453    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1952   the run_score was: 4.0   and mem length: 419781   eps: 0.36683164001001195    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1953   the run_score was: 6.0   and mem length: 420118   eps: 0.36616438001000773    steps: 337    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1954   the run_score was: 4.0   and mem length: 420395   eps: 0.36561592001000426    steps: 277    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1955   the run_score was: 9.0   and mem length: 420870   eps: 0.3646754200099983    steps: 475    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1956   the run_score was: 6.0   and mem length: 421231   eps: 0.3639606400099938    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1957   the run_score was: 3.0   and mem length: 421463   eps: 0.3635012800099909    steps: 232    lr: 6.400000000000001e-06     eval rl_reward: 5.28\n","For episode: 1958   the run_score was: 6.0   and mem length: 421802   eps: 0.36283006000998663    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1959   the run_score was: 4.0   and mem length: 422079   eps: 0.36228160000998316    steps: 277    lr: 6.400000000000001e-06     eval rl_reward: 5.27\n","For episode: 1960   the run_score was: 5.0   and mem length: 422429   eps: 0.3615886000099788    steps: 350    lr: 6.400000000000001e-06     eval rl_reward: 5.27\n","For episode: 1961   the run_score was: 5.0   and mem length: 422739   eps: 0.3609748000099749    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 5.28\n","For episode: 1962   the run_score was: 7.0   and mem length: 423135   eps: 0.36019072000996993    steps: 396    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1963   the run_score was: 10.0   and mem length: 423538   eps: 0.3593927800099649    steps: 403    lr: 6.400000000000001e-06     eval rl_reward: 5.35\n","For episode: 1964   the run_score was: 3.0   and mem length: 423751   eps: 0.3589710400099622    steps: 213    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 1965   the run_score was: 4.0   and mem length: 424011   eps: 0.35845624000995896    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1966   the run_score was: 6.0   and mem length: 424388   eps: 0.35770978000995424    steps: 377    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1967   the run_score was: 4.0   and mem length: 424648   eps: 0.357194980009951    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1968   the run_score was: 6.0   and mem length: 424987   eps: 0.35652376000994673    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1969   the run_score was: 5.0   and mem length: 425292   eps: 0.3559198600099429    steps: 305    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1970   the run_score was: 4.0   and mem length: 425572   eps: 0.3553654600099394    steps: 280    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1971   the run_score was: 6.0   and mem length: 425950   eps: 0.35461702000993467    steps: 378    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1972   the run_score was: 9.0   and mem length: 426442   eps: 0.3536428600099285    steps: 492    lr: 6.400000000000001e-06     eval rl_reward: 5.36\n","For episode: 1973   the run_score was: 4.0   and mem length: 426700   eps: 0.3531320200099253    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 1974   the run_score was: 5.0   and mem length: 427026   eps: 0.3524865400099212    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 5.35\n","For episode: 1975   the run_score was: 5.0   and mem length: 427325   eps: 0.35189452000991744    steps: 299    lr: 6.400000000000001e-06     eval rl_reward: 5.36\n","For episode: 1976   the run_score was: 4.0   and mem length: 427603   eps: 0.35134408000991396    steps: 278    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1977   the run_score was: 7.0   and mem length: 427997   eps: 0.350563960009909    steps: 394    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1978   the run_score was: 3.0   and mem length: 428208   eps: 0.3501461800099064    steps: 211    lr: 6.400000000000001e-06     eval rl_reward: 5.27\n","For episode: 1979   the run_score was: 7.0   and mem length: 428614   eps: 0.3493423000099013    steps: 406    lr: 6.400000000000001e-06     eval rl_reward: 5.27\n","For episode: 1980   the run_score was: 7.0   and mem length: 429020   eps: 0.3485384200098962    steps: 406    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 1981   the run_score was: 6.0   and mem length: 429351   eps: 0.34788304000989206    steps: 331    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1982   the run_score was: 7.0   and mem length: 429753   eps: 0.34708708000988703    steps: 402    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1983   the run_score was: 5.0   and mem length: 430081   eps: 0.3464376400098829    steps: 328    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1984   the run_score was: 6.0   and mem length: 430477   eps: 0.34565356000987796    steps: 396    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 1985   the run_score was: 6.0   and mem length: 430836   eps: 0.34494274000987346    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 5.34\n","For episode: 1986   the run_score was: 4.0   and mem length: 431097   eps: 0.3444259600098702    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.34\n","For episode: 1987   the run_score was: 3.0   and mem length: 431311   eps: 0.3440022400098675    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 1988   the run_score was: 6.0   and mem length: 431685   eps: 0.3432617200098628    steps: 374    lr: 6.400000000000001e-06     eval rl_reward: 5.36\n","For episode: 1989   the run_score was: 5.0   and mem length: 431977   eps: 0.34268356000985917    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.36\n","For episode: 1990   the run_score was: 6.0   and mem length: 432315   eps: 0.34201432000985493    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 5.37\n","For episode: 1991   the run_score was: 6.0   and mem length: 432677   eps: 0.3412975600098504    steps: 362    lr: 6.400000000000001e-06     eval rl_reward: 5.39\n","For episode: 1992   the run_score was: 3.0   and mem length: 432906   eps: 0.34084414000984753    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 1993   the run_score was: 3.0   and mem length: 433153   eps: 0.34035508000984444    steps: 247    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 1994   the run_score was: 6.0   and mem length: 433510   eps: 0.33964822000983996    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1995   the run_score was: 6.0   and mem length: 433867   eps: 0.3389413600098355    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 1996   the run_score was: 3.0   and mem length: 434079   eps: 0.33852160000983283    steps: 212    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 1997   the run_score was: 4.0   and mem length: 434359   eps: 0.3379672000098293    steps: 280    lr: 6.400000000000001e-06     eval rl_reward: 5.28\n","For episode: 1998   the run_score was: 3.0   and mem length: 434610   eps: 0.3374702200098262    steps: 251    lr: 6.400000000000001e-06     eval rl_reward: 5.28\n","For episode: 1999   the run_score was: 5.0   and mem length: 434915   eps: 0.33686632000982236    steps: 305    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 2000   the run_score was: 8.0   and mem length: 435377   eps: 0.3359515600098166    steps: 462    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 2001   the run_score was: 4.0   and mem length: 435657   eps: 0.33539716000981307    steps: 280    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 2002   the run_score was: 8.0   and mem length: 436068   eps: 0.3345833800098079    steps: 411    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 2003   the run_score was: 5.0   and mem length: 436376   eps: 0.33397354000980406    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 2004   the run_score was: 4.0   and mem length: 436633   eps: 0.33346468000980084    steps: 257    lr: 6.400000000000001e-06     eval rl_reward: 5.3\n","For episode: 2005   the run_score was: 4.0   and mem length: 436876   eps: 0.3329835400097978    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.28\n","For episode: 2006   the run_score was: 5.0   and mem length: 437205   eps: 0.3323321200097937    steps: 329    lr: 6.400000000000001e-06     eval rl_reward: 5.29\n","For episode: 2007   the run_score was: 8.0   and mem length: 437659   eps: 0.331433200009788    steps: 454    lr: 6.400000000000001e-06     eval rl_reward: 5.31\n","For episode: 2008   the run_score was: 5.0   and mem length: 437949   eps: 0.33085900000978435    steps: 290    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 2009   the run_score was: 5.0   and mem length: 438239   eps: 0.3302848000097807    steps: 290    lr: 6.400000000000001e-06     eval rl_reward: 5.33\n","For episode: 2010   the run_score was: 5.0   and mem length: 438531   eps: 0.32970664000977706    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.35\n","For episode: 2011   the run_score was: 8.0   and mem length: 438960   eps: 0.3288572200097717    steps: 429    lr: 6.400000000000001e-06     eval rl_reward: 5.4\n","For episode: 2012   the run_score was: 4.0   and mem length: 439203   eps: 0.32837608000976864    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.4\n","For episode: 2013   the run_score was: 5.0   and mem length: 439495   eps: 0.327797920009765    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.38\n","For episode: 2014   the run_score was: 5.0   and mem length: 439803   eps: 0.32718808000976113    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.32\n","For episode: 2015   the run_score was: 8.0   and mem length: 440263   eps: 0.32627728000975537    steps: 460    lr: 6.400000000000001e-06     eval rl_reward: 5.36\n","For episode: 2016   the run_score was: 10.0   and mem length: 440717   eps: 0.3253783600097497    steps: 454    lr: 6.400000000000001e-06     eval rl_reward: 5.42\n","For episode: 2017   the run_score was: 10.0   and mem length: 441217   eps: 0.3243883600097434    steps: 500    lr: 6.400000000000001e-06     eval rl_reward: 5.49\n","For episode: 2018   the run_score was: 7.0   and mem length: 441588   eps: 0.32365378000973877    steps: 371    lr: 6.400000000000001e-06     eval rl_reward: 5.52\n","For episode: 2019   the run_score was: 5.0   and mem length: 441898   eps: 0.3230399800097349    steps: 310    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 2020   the run_score was: 4.0   and mem length: 442158   eps: 0.3225251800097316    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.54\n","For episode: 2021   the run_score was: 6.0   and mem length: 442513   eps: 0.3218222800097272    steps: 355    lr: 6.400000000000001e-06     eval rl_reward: 5.56\n","For episode: 2022   the run_score was: 6.0   and mem length: 442885   eps: 0.3210857200097225    steps: 372    lr: 6.400000000000001e-06     eval rl_reward: 5.56\n","For episode: 2023   the run_score was: 3.0   and mem length: 443114   eps: 0.32063230000971965    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.55\n","For episode: 2024   the run_score was: 7.0   and mem length: 443471   eps: 0.3199254400097152    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 2025   the run_score was: 5.0   and mem length: 443796   eps: 0.3192819400097111    steps: 325    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 2026   the run_score was: 7.0   and mem length: 444208   eps: 0.31846618000970595    steps: 412    lr: 6.400000000000001e-06     eval rl_reward: 5.56\n","For episode: 2027   the run_score was: 6.0   and mem length: 444557   eps: 0.3177751600097016    steps: 349    lr: 6.400000000000001e-06     eval rl_reward: 5.57\n","For episode: 2028   the run_score was: 4.0   and mem length: 444818   eps: 0.3172583800096983    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.49\n","For episode: 2029   the run_score was: 8.0   and mem length: 445232   eps: 0.3164386600096931    steps: 414    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 2030   the run_score was: 5.0   and mem length: 445523   eps: 0.3158624800096895    steps: 291    lr: 6.400000000000001e-06     eval rl_reward: 5.52\n","For episode: 2031   the run_score was: 5.0   and mem length: 445831   eps: 0.3152526400096856    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.51\n","For episode: 2032   the run_score was: 3.0   and mem length: 446060   eps: 0.31479922000968275    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.5\n","For episode: 2033   the run_score was: 3.0   and mem length: 446274   eps: 0.31437550000968006    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.49\n","For episode: 2034   the run_score was: 6.0   and mem length: 446635   eps: 0.31366072000967554    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 5.5\n","For episode: 2035   the run_score was: 7.0   and mem length: 447033   eps: 0.31287268000967056    steps: 398    lr: 6.400000000000001e-06     eval rl_reward: 5.52\n","For episode: 2036   the run_score was: 4.0   and mem length: 447274   eps: 0.31239550000966754    steps: 241    lr: 6.400000000000001e-06     eval rl_reward: 5.53\n","For episode: 2037   the run_score was: 9.0   and mem length: 447711   eps: 0.31153024000966206    steps: 437    lr: 6.400000000000001e-06     eval rl_reward: 5.56\n","For episode: 2038   the run_score was: 7.0   and mem length: 448095   eps: 0.31076992000965725    steps: 384    lr: 6.400000000000001e-06     eval rl_reward: 5.59\n","For episode: 2039   the run_score was: 5.0   and mem length: 448384   eps: 0.31019770000965363    steps: 289    lr: 6.400000000000001e-06     eval rl_reward: 5.59\n","For episode: 2040   the run_score was: 6.0   and mem length: 448723   eps: 0.3095264800096494    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2041   the run_score was: 6.0   and mem length: 449062   eps: 0.30885526000964514    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.59\n","For episode: 2042   the run_score was: 8.0   and mem length: 449485   eps: 0.30801772000963984    steps: 423    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 2043   the run_score was: 6.0   and mem length: 449880   eps: 0.3072356200096349    steps: 395    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 2044   the run_score was: 10.0   and mem length: 450406   eps: 0.3061941400096283    steps: 526    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 2045   the run_score was: 5.0   and mem length: 450719   eps: 0.3055744000096244    steps: 313    lr: 6.400000000000001e-06     eval rl_reward: 5.66\n","For episode: 2046   the run_score was: 11.0   and mem length: 451292   eps: 0.3044398600096172    steps: 573    lr: 6.400000000000001e-06     eval rl_reward: 5.73\n","For episode: 2047   the run_score was: 5.0   and mem length: 451597   eps: 0.3038359600096134    steps: 305    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2048   the run_score was: 4.0   and mem length: 451857   eps: 0.3033211600096101    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.72\n","For episode: 2049   the run_score was: 5.0   and mem length: 452165   eps: 0.30271132000960627    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2050   the run_score was: 6.0   and mem length: 452526   eps: 0.30199654000960174    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2051   the run_score was: 4.0   and mem length: 452805   eps: 0.30144412000959825    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 5.6\n","For episode: 2052   the run_score was: 6.0   and mem length: 453166   eps: 0.3007293400095937    steps: 361    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2053   the run_score was: 9.0   and mem length: 453651   eps: 0.29976904000958765    steps: 485    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2054   the run_score was: 4.0   and mem length: 453912   eps: 0.2992522600095844    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2055   the run_score was: 6.0   and mem length: 454264   eps: 0.29855530000957997    steps: 352    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2056   the run_score was: 7.0   and mem length: 454679   eps: 0.2977336000095748    steps: 415    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 2057   the run_score was: 5.0   and mem length: 455006   eps: 0.2970861400095707    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2058   the run_score was: 3.0   and mem length: 455220   eps: 0.296662420009568    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2059   the run_score was: 6.0   and mem length: 455561   eps: 0.2959872400095637    steps: 341    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 2060   the run_score was: 3.0   and mem length: 455773   eps: 0.29556748000956107    steps: 212    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2061   the run_score was: 6.0   and mem length: 456148   eps: 0.29482498000955637    steps: 375    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 2062   the run_score was: 6.0   and mem length: 456506   eps: 0.2941161400095519    steps: 358    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2063   the run_score was: 8.0   and mem length: 456932   eps: 0.29327266000954655    steps: 426    lr: 6.400000000000001e-06     eval rl_reward: 5.6\n","For episode: 2064   the run_score was: 11.0   and mem length: 457340   eps: 0.29246482000954144    steps: 408    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 2065   the run_score was: 6.0   and mem length: 457697   eps: 0.29175796000953697    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.7\n","For episode: 2066   the run_score was: 5.0   and mem length: 458004   eps: 0.2911501000095331    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2067   the run_score was: 5.0   and mem length: 458342   eps: 0.2904808600095289    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 5.7\n","For episode: 2068   the run_score was: 5.0   and mem length: 458649   eps: 0.28987300000952504    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2069   the run_score was: 7.0   and mem length: 459073   eps: 0.2890334800095197    steps: 424    lr: 6.400000000000001e-06     eval rl_reward: 5.71\n","For episode: 2070   the run_score was: 3.0   and mem length: 459284   eps: 0.2886157000095171    steps: 211    lr: 6.400000000000001e-06     eval rl_reward: 5.7\n","For episode: 2071   the run_score was: 3.0   and mem length: 459498   eps: 0.2881919800095144    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.67\n","For episode: 2072   the run_score was: 5.0   and mem length: 459790   eps: 0.28761382000951075    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.63\n","For episode: 2073   the run_score was: 6.0   and mem length: 460128   eps: 0.2869445800095065    steps: 338    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2074   the run_score was: 4.0   and mem length: 460389   eps: 0.28642780000950324    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 2075   the run_score was: 6.0   and mem length: 460765   eps: 0.28568332000949853    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2076   the run_score was: 3.0   and mem length: 460979   eps: 0.28525960000949585    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.64\n","For episode: 2077   the run_score was: 4.0   and mem length: 461258   eps: 0.28470718000949236    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 5.61\n","For episode: 2078   the run_score was: 4.0   and mem length: 461534   eps: 0.2841607000094889    steps: 276    lr: 6.400000000000001e-06     eval rl_reward: 5.62\n","For episode: 2079   the run_score was: 14.0   and mem length: 461937   eps: 0.28336276000948385    steps: 403    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2080   the run_score was: 7.0   and mem length: 462339   eps: 0.2825668000094788    steps: 402    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2081   the run_score was: 5.0   and mem length: 462646   eps: 0.28195894000947497    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 2082   the run_score was: 4.0   and mem length: 462924   eps: 0.2814085000094715    steps: 278    lr: 6.400000000000001e-06     eval rl_reward: 5.65\n","For episode: 2083   the run_score was: 8.0   and mem length: 463377   eps: 0.2805115600094658    steps: 453    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 2084   the run_score was: 5.0   and mem length: 463705   eps: 0.2798621200094617    steps: 328    lr: 6.400000000000001e-06     eval rl_reward: 5.67\n","For episode: 2085   the run_score was: 6.0   and mem length: 464051   eps: 0.27917704000945737    steps: 346    lr: 6.400000000000001e-06     eval rl_reward: 5.67\n","For episode: 2086   the run_score was: 4.0   and mem length: 464326   eps: 0.2786325400094539    steps: 275    lr: 6.400000000000001e-06     eval rl_reward: 5.67\n","For episode: 2087   the run_score was: 3.0   and mem length: 464538   eps: 0.27821278000945127    steps: 212    lr: 6.400000000000001e-06     eval rl_reward: 5.67\n","For episode: 2088   the run_score was: 9.0   and mem length: 464995   eps: 0.27730792000944554    steps: 457    lr: 6.400000000000001e-06     eval rl_reward: 5.7\n","For episode: 2089   the run_score was: 5.0   and mem length: 465287   eps: 0.2767297600094419    steps: 292    lr: 6.400000000000001e-06     eval rl_reward: 5.7\n","For episode: 2090   the run_score was: 5.0   and mem length: 465614   eps: 0.2760823000094378    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.69\n","For episode: 2091   the run_score was: 5.0   and mem length: 465904   eps: 0.27550810000943415    steps: 290    lr: 6.400000000000001e-06     eval rl_reward: 5.68\n","For episode: 2092   the run_score was: 6.0   and mem length: 466278   eps: 0.27476758000942947    steps: 374    lr: 6.400000000000001e-06     eval rl_reward: 5.71\n","For episode: 2093   the run_score was: 7.0   and mem length: 466654   eps: 0.27402310000942476    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2094   the run_score was: 7.0   and mem length: 467006   eps: 0.27332614000942035    steps: 352    lr: 6.400000000000001e-06     eval rl_reward: 5.76\n","For episode: 2095   the run_score was: 5.0   and mem length: 467331   eps: 0.2726826400094163    steps: 325    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2096   the run_score was: 4.0   and mem length: 467592   eps: 0.272165860009413    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.76\n","For episode: 2097   the run_score was: 6.0   and mem length: 467931   eps: 0.27149464000940876    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2098   the run_score was: 5.0   and mem length: 468207   eps: 0.2709481600094053    steps: 276    lr: 6.400000000000001e-06     eval rl_reward: 5.8\n","For episode: 2099   the run_score was: 7.0   and mem length: 468614   eps: 0.2701423000094002    steps: 407    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2100   the run_score was: 5.0   and mem length: 468925   eps: 0.2695265200093963    steps: 311    lr: 6.400000000000001e-06     eval rl_reward: 5.79\n","For episode: 2101   the run_score was: 3.0   and mem length: 469139   eps: 0.26910280000939363    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2102   the run_score was: 5.0   and mem length: 469463   eps: 0.26846128000938957    steps: 324    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2103   the run_score was: 5.0   and mem length: 469752   eps: 0.26788906000938595    steps: 289    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2104   the run_score was: 4.0   and mem length: 469995   eps: 0.2674079200093829    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2105   the run_score was: 7.0   and mem length: 470379   eps: 0.2666476000093781    steps: 384    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2106   the run_score was: 5.0   and mem length: 470687   eps: 0.26603776000937424    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2107   the run_score was: 3.0   and mem length: 470901   eps: 0.26561404000937155    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.73\n","For episode: 2108   the run_score was: 6.0   and mem length: 471245   eps: 0.26493292000936725    steps: 344    lr: 6.400000000000001e-06     eval rl_reward: 5.74\n","For episode: 2109   the run_score was: 6.0   and mem length: 471599   eps: 0.2642320000093628    steps: 354    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2110   the run_score was: 7.0   and mem length: 472006   eps: 0.2634261400093577    steps: 407    lr: 6.400000000000001e-06     eval rl_reward: 5.77\n","For episode: 2111   the run_score was: 9.0   and mem length: 472536   eps: 0.2623767400093511    steps: 530    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2112   the run_score was: 6.0   and mem length: 472896   eps: 0.26166394000934656    steps: 360    lr: 6.400000000000001e-06     eval rl_reward: 5.8\n","For episode: 2113   the run_score was: 6.0   and mem length: 473237   eps: 0.2609887600093423    steps: 341    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 2114   the run_score was: 7.0   and mem length: 473614   eps: 0.26024230000933757    steps: 377    lr: 6.400000000000001e-06     eval rl_reward: 5.83\n","For episode: 2115   the run_score was: 7.0   and mem length: 474000   eps: 0.25947802000933273    steps: 386    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2116   the run_score was: 6.0   and mem length: 474360   eps: 0.2587652200093282    steps: 360    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2117   the run_score was: 7.0   and mem length: 474789   eps: 0.25791580000932285    steps: 429    lr: 6.400000000000001e-06     eval rl_reward: 5.75\n","For episode: 2118   the run_score was: 9.0   and mem length: 475262   eps: 0.2569792600093169    steps: 473    lr: 6.400000000000001e-06     eval rl_reward: 5.77\n","For episode: 2119   the run_score was: 6.0   and mem length: 475604   eps: 0.25630210000931264    steps: 342    lr: 6.400000000000001e-06     eval rl_reward: 5.78\n","For episode: 2120   the run_score was: 8.0   and mem length: 476066   eps: 0.25538734000930685    steps: 462    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2121   the run_score was: 6.0   and mem length: 476371   eps: 0.25478344000930303    steps: 305    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2122   the run_score was: 12.0   and mem length: 476768   eps: 0.25399738000929806    steps: 397    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2123   the run_score was: 5.0   and mem length: 477077   eps: 0.2533855600092942    steps: 309    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2124   the run_score was: 8.0   and mem length: 477493   eps: 0.252561880009289    steps: 416    lr: 6.400000000000001e-06     eval rl_reward: 5.91\n","For episode: 2125   the run_score was: 6.0   and mem length: 477832   eps: 0.25189066000928473    steps: 339    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2126   the run_score was: 4.0   and mem length: 478090   eps: 0.2513798200092815    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2127   the run_score was: 4.0   and mem length: 478348   eps: 0.25086898000927826    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 5.87\n","For episode: 2128   the run_score was: 6.0   and mem length: 478688   eps: 0.250195780009274    steps: 340    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2129   the run_score was: 8.0   and mem length: 479074   eps: 0.24943150000926917    steps: 386    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2130   the run_score was: 4.0   and mem length: 479335   eps: 0.2489147200092659    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2131   the run_score was: 6.0   and mem length: 479709   eps: 0.24817420000926121    steps: 374    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2132   the run_score was: 4.0   and mem length: 479967   eps: 0.24766336000925798    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2133   the run_score was: 6.0   and mem length: 480312   eps: 0.24698026000925366    steps: 345    lr: 6.400000000000001e-06     eval rl_reward: 5.93\n","For episode: 2134   the run_score was: 6.0   and mem length: 480687   eps: 0.24623776000924896    steps: 375    lr: 6.400000000000001e-06     eval rl_reward: 5.93\n","For episode: 2135   the run_score was: 4.0   and mem length: 480945   eps: 0.24572692000924573    steps: 258    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2136   the run_score was: 6.0   and mem length: 481301   eps: 0.24502204000924127    steps: 356    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2137   the run_score was: 5.0   and mem length: 481630   eps: 0.24437062000923715    steps: 329    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2138   the run_score was: 8.0   and mem length: 482040   eps: 0.243558820009232    steps: 410    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2139   the run_score was: 3.0   and mem length: 482254   eps: 0.24313510000922933    steps: 214    lr: 6.400000000000001e-06     eval rl_reward: 5.87\n","For episode: 2140   the run_score was: 14.0   and mem length: 482832   eps: 0.2419906600092221    steps: 578    lr: 6.400000000000001e-06     eval rl_reward: 5.95\n","For episode: 2141   the run_score was: 5.0   and mem length: 483159   eps: 0.241343200009218    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.94\n","For episode: 2142   the run_score was: 4.0   and mem length: 483402   eps: 0.24086206000921495    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2143   the run_score was: 5.0   and mem length: 483727   eps: 0.24021856000921088    steps: 325    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2144   the run_score was: 6.0   and mem length: 484103   eps: 0.23947408000920617    steps: 376    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 2145   the run_score was: 5.0   and mem length: 484414   eps: 0.23885830000920227    steps: 311    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 2146   the run_score was: 5.0   and mem length: 484741   eps: 0.23821084000919818    steps: 327    lr: 6.400000000000001e-06     eval rl_reward: 5.79\n","For episode: 2147   the run_score was: 7.0   and mem length: 485097   eps: 0.23750596000919372    steps: 356    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 2148   the run_score was: 4.0   and mem length: 485360   eps: 0.23698522000919042    steps: 263    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 2149   the run_score was: 5.0   and mem length: 485668   eps: 0.23637538000918656    steps: 308    lr: 6.400000000000001e-06     eval rl_reward: 5.81\n","For episode: 2150   the run_score was: 5.0   and mem length: 485993   eps: 0.2357318800091825    steps: 325    lr: 6.400000000000001e-06     eval rl_reward: 5.8\n","For episode: 2151   the run_score was: 7.0   and mem length: 486415   eps: 0.2348963200091772    steps: 422    lr: 6.400000000000001e-06     eval rl_reward: 5.83\n","For episode: 2152   the run_score was: 6.0   and mem length: 486721   eps: 0.23429044000917337    steps: 306    lr: 6.400000000000001e-06     eval rl_reward: 5.83\n","For episode: 2153   the run_score was: 8.0   and mem length: 487128   eps: 0.23348458000916827    steps: 407    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2154   the run_score was: 4.0   and mem length: 487407   eps: 0.23293216000916478    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 5.82\n","For episode: 2155   the run_score was: 4.0   and mem length: 487668   eps: 0.2324153800091615    steps: 261    lr: 6.400000000000001e-06     eval rl_reward: 5.8\n","For episode: 2156   the run_score was: 10.0   and mem length: 488141   eps: 0.23147884000915558    steps: 473    lr: 6.400000000000001e-06     eval rl_reward: 5.83\n","For episode: 2157   the run_score was: 10.0   and mem length: 488675   eps: 0.2304215200091489    steps: 534    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2158   the run_score was: 7.0   and mem length: 489079   eps: 0.22962160000914383    steps: 404    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2159   the run_score was: 4.0   and mem length: 489320   eps: 0.22914442000914081    steps: 241    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2160   the run_score was: 8.0   and mem length: 489762   eps: 0.22826926000913528    steps: 442    lr: 6.400000000000001e-06     eval rl_reward: 5.95\n","For episode: 2161   the run_score was: 5.0   and mem length: 490069   eps: 0.22766140000913143    steps: 307    lr: 6.400000000000001e-06     eval rl_reward: 5.94\n","For episode: 2162   the run_score was: 6.0   and mem length: 490406   eps: 0.2269941400091272    steps: 337    lr: 6.400000000000001e-06     eval rl_reward: 5.94\n","For episode: 2163   the run_score was: 6.0   and mem length: 490727   eps: 0.2263585600091232    steps: 321    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2164   the run_score was: 6.0   and mem length: 491086   eps: 0.2256477400091187    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 5.87\n","For episode: 2165   the run_score was: 5.0   and mem length: 491395   eps: 0.22503592000911482    steps: 309    lr: 6.400000000000001e-06     eval rl_reward: 5.86\n","For episode: 2166   the run_score was: 8.0   and mem length: 491842   eps: 0.22415086000910922    steps: 447    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2167   the run_score was: 4.0   and mem length: 492104   eps: 0.22363210000910594    steps: 262    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2168   the run_score was: 7.0   and mem length: 492476   eps: 0.22289554000910128    steps: 372    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2169   the run_score was: 6.0   and mem length: 492835   eps: 0.22218472000909678    steps: 359    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2170   the run_score was: 4.0   and mem length: 493114   eps: 0.22163230000909329    steps: 279    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2171   the run_score was: 3.0   and mem length: 493345   eps: 0.2211749200090904    steps: 231    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2172   the run_score was: 7.0   and mem length: 493749   eps: 0.22037500000908533    steps: 404    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2173   the run_score was: 4.0   and mem length: 493989   eps: 0.21989980000908232    steps: 240    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2174   the run_score was: 4.0   and mem length: 494270   eps: 0.2193434200090788    steps: 281    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2175   the run_score was: 6.0   and mem length: 494647   eps: 0.21859696000907408    steps: 377    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2176   the run_score was: 5.0   and mem length: 494951   eps: 0.21799504000907027    steps: 304    lr: 6.400000000000001e-06     eval rl_reward: 5.92\n","For episode: 2177   the run_score was: 8.0   and mem length: 495408   eps: 0.21709018000906455    steps: 457    lr: 6.400000000000001e-06     eval rl_reward: 5.96\n","For episode: 2178   the run_score was: 5.0   and mem length: 495702   eps: 0.21650806000906087    steps: 294    lr: 6.400000000000001e-06     eval rl_reward: 5.97\n","For episode: 2179   the run_score was: 3.0   and mem length: 495931   eps: 0.216054640009058    steps: 229    lr: 6.400000000000001e-06     eval rl_reward: 5.86\n","For episode: 2180   the run_score was: 7.0   and mem length: 496318   eps: 0.21528838000905315    steps: 387    lr: 6.400000000000001e-06     eval rl_reward: 5.86\n","For episode: 2181   the run_score was: 8.0   and mem length: 496744   eps: 0.2144449000090478    steps: 426    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2182   the run_score was: 5.0   and mem length: 497070   eps: 0.21379942000904373    steps: 326    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2183   the run_score was: 6.0   and mem length: 497427   eps: 0.21309256000903926    steps: 357    lr: 6.400000000000001e-06     eval rl_reward: 5.88\n","For episode: 2184   the run_score was: 4.0   and mem length: 497670   eps: 0.2126114200090362    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.87\n","For episode: 2185   the run_score was: 4.0   and mem length: 497930   eps: 0.21209662000903295    steps: 260    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 2186   the run_score was: 5.0   and mem length: 498219   eps: 0.21152440000902933    steps: 289    lr: 6.400000000000001e-06     eval rl_reward: 5.86\n","For episode: 2187   the run_score was: 7.0   and mem length: 498603   eps: 0.21076408000902452    steps: 384    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2188   the run_score was: 4.0   and mem length: 498846   eps: 0.21028294000902148    steps: 243    lr: 6.400000000000001e-06     eval rl_reward: 5.85\n","For episode: 2189   the run_score was: 9.0   and mem length: 499338   eps: 0.20930878000901532    steps: 492    lr: 6.400000000000001e-06     eval rl_reward: 5.89\n","For episode: 2190   the run_score was: 6.0   and mem length: 499708   eps: 0.20857618000901068    steps: 370    lr: 6.400000000000001e-06     eval rl_reward: 5.9\n","For episode: 2191   the run_score was: 9.0   and mem length: 500146   eps: 0.2077089400090052    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 5.94\n","For episode: 2192   the run_score was: 8.0   and mem length: 500553   eps: 0.2069030800090001    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 5.96\n","For episode: 2193   the run_score was: 7.0   and mem length: 500939   eps: 0.20613880000899526    steps: 386    lr: 2.560000000000001e-06     eval rl_reward: 5.96\n","For episode: 2194   the run_score was: 7.0   and mem length: 501347   eps: 0.20533096000899015    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 5.96\n","For episode: 2195   the run_score was: 3.0   and mem length: 501577   eps: 0.20487556000898727    steps: 230    lr: 2.560000000000001e-06     eval rl_reward: 5.94\n","For episode: 2196   the run_score was: 5.0   and mem length: 501888   eps: 0.20425978000898337    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 5.95\n","For episode: 2197   the run_score was: 19.0   and mem length: 502433   eps: 0.20318068000897654    steps: 545    lr: 2.560000000000001e-06     eval rl_reward: 6.08\n","For episode: 2198   the run_score was: 6.0   and mem length: 502751   eps: 0.20255104000897256    steps: 318    lr: 2.560000000000001e-06     eval rl_reward: 6.09\n","For episode: 2199   the run_score was: 5.0   and mem length: 503058   eps: 0.20194318000896871    steps: 307    lr: 2.560000000000001e-06     eval rl_reward: 6.07\n","For episode: 2200   the run_score was: 6.0   and mem length: 503432   eps: 0.20120266000896403    steps: 374    lr: 2.560000000000001e-06     eval rl_reward: 6.08\n","For episode: 2201   the run_score was: 7.0   and mem length: 503818   eps: 0.2004383800089592    steps: 386    lr: 2.560000000000001e-06     eval rl_reward: 6.12\n","For episode: 2202   the run_score was: 5.0   and mem length: 504147   eps: 0.19978696000895507    steps: 329    lr: 2.560000000000001e-06     eval rl_reward: 6.12\n","For episode: 2203   the run_score was: 8.0   and mem length: 504589   eps: 0.19891180000894954    steps: 442    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2204   the run_score was: 8.0   and mem length: 505017   eps: 0.19806436000894417    steps: 428    lr: 2.560000000000001e-06     eval rl_reward: 6.19\n","For episode: 2205   the run_score was: 7.0   and mem length: 505387   eps: 0.19733176000893954    steps: 370    lr: 2.560000000000001e-06     eval rl_reward: 6.19\n","For episode: 2206   the run_score was: 5.0   and mem length: 505661   eps: 0.1967892400089361    steps: 274    lr: 2.560000000000001e-06     eval rl_reward: 6.19\n","For episode: 2207   the run_score was: 4.0   and mem length: 505904   eps: 0.19630810000893306    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.2\n","For episode: 2208   the run_score was: 8.0   and mem length: 506329   eps: 0.19546660000892774    steps: 425    lr: 2.560000000000001e-06     eval rl_reward: 6.22\n","For episode: 2209   the run_score was: 4.0   and mem length: 506570   eps: 0.19498942000892472    steps: 241    lr: 2.560000000000001e-06     eval rl_reward: 6.2\n","For episode: 2210   the run_score was: 6.0   and mem length: 506908   eps: 0.19432018000892048    steps: 338    lr: 2.560000000000001e-06     eval rl_reward: 6.19\n","For episode: 2211   the run_score was: 4.0   and mem length: 507184   eps: 0.19377370000891703    steps: 276    lr: 2.560000000000001e-06     eval rl_reward: 6.14\n","For episode: 2212   the run_score was: 7.0   and mem length: 507568   eps: 0.19301338000891222    steps: 384    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2213   the run_score was: 6.0   and mem length: 507903   eps: 0.19235008000890802    steps: 335    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2214   the run_score was: 3.0   and mem length: 508117   eps: 0.19192636000890534    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.11\n","For episode: 2215   the run_score was: 6.0   and mem length: 508475   eps: 0.19121752000890085    steps: 358    lr: 2.560000000000001e-06     eval rl_reward: 6.1\n","For episode: 2216   the run_score was: 4.0   and mem length: 508718   eps: 0.1907363800088978    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.08\n","For episode: 2217   the run_score was: 4.0   and mem length: 508963   eps: 0.19025128000889474    steps: 245    lr: 2.560000000000001e-06     eval rl_reward: 6.05\n","For episode: 2218   the run_score was: 4.0   and mem length: 509204   eps: 0.18977410000889172    steps: 241    lr: 2.560000000000001e-06     eval rl_reward: 6.0\n","For episode: 2219   the run_score was: 7.0   and mem length: 509590   eps: 0.1890098200088869    steps: 386    lr: 2.560000000000001e-06     eval rl_reward: 6.01\n","For episode: 2220   the run_score was: 7.0   and mem length: 509995   eps: 0.1882079200088818    steps: 405    lr: 2.560000000000001e-06     eval rl_reward: 6.0\n","For episode: 2221   the run_score was: 6.0   and mem length: 510333   eps: 0.18753868000887758    steps: 338    lr: 2.560000000000001e-06     eval rl_reward: 6.0\n","For episode: 2222   the run_score was: 4.0   and mem length: 510593   eps: 0.18702388000887432    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 5.92\n","For episode: 2223   the run_score was: 7.0   and mem length: 510984   eps: 0.18624970000886942    steps: 391    lr: 2.560000000000001e-06     eval rl_reward: 5.94\n","For episode: 2224   the run_score was: 6.0   and mem length: 511363   eps: 0.18549928000886468    steps: 379    lr: 2.560000000000001e-06     eval rl_reward: 5.92\n","For episode: 2225   the run_score was: 8.0   and mem length: 511835   eps: 0.18456472000885876    steps: 472    lr: 2.560000000000001e-06     eval rl_reward: 5.94\n","For episode: 2226   the run_score was: 7.0   and mem length: 512243   eps: 0.18375688000885365    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 5.97\n","For episode: 2227   the run_score was: 3.0   and mem length: 512454   eps: 0.183339100008851    steps: 211    lr: 2.560000000000001e-06     eval rl_reward: 5.96\n","For episode: 2228   the run_score was: 11.0   and mem length: 512982   eps: 0.1822936600088444    steps: 528    lr: 2.560000000000001e-06     eval rl_reward: 6.01\n","For episode: 2229   the run_score was: 8.0   and mem length: 513413   eps: 0.181440280008839    steps: 431    lr: 2.560000000000001e-06     eval rl_reward: 6.01\n","For episode: 2230   the run_score was: 5.0   and mem length: 513705   eps: 0.18086212000883534    steps: 292    lr: 2.560000000000001e-06     eval rl_reward: 6.02\n","For episode: 2231   the run_score was: 5.0   and mem length: 514033   eps: 0.18021268000883123    steps: 328    lr: 2.560000000000001e-06     eval rl_reward: 6.01\n","For episode: 2232   the run_score was: 5.0   and mem length: 514325   eps: 0.17963452000882757    steps: 292    lr: 2.560000000000001e-06     eval rl_reward: 6.02\n","For episode: 2233   the run_score was: 5.0   and mem length: 514649   eps: 0.1789930000088235    steps: 324    lr: 2.560000000000001e-06     eval rl_reward: 6.01\n","For episode: 2234   the run_score was: 8.0   and mem length: 515107   eps: 0.17808616000881777    steps: 458    lr: 2.560000000000001e-06     eval rl_reward: 6.03\n","For episode: 2235   the run_score was: 6.0   and mem length: 515429   eps: 0.17744860000881374    steps: 322    lr: 2.560000000000001e-06     eval rl_reward: 6.05\n","For episode: 2236   the run_score was: 10.0   and mem length: 515866   eps: 0.17658334000880826    steps: 437    lr: 2.560000000000001e-06     eval rl_reward: 6.09\n","For episode: 2237   the run_score was: 7.0   and mem length: 516264   eps: 0.17579530000880328    steps: 398    lr: 2.560000000000001e-06     eval rl_reward: 6.11\n","For episode: 2238   the run_score was: 4.0   and mem length: 516525   eps: 0.1752785200088    steps: 261    lr: 2.560000000000001e-06     eval rl_reward: 6.07\n","For episode: 2239   the run_score was: 6.0   and mem length: 516862   eps: 0.1746112600087958    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 6.1\n","For episode: 2240   the run_score was: 10.0   and mem length: 517408   eps: 0.17353018000878895    steps: 546    lr: 2.560000000000001e-06     eval rl_reward: 6.06\n","For episode: 2241   the run_score was: 9.0   and mem length: 517882   eps: 0.172591660008783    steps: 474    lr: 2.560000000000001e-06     eval rl_reward: 6.1\n","For episode: 2242   the run_score was: 8.0   and mem length: 518308   eps: 0.17174818000877767    steps: 426    lr: 2.560000000000001e-06     eval rl_reward: 6.14\n","For episode: 2243   the run_score was: 7.0   and mem length: 518695   eps: 0.17098192000877283    steps: 387    lr: 2.560000000000001e-06     eval rl_reward: 6.16\n","For episode: 2244   the run_score was: 5.0   and mem length: 519023   eps: 0.17033248000876872    steps: 328    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2245   the run_score was: 5.0   and mem length: 519345   eps: 0.16969492000876468    steps: 322    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2246   the run_score was: 6.0   and mem length: 519705   eps: 0.16898212000876017    steps: 360    lr: 2.560000000000001e-06     eval rl_reward: 6.16\n","For episode: 2247   the run_score was: 5.0   and mem length: 520014   eps: 0.1683703000087563    steps: 309    lr: 2.560000000000001e-06     eval rl_reward: 6.14\n","For episode: 2248   the run_score was: 7.0   and mem length: 520422   eps: 0.1675624600087512    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 6.17\n","For episode: 2249   the run_score was: 7.0   and mem length: 520791   eps: 0.16683184000874657    steps: 369    lr: 2.560000000000001e-06     eval rl_reward: 6.19\n","For episode: 2250   the run_score was: 4.0   and mem length: 521067   eps: 0.1662853600087431    steps: 276    lr: 2.560000000000001e-06     eval rl_reward: 6.18\n","For episode: 2251   the run_score was: 4.0   and mem length: 521310   eps: 0.16580422000874007    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.15\n","For episode: 2252   the run_score was: 5.0   and mem length: 521599   eps: 0.16523200000873645    steps: 289    lr: 2.560000000000001e-06     eval rl_reward: 6.14\n","For episode: 2253   the run_score was: 7.0   and mem length: 521962   eps: 0.1645132600087319    steps: 363    lr: 2.560000000000001e-06     eval rl_reward: 6.13\n","For episode: 2254   the run_score was: 4.0   and mem length: 522205   eps: 0.16403212000872885    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.13\n","For episode: 2255   the run_score was: 5.0   and mem length: 522496   eps: 0.1634559400087252    steps: 291    lr: 2.560000000000001e-06     eval rl_reward: 6.14\n","For episode: 2256   the run_score was: 9.0   and mem length: 522957   eps: 0.16254316000871943    steps: 461    lr: 2.560000000000001e-06     eval rl_reward: 6.13\n","For episode: 2257   the run_score was: 6.0   and mem length: 523313   eps: 0.16183828000871497    steps: 356    lr: 2.560000000000001e-06     eval rl_reward: 6.09\n","For episode: 2258   the run_score was: 8.0   and mem length: 523678   eps: 0.1611155800087104    steps: 365    lr: 2.560000000000001e-06     eval rl_reward: 6.1\n","For episode: 2259   the run_score was: 14.0   and mem length: 524221   eps: 0.1600404400087036    steps: 543    lr: 2.560000000000001e-06     eval rl_reward: 6.2\n","For episode: 2260   the run_score was: 6.0   and mem length: 524561   eps: 0.15936724000869934    steps: 340    lr: 2.560000000000001e-06     eval rl_reward: 6.18\n","For episode: 2261   the run_score was: 7.0   and mem length: 524952   eps: 0.15859306000869444    steps: 391    lr: 2.560000000000001e-06     eval rl_reward: 6.2\n","For episode: 2262   the run_score was: 12.0   and mem length: 525408   eps: 0.15769018000868873    steps: 456    lr: 2.560000000000001e-06     eval rl_reward: 6.26\n","For episode: 2263   the run_score was: 5.0   and mem length: 525731   eps: 0.15705064000868468    steps: 323    lr: 2.560000000000001e-06     eval rl_reward: 6.25\n","For episode: 2264   the run_score was: 11.0   and mem length: 526191   eps: 0.15613984000867892    steps: 460    lr: 2.560000000000001e-06     eval rl_reward: 6.3\n","For episode: 2265   the run_score was: 5.0   and mem length: 526501   eps: 0.15552604000867504    steps: 310    lr: 2.560000000000001e-06     eval rl_reward: 6.3\n","For episode: 2266   the run_score was: 6.0   and mem length: 526855   eps: 0.1548251200086706    steps: 354    lr: 2.560000000000001e-06     eval rl_reward: 6.28\n","For episode: 2267   the run_score was: 7.0   and mem length: 527243   eps: 0.15405688000866574    steps: 388    lr: 2.560000000000001e-06     eval rl_reward: 6.31\n","For episode: 2268   the run_score was: 8.0   and mem length: 527722   eps: 0.15310846000865974    steps: 479    lr: 2.560000000000001e-06     eval rl_reward: 6.32\n","For episode: 2269   the run_score was: 8.0   and mem length: 528159   eps: 0.15224320000865427    steps: 437    lr: 2.560000000000001e-06     eval rl_reward: 6.34\n","For episode: 2270   the run_score was: 3.0   and mem length: 528373   eps: 0.15181948000865159    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.33\n","For episode: 2271   the run_score was: 8.0   and mem length: 528743   eps: 0.15108688000864695    steps: 370    lr: 2.560000000000001e-06     eval rl_reward: 6.38\n","For episode: 2272   the run_score was: 6.0   and mem length: 529080   eps: 0.15041962000864273    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 6.37\n","For episode: 2273   the run_score was: 12.0   and mem length: 529610   eps: 0.1493702200086361    steps: 530    lr: 2.560000000000001e-06     eval rl_reward: 6.45\n","For episode: 2274   the run_score was: 6.0   and mem length: 529949   eps: 0.14869900000863184    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.47\n","For episode: 2275   the run_score was: 10.0   and mem length: 530448   eps: 0.1477109800086256    steps: 499    lr: 2.560000000000001e-06     eval rl_reward: 6.51\n","For episode: 2276   the run_score was: 7.0   and mem length: 530880   eps: 0.14685562000862018    steps: 432    lr: 2.560000000000001e-06     eval rl_reward: 6.53\n","For episode: 2277   the run_score was: 4.0   and mem length: 531123   eps: 0.14637448000861714    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.49\n","For episode: 2278   the run_score was: 4.0   and mem length: 531383   eps: 0.14585968000861388    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 6.48\n","For episode: 2279   the run_score was: 4.0   and mem length: 531643   eps: 0.14534488000861062    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 6.49\n","For episode: 2280   the run_score was: 6.0   and mem length: 531967   eps: 0.14470336000860656    steps: 324    lr: 2.560000000000001e-06     eval rl_reward: 6.48\n","For episode: 2281   the run_score was: 6.0   and mem length: 532331   eps: 0.143982640008602    steps: 364    lr: 2.560000000000001e-06     eval rl_reward: 6.46\n","For episode: 2282   the run_score was: 11.0   and mem length: 532884   eps: 0.14288770000859508    steps: 553    lr: 2.560000000000001e-06     eval rl_reward: 6.52\n","For episode: 2283   the run_score was: 8.0   and mem length: 533273   eps: 0.1421174800085902    steps: 389    lr: 2.560000000000001e-06     eval rl_reward: 6.54\n","For episode: 2284   the run_score was: 6.0   and mem length: 533615   eps: 0.14144032000858592    steps: 342    lr: 2.560000000000001e-06     eval rl_reward: 6.56\n","For episode: 2285   the run_score was: 7.0   and mem length: 533985   eps: 0.14070772000858128    steps: 370    lr: 2.560000000000001e-06     eval rl_reward: 6.59\n","For episode: 2286   the run_score was: 5.0   and mem length: 534295   eps: 0.1400939200085774    steps: 310    lr: 2.560000000000001e-06     eval rl_reward: 6.59\n","For episode: 2287   the run_score was: 7.0   and mem length: 534720   eps: 0.13925242000857208    steps: 425    lr: 2.560000000000001e-06     eval rl_reward: 6.59\n","For episode: 2288   the run_score was: 6.0   and mem length: 535057   eps: 0.13858516000856785    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 6.61\n","For episode: 2289   the run_score was: 3.0   and mem length: 535271   eps: 0.13816144000856517    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.55\n","For episode: 2290   the run_score was: 6.0   and mem length: 535610   eps: 0.13749022000856093    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.55\n","For episode: 2291   the run_score was: 7.0   and mem length: 535997   eps: 0.13672396000855608    steps: 387    lr: 2.560000000000001e-06     eval rl_reward: 6.53\n","For episode: 2292   the run_score was: 9.0   and mem length: 536457   eps: 0.13581316000855032    steps: 460    lr: 2.560000000000001e-06     eval rl_reward: 6.54\n","For episode: 2293   the run_score was: 7.0   and mem length: 536863   eps: 0.13500928000854523    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 6.54\n","For episode: 2294   the run_score was: 4.0   and mem length: 537106   eps: 0.13452814000854219    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.51\n","For episode: 2295   the run_score was: 5.0   and mem length: 537436   eps: 0.13387474000853805    steps: 330    lr: 2.560000000000001e-06     eval rl_reward: 6.53\n","For episode: 2296   the run_score was: 10.0   and mem length: 537911   eps: 0.1329342400085321    steps: 475    lr: 2.560000000000001e-06     eval rl_reward: 6.58\n","For episode: 2297   the run_score was: 7.0   and mem length: 538318   eps: 0.132128380008527    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 6.46\n","For episode: 2298   the run_score was: 9.0   and mem length: 538786   eps: 0.13120174000852114    steps: 468    lr: 2.560000000000001e-06     eval rl_reward: 6.49\n","For episode: 2299   the run_score was: 6.0   and mem length: 539143   eps: 0.13049488000851667    steps: 357    lr: 2.560000000000001e-06     eval rl_reward: 6.5\n","For episode: 2300   the run_score was: 8.0   and mem length: 539586   eps: 0.12961774000851112    steps: 443    lr: 2.560000000000001e-06     eval rl_reward: 6.52\n","For episode: 2301   the run_score was: 8.0   and mem length: 540012   eps: 0.12877426000850578    steps: 426    lr: 2.560000000000001e-06     eval rl_reward: 6.53\n","For episode: 2302   the run_score was: 9.0   and mem length: 540505   eps: 0.1277981200084996    steps: 493    lr: 2.560000000000001e-06     eval rl_reward: 6.57\n","For episode: 2303   the run_score was: 7.0   and mem length: 540900   eps: 0.12701602000849466    steps: 395    lr: 2.560000000000001e-06     eval rl_reward: 6.56\n","For episode: 2304   the run_score was: 12.0   and mem length: 541321   eps: 0.12618244000848938    steps: 421    lr: 2.560000000000001e-06     eval rl_reward: 6.6\n","For episode: 2305   the run_score was: 6.0   and mem length: 541698   eps: 0.12543598000848466    steps: 377    lr: 2.560000000000001e-06     eval rl_reward: 6.59\n","For episode: 2306   the run_score was: 5.0   and mem length: 542026   eps: 0.12478654000848205    steps: 328    lr: 2.560000000000001e-06     eval rl_reward: 6.59\n","For episode: 2307   the run_score was: 8.0   and mem length: 542460   eps: 0.12392722000848264    steps: 434    lr: 2.560000000000001e-06     eval rl_reward: 6.63\n","For episode: 2308   the run_score was: 10.0   and mem length: 542934   eps: 0.12298870000848328    steps: 474    lr: 2.560000000000001e-06     eval rl_reward: 6.65\n","For episode: 2309   the run_score was: 4.0   and mem length: 543177   eps: 0.1225075600084836    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.65\n","For episode: 2310   the run_score was: 4.0   and mem length: 543418   eps: 0.12203038000848393    steps: 241    lr: 2.560000000000001e-06     eval rl_reward: 6.63\n","For episode: 2311   the run_score was: 8.0   and mem length: 543845   eps: 0.1211849200084845    steps: 427    lr: 2.560000000000001e-06     eval rl_reward: 6.67\n","For episode: 2312   the run_score was: 4.0   and mem length: 544104   eps: 0.12067210000848486    steps: 259    lr: 2.560000000000001e-06     eval rl_reward: 6.64\n","For episode: 2313   the run_score was: 9.0   and mem length: 544525   eps: 0.11983852000848542    steps: 421    lr: 2.560000000000001e-06     eval rl_reward: 6.67\n","For episode: 2314   the run_score was: 3.0   and mem length: 544739   eps: 0.11941480000848571    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.67\n","For episode: 2315   the run_score was: 7.0   and mem length: 545093   eps: 0.11871388000848619    steps: 354    lr: 2.560000000000001e-06     eval rl_reward: 6.68\n","For episode: 2316   the run_score was: 8.0   and mem length: 545549   eps: 0.11781100000848681    steps: 456    lr: 2.560000000000001e-06     eval rl_reward: 6.72\n","For episode: 2317   the run_score was: 6.0   and mem length: 545886   eps: 0.11714374000848726    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 6.74\n","For episode: 2318   the run_score was: 7.0   and mem length: 546268   eps: 0.11638738000848778    steps: 382    lr: 2.560000000000001e-06     eval rl_reward: 6.77\n","For episode: 2319   the run_score was: 10.0   and mem length: 546623   eps: 0.11568448000848826    steps: 355    lr: 2.560000000000001e-06     eval rl_reward: 6.8\n","For episode: 2320   the run_score was: 8.0   and mem length: 547029   eps: 0.1148806000084888    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 6.81\n","For episode: 2321   the run_score was: 10.0   and mem length: 547535   eps: 0.11387872000848949    steps: 506    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2322   the run_score was: 10.0   and mem length: 548026   eps: 0.11290654000849015    steps: 491    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2323   the run_score was: 8.0   and mem length: 548468   eps: 0.11203138000849075    steps: 442    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2324   the run_score was: 9.0   and mem length: 548934   eps: 0.11110870000849138    steps: 466    lr: 2.560000000000001e-06     eval rl_reward: 6.95\n","For episode: 2325   the run_score was: 9.0   and mem length: 549385   eps: 0.11021572000849199    steps: 451    lr: 2.560000000000001e-06     eval rl_reward: 6.96\n","For episode: 2326   the run_score was: 9.0   and mem length: 549862   eps: 0.10927126000849263    steps: 477    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2327   the run_score was: 3.0   and mem length: 550074   eps: 0.10885150000849292    steps: 212    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2328   the run_score was: 4.0   and mem length: 550317   eps: 0.10837036000849325    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2329   the run_score was: 8.0   and mem length: 550727   eps: 0.1075585600084938    steps: 410    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2330   the run_score was: 5.0   and mem length: 551018   eps: 0.1069823800084942    steps: 291    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2331   the run_score was: 3.0   and mem length: 551232   eps: 0.10655866000849448    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2332   the run_score was: 8.0   and mem length: 551628   eps: 0.10577458000849502    steps: 396    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2333   the run_score was: 5.0   and mem length: 551957   eps: 0.10512316000849546    steps: 329    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2334   the run_score was: 7.0   and mem length: 552343   eps: 0.10435888000849598    steps: 386    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2335   the run_score was: 3.0   and mem length: 552557   eps: 0.10393516000849627    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.88\n","For episode: 2336   the run_score was: 5.0   and mem length: 552865   eps: 0.10332532000849669    steps: 308    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2337   the run_score was: 7.0   and mem length: 553290   eps: 0.10248382000849726    steps: 425    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2338   the run_score was: 10.0   and mem length: 553767   eps: 0.1015393600084979    steps: 477    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2339   the run_score was: 8.0   and mem length: 554223   eps: 0.10063648000849852    steps: 456    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2340   the run_score was: 5.0   and mem length: 554534   eps: 0.10002070000849894    steps: 311    lr: 2.560000000000001e-06     eval rl_reward: 6.86\n","For episode: 2341   the run_score was: 5.0   and mem length: 554824   eps: 0.09944650000849933    steps: 290    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2342   the run_score was: 8.0   and mem length: 555230   eps: 0.09864262000849988    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2343   the run_score was: 8.0   and mem length: 555650   eps: 0.09781102000850045    steps: 420    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2344   the run_score was: 7.0   and mem length: 556019   eps: 0.09708040000850095    steps: 369    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2345   the run_score was: 6.0   and mem length: 556358   eps: 0.0964091800085014    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.86\n","For episode: 2346   the run_score was: 3.0   and mem length: 556572   eps: 0.0959854600085017    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2347   the run_score was: 4.0   and mem length: 556831   eps: 0.09547264000850204    steps: 259    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2348   the run_score was: 6.0   and mem length: 557205   eps: 0.09473212000850255    steps: 374    lr: 2.560000000000001e-06     eval rl_reward: 6.81\n","For episode: 2349   the run_score was: 8.0   and mem length: 557580   eps: 0.09398962000850306    steps: 375    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2350   the run_score was: 10.0   and mem length: 558060   eps: 0.0930392200085037    steps: 480    lr: 2.560000000000001e-06     eval rl_reward: 6.88\n","For episode: 2351   the run_score was: 8.0   and mem length: 558511   eps: 0.09214624000850431    steps: 451    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2352   the run_score was: 15.0   and mem length: 559082   eps: 0.09101566000850508    steps: 571    lr: 2.560000000000001e-06     eval rl_reward: 7.02\n","For episode: 2353   the run_score was: 5.0   and mem length: 559408   eps: 0.09037018000850552    steps: 326    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2354   the run_score was: 7.0   and mem length: 559806   eps: 0.08958214000850606    steps: 398    lr: 2.560000000000001e-06     eval rl_reward: 7.03\n","For episode: 2355   the run_score was: 10.0   and mem length: 560342   eps: 0.08852086000850679    steps: 536    lr: 2.560000000000001e-06     eval rl_reward: 7.08\n","For episode: 2356   the run_score was: 7.0   and mem length: 560724   eps: 0.0877645000085073    steps: 382    lr: 2.560000000000001e-06     eval rl_reward: 7.06\n","For episode: 2357   the run_score was: 8.0   and mem length: 561194   eps: 0.08683390000850794    steps: 470    lr: 2.560000000000001e-06     eval rl_reward: 7.08\n","For episode: 2358   the run_score was: 7.0   and mem length: 561572   eps: 0.08608546000850845    steps: 378    lr: 2.560000000000001e-06     eval rl_reward: 7.07\n","For episode: 2359   the run_score was: 7.0   and mem length: 561942   eps: 0.08535286000850895    steps: 370    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2360   the run_score was: 4.0   and mem length: 562185   eps: 0.08487172000850927    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2361   the run_score was: 3.0   and mem length: 562399   eps: 0.08444800000850956    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2362   the run_score was: 4.0   and mem length: 562645   eps: 0.0839609200085099    steps: 246    lr: 2.560000000000001e-06     eval rl_reward: 6.86\n","For episode: 2363   the run_score was: 5.0   and mem length: 562934   eps: 0.08338870000851029    steps: 289    lr: 2.560000000000001e-06     eval rl_reward: 6.86\n","For episode: 2364   the run_score was: 9.0   and mem length: 563402   eps: 0.08246206000851092    steps: 468    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2365   the run_score was: 7.0   and mem length: 563755   eps: 0.0817631200085114    steps: 353    lr: 2.560000000000001e-06     eval rl_reward: 6.86\n","For episode: 2366   the run_score was: 9.0   and mem length: 564194   eps: 0.08089390000851199    steps: 439    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2367   the run_score was: 8.0   and mem length: 564569   eps: 0.0801514000085125    steps: 375    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2368   the run_score was: 6.0   and mem length: 564925   eps: 0.07944652000851297    steps: 356    lr: 2.560000000000001e-06     eval rl_reward: 6.88\n","For episode: 2369   the run_score was: 9.0   and mem length: 565397   eps: 0.07851196000851361    steps: 472    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2370   the run_score was: 7.0   and mem length: 565762   eps: 0.0777892600085141    steps: 365    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2371   the run_score was: 13.0   and mem length: 566302   eps: 0.07672006000851483    steps: 540    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2372   the run_score was: 4.0   and mem length: 566562   eps: 0.07620526000851519    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 6.96\n","For episode: 2373   the run_score was: 10.0   and mem length: 567069   eps: 0.07520140000851587    steps: 507    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2374   the run_score was: 7.0   and mem length: 567481   eps: 0.07438564000851643    steps: 412    lr: 2.560000000000001e-06     eval rl_reward: 6.95\n","For episode: 2375   the run_score was: 8.0   and mem length: 567875   eps: 0.07360552000851696    steps: 394    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2376   the run_score was: 8.0   and mem length: 568304   eps: 0.07275610000851754    steps: 429    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2377   the run_score was: 7.0   and mem length: 568710   eps: 0.07195222000851809    steps: 406    lr: 2.560000000000001e-06     eval rl_reward: 6.97\n","For episode: 2378   the run_score was: 4.0   and mem length: 568951   eps: 0.07147504000851841    steps: 241    lr: 2.560000000000001e-06     eval rl_reward: 6.97\n","For episode: 2379   the run_score was: 7.0   and mem length: 569320   eps: 0.07074442000851891    steps: 369    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2380   the run_score was: 4.0   and mem length: 569563   eps: 0.07026328000851924    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2381   the run_score was: 3.0   and mem length: 569777   eps: 0.06983956000851953    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.95\n","For episode: 2382   the run_score was: 7.0   and mem length: 570145   eps: 0.06911092000852002    steps: 368    lr: 2.560000000000001e-06     eval rl_reward: 6.91\n","For episode: 2383   the run_score was: 9.0   and mem length: 570603   eps: 0.06820408000852064    steps: 458    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2384   the run_score was: 7.0   and mem length: 570975   eps: 0.06746752000852115    steps: 372    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2385   the run_score was: 8.0   and mem length: 571394   eps: 0.06663790000852171    steps: 419    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2386   the run_score was: 9.0   and mem length: 571801   eps: 0.06583204000852226    steps: 407    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2387   the run_score was: 9.0   and mem length: 572268   eps: 0.06490738000852289    steps: 467    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2388   the run_score was: 6.0   and mem length: 572605   eps: 0.06424012000852335    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2389   the run_score was: 9.0   and mem length: 573083   eps: 0.06329368000852399    steps: 478    lr: 2.560000000000001e-06     eval rl_reward: 7.06\n","For episode: 2390   the run_score was: 10.0   and mem length: 573616   eps: 0.06223834000852471    steps: 533    lr: 2.560000000000001e-06     eval rl_reward: 7.1\n","For episode: 2391   the run_score was: 4.0   and mem length: 573859   eps: 0.06175720000852504    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 7.07\n","For episode: 2392   the run_score was: 6.0   and mem length: 574207   eps: 0.06106816000852551    steps: 348    lr: 2.560000000000001e-06     eval rl_reward: 7.04\n","For episode: 2393   the run_score was: 7.0   and mem length: 574636   eps: 0.06021874000852609    steps: 429    lr: 2.560000000000001e-06     eval rl_reward: 7.04\n","For episode: 2394   the run_score was: 3.0   and mem length: 574848   eps: 0.059798980008526376    steps: 212    lr: 2.560000000000001e-06     eval rl_reward: 7.03\n","For episode: 2395   the run_score was: 11.0   and mem length: 575247   eps: 0.059008960008526914    steps: 399    lr: 2.560000000000001e-06     eval rl_reward: 7.09\n","For episode: 2396   the run_score was: 6.0   and mem length: 575603   eps: 0.058304080008527395    steps: 356    lr: 2.560000000000001e-06     eval rl_reward: 7.05\n","For episode: 2397   the run_score was: 3.0   and mem length: 575832   eps: 0.057850660008527705    steps: 229    lr: 2.560000000000001e-06     eval rl_reward: 7.01\n","For episode: 2398   the run_score was: 8.0   and mem length: 576250   eps: 0.05702302000852827    steps: 418    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2399   the run_score was: 4.0   and mem length: 576542   eps: 0.05644486000852866    steps: 292    lr: 2.560000000000001e-06     eval rl_reward: 6.98\n","For episode: 2400   the run_score was: 10.0   and mem length: 577022   eps: 0.05549446000852931    steps: 480    lr: 2.560000000000001e-06     eval rl_reward: 7.0\n","For episode: 2401   the run_score was: 5.0   and mem length: 577329   eps: 0.054886600008529726    steps: 307    lr: 2.560000000000001e-06     eval rl_reward: 6.97\n","For episode: 2402   the run_score was: 5.0   and mem length: 577620   eps: 0.05431042000853012    steps: 291    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2403   the run_score was: 7.0   and mem length: 578011   eps: 0.05353624000853065    steps: 391    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2404   the run_score was: 3.0   and mem length: 578223   eps: 0.053116480008530934    steps: 212    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2405   the run_score was: 9.0   and mem length: 578744   eps: 0.05208490000853164    steps: 521    lr: 2.560000000000001e-06     eval rl_reward: 6.87\n","For episode: 2406   the run_score was: 8.0   and mem length: 579164   eps: 0.051253300008532204    steps: 420    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2407   the run_score was: 3.0   and mem length: 579378   eps: 0.05082958000853249    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2408   the run_score was: 7.0   and mem length: 579740   eps: 0.05011282000853298    steps: 362    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2409   the run_score was: 11.0   and mem length: 580252   eps: 0.049099060008533674    steps: 512    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2410   the run_score was: 10.0   and mem length: 580754   eps: 0.04810510000853435    steps: 502    lr: 2.560000000000001e-06     eval rl_reward: 6.95\n","For episode: 2411   the run_score was: 8.0   and mem length: 581183   eps: 0.04725568000853493    steps: 429    lr: 2.560000000000001e-06     eval rl_reward: 6.95\n","For episode: 2412   the run_score was: 5.0   and mem length: 581454   eps: 0.0467191000085353    steps: 271    lr: 2.560000000000001e-06     eval rl_reward: 6.96\n","For episode: 2413   the run_score was: 3.0   and mem length: 581666   eps: 0.04629934000853558    steps: 212    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2414   the run_score was: 7.0   and mem length: 582035   eps: 0.04556872000853608    steps: 369    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2415   the run_score was: 9.0   and mem length: 582517   eps: 0.04461436000853673    steps: 482    lr: 2.560000000000001e-06     eval rl_reward: 6.96\n","For episode: 2416   the run_score was: 5.0   and mem length: 582825   eps: 0.04400452000853715    steps: 308    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2417   the run_score was: 9.0   and mem length: 583245   eps: 0.043172920008537716    steps: 420    lr: 2.560000000000001e-06     eval rl_reward: 6.96\n","For episode: 2418   the run_score was: 5.0   and mem length: 583533   eps: 0.042602680008538105    steps: 288    lr: 2.560000000000001e-06     eval rl_reward: 6.94\n","For episode: 2419   the run_score was: 9.0   and mem length: 583993   eps: 0.041691880008538726    steps: 460    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2420   the run_score was: 8.0   and mem length: 584431   eps: 0.04082464000853932    steps: 438    lr: 2.560000000000001e-06     eval rl_reward: 6.93\n","For episode: 2421   the run_score was: 6.0   and mem length: 584785   eps: 0.040123720008539795    steps: 354    lr: 2.560000000000001e-06     eval rl_reward: 6.89\n","For episode: 2422   the run_score was: 5.0   and mem length: 585059   eps: 0.039581200008540166    steps: 274    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2423   the run_score was: 8.0   and mem length: 585498   eps: 0.03871198000854076    steps: 439    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2424   the run_score was: 5.0   and mem length: 585807   eps: 0.038100160008541176    steps: 309    lr: 2.560000000000001e-06     eval rl_reward: 6.8\n","For episode: 2425   the run_score was: 5.0   and mem length: 586097   eps: 0.03752596000854157    steps: 290    lr: 2.560000000000001e-06     eval rl_reward: 6.76\n","For episode: 2426   the run_score was: 7.0   and mem length: 586486   eps: 0.03675574000854209    steps: 389    lr: 2.560000000000001e-06     eval rl_reward: 6.74\n","For episode: 2427   the run_score was: 11.0   and mem length: 587041   eps: 0.03565684000854284    steps: 555    lr: 2.560000000000001e-06     eval rl_reward: 6.82\n","For episode: 2428   the run_score was: 3.0   and mem length: 587255   eps: 0.03523312000854313    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.81\n","For episode: 2429   the run_score was: 6.0   and mem length: 587594   eps: 0.03456190000854359    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.79\n","For episode: 2430   the run_score was: 6.0   and mem length: 587933   eps: 0.03389068000854405    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.8\n","For episode: 2431   the run_score was: 13.0   and mem length: 588446   eps: 0.03287494000854474    steps: 513    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2432   the run_score was: 3.0   and mem length: 588660   eps: 0.03245122000854503    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2433   the run_score was: 4.0   and mem length: 588903   eps: 0.03197008000854536    steps: 243    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2434   the run_score was: 8.0   and mem length: 589286   eps: 0.031211740008545874    steps: 383    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2435   the run_score was: 5.0   and mem length: 589560   eps: 0.030669220008546244    steps: 274    lr: 2.560000000000001e-06     eval rl_reward: 6.87\n","For episode: 2436   the run_score was: 6.0   and mem length: 589862   eps: 0.030071260008546652    steps: 302    lr: 2.560000000000001e-06     eval rl_reward: 6.88\n","For episode: 2437   the run_score was: 6.0   and mem length: 590199   eps: 0.029404000008547107    steps: 337    lr: 2.560000000000001e-06     eval rl_reward: 6.87\n","For episode: 2438   the run_score was: 6.0   and mem length: 590538   eps: 0.028732780008547565    steps: 339    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2439   the run_score was: 3.0   and mem length: 590752   eps: 0.028309060008547854    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.78\n","For episode: 2440   the run_score was: 6.0   and mem length: 591074   eps: 0.02767150000854829    steps: 322    lr: 2.560000000000001e-06     eval rl_reward: 6.79\n","For episode: 2441   the run_score was: 5.0   and mem length: 591400   eps: 0.02702602000854873    steps: 326    lr: 2.560000000000001e-06     eval rl_reward: 6.79\n","For episode: 2442   the run_score was: 13.0   and mem length: 591901   eps: 0.026034040008549406    steps: 501    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2443   the run_score was: 9.0   and mem length: 592346   eps: 0.025152940008550007    steps: 445    lr: 2.560000000000001e-06     eval rl_reward: 6.85\n","For episode: 2444   the run_score was: 3.0   and mem length: 592560   eps: 0.024729220008550296    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.81\n","For episode: 2445   the run_score was: 12.0   and mem length: 593059   eps: 0.02374120000855097    steps: 499    lr: 2.560000000000001e-06     eval rl_reward: 6.87\n","For episode: 2446   the run_score was: 4.0   and mem length: 593319   eps: 0.02322640000855132    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 6.88\n","For episode: 2447   the run_score was: 8.0   and mem length: 593718   eps: 0.02243638000855186    steps: 399    lr: 2.560000000000001e-06     eval rl_reward: 6.92\n","For episode: 2448   the run_score was: 4.0   and mem length: 593976   eps: 0.021925540008552208    steps: 258    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2449   the run_score was: 8.0   and mem length: 594407   eps: 0.02107216000855279    steps: 431    lr: 2.560000000000001e-06     eval rl_reward: 6.9\n","For episode: 2450   the run_score was: 7.0   and mem length: 594812   eps: 0.020270260008553337    steps: 405    lr: 2.560000000000001e-06     eval rl_reward: 6.87\n","For episode: 2451   the run_score was: 5.0   and mem length: 595120   eps: 0.019660420008553753    steps: 308    lr: 2.560000000000001e-06     eval rl_reward: 6.84\n","For episode: 2452   the run_score was: 4.0   and mem length: 595380   eps: 0.019145620008554104    steps: 260    lr: 2.560000000000001e-06     eval rl_reward: 6.73\n","For episode: 2453   the run_score was: 5.0   and mem length: 595706   eps: 0.018500140008554544    steps: 326    lr: 2.560000000000001e-06     eval rl_reward: 6.73\n","For episode: 2454   the run_score was: 9.0   and mem length: 596199   eps: 0.01752400000855521    steps: 493    lr: 2.560000000000001e-06     eval rl_reward: 6.75\n","For episode: 2455   the run_score was: 6.0   and mem length: 596504   eps: 0.016920100008555622    steps: 305    lr: 2.560000000000001e-06     eval rl_reward: 6.71\n","For episode: 2456   the run_score was: 3.0   and mem length: 596718   eps: 0.01649638000855591    steps: 214    lr: 2.560000000000001e-06     eval rl_reward: 6.67\n","For episode: 2457   the run_score was: 10.0   and mem length: 597196   eps: 0.01554994000855649    steps: 478    lr: 2.560000000000001e-06     eval rl_reward: 6.69\n","For episode: 2458   the run_score was: 7.0   and mem length: 597532   eps: 0.014884660008556361    steps: 336    lr: 2.560000000000001e-06     eval rl_reward: 6.69\n","For episode: 2459   the run_score was: 10.0   and mem length: 597924   eps: 0.01410850000855621    steps: 392    lr: 2.560000000000001e-06     eval rl_reward: 6.72\n","For episode: 2460   the run_score was: 5.0   and mem length: 598256   eps: 0.013451140008556083    steps: 332    lr: 2.560000000000001e-06     eval rl_reward: 6.73\n","For episode: 2461   the run_score was: 9.0   and mem length: 598724   eps: 0.012524500008555903    steps: 468    lr: 2.560000000000001e-06     eval rl_reward: 6.79\n","For episode: 2462   the run_score was: 6.0   and mem length: 599036   eps: 0.011906740008555784    steps: 312    lr: 2.560000000000001e-06     eval rl_reward: 6.81\n","For episode: 2463   the run_score was: 7.0   and mem length: 599444   eps: 0.011098900008555627    steps: 408    lr: 2.560000000000001e-06     eval rl_reward: 6.83\n","For episode: 2464   the run_score was: 11.0   and mem length: 600004   eps: 0.009998020008555413    steps: 560    lr: 1.0240000000000005e-06     eval rl_reward: 6.85\n","For episode: 2465   the run_score was: 6.0   and mem length: 600306   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 6.84\n","For episode: 2466   the run_score was: 10.0   and mem length: 600776   eps: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     eval rl_reward: 6.85\n","For episode: 2467   the run_score was: 12.0   and mem length: 601319   eps: 0.009998020008555413    steps: 543    lr: 1.0240000000000005e-06     eval rl_reward: 6.89\n","For episode: 2468   the run_score was: 7.0   and mem length: 601708   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.9\n","For episode: 2469   the run_score was: 3.0   and mem length: 601922   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.84\n","For episode: 2470   the run_score was: 12.0   and mem length: 602340   eps: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     eval rl_reward: 6.89\n","For episode: 2471   the run_score was: 10.0   and mem length: 602843   eps: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     eval rl_reward: 6.86\n","For episode: 2472   the run_score was: 7.0   and mem length: 603251   eps: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     eval rl_reward: 6.89\n","For episode: 2473   the run_score was: 3.0   and mem length: 603465   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.82\n","For episode: 2474   the run_score was: 5.0   and mem length: 603772   eps: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     eval rl_reward: 6.8\n","For episode: 2475   the run_score was: 6.0   and mem length: 604126   eps: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2476   the run_score was: 5.0   and mem length: 604421   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 6.75\n","For episode: 2477   the run_score was: 5.0   and mem length: 604728   eps: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2478   the run_score was: 4.0   and mem length: 604973   eps: 0.009998020008555413    steps: 245    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2479   the run_score was: 6.0   and mem length: 605275   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 6.72\n","For episode: 2480   the run_score was: 7.0   and mem length: 605682   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 6.75\n","For episode: 2481   the run_score was: 7.0   and mem length: 606070   eps: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     eval rl_reward: 6.79\n","For episode: 2482   the run_score was: 10.0   and mem length: 606590   eps: 0.009998020008555413    steps: 520    lr: 1.0240000000000005e-06     eval rl_reward: 6.82\n","For episode: 2483   the run_score was: 8.0   and mem length: 606981   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 6.81\n","For episode: 2484   the run_score was: 8.0   and mem length: 607391   eps: 0.009998020008555413    steps: 410    lr: 1.0240000000000005e-06     eval rl_reward: 6.82\n","For episode: 2485   the run_score was: 8.0   and mem length: 607828   eps: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     eval rl_reward: 6.82\n","For episode: 2486   the run_score was: 5.0   and mem length: 608137   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2487   the run_score was: 8.0   and mem length: 608571   eps: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2488   the run_score was: 7.0   and mem length: 608959   eps: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2489   the run_score was: 4.0   and mem length: 609219   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2490   the run_score was: 4.0   and mem length: 609462   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.67\n","For episode: 2491   the run_score was: 3.0   and mem length: 609676   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2492   the run_score was: 8.0   and mem length: 610069   eps: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     eval rl_reward: 6.68\n","For episode: 2493   the run_score was: 7.0   and mem length: 610455   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 6.68\n","For episode: 2494   the run_score was: 8.0   and mem length: 610878   eps: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2495   the run_score was: 7.0   and mem length: 611249   eps: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     eval rl_reward: 6.69\n","For episode: 2496   the run_score was: 3.0   and mem length: 611463   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2497   the run_score was: 3.0   and mem length: 611677   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2498   the run_score was: 5.0   and mem length: 611972   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 6.63\n","For episode: 2499   the run_score was: 3.0   and mem length: 612186   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.62\n","For episode: 2500   the run_score was: 8.0   and mem length: 612624   eps: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     eval rl_reward: 6.6\n","For episode: 2501   the run_score was: 17.0   and mem length: 613262   eps: 0.009998020008555413    steps: 638    lr: 1.0240000000000005e-06     eval rl_reward: 6.72\n","For episode: 2502   the run_score was: 11.0   and mem length: 613769   eps: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2503   the run_score was: 3.0   and mem length: 613983   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.74\n","For episode: 2504   the run_score was: 6.0   and mem length: 614342   eps: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2505   the run_score was: 3.0   and mem length: 614556   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.71\n","For episode: 2506   the run_score was: 4.0   and mem length: 614799   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.67\n","For episode: 2507   the run_score was: 4.0   and mem length: 615059   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.68\n","For episode: 2508   the run_score was: 5.0   and mem length: 615369   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2509   the run_score was: 7.0   and mem length: 615742   eps: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     eval rl_reward: 6.62\n","For episode: 2510   the run_score was: 4.0   and mem length: 616002   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.56\n","For episode: 2511   the run_score was: 7.0   and mem length: 616372   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 6.55\n","For episode: 2512   the run_score was: 4.0   and mem length: 616615   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.54\n","For episode: 2513   the run_score was: 6.0   and mem length: 616953   eps: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     eval rl_reward: 6.57\n","For episode: 2514   the run_score was: 5.0   and mem length: 617262   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 6.55\n","For episode: 2515   the run_score was: 7.0   and mem length: 617648   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 6.53\n","For episode: 2516   the run_score was: 6.0   and mem length: 617950   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 6.54\n","For episode: 2517   the run_score was: 5.0   and mem length: 618243   eps: 0.009998020008555413    steps: 293    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2518   the run_score was: 3.0   and mem length: 618457   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.48\n","For episode: 2519   the run_score was: 10.0   and mem length: 618989   eps: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     eval rl_reward: 6.49\n","For episode: 2520   the run_score was: 3.0   and mem length: 619203   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.44\n","For episode: 2521   the run_score was: 5.0   and mem length: 619513   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.43\n","For episode: 2522   the run_score was: 9.0   and mem length: 619971   eps: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     eval rl_reward: 6.47\n","For episode: 2523   the run_score was: 3.0   and mem length: 620185   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.42\n","For episode: 2524   the run_score was: 5.0   and mem length: 620492   eps: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     eval rl_reward: 6.42\n","For episode: 2525   the run_score was: 8.0   and mem length: 620930   eps: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     eval rl_reward: 6.45\n","For episode: 2526   the run_score was: 4.0   and mem length: 621173   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.42\n","For episode: 2527   the run_score was: 6.0   and mem length: 621512   eps: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     eval rl_reward: 6.37\n","For episode: 2528   the run_score was: 8.0   and mem length: 621930   eps: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     eval rl_reward: 6.42\n","For episode: 2529   the run_score was: 5.0   and mem length: 622240   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.41\n","For episode: 2530   the run_score was: 5.0   and mem length: 622530   eps: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     eval rl_reward: 6.4\n","For episode: 2531   the run_score was: 5.0   and mem length: 622839   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 6.32\n","For episode: 2532   the run_score was: 5.0   and mem length: 623146   eps: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     eval rl_reward: 6.34\n","For episode: 2533   the run_score was: 9.0   and mem length: 623630   eps: 0.009998020008555413    steps: 484    lr: 1.0240000000000005e-06     eval rl_reward: 6.39\n","For episode: 2534   the run_score was: 4.0   and mem length: 623873   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.35\n","For episode: 2535   the run_score was: 7.0   and mem length: 624276   eps: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     eval rl_reward: 6.37\n","For episode: 2536   the run_score was: 9.0   and mem length: 624697   eps: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     eval rl_reward: 6.4\n","For episode: 2537   the run_score was: 7.0   and mem length: 625083   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 6.41\n","For episode: 2538   the run_score was: 15.0   and mem length: 625664   eps: 0.009998020008555413    steps: 581    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2539   the run_score was: 10.0   and mem length: 626168   eps: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     eval rl_reward: 6.57\n","For episode: 2540   the run_score was: 10.0   and mem length: 626676   eps: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     eval rl_reward: 6.61\n","For episode: 2541   the run_score was: 8.0   and mem length: 627112   eps: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     eval rl_reward: 6.64\n","For episode: 2542   the run_score was: 7.0   and mem length: 627474   eps: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     eval rl_reward: 6.58\n","For episode: 2543   the run_score was: 8.0   and mem length: 627885   eps: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     eval rl_reward: 6.57\n","For episode: 2544   the run_score was: 9.0   and mem length: 628353   eps: 0.009998020008555413    steps: 468    lr: 1.0240000000000005e-06     eval rl_reward: 6.63\n","For episode: 2545   the run_score was: 8.0   and mem length: 628744   eps: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     eval rl_reward: 6.59\n","For episode: 2546   the run_score was: 6.0   and mem length: 629103   eps: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     eval rl_reward: 6.61\n","For episode: 2547   the run_score was: 10.0   and mem length: 629554   eps: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     eval rl_reward: 6.63\n","For episode: 2548   the run_score was: 5.0   and mem length: 629844   eps: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     eval rl_reward: 6.64\n","For episode: 2549   the run_score was: 6.0   and mem length: 630146   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 6.62\n","For episode: 2550   the run_score was: 11.0   and mem length: 630716   eps: 0.009998020008555413    steps: 570    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2551   the run_score was: 10.0   and mem length: 631229   eps: 0.009998020008555413    steps: 513    lr: 1.0240000000000005e-06     eval rl_reward: 6.71\n","For episode: 2552   the run_score was: 11.0   and mem length: 631632   eps: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2553   the run_score was: 4.0   and mem length: 631892   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2554   the run_score was: 8.0   and mem length: 632269   eps: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     eval rl_reward: 6.76\n","For episode: 2555   the run_score was: 7.0   and mem length: 632649   eps: 0.009998020008555413    steps: 380    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2556   the run_score was: 4.0   and mem length: 632909   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2557   the run_score was: 5.0   and mem length: 633199   eps: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2558   the run_score was: 11.0   and mem length: 633609   eps: 0.009998020008555413    steps: 410    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2559   the run_score was: 5.0   and mem length: 633902   eps: 0.009998020008555413    steps: 293    lr: 1.0240000000000005e-06     eval rl_reward: 6.72\n","For episode: 2560   the run_score was: 5.0   and mem length: 634193   eps: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     eval rl_reward: 6.72\n","For episode: 2561   the run_score was: 5.0   and mem length: 634467   eps: 0.009998020008555413    steps: 274    lr: 1.0240000000000005e-06     eval rl_reward: 6.68\n","For episode: 2562   the run_score was: 11.0   and mem length: 634866   eps: 0.009998020008555413    steps: 399    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2563   the run_score was: 10.0   and mem length: 635373   eps: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     eval rl_reward: 6.76\n","For episode: 2564   the run_score was: 4.0   and mem length: 635633   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.69\n","For episode: 2565   the run_score was: 4.0   and mem length: 635893   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.67\n","For episode: 2566   the run_score was: 3.0   and mem length: 636107   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.6\n","For episode: 2567   the run_score was: 3.0   and mem length: 636336   eps: 0.009998020008555413    steps: 229    lr: 1.0240000000000005e-06     eval rl_reward: 6.51\n","For episode: 2568   the run_score was: 5.0   and mem length: 636610   eps: 0.009998020008555413    steps: 274    lr: 1.0240000000000005e-06     eval rl_reward: 6.49\n","For episode: 2569   the run_score was: 9.0   and mem length: 637084   eps: 0.009998020008555413    steps: 474    lr: 1.0240000000000005e-06     eval rl_reward: 6.55\n","For episode: 2570   the run_score was: 7.0   and mem length: 637474   eps: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2571   the run_score was: 5.0   and mem length: 637765   eps: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     eval rl_reward: 6.45\n","For episode: 2572   the run_score was: 12.0   and mem length: 638206   eps: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2573   the run_score was: 11.0   and mem length: 638762   eps: 0.009998020008555413    steps: 556    lr: 1.0240000000000005e-06     eval rl_reward: 6.58\n","For episode: 2574   the run_score was: 10.0   and mem length: 639265   eps: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     eval rl_reward: 6.63\n","For episode: 2575   the run_score was: 9.0   and mem length: 639716   eps: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2576   the run_score was: 5.0   and mem length: 640006   eps: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     eval rl_reward: 6.66\n","For episode: 2577   the run_score was: 8.0   and mem length: 640448   eps: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     eval rl_reward: 6.69\n","For episode: 2578   the run_score was: 5.0   and mem length: 640737   eps: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     eval rl_reward: 6.7\n","For episode: 2579   the run_score was: 7.0   and mem length: 641091   eps: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     eval rl_reward: 6.71\n","For episode: 2580   the run_score was: 12.0   and mem length: 641517   eps: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     eval rl_reward: 6.76\n","For episode: 2581   the run_score was: 9.0   and mem length: 641998   eps: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2582   the run_score was: 10.0   and mem length: 642481   eps: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2583   the run_score was: 7.0   and mem length: 642870   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2584   the run_score was: 7.0   and mem length: 643221   eps: 0.009998020008555413    steps: 351    lr: 1.0240000000000005e-06     eval rl_reward: 6.76\n","For episode: 2585   the run_score was: 7.0   and mem length: 643621   eps: 0.009998020008555413    steps: 400    lr: 1.0240000000000005e-06     eval rl_reward: 6.75\n","For episode: 2586   the run_score was: 7.0   and mem length: 644010   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.77\n","For episode: 2587   the run_score was: 7.0   and mem length: 644399   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.76\n","For episode: 2588   the run_score was: 5.0   and mem length: 644708   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 6.74\n","For episode: 2589   the run_score was: 8.0   and mem length: 645123   eps: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2590   the run_score was: 7.0   and mem length: 645493   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 6.81\n","For episode: 2591   the run_score was: 8.0   and mem length: 645886   eps: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     eval rl_reward: 6.86\n","For episode: 2592   the run_score was: 12.0   and mem length: 646291   eps: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     eval rl_reward: 6.9\n","For episode: 2593   the run_score was: 11.0   and mem length: 646676   eps: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     eval rl_reward: 6.94\n","For episode: 2594   the run_score was: 7.0   and mem length: 647012   eps: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     eval rl_reward: 6.93\n","For episode: 2595   the run_score was: 7.0   and mem length: 647401   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.93\n","For episode: 2596   the run_score was: 7.0   and mem length: 647737   eps: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     eval rl_reward: 6.97\n","For episode: 2597   the run_score was: 5.0   and mem length: 648011   eps: 0.009998020008555413    steps: 274    lr: 1.0240000000000005e-06     eval rl_reward: 6.99\n","For episode: 2598   the run_score was: 8.0   and mem length: 648422   eps: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     eval rl_reward: 7.02\n","For episode: 2599   the run_score was: 7.0   and mem length: 648843   eps: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     eval rl_reward: 7.06\n","For episode: 2600   the run_score was: 3.0   and mem length: 649057   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.01\n","For episode: 2601   the run_score was: 15.0   and mem length: 649629   eps: 0.009998020008555413    steps: 572    lr: 1.0240000000000005e-06     eval rl_reward: 6.99\n","For episode: 2602   the run_score was: 7.0   and mem length: 649997   eps: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     eval rl_reward: 6.95\n","For episode: 2603   the run_score was: 12.0   and mem length: 650404   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 7.04\n","For episode: 2604   the run_score was: 6.0   and mem length: 650767   eps: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     eval rl_reward: 7.04\n","For episode: 2605   the run_score was: 3.0   and mem length: 650981   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.04\n","For episode: 2606   the run_score was: 3.0   and mem length: 651195   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.03\n","For episode: 2607   the run_score was: 8.0   and mem length: 651632   eps: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     eval rl_reward: 7.07\n","For episode: 2608   the run_score was: 10.0   and mem length: 652122   eps: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     eval rl_reward: 7.12\n","For episode: 2609   the run_score was: 11.0   and mem length: 652682   eps: 0.009998020008555413    steps: 560    lr: 1.0240000000000005e-06     eval rl_reward: 7.16\n","For episode: 2610   the run_score was: 7.0   and mem length: 653068   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2611   the run_score was: 6.0   and mem length: 653428   eps: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     eval rl_reward: 7.18\n","For episode: 2612   the run_score was: 4.0   and mem length: 653671   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 7.18\n","For episode: 2613   the run_score was: 7.0   and mem length: 654063   eps: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2614   the run_score was: 5.0   and mem length: 654358   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2615   the run_score was: 5.0   and mem length: 654653   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 7.17\n","For episode: 2616   the run_score was: 3.0   and mem length: 654867   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.14\n","For episode: 2617   the run_score was: 6.0   and mem length: 655188   eps: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     eval rl_reward: 7.15\n","For episode: 2618   the run_score was: 3.0   and mem length: 655402   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.15\n","For episode: 2619   the run_score was: 5.0   and mem length: 655675   eps: 0.009998020008555413    steps: 273    lr: 1.0240000000000005e-06     eval rl_reward: 7.1\n","For episode: 2620   the run_score was: 8.0   and mem length: 656094   eps: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     eval rl_reward: 7.15\n","For episode: 2621   the run_score was: 6.0   and mem length: 656409   eps: 0.009998020008555413    steps: 315    lr: 1.0240000000000005e-06     eval rl_reward: 7.16\n","For episode: 2622   the run_score was: 7.0   and mem length: 656795   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 7.14\n","For episode: 2623   the run_score was: 5.0   and mem length: 657090   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 7.16\n","For episode: 2624   the run_score was: 10.0   and mem length: 657594   eps: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     eval rl_reward: 7.21\n","For episode: 2625   the run_score was: 6.0   and mem length: 657896   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2626   the run_score was: 8.0   and mem length: 658303   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 7.23\n","For episode: 2627   the run_score was: 18.0   and mem length: 658817   eps: 0.009998020008555413    steps: 514    lr: 1.0240000000000005e-06     eval rl_reward: 7.35\n","For episode: 2628   the run_score was: 11.0   and mem length: 659241   eps: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     eval rl_reward: 7.38\n","For episode: 2629   the run_score was: 5.0   and mem length: 659536   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 7.38\n","For episode: 2630   the run_score was: 7.0   and mem length: 659887   eps: 0.009998020008555413    steps: 351    lr: 1.0240000000000005e-06     eval rl_reward: 7.4\n","For episode: 2631   the run_score was: 6.0   and mem length: 660189   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 7.41\n","For episode: 2632   the run_score was: 7.0   and mem length: 660559   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 7.43\n","For episode: 2633   the run_score was: 7.0   and mem length: 660921   eps: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     eval rl_reward: 7.41\n","For episode: 2634   the run_score was: 3.0   and mem length: 661135   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.4\n","For episode: 2635   the run_score was: 5.0   and mem length: 661466   eps: 0.009998020008555413    steps: 331    lr: 1.0240000000000005e-06     eval rl_reward: 7.38\n","For episode: 2636   the run_score was: 7.0   and mem length: 661820   eps: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     eval rl_reward: 7.36\n","For episode: 2637   the run_score was: 3.0   and mem length: 662034   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.32\n","For episode: 2638   the run_score was: 4.0   and mem length: 662277   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 7.21\n","For episode: 2639   the run_score was: 6.0   and mem length: 662592   eps: 0.009998020008555413    steps: 315    lr: 1.0240000000000005e-06     eval rl_reward: 7.17\n","For episode: 2640   the run_score was: 12.0   and mem length: 662999   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2641   the run_score was: 12.0   and mem length: 663406   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 7.23\n","For episode: 2642   the run_score was: 4.0   and mem length: 663666   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 7.2\n","For episode: 2643   the run_score was: 7.0   and mem length: 664055   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 7.19\n","For episode: 2644   the run_score was: 5.0   and mem length: 664364   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 7.15\n","For episode: 2645   the run_score was: 3.0   and mem length: 664578   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.1\n","For episode: 2646   the run_score was: 9.0   and mem length: 664926   eps: 0.009998020008555413    steps: 348    lr: 1.0240000000000005e-06     eval rl_reward: 7.13\n","For episode: 2647   the run_score was: 5.0   and mem length: 665217   eps: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     eval rl_reward: 7.08\n","For episode: 2648   the run_score was: 3.0   and mem length: 665431   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 7.06\n","For episode: 2649   the run_score was: 10.0   and mem length: 665950   eps: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     eval rl_reward: 7.1\n","For episode: 2650   the run_score was: 4.0   and mem length: 666210   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 7.03\n","For episode: 2651   the run_score was: 3.0   and mem length: 666441   eps: 0.009998020008555413    steps: 231    lr: 1.0240000000000005e-06     eval rl_reward: 6.96\n","For episode: 2652   the run_score was: 4.0   and mem length: 666684   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.89\n","For episode: 2653   the run_score was: 3.0   and mem length: 666898   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.88\n","For episode: 2654   the run_score was: 10.0   and mem length: 667396   eps: 0.009998020008555413    steps: 498    lr: 1.0240000000000005e-06     eval rl_reward: 6.9\n","For episode: 2655   the run_score was: 4.0   and mem length: 667656   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.87\n","For episode: 2656   the run_score was: 5.0   and mem length: 667966   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.88\n","For episode: 2657   the run_score was: 4.0   and mem length: 668226   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.87\n","For episode: 2658   the run_score was: 7.0   and mem length: 668605   eps: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     eval rl_reward: 6.83\n","For episode: 2659   the run_score was: 13.0   and mem length: 669057   eps: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     eval rl_reward: 6.91\n","For episode: 2660   the run_score was: 4.0   and mem length: 669317   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.9\n","For episode: 2661   the run_score was: 7.0   and mem length: 669687   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 6.92\n","For episode: 2662   the run_score was: 4.0   and mem length: 669947   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.85\n","For episode: 2663   the run_score was: 6.0   and mem length: 670308   eps: 0.009998020008555413    steps: 361    lr: 1.0240000000000005e-06     eval rl_reward: 6.81\n","For episode: 2664   the run_score was: 10.0   and mem length: 670814   eps: 0.009998020008555413    steps: 506    lr: 1.0240000000000005e-06     eval rl_reward: 6.87\n","For episode: 2665   the run_score was: 6.0   and mem length: 671135   eps: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     eval rl_reward: 6.89\n","For episode: 2666   the run_score was: 9.0   and mem length: 671604   eps: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     eval rl_reward: 6.95\n","For episode: 2667   the run_score was: 5.0   and mem length: 671894   eps: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     eval rl_reward: 6.97\n","For episode: 2668   the run_score was: 7.0   and mem length: 672280   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 6.99\n","For episode: 2669   the run_score was: 5.0   and mem length: 672554   eps: 0.009998020008555413    steps: 274    lr: 1.0240000000000005e-06     eval rl_reward: 6.95\n","For episode: 2670   the run_score was: 3.0   and mem length: 672768   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.91\n","For episode: 2671   the run_score was: 6.0   and mem length: 673070   eps: 0.009998020008555413    steps: 302    lr: 1.0240000000000005e-06     eval rl_reward: 6.92\n","For episode: 2672   the run_score was: 4.0   and mem length: 673313   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.84\n","For episode: 2673   the run_score was: 8.0   and mem length: 673757   eps: 0.009998020008555413    steps: 444    lr: 1.0240000000000005e-06     eval rl_reward: 6.81\n","For episode: 2674   the run_score was: 12.0   and mem length: 674164   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 6.83\n","For episode: 2675   the run_score was: 6.0   and mem length: 674479   eps: 0.009998020008555413    steps: 315    lr: 1.0240000000000005e-06     eval rl_reward: 6.8\n","For episode: 2676   the run_score was: 3.0   and mem length: 674693   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.78\n","For episode: 2677   the run_score was: 3.0   and mem length: 674907   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.73\n","For episode: 2678   the run_score was: 3.0   and mem length: 675121   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.71\n","For episode: 2679   the run_score was: 5.0   and mem length: 675430   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 6.69\n","For episode: 2680   the run_score was: 6.0   and mem length: 675788   eps: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     eval rl_reward: 6.63\n","For episode: 2681   the run_score was: 5.0   and mem length: 676098   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.59\n","For episode: 2682   the run_score was: 3.0   and mem length: 676312   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.52\n","For episode: 2683   the run_score was: 5.0   and mem length: 676603   eps: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2684   the run_score was: 7.0   and mem length: 676992   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2685   the run_score was: 7.0   and mem length: 677378   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 6.5\n","For episode: 2686   the run_score was: 4.0   and mem length: 677638   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.47\n","For episode: 2687   the run_score was: 4.0   and mem length: 677881   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.44\n","For episode: 2688   the run_score was: 6.0   and mem length: 678184   eps: 0.009998020008555413    steps: 303    lr: 1.0240000000000005e-06     eval rl_reward: 6.45\n","For episode: 2689   the run_score was: 3.0   and mem length: 678398   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.4\n","For episode: 2690   the run_score was: 4.0   and mem length: 678641   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.37\n","For episode: 2691   the run_score was: 4.0   and mem length: 678884   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.33\n","For episode: 2692   the run_score was: 8.0   and mem length: 679301   eps: 0.009998020008555413    steps: 417    lr: 1.0240000000000005e-06     eval rl_reward: 6.29\n","For episode: 2693   the run_score was: 4.0   and mem length: 679544   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.22\n","For episode: 2694   the run_score was: 3.0   and mem length: 679758   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.18\n","For episode: 2695   the run_score was: 3.0   and mem length: 679972   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.14\n","For episode: 2696   the run_score was: 11.0   and mem length: 680380   eps: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     eval rl_reward: 6.18\n","For episode: 2697   the run_score was: 3.0   and mem length: 680594   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.16\n","For episode: 2698   the run_score was: 5.0   and mem length: 680905   eps: 0.009998020008555413    steps: 311    lr: 1.0240000000000005e-06     eval rl_reward: 6.13\n","For episode: 2699   the run_score was: 5.0   and mem length: 681200   eps: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     eval rl_reward: 6.11\n","For episode: 2700   the run_score was: 3.0   and mem length: 681414   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.11\n","For episode: 2701   the run_score was: 3.0   and mem length: 681628   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 5.99\n","For episode: 2702   the run_score was: 5.0   and mem length: 681937   eps: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     eval rl_reward: 5.97\n","For episode: 2703   the run_score was: 13.0   and mem length: 682431   eps: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     eval rl_reward: 5.98\n","For episode: 2704   the run_score was: 8.0   and mem length: 682865   eps: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     eval rl_reward: 6.0\n","For episode: 2705   the run_score was: 4.0   and mem length: 683125   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.01\n","For episode: 2706   the run_score was: 5.0   and mem length: 683435   eps: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     eval rl_reward: 6.03\n","For episode: 2707   the run_score was: 4.0   and mem length: 683695   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 5.99\n","For episode: 2708   the run_score was: 6.0   and mem length: 684000   eps: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     eval rl_reward: 5.95\n","For episode: 2709   the run_score was: 8.0   and mem length: 684393   eps: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     eval rl_reward: 5.92\n","For episode: 2710   the run_score was: 11.0   and mem length: 684771   eps: 0.009998020008555413    steps: 378    lr: 1.0240000000000005e-06     eval rl_reward: 5.96\n","For episode: 2711   the run_score was: 5.0   and mem length: 685079   eps: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     eval rl_reward: 5.95\n","For episode: 2712   the run_score was: 4.0   and mem length: 685322   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 5.95\n","For episode: 2713   the run_score was: 5.0   and mem length: 685630   eps: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     eval rl_reward: 5.93\n","For episode: 2714   the run_score was: 7.0   and mem length: 686019   eps: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     eval rl_reward: 5.95\n","For episode: 2715   the run_score was: 7.0   and mem length: 686405   eps: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     eval rl_reward: 5.97\n","For episode: 2716   the run_score was: 10.0   and mem length: 686912   eps: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     eval rl_reward: 6.04\n","For episode: 2717   the run_score was: 17.0   and mem length: 687542   eps: 0.009998020008555413    steps: 630    lr: 1.0240000000000005e-06     eval rl_reward: 6.15\n","For episode: 2718   the run_score was: 7.0   and mem length: 687901   eps: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     eval rl_reward: 6.19\n","For episode: 2719   the run_score was: 11.0   and mem length: 688308   eps: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     eval rl_reward: 6.25\n","For episode: 2720   the run_score was: 10.0   and mem length: 688657   eps: 0.009998020008555413    steps: 349    lr: 1.0240000000000005e-06     eval rl_reward: 6.27\n","For episode: 2721   the run_score was: 8.0   and mem length: 689091   eps: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     eval rl_reward: 6.29\n","For episode: 2722   the run_score was: 4.0   and mem length: 689351   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.26\n","For episode: 2723   the run_score was: 8.0   and mem length: 689744   eps: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     eval rl_reward: 6.29\n","For episode: 2724   the run_score was: 7.0   and mem length: 690114   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 6.26\n","For episode: 2725   the run_score was: 10.0   and mem length: 690593   eps: 0.009998020008555413    steps: 479    lr: 1.0240000000000005e-06     eval rl_reward: 6.3\n","For episode: 2726   the run_score was: 6.0   and mem length: 690931   eps: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     eval rl_reward: 6.28\n","For episode: 2727   the run_score was: 7.0   and mem length: 691301   eps: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     eval rl_reward: 6.17\n","For episode: 2728   the run_score was: 8.0   and mem length: 691742   eps: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     eval rl_reward: 6.14\n","For episode: 2729   the run_score was: 4.0   and mem length: 692002   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.13\n","For episode: 2730   the run_score was: 11.0   and mem length: 692532   eps: 0.009998020008555413    steps: 530    lr: 1.0240000000000005e-06     eval rl_reward: 6.17\n","For episode: 2731   the run_score was: 4.0   and mem length: 692793   eps: 0.009998020008555413    steps: 261    lr: 1.0240000000000005e-06     eval rl_reward: 6.15\n","For episode: 2732   the run_score was: 4.0   and mem length: 693036   eps: 0.009998020008555413    steps: 243    lr: 1.0240000000000005e-06     eval rl_reward: 6.12\n","For episode: 2733   the run_score was: 7.0   and mem length: 693442   eps: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     eval rl_reward: 6.12\n","For episode: 2734   the run_score was: 8.0   and mem length: 693858   eps: 0.009998020008555413    steps: 416    lr: 1.0240000000000005e-06     eval rl_reward: 6.17\n","For episode: 2735   the run_score was: 4.0   and mem length: 694118   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.16\n","For episode: 2736   the run_score was: 8.0   and mem length: 694505   eps: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     eval rl_reward: 6.17\n","For episode: 2737   the run_score was: 4.0   and mem length: 694765   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.18\n","For episode: 2738   the run_score was: 6.0   and mem length: 695070   eps: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     eval rl_reward: 6.2\n","For episode: 2739   the run_score was: 3.0   and mem length: 695284   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.17\n","For episode: 2740   the run_score was: 7.0   and mem length: 695672   eps: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     eval rl_reward: 6.12\n","For episode: 2741   the run_score was: 4.0   and mem length: 695932   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.04\n","For episode: 2742   the run_score was: 7.0   and mem length: 696294   eps: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     eval rl_reward: 6.07\n","For episode: 2743   the run_score was: 3.0   and mem length: 696508   eps: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     eval rl_reward: 6.03\n","For episode: 2744   the run_score was: 4.0   and mem length: 696768   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.02\n","For episode: 2745   the run_score was: 12.0   and mem length: 697197   eps: 0.009998020008555413    steps: 429    lr: 1.0240000000000005e-06     eval rl_reward: 6.11\n","For episode: 2746   the run_score was: 12.0   and mem length: 697626   eps: 0.009998020008555413    steps: 429    lr: 1.0240000000000005e-06     eval rl_reward: 6.14\n","For episode: 2747   the run_score was: 7.0   and mem length: 697995   eps: 0.009998020008555413    steps: 369    lr: 1.0240000000000005e-06     eval rl_reward: 6.16\n","For episode: 2748   the run_score was: 7.0   and mem length: 698331   eps: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     eval rl_reward: 6.2\n","For episode: 2749   the run_score was: 11.0   and mem length: 698753   eps: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     eval rl_reward: 6.21\n","For episode: 2750   the run_score was: 4.0   and mem length: 699013   eps: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     eval rl_reward: 6.21\n","For episode: 2751   the run_score was: 7.0   and mem length: 699372   eps: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     eval rl_reward: 6.25\n","For episode: 2752   the run_score was: 10.0   and mem length: 699817   eps: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     eval rl_reward: 6.31\n","For episode: 2753   the run_score was: 8.0   and mem length: 700200   eps: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     eval rl_reward: 6.36\n","For episode: 2754   the run_score was: 3.0   and mem length: 700431   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2755   the run_score was: 6.0   and mem length: 700772   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 6.31\n","For episode: 2756   the run_score was: 4.0   and mem length: 701032   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2757   the run_score was: 8.0   and mem length: 701448   eps: 0.009998020008555413    steps: 416    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2758   the run_score was: 6.0   and mem length: 701802   eps: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     eval rl_reward: 6.33\n","For episode: 2759   the run_score was: 7.0   and mem length: 702188   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.27\n","For episode: 2760   the run_score was: 7.0   and mem length: 702558   eps: 0.009998020008555413    steps: 370    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2761   the run_score was: 7.0   and mem length: 702920   eps: 0.009998020008555413    steps: 362    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2762   the run_score was: 7.0   and mem length: 703287   eps: 0.009998020008555413    steps: 367    lr: 4.0960000000000023e-07     eval rl_reward: 6.33\n","For episode: 2763   the run_score was: 7.0   and mem length: 703678   eps: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2764   the run_score was: 4.0   and mem length: 703938   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.28\n","For episode: 2765   the run_score was: 11.0   and mem length: 704469   eps: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     eval rl_reward: 6.33\n","For episode: 2766   the run_score was: 8.0   and mem length: 704885   eps: 0.009998020008555413    steps: 416    lr: 4.0960000000000023e-07     eval rl_reward: 6.32\n","For episode: 2767   the run_score was: 4.0   and mem length: 705145   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.31\n","For episode: 2768   the run_score was: 7.0   and mem length: 705553   eps: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     eval rl_reward: 6.31\n","For episode: 2769   the run_score was: 4.0   and mem length: 705813   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2770   the run_score was: 5.0   and mem length: 706124   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.32\n","For episode: 2771   the run_score was: 3.0   and mem length: 706338   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2772   the run_score was: 6.0   and mem length: 706643   eps: 0.009998020008555413    steps: 305    lr: 4.0960000000000023e-07     eval rl_reward: 6.31\n","For episode: 2773   the run_score was: 7.0   and mem length: 706981   eps: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2774   the run_score was: 6.0   and mem length: 707321   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.24\n","For episode: 2775   the run_score was: 6.0   and mem length: 707661   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.24\n","For episode: 2776   the run_score was: 6.0   and mem length: 708001   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.27\n","For episode: 2777   the run_score was: 6.0   and mem length: 708341   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2778   the run_score was: 7.0   and mem length: 708732   eps: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2779   the run_score was: 6.0   and mem length: 709073   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 6.35\n","For episode: 2780   the run_score was: 6.0   and mem length: 709413   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.35\n","For episode: 2781   the run_score was: 6.0   and mem length: 709753   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.36\n","For episode: 2782   the run_score was: 3.0   and mem length: 709967   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.36\n","For episode: 2783   the run_score was: 4.0   and mem length: 710210   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 6.35\n","For episode: 2784   the run_score was: 6.0   and mem length: 710549   eps: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2785   the run_score was: 4.0   and mem length: 710792   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 6.31\n","For episode: 2786   the run_score was: 8.0   and mem length: 711210   eps: 0.009998020008555413    steps: 418    lr: 4.0960000000000023e-07     eval rl_reward: 6.35\n","For episode: 2787   the run_score was: 6.0   and mem length: 711550   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.37\n","For episode: 2788   the run_score was: 6.0   and mem length: 711904   eps: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     eval rl_reward: 6.37\n","For episode: 2789   the run_score was: 5.0   and mem length: 712197   eps: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     eval rl_reward: 6.39\n","For episode: 2790   the run_score was: 4.0   and mem length: 712457   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.39\n","For episode: 2791   the run_score was: 4.0   and mem length: 712717   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.39\n","For episode: 2792   the run_score was: 5.0   and mem length: 713028   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.36\n","For episode: 2793   the run_score was: 8.0   and mem length: 713415   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 6.4\n","For episode: 2794   the run_score was: 11.0   and mem length: 713969   eps: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     eval rl_reward: 6.48\n","For episode: 2795   the run_score was: 3.0   and mem length: 714200   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.48\n","For episode: 2796   the run_score was: 4.0   and mem length: 714460   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.41\n","For episode: 2797   the run_score was: 7.0   and mem length: 714845   eps: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     eval rl_reward: 6.45\n","For episode: 2798   the run_score was: 8.0   and mem length: 715279   eps: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     eval rl_reward: 6.48\n","For episode: 2799   the run_score was: 8.0   and mem length: 715672   eps: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     eval rl_reward: 6.51\n","For episode: 2800   the run_score was: 12.0   and mem length: 716079   eps: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     eval rl_reward: 6.6\n","For episode: 2801   the run_score was: 8.0   and mem length: 716495   eps: 0.009998020008555413    steps: 416    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2802   the run_score was: 5.0   and mem length: 716805   eps: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2803   the run_score was: 3.0   and mem length: 717036   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.55\n","For episode: 2804   the run_score was: 7.0   and mem length: 717415   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 6.54\n","For episode: 2805   the run_score was: 4.0   and mem length: 717675   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.54\n","For episode: 2806   the run_score was: 8.0   and mem length: 718089   eps: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     eval rl_reward: 6.57\n","For episode: 2807   the run_score was: 3.0   and mem length: 718303   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.56\n","For episode: 2808   the run_score was: 4.0   and mem length: 718563   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.54\n","For episode: 2809   the run_score was: 4.0   and mem length: 718823   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.5\n","For episode: 2810   the run_score was: 5.0   and mem length: 719134   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.44\n","For episode: 2811   the run_score was: 3.0   and mem length: 719365   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2812   the run_score was: 5.0   and mem length: 719660   eps: 0.009998020008555413    steps: 295    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2813   the run_score was: 7.0   and mem length: 720049   eps: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     eval rl_reward: 6.45\n","For episode: 2814   the run_score was: 6.0   and mem length: 720389   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.44\n","For episode: 2815   the run_score was: 8.0   and mem length: 720817   eps: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     eval rl_reward: 6.45\n","For episode: 2816   the run_score was: 4.0   and mem length: 721062   eps: 0.009998020008555413    steps: 245    lr: 4.0960000000000023e-07     eval rl_reward: 6.39\n","For episode: 2817   the run_score was: 7.0   and mem length: 721453   eps: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2818   the run_score was: 8.0   and mem length: 721876   eps: 0.009998020008555413    steps: 423    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2819   the run_score was: 6.0   and mem length: 722216   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.25\n","For episode: 2820   the run_score was: 9.0   and mem length: 722676   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 6.24\n","For episode: 2821   the run_score was: 10.0   and mem length: 723207   eps: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     eval rl_reward: 6.26\n","For episode: 2822   the run_score was: 6.0   and mem length: 723547   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.28\n","For episode: 2823   the run_score was: 8.0   and mem length: 723963   eps: 0.009998020008555413    steps: 416    lr: 4.0960000000000023e-07     eval rl_reward: 6.28\n","For episode: 2824   the run_score was: 6.0   and mem length: 724301   eps: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     eval rl_reward: 6.27\n","For episode: 2825   the run_score was: 5.0   and mem length: 724612   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.22\n","For episode: 2826   the run_score was: 6.0   and mem length: 724953   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 6.22\n","For episode: 2827   the run_score was: 6.0   and mem length: 725294   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 6.21\n","For episode: 2828   the run_score was: 6.0   and mem length: 725634   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.19\n","For episode: 2829   the run_score was: 7.0   and mem length: 726067   eps: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     eval rl_reward: 6.22\n","For episode: 2830   the run_score was: 6.0   and mem length: 726407   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.17\n","For episode: 2831   the run_score was: 10.0   and mem length: 726924   eps: 0.009998020008555413    steps: 517    lr: 4.0960000000000023e-07     eval rl_reward: 6.23\n","For episode: 2832   the run_score was: 6.0   and mem length: 727264   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.25\n","For episode: 2833   the run_score was: 11.0   and mem length: 727839   eps: 0.009998020008555413    steps: 575    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2834   the run_score was: 9.0   and mem length: 728292   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2835   the run_score was: 7.0   and mem length: 728679   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 6.33\n","For episode: 2836   the run_score was: 9.0   and mem length: 729174   eps: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2837   the run_score was: 7.0   and mem length: 729561   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 6.37\n","For episode: 2838   the run_score was: 8.0   and mem length: 729940   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 6.39\n","For episode: 2839   the run_score was: 6.0   and mem length: 730280   eps: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2840   the run_score was: 5.0   and mem length: 730591   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.4\n","For episode: 2841   the run_score was: 8.0   and mem length: 731029   eps: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     eval rl_reward: 6.44\n","For episode: 2842   the run_score was: 6.0   and mem length: 731404   eps: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2843   the run_score was: 6.0   and mem length: 731747   eps: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     eval rl_reward: 6.46\n","For episode: 2844   the run_score was: 9.0   and mem length: 732201   eps: 0.009998020008555413    steps: 454    lr: 4.0960000000000023e-07     eval rl_reward: 6.51\n","For episode: 2845   the run_score was: 7.0   and mem length: 732587   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.46\n","For episode: 2846   the run_score was: 8.0   and mem length: 733022   eps: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2847   the run_score was: 5.0   and mem length: 733333   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.4\n","For episode: 2848   the run_score was: 8.0   and mem length: 733786   eps: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     eval rl_reward: 6.41\n","For episode: 2849   the run_score was: 11.0   and mem length: 734170   eps: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     eval rl_reward: 6.41\n","For episode: 2850   the run_score was: 9.0   and mem length: 734636   eps: 0.009998020008555413    steps: 466    lr: 4.0960000000000023e-07     eval rl_reward: 6.46\n","For episode: 2851   the run_score was: 9.0   and mem length: 735096   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 6.48\n","For episode: 2852   the run_score was: 4.0   and mem length: 735356   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2853   the run_score was: 8.0   and mem length: 735759   eps: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2854   the run_score was: 8.0   and mem length: 736214   eps: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     eval rl_reward: 6.47\n","For episode: 2855   the run_score was: 6.0   and mem length: 736553   eps: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     eval rl_reward: 6.47\n","For episode: 2856   the run_score was: 4.0   and mem length: 736813   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.47\n","For episode: 2857   the run_score was: 4.0   and mem length: 737073   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2858   the run_score was: 6.0   and mem length: 737397   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2859   the run_score was: 4.0   and mem length: 737657   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.4\n","For episode: 2860   the run_score was: 9.0   and mem length: 738018   eps: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2861   the run_score was: 15.0   and mem length: 738606   eps: 0.009998020008555413    steps: 588    lr: 4.0960000000000023e-07     eval rl_reward: 6.5\n","For episode: 2862   the run_score was: 4.0   and mem length: 738866   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.47\n","For episode: 2863   the run_score was: 7.0   and mem length: 739252   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.47\n","For episode: 2864   the run_score was: 7.0   and mem length: 739588   eps: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     eval rl_reward: 6.5\n","For episode: 2865   the run_score was: 4.0   and mem length: 739848   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2866   the run_score was: 7.0   and mem length: 740227   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 6.42\n","For episode: 2867   the run_score was: 6.0   and mem length: 740566   eps: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     eval rl_reward: 6.44\n","For episode: 2868   the run_score was: 4.0   and mem length: 740826   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.41\n","For episode: 2869   the run_score was: 8.0   and mem length: 741267   eps: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     eval rl_reward: 6.45\n","For episode: 2870   the run_score was: 9.0   and mem length: 741726   eps: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     eval rl_reward: 6.49\n","For episode: 2871   the run_score was: 9.0   and mem length: 742186   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 6.55\n","For episode: 2872   the run_score was: 8.0   and mem length: 742588   eps: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     eval rl_reward: 6.57\n","For episode: 2873   the run_score was: 7.0   and mem length: 742974   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.57\n","For episode: 2874   the run_score was: 7.0   and mem length: 743360   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.58\n","For episode: 2875   the run_score was: 7.0   and mem length: 743749   eps: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     eval rl_reward: 6.59\n","For episode: 2876   the run_score was: 8.0   and mem length: 744157   eps: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     eval rl_reward: 6.61\n","For episode: 2877   the run_score was: 11.0   and mem length: 744689   eps: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     eval rl_reward: 6.66\n","For episode: 2878   the run_score was: 4.0   and mem length: 744949   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.63\n","For episode: 2879   the run_score was: 10.0   and mem length: 745404   eps: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     eval rl_reward: 6.67\n","For episode: 2880   the run_score was: 4.0   and mem length: 745664   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2881   the run_score was: 7.0   and mem length: 746015   eps: 0.009998020008555413    steps: 351    lr: 4.0960000000000023e-07     eval rl_reward: 6.66\n","For episode: 2882   the run_score was: 3.0   and mem length: 746229   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.66\n","For episode: 2883   the run_score was: 3.0   and mem length: 746443   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2884   the run_score was: 24.0   and mem length: 747031   eps: 0.009998020008555413    steps: 588    lr: 4.0960000000000023e-07     eval rl_reward: 6.83\n","For episode: 2885   the run_score was: 6.0   and mem length: 747374   eps: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     eval rl_reward: 6.85\n","For episode: 2886   the run_score was: 5.0   and mem length: 747664   eps: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     eval rl_reward: 6.82\n","For episode: 2887   the run_score was: 10.0   and mem length: 748134   eps: 0.009998020008555413    steps: 470    lr: 4.0960000000000023e-07     eval rl_reward: 6.86\n","For episode: 2888   the run_score was: 4.0   and mem length: 748394   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.84\n","For episode: 2889   the run_score was: 8.0   and mem length: 748836   eps: 0.009998020008555413    steps: 442    lr: 4.0960000000000023e-07     eval rl_reward: 6.87\n","For episode: 2890   the run_score was: 10.0   and mem length: 749314   eps: 0.009998020008555413    steps: 478    lr: 4.0960000000000023e-07     eval rl_reward: 6.93\n","For episode: 2891   the run_score was: 8.0   and mem length: 749715   eps: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     eval rl_reward: 6.97\n","For episode: 2892   the run_score was: 3.0   and mem length: 749929   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.95\n","For episode: 2893   the run_score was: 7.0   and mem length: 750296   eps: 0.009998020008555413    steps: 367    lr: 4.0960000000000023e-07     eval rl_reward: 6.94\n","For episode: 2894   the run_score was: 8.0   and mem length: 750701   eps: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     eval rl_reward: 6.91\n","For episode: 2895   the run_score was: 5.0   and mem length: 750992   eps: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     eval rl_reward: 6.93\n","For episode: 2896   the run_score was: 3.0   and mem length: 751206   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.92\n","For episode: 2897   the run_score was: 3.0   and mem length: 751420   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.88\n","For episode: 2898   the run_score was: 4.0   and mem length: 751681   eps: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     eval rl_reward: 6.84\n","For episode: 2899   the run_score was: 6.0   and mem length: 752005   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.82\n","For episode: 2900   the run_score was: 3.0   and mem length: 752219   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.73\n","For episode: 2901   the run_score was: 6.0   and mem length: 752592   eps: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     eval rl_reward: 6.71\n","For episode: 2902   the run_score was: 6.0   and mem length: 752918   eps: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     eval rl_reward: 6.72\n","For episode: 2903   the run_score was: 4.0   and mem length: 753158   eps: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     eval rl_reward: 6.73\n","For episode: 2904   the run_score was: 4.0   and mem length: 753418   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.7\n","For episode: 2905   the run_score was: 7.0   and mem length: 753797   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 6.73\n","For episode: 2906   the run_score was: 5.0   and mem length: 754088   eps: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     eval rl_reward: 6.7\n","For episode: 2907   the run_score was: 3.0   and mem length: 754302   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.7\n","For episode: 2908   the run_score was: 5.0   and mem length: 754612   eps: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     eval rl_reward: 6.71\n","For episode: 2909   the run_score was: 3.0   and mem length: 754826   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.7\n","For episode: 2910   the run_score was: 9.0   and mem length: 755297   eps: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     eval rl_reward: 6.74\n","For episode: 2911   the run_score was: 6.0   and mem length: 755671   eps: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     eval rl_reward: 6.77\n","For episode: 2912   the run_score was: 6.0   and mem length: 756036   eps: 0.009998020008555413    steps: 365    lr: 4.0960000000000023e-07     eval rl_reward: 6.78\n","For episode: 2913   the run_score was: 8.0   and mem length: 756429   eps: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     eval rl_reward: 6.79\n","For episode: 2914   the run_score was: 8.0   and mem length: 756842   eps: 0.009998020008555413    steps: 413    lr: 4.0960000000000023e-07     eval rl_reward: 6.81\n","For episode: 2915   the run_score was: 12.0   and mem length: 757264   eps: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     eval rl_reward: 6.85\n","For episode: 2916   the run_score was: 6.0   and mem length: 757588   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.87\n","For episode: 2917   the run_score was: 8.0   and mem length: 757990   eps: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     eval rl_reward: 6.88\n","For episode: 2918   the run_score was: 7.0   and mem length: 758377   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 6.87\n","For episode: 2919   the run_score was: 3.0   and mem length: 758608   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.84\n","For episode: 2920   the run_score was: 8.0   and mem length: 759022   eps: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     eval rl_reward: 6.83\n","For episode: 2921   the run_score was: 3.0   and mem length: 759236   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.76\n","For episode: 2922   the run_score was: 5.0   and mem length: 759542   eps: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     eval rl_reward: 6.75\n","For episode: 2923   the run_score was: 6.0   and mem length: 759899   eps: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     eval rl_reward: 6.73\n","For episode: 2924   the run_score was: 7.0   and mem length: 760254   eps: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     eval rl_reward: 6.74\n","For episode: 2925   the run_score was: 8.0   and mem length: 760662   eps: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     eval rl_reward: 6.77\n","For episode: 2926   the run_score was: 6.0   and mem length: 761004   eps: 0.009998020008555413    steps: 342    lr: 4.0960000000000023e-07     eval rl_reward: 6.77\n","For episode: 2927   the run_score was: 10.0   and mem length: 761486   eps: 0.009998020008555413    steps: 482    lr: 4.0960000000000023e-07     eval rl_reward: 6.81\n","For episode: 2928   the run_score was: 3.0   and mem length: 761700   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.78\n","For episode: 2929   the run_score was: 9.0   and mem length: 762180   eps: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     eval rl_reward: 6.8\n","For episode: 2930   the run_score was: 9.0   and mem length: 762617   eps: 0.009998020008555413    steps: 437    lr: 4.0960000000000023e-07     eval rl_reward: 6.83\n","For episode: 2931   the run_score was: 8.0   and mem length: 763066   eps: 0.009998020008555413    steps: 449    lr: 4.0960000000000023e-07     eval rl_reward: 6.81\n","For episode: 2932   the run_score was: 4.0   and mem length: 763326   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.79\n","For episode: 2933   the run_score was: 9.0   and mem length: 763786   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 6.77\n","For episode: 2934   the run_score was: 3.0   and mem length: 764017   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.71\n","For episode: 2935   the run_score was: 4.0   and mem length: 764277   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.68\n","For episode: 2936   the run_score was: 6.0   and mem length: 764619   eps: 0.009998020008555413    steps: 342    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2937   the run_score was: 9.0   and mem length: 765036   eps: 0.009998020008555413    steps: 417    lr: 4.0960000000000023e-07     eval rl_reward: 6.67\n","For episode: 2938   the run_score was: 7.0   and mem length: 765425   eps: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     eval rl_reward: 6.66\n","For episode: 2939   the run_score was: 6.0   and mem length: 765749   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.66\n","For episode: 2940   the run_score was: 3.0   and mem length: 765963   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.64\n","For episode: 2941   the run_score was: 3.0   and mem length: 766177   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.59\n","For episode: 2942   the run_score was: 9.0   and mem length: 766638   eps: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     eval rl_reward: 6.62\n","For episode: 2943   the run_score was: 9.0   and mem length: 767096   eps: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     eval rl_reward: 6.65\n","For episode: 2944   the run_score was: 3.0   and mem length: 767310   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.59\n","For episode: 2945   the run_score was: 3.0   and mem length: 767524   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.55\n","For episode: 2946   the run_score was: 3.0   and mem length: 767738   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.5\n","For episode: 2947   the run_score was: 3.0   and mem length: 767952   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.48\n","For episode: 2948   the run_score was: 3.0   and mem length: 768166   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.43\n","For episode: 2949   the run_score was: 8.0   and mem length: 768561   eps: 0.009998020008555413    steps: 395    lr: 4.0960000000000023e-07     eval rl_reward: 6.4\n","For episode: 2950   the run_score was: 3.0   and mem length: 768775   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.34\n","For episode: 2951   the run_score was: 3.0   and mem length: 768989   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.28\n","For episode: 2952   the run_score was: 3.0   and mem length: 769203   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.27\n","For episode: 2953   the run_score was: 3.0   and mem length: 769417   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.22\n","For episode: 2954   the run_score was: 3.0   and mem length: 769648   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.17\n","For episode: 2955   the run_score was: 16.0   and mem length: 770251   eps: 0.009998020008555413    steps: 603    lr: 4.0960000000000023e-07     eval rl_reward: 6.27\n","For episode: 2956   the run_score was: 6.0   and mem length: 770607   eps: 0.009998020008555413    steps: 356    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2957   the run_score was: 4.0   and mem length: 770867   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2958   the run_score was: 6.0   and mem length: 771205   eps: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     eval rl_reward: 6.29\n","For episode: 2959   the run_score was: 7.0   and mem length: 771578   eps: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     eval rl_reward: 6.32\n","For episode: 2960   the run_score was: 7.0   and mem length: 771952   eps: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     eval rl_reward: 6.3\n","For episode: 2961   the run_score was: 8.0   and mem length: 772427   eps: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     eval rl_reward: 6.23\n","For episode: 2962   the run_score was: 7.0   and mem length: 772786   eps: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     eval rl_reward: 6.26\n","For episode: 2963   the run_score was: 6.0   and mem length: 773106   eps: 0.009998020008555413    steps: 320    lr: 4.0960000000000023e-07     eval rl_reward: 6.25\n","For episode: 2964   the run_score was: 4.0   and mem length: 773366   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.22\n","For episode: 2965   the run_score was: 3.0   and mem length: 773580   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.21\n","For episode: 2966   the run_score was: 6.0   and mem length: 773921   eps: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     eval rl_reward: 6.2\n","For episode: 2967   the run_score was: 6.0   and mem length: 774245   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.2\n","For episode: 2968   the run_score was: 8.0   and mem length: 774629   eps: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     eval rl_reward: 6.24\n","For episode: 2969   the run_score was: 3.0   and mem length: 774860   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.19\n","For episode: 2970   the run_score was: 6.0   and mem length: 775184   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.16\n","For episode: 2971   the run_score was: 13.0   and mem length: 775643   eps: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     eval rl_reward: 6.2\n","For episode: 2972   the run_score was: 4.0   and mem length: 775903   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.16\n","For episode: 2973   the run_score was: 5.0   and mem length: 776211   eps: 0.009998020008555413    steps: 308    lr: 4.0960000000000023e-07     eval rl_reward: 6.14\n","For episode: 2974   the run_score was: 5.0   and mem length: 776485   eps: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     eval rl_reward: 6.12\n","For episode: 2975   the run_score was: 13.0   and mem length: 776957   eps: 0.009998020008555413    steps: 472    lr: 4.0960000000000023e-07     eval rl_reward: 6.18\n","For episode: 2976   the run_score was: 6.0   and mem length: 777281   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 6.16\n","For episode: 2977   the run_score was: 7.0   and mem length: 777650   eps: 0.009998020008555413    steps: 369    lr: 4.0960000000000023e-07     eval rl_reward: 6.12\n","For episode: 2978   the run_score was: 7.0   and mem length: 778058   eps: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     eval rl_reward: 6.15\n","For episode: 2979   the run_score was: 9.0   and mem length: 778518   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 6.14\n","For episode: 2980   the run_score was: 5.0   and mem length: 778829   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 6.15\n","For episode: 2981   the run_score was: 7.0   and mem length: 779215   eps: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     eval rl_reward: 6.15\n","For episode: 2982   the run_score was: 4.0   and mem length: 779475   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 6.16\n","For episode: 2983   the run_score was: 4.0   and mem length: 779718   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 6.17\n","For episode: 2984   the run_score was: 3.0   and mem length: 779949   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 5.96\n","For episode: 2985   the run_score was: 5.0   and mem length: 780239   eps: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     eval rl_reward: 5.95\n","For episode: 2986   the run_score was: 6.0   and mem length: 780618   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 5.96\n","For episode: 2987   the run_score was: 4.0   and mem length: 780878   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 2988   the run_score was: 4.0   and mem length: 781138   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 2989   the run_score was: 5.0   and mem length: 781431   eps: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     eval rl_reward: 5.87\n","For episode: 2990   the run_score was: 5.0   and mem length: 781742   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.82\n","For episode: 2991   the run_score was: 5.0   and mem length: 782053   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.79\n","For episode: 2992   the run_score was: 8.0   and mem length: 782487   eps: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     eval rl_reward: 5.84\n","For episode: 2993   the run_score was: 7.0   and mem length: 782874   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 5.84\n","For episode: 2994   the run_score was: 12.0   and mem length: 783281   eps: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     eval rl_reward: 5.88\n","For episode: 2995   the run_score was: 6.0   and mem length: 783620   eps: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     eval rl_reward: 5.89\n","For episode: 2996   the run_score was: 4.0   and mem length: 783880   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 2997   the run_score was: 3.0   and mem length: 784111   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 2998   the run_score was: 7.0   and mem length: 784488   eps: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     eval rl_reward: 5.93\n","For episode: 2999   the run_score was: 5.0   and mem length: 784799   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.92\n","For episode: 3000   the run_score was: 12.0   and mem length: 785382   eps: 0.009998020008555413    steps: 583    lr: 4.0960000000000023e-07     eval rl_reward: 6.01\n","For episode: 3001   the run_score was: 6.0   and mem length: 785761   eps: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     eval rl_reward: 6.01\n","For episode: 3002   the run_score was: 3.0   and mem length: 785975   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 5.98\n","For episode: 3003   the run_score was: 3.0   and mem length: 786189   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 5.97\n","For episode: 3004   the run_score was: 6.0   and mem length: 786515   eps: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     eval rl_reward: 5.99\n","For episode: 3005   the run_score was: 5.0   and mem length: 786825   eps: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     eval rl_reward: 5.97\n","For episode: 3006   the run_score was: 6.0   and mem length: 787149   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 5.98\n","For episode: 3007   the run_score was: 11.0   and mem length: 787636   eps: 0.009998020008555413    steps: 487    lr: 4.0960000000000023e-07     eval rl_reward: 6.06\n","For episode: 3008   the run_score was: 8.0   and mem length: 788021   eps: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     eval rl_reward: 6.09\n","For episode: 3009   the run_score was: 5.0   and mem length: 788295   eps: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     eval rl_reward: 6.11\n","For episode: 3010   the run_score was: 3.0   and mem length: 788526   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 6.05\n","For episode: 3011   the run_score was: 5.0   and mem length: 788800   eps: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     eval rl_reward: 6.04\n","For episode: 3012   the run_score was: 6.0   and mem length: 789137   eps: 0.009998020008555413    steps: 337    lr: 4.0960000000000023e-07     eval rl_reward: 6.04\n","For episode: 3013   the run_score was: 12.0   and mem length: 789565   eps: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     eval rl_reward: 6.08\n","For episode: 3014   the run_score was: 3.0   and mem length: 789779   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.03\n","For episode: 3015   the run_score was: 3.0   and mem length: 789993   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 5.94\n","For episode: 3016   the run_score was: 6.0   and mem length: 790316   eps: 0.009998020008555413    steps: 323    lr: 4.0960000000000023e-07     eval rl_reward: 5.94\n","For episode: 3017   the run_score was: 6.0   and mem length: 790640   eps: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     eval rl_reward: 5.92\n","For episode: 3018   the run_score was: 7.0   and mem length: 791002   eps: 0.009998020008555413    steps: 362    lr: 4.0960000000000023e-07     eval rl_reward: 5.92\n","For episode: 3019   the run_score was: 6.0   and mem length: 791340   eps: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     eval rl_reward: 5.95\n","For episode: 3020   the run_score was: 5.0   and mem length: 791630   eps: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     eval rl_reward: 5.92\n","For episode: 3021   the run_score was: 14.0   and mem length: 792140   eps: 0.009998020008555413    steps: 510    lr: 4.0960000000000023e-07     eval rl_reward: 6.03\n","For episode: 3022   the run_score was: 6.0   and mem length: 792445   eps: 0.009998020008555413    steps: 305    lr: 4.0960000000000023e-07     eval rl_reward: 6.04\n","For episode: 3023   the run_score was: 3.0   and mem length: 792659   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 6.01\n","For episode: 3024   the run_score was: 4.0   and mem length: 792902   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 5.98\n","For episode: 3025   the run_score was: 4.0   and mem length: 793145   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 5.94\n","For episode: 3026   the run_score was: 4.0   and mem length: 793405   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.92\n","For episode: 3027   the run_score was: 5.0   and mem length: 793716   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.87\n","For episode: 3028   the run_score was: 5.0   and mem length: 794027   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.89\n","For episode: 3029   the run_score was: 4.0   and mem length: 794287   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.84\n","For episode: 3030   the run_score was: 4.0   and mem length: 794547   eps: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     eval rl_reward: 5.79\n","For episode: 3031   the run_score was: 12.0   and mem length: 794988   eps: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     eval rl_reward: 5.83\n","For episode: 3032   the run_score was: 3.0   and mem length: 795202   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 5.82\n","For episode: 3033   the run_score was: 3.0   and mem length: 795416   eps: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     eval rl_reward: 5.76\n","For episode: 3034   the run_score was: 9.0   and mem length: 795873   eps: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     eval rl_reward: 5.82\n","For episode: 3035   the run_score was: 7.0   and mem length: 796226   eps: 0.009998020008555413    steps: 353    lr: 4.0960000000000023e-07     eval rl_reward: 5.85\n","For episode: 3036   the run_score was: 8.0   and mem length: 796613   eps: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     eval rl_reward: 5.87\n","For episode: 3037   the run_score was: 8.0   and mem length: 797018   eps: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     eval rl_reward: 5.86\n","For episode: 3038   the run_score was: 9.0   and mem length: 797478   eps: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     eval rl_reward: 5.88\n","For episode: 3039   the run_score was: 4.0   and mem length: 797721   eps: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     eval rl_reward: 5.86\n","For episode: 3040   the run_score was: 5.0   and mem length: 798012   eps: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     eval rl_reward: 5.88\n","For episode: 3041   the run_score was: 5.0   and mem length: 798323   eps: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 3042   the run_score was: 8.0   and mem length: 798725   eps: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     eval rl_reward: 5.89\n","For episode: 3043   the run_score was: 10.0   and mem length: 799229   eps: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     eval rl_reward: 5.9\n","For episode: 3044   the run_score was: 7.0   and mem length: 799614   eps: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     eval rl_reward: 5.94\n","For episode: 3045   the run_score was: 3.0   and mem length: 799845   eps: 0.009998020008555413    steps: 231    lr: 4.0960000000000023e-07     eval rl_reward: 5.94\n","For episode: 3046   the run_score was: 4.0   and mem length: 800105   eps: 0.009998020008555413    steps: 260    lr: 1.638400000000001e-07     eval rl_reward: 5.95\n","For episode: 3047   the run_score was: 5.0   and mem length: 800395   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 5.97\n","For episode: 3048   the run_score was: 3.0   and mem length: 800609   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.97\n","For episode: 3049   the run_score was: 5.0   and mem length: 800900   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3050   the run_score was: 5.0   and mem length: 801190   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 5.96\n","For episode: 3051   the run_score was: 6.0   and mem length: 801527   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3052   the run_score was: 6.0   and mem length: 801864   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3053   the run_score was: 6.0   and mem length: 802201   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3054   the run_score was: 9.0   and mem length: 802688   eps: 0.009998020008555413    steps: 487    lr: 1.638400000000001e-07     eval rl_reward: 6.11\n","For episode: 3055   the run_score was: 6.0   and mem length: 803025   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3056   the run_score was: 3.0   and mem length: 803239   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.98\n","For episode: 3057   the run_score was: 6.0   and mem length: 803583   eps: 0.009998020008555413    steps: 344    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3058   the run_score was: 8.0   and mem length: 803983   eps: 0.009998020008555413    steps: 400    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3059   the run_score was: 10.0   and mem length: 804470   eps: 0.009998020008555413    steps: 487    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3060   the run_score was: 9.0   and mem length: 804930   eps: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3061   the run_score was: 5.0   and mem length: 805221   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3062   the run_score was: 5.0   and mem length: 805512   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3063   the run_score was: 4.0   and mem length: 805755   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3064   the run_score was: 5.0   and mem length: 806046   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3065   the run_score was: 7.0   and mem length: 806417   eps: 0.009998020008555413    steps: 371    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3066   the run_score was: 8.0   and mem length: 806796   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3067   the run_score was: 3.0   and mem length: 807010   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3068   the run_score was: 5.0   and mem length: 807301   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3069   the run_score was: 3.0   and mem length: 807532   eps: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3070   the run_score was: 5.0   and mem length: 807822   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3071   the run_score was: 5.0   and mem length: 808112   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 5.92\n","For episode: 3072   the run_score was: 3.0   and mem length: 808326   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.91\n","For episode: 3073   the run_score was: 5.0   and mem length: 808634   eps: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     eval rl_reward: 5.91\n","For episode: 3074   the run_score was: 7.0   and mem length: 809020   eps: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     eval rl_reward: 5.93\n","For episode: 3075   the run_score was: 7.0   and mem length: 809373   eps: 0.009998020008555413    steps: 353    lr: 1.638400000000001e-07     eval rl_reward: 5.87\n","For episode: 3076   the run_score was: 5.0   and mem length: 809662   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3077   the run_score was: 3.0   and mem length: 809876   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3078   the run_score was: 3.0   and mem length: 810107   eps: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     eval rl_reward: 5.78\n","For episode: 3079   the run_score was: 3.0   and mem length: 810338   eps: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     eval rl_reward: 5.72\n","For episode: 3080   the run_score was: 4.0   and mem length: 810598   eps: 0.009998020008555413    steps: 260    lr: 1.638400000000001e-07     eval rl_reward: 5.71\n","For episode: 3081   the run_score was: 6.0   and mem length: 810977   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 5.7\n","For episode: 3082   the run_score was: 3.0   and mem length: 811208   eps: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     eval rl_reward: 5.69\n","For episode: 3083   the run_score was: 14.0   and mem length: 811725   eps: 0.009998020008555413    steps: 517    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3084   the run_score was: 5.0   and mem length: 812035   eps: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     eval rl_reward: 5.81\n","For episode: 3085   the run_score was: 10.0   and mem length: 812526   eps: 0.009998020008555413    steps: 491    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3086   the run_score was: 3.0   and mem length: 812757   eps: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3087   the run_score was: 7.0   and mem length: 813132   eps: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3088   the run_score was: 6.0   and mem length: 813437   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 5.88\n","For episode: 3089   the run_score was: 3.0   and mem length: 813651   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3090   the run_score was: 5.0   and mem length: 813942   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3091   the run_score was: 7.0   and mem length: 814313   eps: 0.009998020008555413    steps: 371    lr: 1.638400000000001e-07     eval rl_reward: 5.88\n","For episode: 3092   the run_score was: 5.0   and mem length: 814602   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 5.85\n","For episode: 3093   the run_score was: 4.0   and mem length: 814862   eps: 0.009998020008555413    steps: 260    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3094   the run_score was: 7.0   and mem length: 815250   eps: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3095   the run_score was: 7.0   and mem length: 815586   eps: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     eval rl_reward: 5.78\n","For episode: 3096   the run_score was: 3.0   and mem length: 815800   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3097   the run_score was: 10.0   and mem length: 816169   eps: 0.009998020008555413    steps: 369    lr: 1.638400000000001e-07     eval rl_reward: 5.84\n","For episode: 3098   the run_score was: 3.0   and mem length: 816383   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.8\n","For episode: 3099   the run_score was: 3.0   and mem length: 816597   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.78\n","For episode: 3100   the run_score was: 17.0   and mem length: 817079   eps: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3101   the run_score was: 3.0   and mem length: 817293   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.8\n","For episode: 3102   the run_score was: 5.0   and mem length: 817584   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3103   the run_score was: 3.0   and mem length: 817798   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3104   the run_score was: 6.0   and mem length: 818103   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3105   the run_score was: 7.0   and mem length: 818474   eps: 0.009998020008555413    steps: 371    lr: 1.638400000000001e-07     eval rl_reward: 5.84\n","For episode: 3106   the run_score was: 7.0   and mem length: 818845   eps: 0.009998020008555413    steps: 371    lr: 1.638400000000001e-07     eval rl_reward: 5.85\n","For episode: 3107   the run_score was: 5.0   and mem length: 819136   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3108   the run_score was: 4.0   and mem length: 819381   eps: 0.009998020008555413    steps: 245    lr: 1.638400000000001e-07     eval rl_reward: 5.75\n","For episode: 3109   the run_score was: 5.0   and mem length: 819672   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.75\n","For episode: 3110   the run_score was: 5.0   and mem length: 819963   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3111   the run_score was: 5.0   and mem length: 820254   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3112   the run_score was: 5.0   and mem length: 820545   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.76\n","For episode: 3113   the run_score was: 8.0   and mem length: 820981   eps: 0.009998020008555413    steps: 436    lr: 1.638400000000001e-07     eval rl_reward: 5.72\n","For episode: 3114   the run_score was: 8.0   and mem length: 821389   eps: 0.009998020008555413    steps: 408    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3115   the run_score was: 3.0   and mem length: 821603   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3116   the run_score was: 6.0   and mem length: 821940   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3117   the run_score was: 7.0   and mem length: 822300   eps: 0.009998020008555413    steps: 360    lr: 1.638400000000001e-07     eval rl_reward: 5.78\n","For episode: 3118   the run_score was: 10.0   and mem length: 822733   eps: 0.009998020008555413    steps: 433    lr: 1.638400000000001e-07     eval rl_reward: 5.81\n","For episode: 3119   the run_score was: 4.0   and mem length: 822975   eps: 0.009998020008555413    steps: 242    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3120   the run_score was: 9.0   and mem length: 823434   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3121   the run_score was: 8.0   and mem length: 823851   eps: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     eval rl_reward: 5.77\n","For episode: 3122   the run_score was: 8.0   and mem length: 824243   eps: 0.009998020008555413    steps: 392    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3123   the run_score was: 4.0   and mem length: 824486   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 5.8\n","For episode: 3124   the run_score was: 5.0   and mem length: 824775   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 5.81\n","For episode: 3125   the run_score was: 6.0   and mem length: 825115   eps: 0.009998020008555413    steps: 340    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3126   the run_score was: 3.0   and mem length: 825329   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.82\n","For episode: 3127   the run_score was: 3.0   and mem length: 825543   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.8\n","For episode: 3128   the run_score was: 3.0   and mem length: 825757   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.78\n","For episode: 3129   the run_score was: 9.0   and mem length: 826240   eps: 0.009998020008555413    steps: 483    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3130   the run_score was: 7.0   and mem length: 826618   eps: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3131   the run_score was: 5.0   and mem length: 826909   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3132   the run_score was: 3.0   and mem length: 827123   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.79\n","For episode: 3133   the run_score was: 18.0   and mem length: 827793   eps: 0.009998020008555413    steps: 670    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3134   the run_score was: 5.0   and mem length: 828084   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.9\n","For episode: 3135   the run_score was: 3.0   and mem length: 828298   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3136   the run_score was: 7.0   and mem length: 828672   eps: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     eval rl_reward: 5.85\n","For episode: 3137   the run_score was: 9.0   and mem length: 829107   eps: 0.009998020008555413    steps: 435    lr: 1.638400000000001e-07     eval rl_reward: 5.86\n","For episode: 3138   the run_score was: 6.0   and mem length: 829465   eps: 0.009998020008555413    steps: 358    lr: 1.638400000000001e-07     eval rl_reward: 5.83\n","For episode: 3139   the run_score was: 9.0   and mem length: 829925   eps: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     eval rl_reward: 5.88\n","For episode: 3140   the run_score was: 11.0   and mem length: 830459   eps: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3141   the run_score was: 5.0   and mem length: 830767   eps: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3142   the run_score was: 6.0   and mem length: 831072   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 5.92\n","For episode: 3143   the run_score was: 5.0   and mem length: 831363   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.87\n","For episode: 3144   the run_score was: 7.0   and mem length: 831730   eps: 0.009998020008555413    steps: 367    lr: 1.638400000000001e-07     eval rl_reward: 5.87\n","For episode: 3145   the run_score was: 14.0   and mem length: 832285   eps: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     eval rl_reward: 5.98\n","For episode: 3146   the run_score was: 9.0   and mem length: 832743   eps: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     eval rl_reward: 6.03\n","For episode: 3147   the run_score was: 7.0   and mem length: 833122   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3148   the run_score was: 7.0   and mem length: 833501   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.09\n","For episode: 3149   the run_score was: 8.0   and mem length: 833911   eps: 0.009998020008555413    steps: 410    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3150   the run_score was: 3.0   and mem length: 834125   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.1\n","For episode: 3151   the run_score was: 8.0   and mem length: 834527   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3152   the run_score was: 10.0   and mem length: 834988   eps: 0.009998020008555413    steps: 461    lr: 1.638400000000001e-07     eval rl_reward: 6.16\n","For episode: 3153   the run_score was: 5.0   and mem length: 835279   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.15\n","For episode: 3154   the run_score was: 9.0   and mem length: 835685   eps: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     eval rl_reward: 6.15\n","For episode: 3155   the run_score was: 4.0   and mem length: 835963   eps: 0.009998020008555413    steps: 278    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3156   the run_score was: 3.0   and mem length: 836177   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3157   the run_score was: 3.0   and mem length: 836391   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.1\n","For episode: 3158   the run_score was: 3.0   and mem length: 836605   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3159   the run_score was: 4.0   and mem length: 836848   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3160   the run_score was: 11.0   and mem length: 837238   eps: 0.009998020008555413    steps: 390    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3161   the run_score was: 6.0   and mem length: 837543   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3162   the run_score was: 7.0   and mem length: 837879   eps: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3163   the run_score was: 8.0   and mem length: 838274   eps: 0.009998020008555413    steps: 395    lr: 1.638400000000001e-07     eval rl_reward: 6.08\n","For episode: 3164   the run_score was: 3.0   and mem length: 838488   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3165   the run_score was: 3.0   and mem length: 838702   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3166   the run_score was: 3.0   and mem length: 838916   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.97\n","For episode: 3167   the run_score was: 3.0   and mem length: 839130   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.97\n","For episode: 3168   the run_score was: 3.0   and mem length: 839344   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.95\n","For episode: 3169   the run_score was: 3.0   and mem length: 839558   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.95\n","For episode: 3170   the run_score was: 10.0   and mem length: 840043   eps: 0.009998020008555413    steps: 485    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3171   the run_score was: 7.0   and mem length: 840429   eps: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3172   the run_score was: 8.0   and mem length: 840854   eps: 0.009998020008555413    steps: 425    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3173   the run_score was: 5.0   and mem length: 841145   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3174   the run_score was: 6.0   and mem length: 841450   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3175   the run_score was: 3.0   and mem length: 841664   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3176   the run_score was: 7.0   and mem length: 842039   eps: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3177   the run_score was: 4.0   and mem length: 842282   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3178   the run_score was: 5.0   and mem length: 842572   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3179   the run_score was: 4.0   and mem length: 842815   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.08\n","For episode: 3180   the run_score was: 7.0   and mem length: 843192   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.11\n","For episode: 3181   the run_score was: 7.0   and mem length: 843566   eps: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3182   the run_score was: 4.0   and mem length: 843809   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3183   the run_score was: 3.0   and mem length: 844023   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3184   the run_score was: 4.0   and mem length: 844266   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3185   the run_score was: 3.0   and mem length: 844480   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3186   the run_score was: 3.0   and mem length: 844694   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.94\n","For episode: 3187   the run_score was: 6.0   and mem length: 845035   eps: 0.009998020008555413    steps: 341    lr: 1.638400000000001e-07     eval rl_reward: 5.93\n","For episode: 3188   the run_score was: 3.0   and mem length: 845249   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.9\n","For episode: 3189   the run_score was: 10.0   and mem length: 845597   eps: 0.009998020008555413    steps: 348    lr: 1.638400000000001e-07     eval rl_reward: 5.97\n","For episode: 3190   the run_score was: 7.0   and mem length: 845974   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3191   the run_score was: 7.0   and mem length: 846351   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3192   the run_score was: 10.0   and mem length: 846828   eps: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3193   the run_score was: 7.0   and mem length: 847205   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3194   the run_score was: 6.0   and mem length: 847545   eps: 0.009998020008555413    steps: 340    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3195   the run_score was: 3.0   and mem length: 847759   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3196   the run_score was: 5.0   and mem length: 848050   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3197   the run_score was: 5.0   and mem length: 848341   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3198   the run_score was: 8.0   and mem length: 848743   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3199   the run_score was: 7.0   and mem length: 849089   eps: 0.009998020008555413    steps: 346    lr: 1.638400000000001e-07     eval rl_reward: 6.08\n","For episode: 3200   the run_score was: 4.0   and mem length: 849332   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 5.95\n","For episode: 3201   the run_score was: 8.0   and mem length: 849751   eps: 0.009998020008555413    steps: 419    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3202   the run_score was: 8.0   and mem length: 850133   eps: 0.009998020008555413    steps: 382    lr: 1.638400000000001e-07     eval rl_reward: 6.03\n","For episode: 3203   the run_score was: 7.0   and mem length: 850507   eps: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3204   the run_score was: 5.0   and mem length: 850798   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3205   the run_score was: 5.0   and mem length: 851089   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3206   the run_score was: 6.0   and mem length: 851426   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.03\n","For episode: 3207   the run_score was: 4.0   and mem length: 851668   eps: 0.009998020008555413    steps: 242    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3208   the run_score was: 3.0   and mem length: 851882   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3209   the run_score was: 5.0   and mem length: 852171   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3210   the run_score was: 3.0   and mem length: 852385   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3211   the run_score was: 8.0   and mem length: 852787   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3212   the run_score was: 3.0   and mem length: 853001   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3213   the run_score was: 6.0   and mem length: 853325   eps: 0.009998020008555413    steps: 324    lr: 1.638400000000001e-07     eval rl_reward: 5.98\n","For episode: 3214   the run_score was: 9.0   and mem length: 853784   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 5.99\n","For episode: 3215   the run_score was: 4.0   and mem length: 854027   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.0\n","For episode: 3216   the run_score was: 7.0   and mem length: 854406   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.01\n","For episode: 3217   the run_score was: 11.0   and mem length: 854929   eps: 0.009998020008555413    steps: 523    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3218   the run_score was: 7.0   and mem length: 855341   eps: 0.009998020008555413    steps: 412    lr: 1.638400000000001e-07     eval rl_reward: 6.02\n","For episode: 3219   the run_score was: 11.0   and mem length: 855850   eps: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     eval rl_reward: 6.09\n","For episode: 3220   the run_score was: 6.0   and mem length: 856187   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3221   the run_score was: 8.0   and mem length: 856607   eps: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     eval rl_reward: 6.06\n","For episode: 3222   the run_score was: 6.0   and mem length: 856933   eps: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     eval rl_reward: 6.04\n","For episode: 3223   the run_score was: 5.0   and mem length: 857244   eps: 0.009998020008555413    steps: 311    lr: 1.638400000000001e-07     eval rl_reward: 6.05\n","For episode: 3224   the run_score was: 7.0   and mem length: 857621   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.07\n","For episode: 3225   the run_score was: 8.0   and mem length: 858023   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.09\n","For episode: 3226   the run_score was: 7.0   and mem length: 858400   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3227   the run_score was: 7.0   and mem length: 858777   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.17\n","For episode: 3228   the run_score was: 8.0   and mem length: 859179   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3229   the run_score was: 7.0   and mem length: 859558   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.2\n","For episode: 3230   the run_score was: 9.0   and mem length: 860018   eps: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3231   the run_score was: 7.0   and mem length: 860378   eps: 0.009998020008555413    steps: 360    lr: 1.638400000000001e-07     eval rl_reward: 6.24\n","For episode: 3232   the run_score was: 5.0   and mem length: 860669   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.26\n","For episode: 3233   the run_score was: 6.0   and mem length: 861008   eps: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     eval rl_reward: 6.14\n","For episode: 3234   the run_score was: 7.0   and mem length: 861392   eps: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     eval rl_reward: 6.16\n","For episode: 3235   the run_score was: 9.0   and mem length: 861851   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3236   the run_score was: 4.0   and mem length: 862094   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.19\n","For episode: 3237   the run_score was: 9.0   and mem length: 862553   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 6.19\n","For episode: 3238   the run_score was: 9.0   and mem length: 863012   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3239   the run_score was: 9.0   and mem length: 863470   eps: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3240   the run_score was: 9.0   and mem length: 863892   eps: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     eval rl_reward: 6.2\n","For episode: 3241   the run_score was: 11.0   and mem length: 864406   eps: 0.009998020008555413    steps: 514    lr: 1.638400000000001e-07     eval rl_reward: 6.26\n","For episode: 3242   the run_score was: 8.0   and mem length: 864808   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.28\n","For episode: 3243   the run_score was: 7.0   and mem length: 865187   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.3\n","For episode: 3244   the run_score was: 8.0   and mem length: 865621   eps: 0.009998020008555413    steps: 434    lr: 1.638400000000001e-07     eval rl_reward: 6.31\n","For episode: 3245   the run_score was: 5.0   and mem length: 865894   eps: 0.009998020008555413    steps: 273    lr: 1.638400000000001e-07     eval rl_reward: 6.22\n","For episode: 3246   the run_score was: 5.0   and mem length: 866185   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.18\n","For episode: 3247   the run_score was: 5.0   and mem length: 866476   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.16\n","For episode: 3248   the run_score was: 7.0   and mem length: 866848   eps: 0.009998020008555413    steps: 372    lr: 1.638400000000001e-07     eval rl_reward: 6.16\n","For episode: 3249   the run_score was: 5.0   and mem length: 867139   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3250   the run_score was: 3.0   and mem length: 867353   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.13\n","For episode: 3251   the run_score was: 9.0   and mem length: 867775   eps: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     eval rl_reward: 6.14\n","For episode: 3252   the run_score was: 8.0   and mem length: 868158   eps: 0.009998020008555413    steps: 383    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3253   the run_score was: 5.0   and mem length: 868432   eps: 0.009998020008555413    steps: 274    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3254   the run_score was: 8.0   and mem length: 868855   eps: 0.009998020008555413    steps: 423    lr: 1.638400000000001e-07     eval rl_reward: 6.11\n","For episode: 3255   the run_score was: 5.0   and mem length: 869146   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.12\n","For episode: 3256   the run_score was: 5.0   and mem length: 869437   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.14\n","For episode: 3257   the run_score was: 8.0   and mem length: 869830   eps: 0.009998020008555413    steps: 393    lr: 1.638400000000001e-07     eval rl_reward: 6.19\n","For episode: 3258   the run_score was: 8.0   and mem length: 870232   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.24\n","For episode: 3259   the run_score was: 5.0   and mem length: 870523   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.25\n","For episode: 3260   the run_score was: 7.0   and mem length: 870895   eps: 0.009998020008555413    steps: 372    lr: 1.638400000000001e-07     eval rl_reward: 6.21\n","For episode: 3261   the run_score was: 4.0   and mem length: 871155   eps: 0.009998020008555413    steps: 260    lr: 1.638400000000001e-07     eval rl_reward: 6.19\n","For episode: 3262   the run_score was: 6.0   and mem length: 871481   eps: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     eval rl_reward: 6.18\n","For episode: 3263   the run_score was: 7.0   and mem length: 871836   eps: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     eval rl_reward: 6.17\n","For episode: 3264   the run_score was: 6.0   and mem length: 872156   eps: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     eval rl_reward: 6.2\n","For episode: 3265   the run_score was: 10.0   and mem length: 872507   eps: 0.009998020008555413    steps: 351    lr: 1.638400000000001e-07     eval rl_reward: 6.27\n","For episode: 3266   the run_score was: 7.0   and mem length: 872886   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.31\n","For episode: 3267   the run_score was: 6.0   and mem length: 873206   eps: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     eval rl_reward: 6.34\n","For episode: 3268   the run_score was: 4.0   and mem length: 873449   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.35\n","For episode: 3269   the run_score was: 8.0   and mem length: 873837   eps: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     eval rl_reward: 6.4\n","For episode: 3270   the run_score was: 8.0   and mem length: 874239   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.38\n","For episode: 3271   the run_score was: 10.0   and mem length: 874681   eps: 0.009998020008555413    steps: 442    lr: 1.638400000000001e-07     eval rl_reward: 6.41\n","For episode: 3272   the run_score was: 4.0   and mem length: 874924   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.37\n","For episode: 3273   the run_score was: 6.0   and mem length: 875244   eps: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     eval rl_reward: 6.38\n","For episode: 3274   the run_score was: 8.0   and mem length: 875693   eps: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     eval rl_reward: 6.4\n","For episode: 3275   the run_score was: 8.0   and mem length: 876086   eps: 0.009998020008555413    steps: 393    lr: 1.638400000000001e-07     eval rl_reward: 6.45\n","For episode: 3276   the run_score was: 7.0   and mem length: 876447   eps: 0.009998020008555413    steps: 361    lr: 1.638400000000001e-07     eval rl_reward: 6.45\n","For episode: 3277   the run_score was: 5.0   and mem length: 876737   eps: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     eval rl_reward: 6.46\n","For episode: 3278   the run_score was: 6.0   and mem length: 877074   eps: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     eval rl_reward: 6.47\n","For episode: 3279   the run_score was: 4.0   and mem length: 877317   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.47\n","For episode: 3280   the run_score was: 12.0   and mem length: 877871   eps: 0.009998020008555413    steps: 554    lr: 1.638400000000001e-07     eval rl_reward: 6.52\n","For episode: 3281   the run_score was: 9.0   and mem length: 878311   eps: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     eval rl_reward: 6.54\n","For episode: 3282   the run_score was: 4.0   and mem length: 878571   eps: 0.009998020008555413    steps: 260    lr: 1.638400000000001e-07     eval rl_reward: 6.54\n","For episode: 3283   the run_score was: 5.0   and mem length: 878860   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 6.56\n","For episode: 3284   the run_score was: 5.0   and mem length: 879151   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.57\n","For episode: 3285   the run_score was: 5.0   and mem length: 879442   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.59\n","For episode: 3286   the run_score was: 3.0   and mem length: 879656   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.59\n","For episode: 3287   the run_score was: 5.0   and mem length: 879947   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.58\n","For episode: 3288   the run_score was: 8.0   and mem length: 880367   eps: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     eval rl_reward: 6.63\n","For episode: 3289   the run_score was: 7.0   and mem length: 880753   eps: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3290   the run_score was: 7.0   and mem length: 881141   eps: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3291   the run_score was: 7.0   and mem length: 881493   eps: 0.009998020008555413    steps: 352    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3292   the run_score was: 7.0   and mem length: 881829   eps: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     eval rl_reward: 6.57\n","For episode: 3293   the run_score was: 7.0   and mem length: 882218   eps: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     eval rl_reward: 6.57\n","For episode: 3294   the run_score was: 6.0   and mem length: 882523   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.57\n","For episode: 3295   the run_score was: 6.0   and mem length: 882849   eps: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3296   the run_score was: 6.0   and mem length: 883175   eps: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     eval rl_reward: 6.61\n","For episode: 3297   the run_score was: 8.0   and mem length: 883625   eps: 0.009998020008555413    steps: 450    lr: 1.638400000000001e-07     eval rl_reward: 6.64\n","For episode: 3298   the run_score was: 5.0   and mem length: 883916   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.61\n","For episode: 3299   the run_score was: 8.0   and mem length: 884298   eps: 0.009998020008555413    steps: 382    lr: 1.638400000000001e-07     eval rl_reward: 6.62\n","For episode: 3300   the run_score was: 6.0   and mem length: 884603   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.64\n","For episode: 3301   the run_score was: 3.0   and mem length: 884817   eps: 0.009998020008555413    steps: 214    lr: 1.638400000000001e-07     eval rl_reward: 6.59\n","For episode: 3302   the run_score was: 9.0   and mem length: 885277   eps: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3303   the run_score was: 9.0   and mem length: 885736   eps: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     eval rl_reward: 6.62\n","For episode: 3304   the run_score was: 5.0   and mem length: 886027   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.62\n","For episode: 3305   the run_score was: 4.0   and mem length: 886270   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.61\n","For episode: 3306   the run_score was: 5.0   and mem length: 886561   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3307   the run_score was: 5.0   and mem length: 886852   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.61\n","For episode: 3308   the run_score was: 7.0   and mem length: 887236   eps: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     eval rl_reward: 6.65\n","For episode: 3309   the run_score was: 5.0   and mem length: 887527   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.65\n","For episode: 3310   the run_score was: 7.0   and mem length: 887928   eps: 0.009998020008555413    steps: 401    lr: 1.638400000000001e-07     eval rl_reward: 6.69\n","For episode: 3311   the run_score was: 3.0   and mem length: 888157   eps: 0.009998020008555413    steps: 229    lr: 1.638400000000001e-07     eval rl_reward: 6.64\n","For episode: 3312   the run_score was: 5.0   and mem length: 888448   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.66\n","For episode: 3313   the run_score was: 14.0   and mem length: 888936   eps: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     eval rl_reward: 6.74\n","For episode: 3314   the run_score was: 5.0   and mem length: 889227   eps: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     eval rl_reward: 6.7\n","For episode: 3315   the run_score was: 6.0   and mem length: 889532   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.72\n","For episode: 3316   the run_score was: 10.0   and mem length: 890077   eps: 0.009998020008555413    steps: 545    lr: 1.638400000000001e-07     eval rl_reward: 6.75\n","For episode: 3317   the run_score was: 4.0   and mem length: 890320   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.68\n","For episode: 3318   the run_score was: 5.0   and mem length: 890609   eps: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     eval rl_reward: 6.66\n","For episode: 3319   the run_score was: 8.0   and mem length: 890994   eps: 0.009998020008555413    steps: 385    lr: 1.638400000000001e-07     eval rl_reward: 6.63\n","For episode: 3320   the run_score was: 7.0   and mem length: 891372   eps: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     eval rl_reward: 6.64\n","For episode: 3321   the run_score was: 8.0   and mem length: 891774   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.64\n","For episode: 3322   the run_score was: 8.0   and mem length: 892169   eps: 0.009998020008555413    steps: 395    lr: 1.638400000000001e-07     eval rl_reward: 6.66\n","For episode: 3323   the run_score was: 7.0   and mem length: 892528   eps: 0.009998020008555413    steps: 359    lr: 1.638400000000001e-07     eval rl_reward: 6.68\n","For episode: 3324   the run_score was: 11.0   and mem length: 892947   eps: 0.009998020008555413    steps: 419    lr: 1.638400000000001e-07     eval rl_reward: 6.72\n","For episode: 3325   the run_score was: 7.0   and mem length: 893326   eps: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     eval rl_reward: 6.71\n","For episode: 3326   the run_score was: 9.0   and mem length: 893748   eps: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     eval rl_reward: 6.73\n","For episode: 3327   the run_score was: 8.0   and mem length: 894149   eps: 0.009998020008555413    steps: 401    lr: 1.638400000000001e-07     eval rl_reward: 6.74\n","For episode: 3328   the run_score was: 9.0   and mem length: 894566   eps: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     eval rl_reward: 6.75\n","For episode: 3329   the run_score was: 8.0   and mem length: 894968   eps: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     eval rl_reward: 6.76\n","For episode: 3330   the run_score was: 10.0   and mem length: 895422   eps: 0.009998020008555413    steps: 454    lr: 1.638400000000001e-07     eval rl_reward: 6.77\n","For episode: 3331   the run_score was: 3.0   and mem length: 895651   eps: 0.009998020008555413    steps: 229    lr: 1.638400000000001e-07     eval rl_reward: 6.73\n","For episode: 3332   the run_score was: 9.0   and mem length: 896107   eps: 0.009998020008555413    steps: 456    lr: 1.638400000000001e-07     eval rl_reward: 6.77\n","For episode: 3333   the run_score was: 7.0   and mem length: 896500   eps: 0.009998020008555413    steps: 393    lr: 1.638400000000001e-07     eval rl_reward: 6.78\n","For episode: 3334   the run_score was: 8.0   and mem length: 896927   eps: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     eval rl_reward: 6.79\n","For episode: 3335   the run_score was: 7.0   and mem length: 897304   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.77\n","For episode: 3336   the run_score was: 5.0   and mem length: 897615   eps: 0.009998020008555413    steps: 311    lr: 1.638400000000001e-07     eval rl_reward: 6.78\n","For episode: 3337   the run_score was: 7.0   and mem length: 897992   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.76\n","For episode: 3338   the run_score was: 7.0   and mem length: 898369   eps: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     eval rl_reward: 6.74\n","For episode: 3339   the run_score was: 4.0   and mem length: 898612   eps: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     eval rl_reward: 6.69\n","For episode: 3340   the run_score was: 5.0   and mem length: 898886   eps: 0.009998020008555413    steps: 274    lr: 1.638400000000001e-07     eval rl_reward: 6.65\n","For episode: 3341   the run_score was: 6.0   and mem length: 899191   eps: 0.009998020008555413    steps: 305    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3342   the run_score was: 6.0   and mem length: 899511   eps: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     eval rl_reward: 6.58\n","For episode: 3343   the run_score was: 9.0   and mem length: 899967   eps: 0.009998020008555413    steps: 456    lr: 1.638400000000001e-07     eval rl_reward: 6.6\n","For episode: 3344   the run_score was: 6.0   and mem length: 900304   eps: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     eval rl_reward: 6.58\n","For episode: 3345   the run_score was: 11.0   and mem length: 900852   eps: 0.009998020008555413    steps: 548    lr: 6.553600000000004e-08     eval rl_reward: 6.64\n","For episode: 3346   the run_score was: 7.0   and mem length: 901211   eps: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     eval rl_reward: 6.66\n","For episode: 3347   the run_score was: 6.0   and mem length: 901541   eps: 0.009998020008555413    steps: 330    lr: 6.553600000000004e-08     eval rl_reward: 6.67\n","For episode: 3348   the run_score was: 8.0   and mem length: 901943   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.68\n","For episode: 3349   the run_score was: 8.0   and mem length: 902361   eps: 0.009998020008555413    steps: 418    lr: 6.553600000000004e-08     eval rl_reward: 6.71\n","For episode: 3350   the run_score was: 25.0   and mem length: 902846   eps: 0.009998020008555413    steps: 485    lr: 6.553600000000004e-08     eval rl_reward: 6.93\n","For episode: 3351   the run_score was: 8.0   and mem length: 903265   eps: 0.009998020008555413    steps: 419    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3352   the run_score was: 12.0   and mem length: 903690   eps: 0.009998020008555413    steps: 425    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3353   the run_score was: 5.0   and mem length: 903981   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3354   the run_score was: 8.0   and mem length: 904402   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3355   the run_score was: 5.0   and mem length: 904693   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3356   the run_score was: 9.0   and mem length: 905153   eps: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3357   the run_score was: 6.0   and mem length: 905458   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3358   the run_score was: 8.0   and mem length: 905893   eps: 0.009998020008555413    steps: 435    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3359   the run_score was: 7.0   and mem length: 906272   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3360   the run_score was: 6.0   and mem length: 906577   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.99\n","For episode: 3361   the run_score was: 6.0   and mem length: 906882   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.01\n","For episode: 3362   the run_score was: 5.0   and mem length: 907154   eps: 0.009998020008555413    steps: 272    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3363   the run_score was: 5.0   and mem length: 907428   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3364   the run_score was: 6.0   and mem length: 907733   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3365   the run_score was: 6.0   and mem length: 908053   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3366   the run_score was: 5.0   and mem length: 908327   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3367   the run_score was: 5.0   and mem length: 908601   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.91\n","For episode: 3368   the run_score was: 6.0   and mem length: 908921   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.93\n","For episode: 3369   the run_score was: 5.0   and mem length: 909195   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3370   the run_score was: 5.0   and mem length: 909469   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.87\n","For episode: 3371   the run_score was: 6.0   and mem length: 909774   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.83\n","For episode: 3372   the run_score was: 7.0   and mem length: 910163   eps: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     eval rl_reward: 6.86\n","For episode: 3373   the run_score was: 14.0   and mem length: 910664   eps: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3374   the run_score was: 3.0   and mem length: 910878   eps: 0.009998020008555413    steps: 214    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3375   the run_score was: 13.0   and mem length: 911372   eps: 0.009998020008555413    steps: 494    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3376   the run_score was: 3.0   and mem length: 911586   eps: 0.009998020008555413    steps: 214    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3377   the run_score was: 3.0   and mem length: 911800   eps: 0.009998020008555413    steps: 214    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3378   the run_score was: 3.0   and mem length: 912014   eps: 0.009998020008555413    steps: 214    lr: 6.553600000000004e-08     eval rl_reward: 6.85\n","For episode: 3379   the run_score was: 9.0   and mem length: 912462   eps: 0.009998020008555413    steps: 448    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3380   the run_score was: 7.0   and mem length: 912827   eps: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     eval rl_reward: 6.85\n","For episode: 3381   the run_score was: 6.0   and mem length: 913147   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3382   the run_score was: 9.0   and mem length: 913563   eps: 0.009998020008555413    steps: 416    lr: 6.553600000000004e-08     eval rl_reward: 6.87\n","For episode: 3383   the run_score was: 8.0   and mem length: 913965   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3384   the run_score was: 5.0   and mem length: 914256   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3385   the run_score was: 6.0   and mem length: 914561   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.91\n","For episode: 3386   the run_score was: 6.0   and mem length: 914901   eps: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3387   the run_score was: 5.0   and mem length: 915175   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3388   the run_score was: 10.0   and mem length: 915535   eps: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3389   the run_score was: 7.0   and mem length: 915902   eps: 0.009998020008555413    steps: 367    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3390   the run_score was: 5.0   and mem length: 916176   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.94\n","For episode: 3391   the run_score was: 5.0   and mem length: 916449   eps: 0.009998020008555413    steps: 273    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3392   the run_score was: 7.0   and mem length: 916814   eps: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3393   the run_score was: 5.0   and mem length: 917088   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3394   the run_score was: 7.0   and mem length: 917458   eps: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     eval rl_reward: 6.91\n","For episode: 3395   the run_score was: 5.0   and mem length: 917732   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3396   the run_score was: 8.0   and mem length: 918134   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3397   the run_score was: 8.0   and mem length: 918536   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3398   the run_score was: 5.0   and mem length: 918810   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3399   the run_score was: 8.0   and mem length: 919198   eps: 0.009998020008555413    steps: 388    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3400   the run_score was: 5.0   and mem length: 919489   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.91\n","For episode: 3401   the run_score was: 8.0   and mem length: 919879   eps: 0.009998020008555413    steps: 390    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3402   the run_score was: 5.0   and mem length: 920153   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3403   the run_score was: 6.0   and mem length: 920477   eps: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3404   the run_score was: 13.0   and mem length: 920922   eps: 0.009998020008555413    steps: 445    lr: 6.553600000000004e-08     eval rl_reward: 6.97\n","For episode: 3405   the run_score was: 5.0   and mem length: 921213   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3406   the run_score was: 8.0   and mem length: 921615   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 7.01\n","For episode: 3407   the run_score was: 6.0   and mem length: 921920   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.02\n","For episode: 3408   the run_score was: 5.0   and mem length: 922211   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3409   the run_score was: 5.0   and mem length: 922485   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3410   the run_score was: 8.0   and mem length: 922887   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 7.01\n","For episode: 3411   the run_score was: 5.0   and mem length: 923178   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 7.03\n","For episode: 3412   the run_score was: 7.0   and mem length: 923542   eps: 0.009998020008555413    steps: 364    lr: 6.553600000000004e-08     eval rl_reward: 7.05\n","For episode: 3413   the run_score was: 4.0   and mem length: 923785   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 6.95\n","For episode: 3414   the run_score was: 8.0   and mem length: 924187   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3415   the run_score was: 6.0   and mem length: 924492   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.98\n","For episode: 3416   the run_score was: 7.0   and mem length: 924869   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 6.95\n","For episode: 3417   the run_score was: 4.0   and mem length: 925110   eps: 0.009998020008555413    steps: 241    lr: 6.553600000000004e-08     eval rl_reward: 6.95\n","For episode: 3418   the run_score was: 5.0   and mem length: 925401   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.95\n","For episode: 3419   the run_score was: 8.0   and mem length: 925803   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.95\n","For episode: 3420   the run_score was: 12.0   and mem length: 926232   eps: 0.009998020008555413    steps: 429    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3421   the run_score was: 8.0   and mem length: 926634   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3422   the run_score was: 8.0   and mem length: 927036   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 7.0\n","For episode: 3423   the run_score was: 3.0   and mem length: 927266   eps: 0.009998020008555413    steps: 230    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3424   the run_score was: 3.0   and mem length: 927497   eps: 0.009998020008555413    steps: 231    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3425   the run_score was: 7.0   and mem length: 927874   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3426   the run_score was: 5.0   and mem length: 928165   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.84\n","For episode: 3427   the run_score was: 7.0   and mem length: 928542   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 6.83\n","For episode: 3428   the run_score was: 7.0   and mem length: 928901   eps: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     eval rl_reward: 6.81\n","For episode: 3429   the run_score was: 8.0   and mem length: 929293   eps: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     eval rl_reward: 6.81\n","For episode: 3430   the run_score was: 6.0   and mem length: 929598   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.77\n","For episode: 3431   the run_score was: 6.0   and mem length: 929919   eps: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     eval rl_reward: 6.8\n","For episode: 3432   the run_score was: 6.0   and mem length: 930224   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.77\n","For episode: 3433   the run_score was: 7.0   and mem length: 930603   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 6.77\n","For episode: 3434   the run_score was: 12.0   and mem length: 931031   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.81\n","For episode: 3435   the run_score was: 6.0   and mem length: 931351   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.8\n","For episode: 3436   the run_score was: 7.0   and mem length: 931728   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3437   the run_score was: 7.0   and mem length: 932087   eps: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3438   the run_score was: 7.0   and mem length: 932474   eps: 0.009998020008555413    steps: 387    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3439   the run_score was: 5.0   and mem length: 932782   eps: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     eval rl_reward: 6.83\n","For episode: 3440   the run_score was: 8.0   and mem length: 933192   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 6.86\n","For episode: 3441   the run_score was: 6.0   and mem length: 933497   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.86\n","For episode: 3442   the run_score was: 6.0   and mem length: 933802   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.86\n","For episode: 3443   the run_score was: 12.0   and mem length: 934221   eps: 0.009998020008555413    steps: 419    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3444   the run_score was: 6.0   and mem length: 934526   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3445   the run_score was: 7.0   and mem length: 934915   eps: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     eval rl_reward: 6.85\n","For episode: 3446   the run_score was: 6.0   and mem length: 935220   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.84\n","For episode: 3447   the run_score was: 5.0   and mem length: 935511   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.83\n","For episode: 3448   the run_score was: 8.0   and mem length: 935913   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.83\n","For episode: 3449   the run_score was: 5.0   and mem length: 936202   eps: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     eval rl_reward: 6.8\n","For episode: 3450   the run_score was: 8.0   and mem length: 936604   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.63\n","For episode: 3451   the run_score was: 5.0   and mem length: 936878   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3452   the run_score was: 12.0   and mem length: 937400   eps: 0.009998020008555413    steps: 522    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3453   the run_score was: 8.0   and mem length: 937794   eps: 0.009998020008555413    steps: 394    lr: 6.553600000000004e-08     eval rl_reward: 6.63\n","For episode: 3454   the run_score was: 7.0   and mem length: 938164   eps: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     eval rl_reward: 6.62\n","For episode: 3455   the run_score was: 7.0   and mem length: 938517   eps: 0.009998020008555413    steps: 353    lr: 6.553600000000004e-08     eval rl_reward: 6.64\n","For episode: 3456   the run_score was: 5.0   and mem length: 938808   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3457   the run_score was: 8.0   and mem length: 939194   eps: 0.009998020008555413    steps: 386    lr: 6.553600000000004e-08     eval rl_reward: 6.62\n","For episode: 3458   the run_score was: 5.0   and mem length: 939468   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.59\n","For episode: 3459   the run_score was: 7.0   and mem length: 939823   eps: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     eval rl_reward: 6.59\n","For episode: 3460   the run_score was: 6.0   and mem length: 940162   eps: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     eval rl_reward: 6.59\n","For episode: 3461   the run_score was: 5.0   and mem length: 940436   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.58\n","For episode: 3462   the run_score was: 7.0   and mem length: 940772   eps: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3463   the run_score was: 5.0   and mem length: 941063   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3464   the run_score was: 5.0   and mem length: 941337   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.59\n","For episode: 3465   the run_score was: 7.0   and mem length: 941673   eps: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3466   the run_score was: 5.0   and mem length: 941964   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.6\n","For episode: 3467   the run_score was: 8.0   and mem length: 942366   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.63\n","For episode: 3468   the run_score was: 6.0   and mem length: 942671   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.63\n","For episode: 3469   the run_score was: 8.0   and mem length: 943073   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.66\n","For episode: 3470   the run_score was: 5.0   and mem length: 943364   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.66\n","For episode: 3471   the run_score was: 14.0   and mem length: 943838   eps: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     eval rl_reward: 6.74\n","For episode: 3472   the run_score was: 7.0   and mem length: 944208   eps: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     eval rl_reward: 6.74\n","For episode: 3473   the run_score was: 7.0   and mem length: 944586   eps: 0.009998020008555413    steps: 378    lr: 6.553600000000004e-08     eval rl_reward: 6.67\n","For episode: 3474   the run_score was: 6.0   and mem length: 944906   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.7\n","For episode: 3475   the run_score was: 9.0   and mem length: 945362   eps: 0.009998020008555413    steps: 456    lr: 6.553600000000004e-08     eval rl_reward: 6.66\n","For episode: 3476   the run_score was: 6.0   and mem length: 945717   eps: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     eval rl_reward: 6.69\n","For episode: 3477   the run_score was: 5.0   and mem length: 946008   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.71\n","For episode: 3478   the run_score was: 6.0   and mem length: 946313   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.74\n","For episode: 3479   the run_score was: 9.0   and mem length: 946773   eps: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     eval rl_reward: 6.74\n","For episode: 3480   the run_score was: 5.0   and mem length: 947064   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.72\n","For episode: 3481   the run_score was: 16.0   and mem length: 947501   eps: 0.009998020008555413    steps: 437    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3482   the run_score was: 9.0   and mem length: 947929   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3483   the run_score was: 5.0   and mem length: 948237   eps: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     eval rl_reward: 6.79\n","For episode: 3484   the run_score was: 7.0   and mem length: 948597   eps: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     eval rl_reward: 6.81\n","For episode: 3485   the run_score was: 7.0   and mem length: 948956   eps: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     eval rl_reward: 6.82\n","For episode: 3486   the run_score was: 8.0   and mem length: 949377   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 6.84\n","For episode: 3487   the run_score was: 8.0   and mem length: 949798   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 6.87\n","For episode: 3488   the run_score was: 7.0   and mem length: 950134   eps: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     eval rl_reward: 6.84\n","For episode: 3489   the run_score was: 7.0   and mem length: 950511   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 6.84\n","For episode: 3490   the run_score was: 9.0   and mem length: 950939   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3491   the run_score was: 6.0   and mem length: 951259   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3492   the run_score was: 6.0   and mem length: 951581   eps: 0.009998020008555413    steps: 322    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3493   the run_score was: 6.0   and mem length: 951886   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3494   the run_score was: 6.0   and mem length: 952206   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.88\n","For episode: 3495   the run_score was: 6.0   and mem length: 952526   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3496   the run_score was: 9.0   and mem length: 952957   eps: 0.009998020008555413    steps: 431    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3497   the run_score was: 7.0   and mem length: 953328   eps: 0.009998020008555413    steps: 371    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3498   the run_score was: 9.0   and mem length: 953756   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.93\n","For episode: 3499   the run_score was: 7.0   and mem length: 954135   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3500   the run_score was: 5.0   and mem length: 954409   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3501   the run_score was: 5.0   and mem length: 954683   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3502   the run_score was: 9.0   and mem length: 955111   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.93\n","For episode: 3503   the run_score was: 5.0   and mem length: 955385   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 6.92\n","For episode: 3504   the run_score was: 8.0   and mem length: 955787   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.87\n","For episode: 3505   the run_score was: 7.0   and mem length: 956176   eps: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     eval rl_reward: 6.89\n","For episode: 3506   the run_score was: 9.0   and mem length: 956604   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.9\n","For episode: 3507   the run_score was: 9.0   and mem length: 957032   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 6.93\n","For episode: 3508   the run_score was: 8.0   and mem length: 957443   eps: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     eval rl_reward: 6.96\n","For episode: 3509   the run_score was: 8.0   and mem length: 957845   eps: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     eval rl_reward: 6.99\n","For episode: 3510   the run_score was: 8.0   and mem length: 958256   eps: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     eval rl_reward: 6.99\n","For episode: 3511   the run_score was: 5.0   and mem length: 958547   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 6.99\n","For episode: 3512   the run_score was: 13.0   and mem length: 959016   eps: 0.009998020008555413    steps: 469    lr: 6.553600000000004e-08     eval rl_reward: 7.05\n","For episode: 3513   the run_score was: 13.0   and mem length: 959522   eps: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     eval rl_reward: 7.14\n","For episode: 3514   the run_score was: 5.0   and mem length: 959796   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.11\n","For episode: 3515   the run_score was: 8.0   and mem length: 960217   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.13\n","For episode: 3516   the run_score was: 8.0   and mem length: 960638   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.14\n","For episode: 3517   the run_score was: 5.0   and mem length: 960929   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 7.15\n","For episode: 3518   the run_score was: 5.0   and mem length: 961203   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.15\n","For episode: 3519   the run_score was: 8.0   and mem length: 961586   eps: 0.009998020008555413    steps: 383    lr: 6.553600000000004e-08     eval rl_reward: 7.15\n","For episode: 3520   the run_score was: 13.0   and mem length: 962203   eps: 0.009998020008555413    steps: 617    lr: 6.553600000000004e-08     eval rl_reward: 7.16\n","For episode: 3521   the run_score was: 7.0   and mem length: 962590   eps: 0.009998020008555413    steps: 387    lr: 6.553600000000004e-08     eval rl_reward: 7.15\n","For episode: 3522   the run_score was: 9.0   and mem length: 963012   eps: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     eval rl_reward: 7.16\n","For episode: 3523   the run_score was: 7.0   and mem length: 963383   eps: 0.009998020008555413    steps: 371    lr: 6.553600000000004e-08     eval rl_reward: 7.2\n","For episode: 3524   the run_score was: 8.0   and mem length: 963804   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.25\n","For episode: 3525   the run_score was: 5.0   and mem length: 964078   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.23\n","For episode: 3526   the run_score was: 6.0   and mem length: 964435   eps: 0.009998020008555413    steps: 357    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3527   the run_score was: 8.0   and mem length: 964827   eps: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     eval rl_reward: 7.25\n","For episode: 3528   the run_score was: 6.0   and mem length: 965132   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3529   the run_score was: 5.0   and mem length: 965405   eps: 0.009998020008555413    steps: 273    lr: 6.553600000000004e-08     eval rl_reward: 7.21\n","For episode: 3530   the run_score was: 9.0   and mem length: 965860   eps: 0.009998020008555413    steps: 455    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3531   the run_score was: 5.0   and mem length: 966134   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.23\n","For episode: 3532   the run_score was: 13.0   and mem length: 966592   eps: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     eval rl_reward: 7.3\n","For episode: 3533   the run_score was: 7.0   and mem length: 966946   eps: 0.009998020008555413    steps: 354    lr: 6.553600000000004e-08     eval rl_reward: 7.3\n","For episode: 3534   the run_score was: 7.0   and mem length: 967313   eps: 0.009998020008555413    steps: 367    lr: 6.553600000000004e-08     eval rl_reward: 7.25\n","For episode: 3535   the run_score was: 5.0   and mem length: 967587   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3536   the run_score was: 4.0   and mem length: 967830   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.21\n","For episode: 3537   the run_score was: 5.0   and mem length: 968121   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 7.19\n","For episode: 3538   the run_score was: 6.0   and mem length: 968426   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.18\n","For episode: 3539   the run_score was: 6.0   and mem length: 968731   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.19\n","For episode: 3540   the run_score was: 6.0   and mem length: 969051   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 7.17\n","For episode: 3541   the run_score was: 9.0   and mem length: 969490   eps: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     eval rl_reward: 7.2\n","For episode: 3542   the run_score was: 8.0   and mem length: 969875   eps: 0.009998020008555413    steps: 385    lr: 6.553600000000004e-08     eval rl_reward: 7.22\n","For episode: 3543   the run_score was: 10.0   and mem length: 970391   eps: 0.009998020008555413    steps: 516    lr: 6.553600000000004e-08     eval rl_reward: 7.2\n","For episode: 3544   the run_score was: 8.0   and mem length: 970841   eps: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     eval rl_reward: 7.22\n","For episode: 3545   the run_score was: 9.0   and mem length: 971271   eps: 0.009998020008555413    steps: 430    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3546   the run_score was: 8.0   and mem length: 971638   eps: 0.009998020008555413    steps: 367    lr: 6.553600000000004e-08     eval rl_reward: 7.26\n","For episode: 3547   the run_score was: 7.0   and mem length: 972017   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 7.28\n","For episode: 3548   the run_score was: 7.0   and mem length: 972384   eps: 0.009998020008555413    steps: 367    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3549   the run_score was: 5.0   and mem length: 972658   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3550   the run_score was: 7.0   and mem length: 973082   eps: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     eval rl_reward: 7.26\n","For episode: 3551   the run_score was: 9.0   and mem length: 973514   eps: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     eval rl_reward: 7.3\n","For episode: 3552   the run_score was: 5.0   and mem length: 973788   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.23\n","For episode: 3553   the run_score was: 9.0   and mem length: 974204   eps: 0.009998020008555413    steps: 416    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3554   the run_score was: 9.0   and mem length: 974644   eps: 0.009998020008555413    steps: 440    lr: 6.553600000000004e-08     eval rl_reward: 7.26\n","For episode: 3555   the run_score was: 5.0   and mem length: 974933   eps: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3556   the run_score was: 8.0   and mem length: 975354   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3557   the run_score was: 5.0   and mem length: 975628   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3558   the run_score was: 5.0   and mem length: 975902   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3559   the run_score was: 8.0   and mem length: 976340   eps: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     eval rl_reward: 7.25\n","For episode: 3560   the run_score was: 5.0   and mem length: 976614   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.24\n","For episode: 3561   the run_score was: 7.0   and mem length: 976982   eps: 0.009998020008555413    steps: 368    lr: 6.553600000000004e-08     eval rl_reward: 7.26\n","For episode: 3562   the run_score was: 7.0   and mem length: 977335   eps: 0.009998020008555413    steps: 353    lr: 6.553600000000004e-08     eval rl_reward: 7.26\n","For episode: 3563   the run_score was: 6.0   and mem length: 977640   eps: 0.009998020008555413    steps: 305    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3564   the run_score was: 11.0   and mem length: 978194   eps: 0.009998020008555413    steps: 554    lr: 6.553600000000004e-08     eval rl_reward: 7.33\n","For episode: 3565   the run_score was: 11.0   and mem length: 978692   eps: 0.009998020008555413    steps: 498    lr: 6.553600000000004e-08     eval rl_reward: 7.37\n","For episode: 3566   the run_score was: 7.0   and mem length: 979071   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3567   the run_score was: 9.0   and mem length: 979529   eps: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     eval rl_reward: 7.4\n","For episode: 3568   the run_score was: 4.0   and mem length: 979772   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.38\n","For episode: 3569   the run_score was: 5.0   and mem length: 980046   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.35\n","For episode: 3570   the run_score was: 9.0   and mem length: 980485   eps: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3571   the run_score was: 7.0   and mem length: 980852   eps: 0.009998020008555413    steps: 367    lr: 6.553600000000004e-08     eval rl_reward: 7.32\n","For episode: 3572   the run_score was: 5.0   and mem length: 981126   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.3\n","For episode: 3573   the run_score was: 4.0   and mem length: 981369   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3574   the run_score was: 9.0   and mem length: 981819   eps: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     eval rl_reward: 7.3\n","For episode: 3575   the run_score was: 4.0   and mem length: 982062   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.25\n","For episode: 3576   the run_score was: 8.0   and mem length: 982470   eps: 0.009998020008555413    steps: 408    lr: 6.553600000000004e-08     eval rl_reward: 7.27\n","For episode: 3577   the run_score was: 16.0   and mem length: 983034   eps: 0.009998020008555413    steps: 564    lr: 6.553600000000004e-08     eval rl_reward: 7.38\n","For episode: 3578   the run_score was: 8.0   and mem length: 983455   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.4\n","For episode: 3579   the run_score was: 8.0   and mem length: 983876   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3580   the run_score was: 12.0   and mem length: 984304   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.46\n","For episode: 3581   the run_score was: 5.0   and mem length: 984595   eps: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     eval rl_reward: 7.35\n","For episode: 3582   the run_score was: 10.0   and mem length: 985092   eps: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     eval rl_reward: 7.36\n","For episode: 3583   the run_score was: 9.0   and mem length: 985533   eps: 0.009998020008555413    steps: 441    lr: 6.553600000000004e-08     eval rl_reward: 7.4\n","For episode: 3584   the run_score was: 6.0   and mem length: 985856   eps: 0.009998020008555413    steps: 323    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3585   the run_score was: 6.0   and mem length: 986176   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 7.38\n","For episode: 3586   the run_score was: 6.0   and mem length: 986496   eps: 0.009998020008555413    steps: 320    lr: 6.553600000000004e-08     eval rl_reward: 7.36\n","For episode: 3587   the run_score was: 10.0   and mem length: 986844   eps: 0.009998020008555413    steps: 348    lr: 6.553600000000004e-08     eval rl_reward: 7.38\n","For episode: 3588   the run_score was: 8.0   and mem length: 987254   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3589   the run_score was: 8.0   and mem length: 987664   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 7.4\n","For episode: 3590   the run_score was: 8.0   and mem length: 988055   eps: 0.009998020008555413    steps: 391    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3591   the run_score was: 6.0   and mem length: 988384   eps: 0.009998020008555413    steps: 329    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3592   the run_score was: 6.0   and mem length: 988728   eps: 0.009998020008555413    steps: 344    lr: 6.553600000000004e-08     eval rl_reward: 7.39\n","For episode: 3593   the run_score was: 7.0   and mem length: 989105   eps: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     eval rl_reward: 7.4\n","For episode: 3594   the run_score was: 11.0   and mem length: 989594   eps: 0.009998020008555413    steps: 489    lr: 6.553600000000004e-08     eval rl_reward: 7.45\n","For episode: 3595   the run_score was: 8.0   and mem length: 990004   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 7.47\n","For episode: 3596   the run_score was: 9.0   and mem length: 990432   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.47\n","For episode: 3597   the run_score was: 8.0   and mem length: 990843   eps: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     eval rl_reward: 7.48\n","For episode: 3598   the run_score was: 9.0   and mem length: 991258   eps: 0.009998020008555413    steps: 415    lr: 6.553600000000004e-08     eval rl_reward: 7.48\n","For episode: 3599   the run_score was: 9.0   and mem length: 991689   eps: 0.009998020008555413    steps: 431    lr: 6.553600000000004e-08     eval rl_reward: 7.5\n","For episode: 3600   the run_score was: 9.0   and mem length: 992117   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.54\n","For episode: 3601   the run_score was: 5.0   and mem length: 992425   eps: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     eval rl_reward: 7.54\n","For episode: 3602   the run_score was: 9.0   and mem length: 992853   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.54\n","For episode: 3603   the run_score was: 8.0   and mem length: 993257   eps: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     eval rl_reward: 7.57\n","For episode: 3604   the run_score was: 9.0   and mem length: 993685   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.58\n","For episode: 3605   the run_score was: 7.0   and mem length: 994047   eps: 0.009998020008555413    steps: 362    lr: 6.553600000000004e-08     eval rl_reward: 7.58\n","For episode: 3606   the run_score was: 13.0   and mem length: 994514   eps: 0.009998020008555413    steps: 467    lr: 6.553600000000004e-08     eval rl_reward: 7.62\n","For episode: 3607   the run_score was: 7.0   and mem length: 994893   eps: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     eval rl_reward: 7.6\n","For episode: 3608   the run_score was: 9.0   and mem length: 995321   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.61\n","For episode: 3609   the run_score was: 4.0   and mem length: 995564   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.57\n","For episode: 3610   the run_score was: 4.0   and mem length: 995807   eps: 0.009998020008555413    steps: 243    lr: 6.553600000000004e-08     eval rl_reward: 7.53\n","For episode: 3611   the run_score was: 8.0   and mem length: 996217   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 7.56\n","For episode: 3612   the run_score was: 8.0   and mem length: 996627   eps: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     eval rl_reward: 7.51\n","For episode: 3613   the run_score was: 8.0   and mem length: 997048   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.46\n","For episode: 3614   the run_score was: 12.0   and mem length: 997476   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.53\n","For episode: 3615   the run_score was: 8.0   and mem length: 997897   eps: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     eval rl_reward: 7.53\n","For episode: 3616   the run_score was: 8.0   and mem length: 998308   eps: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     eval rl_reward: 7.53\n","For episode: 3617   the run_score was: 12.0   and mem length: 998736   eps: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     eval rl_reward: 7.6\n","For episode: 3618   the run_score was: 5.0   and mem length: 999010   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.6\n","For episode: 3619   the run_score was: 5.0   and mem length: 999284   eps: 0.009998020008555413    steps: 274    lr: 6.553600000000004e-08     eval rl_reward: 7.57\n","For episode: 3620   the run_score was: 8.0   and mem length: 999692   eps: 0.009998020008555413    steps: 408    lr: 6.553600000000004e-08     eval rl_reward: 7.52\n","For episode: 3621   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     eval rl_reward: 7.55\n","For episode: 3622   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     eval rl_reward: 7.54\n","For episode: 3623   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     eval rl_reward: 7.56\n","For episode: 3624   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 7.53\n","For episode: 3625   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.57\n","For episode: 3626   the run_score was: 14.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 508    lr: 2.6214400000000017e-08     eval rl_reward: 7.65\n","For episode: 3627   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 381    lr: 2.6214400000000017e-08     eval rl_reward: 7.65\n","For episode: 3628   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.68\n","For episode: 3629   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 2.6214400000000017e-08     eval rl_reward: 7.68\n","For episode: 3630   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     eval rl_reward: 7.66\n","For episode: 3631   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.7\n","For episode: 3632   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     eval rl_reward: 7.66\n","For episode: 3633   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.68\n","For episode: 3634   the run_score was: 13.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 445    lr: 2.6214400000000017e-08     eval rl_reward: 7.74\n","For episode: 3635   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 408    lr: 2.6214400000000017e-08     eval rl_reward: 7.78\n","For episode: 3636   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.81\n","For episode: 3637   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.83\n","For episode: 3638   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3639   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.86\n","For episode: 3640   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3641   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 383    lr: 2.6214400000000017e-08     eval rl_reward: 7.86\n","For episode: 3642   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3643   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     eval rl_reward: 7.84\n","For episode: 3644   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.83\n","For episode: 3645   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.81\n","For episode: 3646   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 495    lr: 2.6214400000000017e-08     eval rl_reward: 7.82\n","For episode: 3647   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 388    lr: 2.6214400000000017e-08     eval rl_reward: 7.82\n","For episode: 3648   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     eval rl_reward: 7.84\n","For episode: 3649   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.88\n","For episode: 3650   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3651   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 452    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3652   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3653   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 410    lr: 2.6214400000000017e-08     eval rl_reward: 7.86\n","For episode: 3654   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 468    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3655   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 401    lr: 2.6214400000000017e-08     eval rl_reward: 7.9\n","For episode: 3656   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3657   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 214    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3658   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     eval rl_reward: 7.9\n","For episode: 3659   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 7.89\n","For episode: 3660   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 360    lr: 2.6214400000000017e-08     eval rl_reward: 7.91\n","For episode: 3661   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     eval rl_reward: 7.93\n","For episode: 3662   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 383    lr: 2.6214400000000017e-08     eval rl_reward: 7.94\n","For episode: 3663   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 8.0\n","For episode: 3664   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     eval rl_reward: 7.98\n","For episode: 3665   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 547    lr: 2.6214400000000017e-08     eval rl_reward: 7.99\n","For episode: 3666   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 495    lr: 2.6214400000000017e-08     eval rl_reward: 8.01\n","For episode: 3667   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     eval rl_reward: 7.99\n","For episode: 3668   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     eval rl_reward: 8.02\n","For episode: 3669   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 8.03\n","For episode: 3670   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 8.03\n","For episode: 3671   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     eval rl_reward: 8.03\n","For episode: 3672   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 8.02\n","For episode: 3673   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 460    lr: 2.6214400000000017e-08     eval rl_reward: 8.07\n","For episode: 3674   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 8.02\n","For episode: 3675   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 8.02\n","For episode: 3676   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 214    lr: 2.6214400000000017e-08     eval rl_reward: 7.97\n","For episode: 3677   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3678   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 412    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3679   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 230    lr: 2.6214400000000017e-08     eval rl_reward: 7.8\n","For episode: 3680   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 2.6214400000000017e-08     eval rl_reward: 7.73\n","For episode: 3681   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.72\n","For episode: 3682   the run_score was: 15.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 515    lr: 2.6214400000000017e-08     eval rl_reward: 7.77\n","For episode: 3683   the run_score was: 11.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 498    lr: 2.6214400000000017e-08     eval rl_reward: 7.79\n","For episode: 3684   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 410    lr: 2.6214400000000017e-08     eval rl_reward: 7.81\n","For episode: 3685   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     eval rl_reward: 7.82\n","For episode: 3686   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 367    lr: 2.6214400000000017e-08     eval rl_reward: 7.83\n","For episode: 3687   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     eval rl_reward: 7.82\n","For episode: 3688   the run_score was: 16.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 633    lr: 2.6214400000000017e-08     eval rl_reward: 7.9\n","For episode: 3689   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     eval rl_reward: 7.9\n","For episode: 3690   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     eval rl_reward: 7.89\n","For episode: 3691   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.87\n","For episode: 3692   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.85\n","For episode: 3693   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     eval rl_reward: 7.86\n","For episode: 3694   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.79\n","For episode: 3695   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.75\n","For episode: 3696   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     eval rl_reward: 7.71\n","For episode: 3697   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.67\n","For episode: 3698   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.62\n","For episode: 3699   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.57\n","For episode: 3700   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.52\n","For episode: 3701   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.51\n","For episode: 3702   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.46\n","For episode: 3703   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.42\n","For episode: 3704   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.37\n","For episode: 3705   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.34\n","For episode: 3706   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 7.3\n","For episode: 3707   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.27\n","For episode: 3708   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 7.24\n","For episode: 3709   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.24\n","For episode: 3710   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.24\n","For episode: 3711   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.2\n","For episode: 3712   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.16\n","For episode: 3713   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.12\n","For episode: 3714   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.04\n","For episode: 3715   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 7.0\n","For episode: 3716   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 6.97\n","For episode: 3717   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 449    lr: 2.6214400000000017e-08     eval rl_reward: 6.94\n","For episode: 3718   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 6.98\n","For episode: 3719   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     eval rl_reward: 7.01\n","For episode: 3720   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.97\n","For episode: 3721   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     eval rl_reward: 6.92\n","For episode: 3722   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.88\n","For episode: 3723   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.83\n","For episode: 3724   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.82\n","For episode: 3725   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.77\n","For episode: 3726   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 6.68\n","For episode: 3727   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.66\n","For episode: 3728   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.61\n","For episode: 3729   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.6\n","For episode: 3730   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.57\n","For episode: 3731   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 6.54\n","For episode: 3732   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 6.52\n","For episode: 3733   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.47\n","For episode: 3734   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.38\n","For episode: 3735   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 463    lr: 2.6214400000000017e-08     eval rl_reward: 6.39\n","For episode: 3736   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.38\n","For episode: 3737   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.35\n","For episode: 3738   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 6.34\n","For episode: 3739   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.31\n","For episode: 3740   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.28\n","For episode: 3741   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 305    lr: 2.6214400000000017e-08     eval rl_reward: 6.26\n","For episode: 3742   the run_score was: 16.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 437    lr: 2.6214400000000017e-08     eval rl_reward: 6.35\n","For episode: 3743   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 6.35\n","For episode: 3744   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 305    lr: 2.6214400000000017e-08     eval rl_reward: 6.34\n","For episode: 3745   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 486    lr: 2.6214400000000017e-08     eval rl_reward: 6.37\n","For episode: 3746   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 6.37\n","For episode: 3747   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 305    lr: 2.6214400000000017e-08     eval rl_reward: 6.36\n","For episode: 3748   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.31\n","For episode: 3749   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 305    lr: 2.6214400000000017e-08     eval rl_reward: 6.28\n","For episode: 3750   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.26\n","For episode: 3751   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 452    lr: 2.6214400000000017e-08     eval rl_reward: 6.27\n","For episode: 3752   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 410    lr: 2.6214400000000017e-08     eval rl_reward: 6.3\n","For episode: 3753   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 500    lr: 2.6214400000000017e-08     eval rl_reward: 6.31\n","For episode: 3754   the run_score was: 27.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 515    lr: 2.6214400000000017e-08     eval rl_reward: 6.48\n","For episode: 3755   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3756   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.48\n","For episode: 3757   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3758   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.43\n","For episode: 3759   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.4\n","For episode: 3760   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.37\n","For episode: 3761   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 2.6214400000000017e-08     eval rl_reward: 6.35\n","For episode: 3762   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.31\n","For episode: 3763   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 2.6214400000000017e-08     eval rl_reward: 6.24\n","For episode: 3764   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 6.2\n","For episode: 3765   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     eval rl_reward: 6.17\n","For episode: 3766   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.14\n","For episode: 3767   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.11\n","For episode: 3768   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 403    lr: 2.6214400000000017e-08     eval rl_reward: 6.12\n","For episode: 3769   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     eval rl_reward: 6.11\n","For episode: 3770   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 6.08\n","For episode: 3771   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.05\n","For episode: 3772   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 240    lr: 2.6214400000000017e-08     eval rl_reward: 6.05\n","For episode: 3773   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.0\n","For episode: 3774   the run_score was: 14.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 525    lr: 2.6214400000000017e-08     eval rl_reward: 6.1\n","For episode: 3775   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.1\n","For episode: 3776   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 552    lr: 2.6214400000000017e-08     eval rl_reward: 6.19\n","For episode: 3777   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.19\n","For episode: 3778   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.15\n","For episode: 3779   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.16\n","For episode: 3780   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.15\n","For episode: 3781   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 358    lr: 2.6214400000000017e-08     eval rl_reward: 6.17\n","For episode: 3782   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.06\n","For episode: 3783   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.99\n","For episode: 3784   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 367    lr: 2.6214400000000017e-08     eval rl_reward: 5.99\n","For episode: 3785   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.96\n","For episode: 3786   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.93\n","For episode: 3787   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 360    lr: 2.6214400000000017e-08     eval rl_reward: 5.91\n","For episode: 3788   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3789   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.77\n","For episode: 3790   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.74\n","For episode: 3791   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3792   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3793   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 214    lr: 2.6214400000000017e-08     eval rl_reward: 5.7\n","For episode: 3794   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.7\n","For episode: 3795   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 5.73\n","For episode: 3796   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.72\n","For episode: 3797   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 391    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3798   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 5.78\n","For episode: 3799   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 337    lr: 2.6214400000000017e-08     eval rl_reward: 5.8\n","For episode: 3800   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 408    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3801   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3802   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 2.6214400000000017e-08     eval rl_reward: 5.84\n","For episode: 3803   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 5.87\n","For episode: 3804   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 2.6214400000000017e-08     eval rl_reward: 5.88\n","For episode: 3805   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 2.6214400000000017e-08     eval rl_reward: 5.89\n","For episode: 3806   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 214    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3807   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3808   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3809   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3810   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3811   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3812   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 273    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3813   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3814   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3815   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3816   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3817   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.76\n","For episode: 3818   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.71\n","For episode: 3819   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 2.6214400000000017e-08     eval rl_reward: 5.68\n","For episode: 3820   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.68\n","For episode: 3821   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.69\n","For episode: 3822   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3823   the run_score was: 11.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3824   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3825   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.91\n","For episode: 3826   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.9\n","For episode: 3827   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 413    lr: 2.6214400000000017e-08     eval rl_reward: 5.93\n","For episode: 3828   the run_score was: 11.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 514    lr: 2.6214400000000017e-08     eval rl_reward: 6.0\n","For episode: 3829   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.0\n","For episode: 3830   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.0\n","For episode: 3831   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.98\n","For episode: 3832   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.95\n","For episode: 3833   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.95\n","For episode: 3834   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.95\n","For episode: 3835   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.89\n","For episode: 3836   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 358    lr: 2.6214400000000017e-08     eval rl_reward: 5.89\n","For episode: 3837   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.89\n","For episode: 3838   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 471    lr: 2.6214400000000017e-08     eval rl_reward: 5.91\n","For episode: 3839   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.93\n","For episode: 3840   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 289    lr: 2.6214400000000017e-08     eval rl_reward: 5.94\n","For episode: 3841   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.94\n","For episode: 3842   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.82\n","For episode: 3843   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 389    lr: 2.6214400000000017e-08     eval rl_reward: 5.8\n","For episode: 3844   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 441    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3845   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 292    lr: 2.6214400000000017e-08     eval rl_reward: 5.78\n","For episode: 3846   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.73\n","For episode: 3847   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.71\n","For episode: 3848   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.71\n","For episode: 3849   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     eval rl_reward: 5.72\n","For episode: 3850   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.8\n","For episode: 3851   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.74\n","For episode: 3852   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.78\n","For episode: 3853   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.73\n","For episode: 3854   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.5\n","For episode: 3855   the run_score was: 15.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 539    lr: 2.6214400000000017e-08     eval rl_reward: 5.56\n","For episode: 3856   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.64\n","For episode: 3857   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.72\n","For episode: 3858   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 310    lr: 2.6214400000000017e-08     eval rl_reward: 5.73\n","For episode: 3859   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3860   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.83\n","For episode: 3861   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 311    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3862   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.81\n","For episode: 3863   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.8\n","For episode: 3864   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.79\n","For episode: 3865   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 378    lr: 2.6214400000000017e-08     eval rl_reward: 5.77\n","For episode: 3866   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3867   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.75\n","For episode: 3868   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.71\n","For episode: 3869   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 5.72\n","For episode: 3870   the run_score was: 33.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 589    lr: 2.6214400000000017e-08     eval rl_reward: 5.99\n","For episode: 3871   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.99\n","For episode: 3872   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     eval rl_reward: 6.0\n","For episode: 3873   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.03\n","For episode: 3874   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.93\n","For episode: 3875   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.93\n","For episode: 3876   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 5.85\n","For episode: 3877   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 5.87\n","For episode: 3878   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 240    lr: 2.6214400000000017e-08     eval rl_reward: 5.87\n","For episode: 3879   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 324    lr: 2.6214400000000017e-08     eval rl_reward: 5.89\n","For episode: 3880   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     eval rl_reward: 5.9\n","For episode: 3881   the run_score was: 13.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 442    lr: 2.6214400000000017e-08     eval rl_reward: 5.97\n","For episode: 3882   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: 5.99\n","For episode: 3883   the run_score was: 14.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 519    lr: 2.6214400000000017e-08     eval rl_reward: 6.09\n","For episode: 3884   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.07\n","For episode: 3885   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     eval rl_reward: 6.1\n","For episode: 3886   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     eval rl_reward: 6.13\n","For episode: 3887   the run_score was: 15.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 539    lr: 2.6214400000000017e-08     eval rl_reward: 6.21\n","For episode: 3888   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 351    lr: 2.6214400000000017e-08     eval rl_reward: 6.25\n","For episode: 3889   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.27\n","For episode: 3890   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 6.35\n","For episode: 3891   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     eval rl_reward: 6.42\n","For episode: 3892   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     eval rl_reward: 6.46\n","For episode: 3893   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     eval rl_reward: 6.48\n","For episode: 3894   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3895   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.46\n","For episode: 3896   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3897   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3898   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: 6.46\n","For episode: 3899   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.47\n","For episode: 3900   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.47\n","For episode: 3901   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 331    lr: 2.6214400000000017e-08     eval rl_reward: 6.49\n","For episode: 3902   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.51\n","For episode: 3903   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.51\n","For episode: 3904   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     eval rl_reward: 6.56\n","For episode: 3905   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 391    lr: 2.6214400000000017e-08     eval rl_reward: 6.59\n","For episode: 3906   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     eval rl_reward: 6.63\n","For episode: 3907   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 348    lr: 2.6214400000000017e-08     eval rl_reward: 6.69\n","For episode: 3908   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.72\n","For episode: 3909   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.75\n","For episode: 3910   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 408    lr: 2.6214400000000017e-08     eval rl_reward: 6.79\n","For episode: 3911   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.82\n","For episode: 3912   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 442    lr: 2.6214400000000017e-08     eval rl_reward: 6.86\n","For episode: 3913   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.89\n","For episode: 3914   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.92\n","For episode: 3915   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 6.95\n","For episode: 3916   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     eval rl_reward: 7.01\n","For episode: 3917   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 390    lr: 2.6214400000000017e-08     eval rl_reward: 7.04\n","For episode: 3918   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 7.07\n","For episode: 3919   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 403    lr: 2.6214400000000017e-08     eval rl_reward: 7.1\n","For episode: 3920   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     eval rl_reward: 7.13\n","For episode: 3921   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.14\n","For episode: 3922   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 1.0485760000000008e-08     eval rl_reward: 7.09\n","For episode: 3923   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.05\n","For episode: 3924   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 472    lr: 1.0485760000000008e-08     eval rl_reward: 7.1\n","For episode: 3925   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 441    lr: 1.0485760000000008e-08     eval rl_reward: 7.07\n","For episode: 3926   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.1\n","For episode: 3927   the run_score was: 3.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 214    lr: 1.0485760000000008e-08     eval rl_reward: 7.04\n","For episode: 3928   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 363    lr: 1.0485760000000008e-08     eval rl_reward: 7.0\n","For episode: 3929   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 1.0485760000000008e-08     eval rl_reward: 7.01\n","For episode: 3930   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.04\n","For episode: 3931   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 389    lr: 1.0485760000000008e-08     eval rl_reward: 7.08\n","For episode: 3932   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.11\n","For episode: 3933   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.14\n","For episode: 3934   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.17\n","For episode: 3935   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.2\n","For episode: 3936   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.21\n","For episode: 3937   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 386    lr: 1.0485760000000008e-08     eval rl_reward: 7.25\n","For episode: 3938   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 1.0485760000000008e-08     eval rl_reward: 7.23\n","For episode: 3939   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 380    lr: 1.0485760000000008e-08     eval rl_reward: 7.24\n","For episode: 3940   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 389    lr: 1.0485760000000008e-08     eval rl_reward: 7.27\n","For episode: 3941   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.28\n","For episode: 3942   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 378    lr: 1.0485760000000008e-08     eval rl_reward: 7.31\n","For episode: 3943   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.31\n","For episode: 3944   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.29\n","For episode: 3945   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.31\n","For episode: 3946   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.34\n","For episode: 3947   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 410    lr: 1.0485760000000008e-08     eval rl_reward: 7.38\n","For episode: 3948   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.41\n","For episode: 3949   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.41\n","For episode: 3950   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.36\n","For episode: 3951   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.36\n","For episode: 3952   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.28\n","For episode: 3953   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.31\n","For episode: 3954   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 1.0485760000000008e-08     eval rl_reward: 7.32\n","For episode: 3955   the run_score was: 12.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 612    lr: 1.0485760000000008e-08     eval rl_reward: 7.29\n","For episode: 3956   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 1.0485760000000008e-08     eval rl_reward: 7.22\n","For episode: 3957   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.14\n","For episode: 3958   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 458    lr: 1.0485760000000008e-08     eval rl_reward: 7.18\n","For episode: 3959   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.1\n","For episode: 3960   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 378    lr: 1.0485760000000008e-08     eval rl_reward: 7.11\n","For episode: 3961   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.1\n","For episode: 3962   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 382    lr: 1.0485760000000008e-08     eval rl_reward: 7.13\n","For episode: 3963   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 1.0485760000000008e-08     eval rl_reward: 7.15\n","For episode: 3964   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.15\n","For episode: 3965   the run_score was: 11.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 489    lr: 1.0485760000000008e-08     eval rl_reward: 7.19\n","For episode: 3966   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 1.0485760000000008e-08     eval rl_reward: 7.2\n","For episode: 3967   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 374    lr: 1.0485760000000008e-08     eval rl_reward: 7.24\n","For episode: 3968   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.24\n","For episode: 3969   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 441    lr: 1.0485760000000008e-08     eval rl_reward: 7.27\n","For episode: 3970   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.01\n","For episode: 3971   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.04\n","For episode: 3972   the run_score was: 10.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 485    lr: 1.0485760000000008e-08     eval rl_reward: 7.09\n","For episode: 3973   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 7.06\n","For episode: 3974   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.09\n","For episode: 3975   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.12\n","For episode: 3976   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 311    lr: 1.0485760000000008e-08     eval rl_reward: 7.13\n","For episode: 3977   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.14\n","For episode: 3978   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 382    lr: 1.0485760000000008e-08     eval rl_reward: 7.17\n","For episode: 3979   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.18\n","For episode: 3980   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.2\n","For episode: 3981   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 1.0485760000000008e-08     eval rl_reward: 7.12\n","For episode: 3982   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 389    lr: 1.0485760000000008e-08     eval rl_reward: 7.13\n","For episode: 3983   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 406    lr: 1.0485760000000008e-08     eval rl_reward: 7.07\n","For episode: 3984   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 309    lr: 1.0485760000000008e-08     eval rl_reward: 7.06\n","For episode: 3985   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 291    lr: 1.0485760000000008e-08     eval rl_reward: 7.04\n","For episode: 3986   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 7.04\n","For episode: 3987   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.96\n","For episode: 3988   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.93\n","For episode: 3989   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 342    lr: 1.0485760000000008e-08     eval rl_reward: 6.93\n","For episode: 3990   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.88\n","For episode: 3991   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 1.0485760000000008e-08     eval rl_reward: 6.83\n","For episode: 3992   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.82\n","For episode: 3993   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 379    lr: 1.0485760000000008e-08     eval rl_reward: 6.84\n","For episode: 3994   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.86\n","For episode: 3995   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.89\n","For episode: 3996   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.89\n","For episode: 3997   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 1.0485760000000008e-08     eval rl_reward: 6.87\n","For episode: 3998   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.87\n","For episode: 3999   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 409    lr: 1.0485760000000008e-08     eval rl_reward: 6.89\n","For episode: 4000   the run_score was: 11.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 541    lr: 1.0485760000000008e-08     eval rl_reward: 6.93\n","For episode: 4001   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 330    lr: 1.0485760000000008e-08     eval rl_reward: 6.93\n","For episode: 4002   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 274    lr: 1.0485760000000008e-08     eval rl_reward: 6.91\n","For episode: 4003   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.91\n","For episode: 4004   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.85\n","For episode: 4005   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 330    lr: 1.0485760000000008e-08     eval rl_reward: 6.83\n","For episode: 4006   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.83\n","For episode: 4007   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.8\n","For episode: 4008   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 389    lr: 1.0485760000000008e-08     eval rl_reward: 6.81\n","For episode: 4009   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 361    lr: 1.0485760000000008e-08     eval rl_reward: 6.81\n","For episode: 4010   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.8\n","For episode: 4011   the run_score was: 8.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 411    lr: 1.0485760000000008e-08     eval rl_reward: 6.81\n","For episode: 4012   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.79\n","For episode: 4013   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.79\n","For episode: 4014   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 492    lr: 1.0485760000000008e-08     eval rl_reward: 6.81\n","For episode: 4015   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.78\n","For episode: 4016   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 311    lr: 1.0485760000000008e-08     eval rl_reward: 6.73\n","For episode: 4017   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.7\n","For episode: 4018   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.67\n","For episode: 4019   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.66\n","For episode: 4020   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.66\n","For episode: 4021   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 1.0485760000000008e-08     eval rl_reward: 6.65\n","For episode: 4022   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.67\n","For episode: 4023   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.67\n","For episode: 4024   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.64\n","For episode: 4025   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.62\n","For episode: 4026   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.59\n","For episode: 4027   the run_score was: 5.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 313    lr: 1.0485760000000008e-08     eval rl_reward: 6.61\n","For episode: 4028   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 330    lr: 1.0485760000000008e-08     eval rl_reward: 6.6\n","For episode: 4029   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.59\n","For episode: 4030   the run_score was: 15.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 539    lr: 1.0485760000000008e-08     eval rl_reward: 6.67\n","For episode: 4031   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 364    lr: 1.0485760000000008e-08     eval rl_reward: 6.66\n","For episode: 4032   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.63\n","For episode: 4033   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 1.0485760000000008e-08     eval rl_reward: 6.6\n","For episode: 4034   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 305    lr: 1.0485760000000008e-08     eval rl_reward: 6.59\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-49f650223a5a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# only train when ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0mtraining_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_net_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdouble_d\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt_frame\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mtarget_update_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_to_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/part2/your_agent.py\u001b[0m in \u001b[0;36mp_net_training\u001b[0;34m(self, current_step)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Sampling from replay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msys_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/part2/memory.py\u001b[0m in \u001b[0;36mget_mini_batch\u001b[0;34m(self, current_step)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT0ElEQVR4nO3dd3xT5f4H8E+60kW6W1pa2kKRvWdlqZRREETFwUUpoCJLRIaK98d0FBwIIqIiF3CBggJepCAoQxCQPRQqINACLUVKmw468/z+6G1o2qRN2iTnJPm8X6+8aM55cvJ9ckLPt886CiGEABEREZEMOUkdABEREZEhTFSIiIhItpioEBERkWwxUSEiIiLZYqJCREREssVEhYiIiGSLiQoRERHJFhMVIiIiki0mKkRERCRbTFTI7u3evRsKhQK7d++WOhQdX3zxBZo1awZXV1f4+vpa9b1HjRqFqKgoq76nXM+DuURFRWHUqFFShyELUny/yH4xUSGbtXr1aigUCu3D3d0d99xzDyZNmoQbN26Y5T22bt2KuXPnmuVYFZ07dw6jRo1C48aNsWLFCnz66acGy86dO1ennpUf6enpZo+PLKfy+VOpVOjduzd+/PFHqUMjkiUXqQMgqqv58+cjOjoaBQUF2LdvH5YvX46tW7fizJkz8PT0rNOxt27dimXLlpk9Wdm9ezc0Gg2WLFmCmJgYo16zfPlyeHt7V9lem9aYFStWQKPRmPw6Mo++ffti5MiREELgypUrWL58OQYPHoykpCT0799f6vCIZIWJCtm8+Ph4dOrUCQDw7LPPIiAgAIsWLcLmzZsxfPhwiaPTLyMjA4BpScawYcMQGBholvd3dXU1y3Godu655x489dRT2uePPvooWrRogSVLlthEolJQUAA3Nzc4ObFRniyP3zKyOw888AAA4NKlS9WWW79+PTp27AgPDw8EBgbiqaeewrVr17T7R40ahWXLlgHQba6vyUcffYSWLVtCqVQiLCwMEydORFZWlnZ/VFQU5syZAwAICgqCQqEwS4tN+RiQb775Bq+99hrq168PLy8vDBkyBKmpqTpl9Y0hWLduHTp27Ih69epBpVKhdevWWLJkiU6Zv//+G4899hj8/f3h6emJbt266e2yuHr1KoYOHQovLy8EBwfjpZdeQmFhod64Dx06hAEDBsDHxweenp7o3bs39u/fr1MmJycHU6ZMQVRUFJRKJYKDg9G3b18cO3as2s/kypUrmDBhApo2bQoPDw8EBATgsccew+XLl3XKlXcj7t+/H1OnTkVQUBC8vLzw8MMP4+bNmzplhRB44403EB4eDk9PT9x///34448/qo2jJs2bN0dgYCAuXryos72wsBBz5sxBTEwMlEolIiIi8PLLL+t8lo888gg6dOig87rBgwdDoVDghx9+0G47dOgQFAoFkpKSAACZmZmYPn06WrduDW9vb6hUKsTHx+PkyZM6xyr/Xq1btw7/93//hwYNGsDT0xNqtRoAsGnTJrRq1Qru7u5o1aoVNm7cqLeOxny/iPRhiwrZnfJf9gEBAQbLrF69GqNHj0bnzp2RmJiIGzduYMmSJdi/fz+OHz8OX19fPP/887h+/Tp27NiBL774wqj3njt3LubNm4e4uDiMHz8eycnJWL58OQ4fPoz9+/fD1dUVixcvxueff46NGzdqu3PatGlT47EzMzOrbHNxcanSKvPmm29CoVDglVdeQUZGBhYvXoy4uDicOHECHh4eeo+9Y8cODB8+HH369MHChQsBAGfPnsX+/fvx4osvAgBu3LiBe++9F/n5+Zg8eTICAgKwZs0aDBkyBBs2bMDDDz8MALhz5w769OmDlJQUTJ48GWFhYfjiiy/wyy+/VHnfX375BfHx8ejYsSPmzJkDJycnrFq1Cg888AB+/fVXdOnSBQAwbtw4bNiwAZMmTUKLFi1w69Yt7Nu3D2fPnq1yka7o8OHD+O233/Dkk08iPDwcly9fxvLly3Hffffhzz//rNI1+MILL8DPzw9z5szB5cuXsXjxYkyaNAnffPONtszs2bPxxhtvYODAgRg4cCCOHTuGfv36oaioyGAcNcnOzsbt27fRuHFj7TaNRoMhQ4Zg3759GDt2LJo3b47Tp0/j/fffx19//YVNmzYBAHr27InNmzdDrVZDpVJBCIH9+/fDyckJv/76K4YMGQIA+PXXX+Hk5ITu3bsDKEs6N23ahMceewzR0dG4ceMGPvnkE/Tu3Rt//vknwsLCdGJ8/fXX4ebmhunTp6OwsBBubm746aeftK1BiYmJuHXrFkaPHo3w8HCd1xrz/SIySBDZqFWrVgkAYufOneLmzZsiNTVVrFu3TgQEBAgPDw9x9epVIYQQu3btEgDErl27hBBCFBUVieDgYNGqVStx584d7fG2bNkiAIjZs2drt02cOFEY+98kIyNDuLm5iX79+onS0lLt9g8//FAAEP/5z3+02+bMmSMAiJs3b9Z43PKy+h5NmzbVliuvZ4MGDYRardZu//bbbwUAsWTJEu22hIQEERkZqX3+4osvCpVKJUpKSgzGMWXKFAFA/Prrr9ptOTk5Ijo6WkRFRWnrvHjxYgFAfPvtt9pyeXl5IiYmRuc8aDQa0aRJE9G/f3+h0Wi0ZfPz80V0dLTo27evdpuPj4+YOHFijZ9VZfn5+VW2HThwQAAQn3/+uXZb+XcpLi5OJ5aXXnpJODs7i6ysLCHE3XM8aNAgnXKvvfaaACASEhJqjAmAeOaZZ8TNmzdFRkaGOHLkiBgwYIAAIN555x1tuS+++EI4OTnpfN5CCPHxxx8LAGL//v1CCCEOHz4sAIitW7cKIYQ4deqUACAee+wx0bVrV+3rhgwZItq3b699XlBQoPM9FUKIS5cuCaVSKebPn6/dVv69atSoUZXPs127diI0NFT7+QghxE8//SQAmPz9IjKEXT9k8+Li4hAUFISIiAg8+eST8Pb2xsaNG9GgQQO95Y8cOYKMjAxMmDAB7u7u2u2DBg1Cs2bNaj37YufOnSgqKsKUKVN0+u6fe+45qFSqOs/q+O6777Bjxw6dx6pVq6qUGzlyJOrVq6d9PmzYMISGhmLr1q0Gj+3r64u8vDzs2LHDYJmtW7eiS5cu6NGjh3abt7c3xo4di8uXL+PPP//UlgsNDcWwYcO05Tw9PTF27Fid4504cQLnz5/Hv/71L9y6dQv//PMP/vnnH+Tl5aFPnz7Yu3evdsCvr68vDh06hOvXr9fwKemq2IJUXFyMW7duISYmBr6+vnq7jcaOHavTvdezZ0+UlpbiypUrAO6e4xdeeEGn3JQpU0yKa+XKlQgKCkJwcDA6deqEn3/+GS+//DKmTp2qLbN+/Xo0b94czZo10342//zzj7Zrc9euXQCA9u3bw9vbG3v37gVQ1nISHh6OkSNH4tixY8jPz4cQAvv27UPPnj21x1cqldrvaWlpKW7dugVvb280bdpU72eTkJCg83mmpaXhxIkTSEhIgI+Pj3Z737590aJFC53XGvP9IjKEXT9k85YtW4Z77rkHLi4uCAkJQdOmTasd5Fd+0WnatGmVfc2aNcO+fftqFYeh47q5uaFRo0ba/bXVq1cvowbTNmnSROe5QqFATExMlXEZFU2YMAHffvst4uPj0aBBA/Tr1w+PP/44BgwYoC1z5coVdO3atcprmzdvrt3fqlUrXLlyBTExMVXG81T+XM6fPw+g7AJoSHZ2Nvz8/PD2228jISEBERER6NixIwYOHIiRI0eiUaNGBl8LlHVDJSYmYtWqVbh27RqEEDrHrqxhw4Y6z/38/AAAt2/f1tYRqPoZBwUFacsa46GHHsKkSZNQVFSEw4cP46233kJ+fr7O9/b8+fM4e/YsgoKC9B6jfEC2s7MzYmNj8euvvwIoS1R69uyJHj16oLS0FAcPHkRISAgyMzN1EpXyWWcfffQRLl26hNLSUu0+fd2m0dHROs8NfRYAqiQ7xny/iAxhokI2r0uXLtpZP1Q7wcHBOHHiBLZv346kpCQkJSVh1apVGDlyJNasWWOR9yxvLXnnnXfQrl07vWXKp2M//vjj6NmzJzZu3IiffvoJ77zzDhYuXIjvv/8e8fHxBt/jhRdewKpVqzBlyhTExsbCx8cHCoUCTz75pN7p2c7OznqPUzHBMYfw8HDExcUBAAYOHIjAwEBMmjQJ999/Px555BEAZZ9P69atsWjRIr3HiIiI0P7co0cPvPnmmygoKMCvv/6Kf//73/D19UWrVq3w66+/IiQkBAB0EpW33noLs2bNwpgxY/D666/D398fTk5OmDJlit7PxtD4JmNI8f0i+8FEhRxOZGQkACA5OVnbjF4uOTlZux+AUbN89B234l/6RUVFuHTpkvbCZGnlLRXlhBC4cOFCjQN23dzcMHjwYAwePBgajQYTJkzAJ598glmzZiEmJgaRkZFITk6u8rpz584BuFv/yMhInDlzBkIInc+v8mvLB46qVCqjPpvQ0FBMmDABEyZMQEZGBjp06IA333yz2kRlw4YNSEhIwHvvvafdVlBQoDMLyxTldTx//rzOOb5586a21aU2nn/+ebz//vv4v//7Pzz88MNQKBRo3LgxTp48iT59+tT4PezZsyeKioqwdu1aXLt2TZuQ9OrVS5uo3HPPPdqEBSj7bO6//36sXLlS51hZWVlGtdxV/Cwq0/c9qen7RWQIx6iQw+nUqROCg4Px8ccf60zzTEpKwtmzZzFo0CDtNi8vLwAw6sIWFxcHNzc3fPDBBzp/ga9cuRLZ2dk6x7Wkzz//HDk5OdrnGzZsQFpaWrUX9Fu3buk8d3Jy0iY25Z/RwIED8fvvv+PAgQPacnl5efj0008RFRWlHZcwcOBAXL9+HRs2bNCWy8/Pr7L6bseOHdG4cWO8++67yM3NrRJT+bTg0tLSKt00wcHBCAsLMzjluZyzs3OV1pClS5fqdHOYIi4uDq6urli6dKnOcRcvXlyr45VzcXHBtGnTcPbsWWzevBlAWSvStWvXsGLFiirl79y5g7y8PO3zrl27wtXVFQsXLoS/vz9atmwJoCyBOXjwIPbs2aPTmgLo/2zWr1+vM0W/OqGhoWjXrh3WrFmjc3527NihHa9UzpjvF5EhbFEhh1P+C3306NHo3bs3hg8frp2eHBUVhZdeeklbtmPHjgCAyZMno3///nB2dsaTTz6p97hBQUGYOXMm5s2bhwEDBmDIkCFITk7GRx99hM6dO+ss8FUbGzZs0Lsybd++fXX+Uvb390ePHj0wevRo3LhxA4sXL0ZMTAyee+45g8d+9tlnkZmZiQceeADh4eG4cuUKli5dinbt2mnHoLz66qtYu3Yt4uPjMXnyZPj7+2PNmjW4dOkSvvvuO+34iueeew4ffvghRo4ciaNHjyI0NBRffPFFlanATk5O+OyzzxAfH4+WLVti9OjRaNCgAa5du4Zdu3ZBpVLhv//9L3JychAeHo5hw4ahbdu28Pb2xs6dO3H48GGdlhJ9HnzwQXzxxRfw8fFBixYtcODAAezcubPaqevVCQoKwvTp05GYmIgHH3wQAwcOxPHjx5GUlFTnxfhGjRqF2bNnY+HChRg6dCiefvppfPvttxg3bhx27dqF7t27o7S0FOfOncO3336L7du3a7s8PT090bFjRxw8eFC7hgpQ1qKSl5eHvLy8KonKgw8+iPnz52P06NG49957cfr0aXz11Vc1jvupKDExEYMGDUKPHj0wZswYZGZmYunSpWjZsqVO8mnM94vIIMnmGxHVUfmU0sOHD1dbrvL05HLffPONaN++vVAqlcLf31+MGDFCO6W5XElJiXjhhRdEUFCQUCgURk1V/vDDD0WzZs2Eq6urCAkJEePHjxe3b9/WKWOu6ckV61Vez7Vr14qZM2eK4OBg4eHhIQYNGiSuXLmic8zK05M3bNgg+vXrJ4KDg4Wbm5to2LCheP7550VaWprO6y5evCiGDRsmfH19hbu7u+jSpYvYsmVLlZivXLkihgwZIjw9PUVgYKB48cUXxbZt2/Seh+PHj4tHHnlEBAQECKVSKSIjI8Xjjz8ufv75ZyGEEIWFhWLGjBmibdu2ol69esLLy0u0bdtWfPTRRzV+drdv3xajR48WgYGBwtvbW/Tv31+cO3dOREZG6kwlNvRd0vfdKS0tFfPmzROhoaHCw8ND3HfffeLMmTNVjmkIAINTrefOnVtlKv3ChQtFy5YthVKpFH5+fqJjx45i3rx5Ijs7W+e1M2bMEADEwoULdbaXTwu/ePGizvaCggIxbdo0bT26d+8uDhw4IHr37i169+5d5TNYv3693pi/++470bx5c6FUKkWLFi3E999/X+vvF5E+CiHMPEqMiCSxe/du3H///Vi/fr3O1GAiIlvGMSpEREQkW0xUiIiISLaYqBAREZFscYwKERERyRZbVIiIiEi2mKgQERGRbNn0gm8ajQbXr19HvXr1TFrqnIiIiKQjhEBOTg7CwsKqvYksYOOJyvXr13VuzEVERES2IzU1FeHh4dWWselEpV69egDKKqpSqSSOhoiIiIyhVqsRERGhvY5Xx6YTlfLuHpVKxUSFiIjIxhgzbIODaYmIiEi2mKgQERGRbDFRISIiItliokJERESyxUSFiIiIZIuJChEREckWExUiIiKSLSYqREREJFtMVIiIiEi2mKgQERGRbDFRISIiItliokJERESyxUSFiIhIAgpF2aOgQOpI5E3SRKW0tBSzZs1CdHQ0PDw80LhxY7z++usQQkgZFhERkdV4eEgdgby5SPnmCxcuxPLly7FmzRq0bNkSR44cwejRo+Hj44PJkydLGRoREZHF3LkjdQS2Q9JE5bfffsNDDz2EQYMGAQCioqKwdu1a/P7771KGRUREZFGenlJHYDsk7fq599578fPPP+Ovv/4CAJw8eRL79u1DfHy83vKFhYVQq9U6DyIiIrJfkraovPrqq1Cr1WjWrBmcnZ1RWlqKN998EyNGjNBbPjExEfPmzbNylERERCQVSVtUvv32W3z11Vf4+uuvcezYMaxZswbvvvsu1qxZo7f8zJkzkZ2drX2kpqZaOWIiIiKyJoWQcIpNREQEXn31VUycOFG77Y033sCXX36Jc+fO1fh6tVoNHx8fZGdnQ6VSWTJUIiIis1Aoqm5ztMmuply/JW1Ryc/Ph5OTbgjOzs7QaDQSRURERERyIukYlcGDB+PNN99Ew4YN0bJlSxw/fhyLFi3CmDFjpAyLiIjIqspbWRytZcUYknb95OTkYNasWdi4cSMyMjIQFhaG4cOHY/bs2XBzc6vx9ez6ISIiW6Gvy6cyR0lUTLl+S5qo1BUTFSIishVMVO6ymTEqRERERNVhokJERESyxUSFiIiIZIuJChERkYWVlEgdge1iokJERGRhrq66zx1l0Kw5MFEhIiKSQE6O1BHYBiYqREREVlTemuLhIW0ctoKJChERkQScnaWOwDYwUSEiIpJIdrbUEcgfExUiIiILqm7GT+VFWY1ZvdbRMFEhIiKyALW6LPGoPOOHTMNEhYiIyAJ8fKSOwD4wUSEiIrISfeuncE2V6jFRISIiItliokJERESyxUSFiIiIZIuJChERkZlxmrH5MFEhIiIi2WKiQkREZCa3bxtuTeHsntphokJEZAOEADQaqaOgmvj7Sx2B/WGiQkRkA5ycym5ip1AAxcVSR0NkPUxUiIhsjJub1BGQPtV1+cip2+frr8tiVSiA4GCpo6kZExUiIiIHMmLE3Z9v3pQuDmMxUSEiIiLZYqJCRERkIXfuSB2B7WOiQkREZCHu7lJHYPtcpA6AiIjIFtW0+mxtp5MrFPIafCs1tqgQERFZgK0so+/vDxQVSR2FYUxUiIiITJSZKXUEtZOXV3Xb7duAUmn9WIzFRIWIyAaxa0BaAQHmPZ61zqe3t3Xex5yYqBARyRyTEnJkHExLRCRjhsY5ODkxgZErWz0vch3Ey0SFiIjIDOR4kbcH7PohIiIyQUGB1BE4FiYqREREJvDwkDoC0+XkGDddWo6tQuz6ISIiqgM5XtwrU6mkjqD2mKgQEdVS5b9QbeGCReZlb+dcjovUMVEhIjKSHH+JE9k7SceoREVFQaFQVHlMnDhRyrCIiGSBiZH1KBRlj6wsqSOR1tChUkdQlaQtKocPH0Zpaan2+ZkzZ9C3b1889thjEkZFRCRPQjB5sYSKn6mfn/115xii7/u0ebM0sVRH0kQlKChI5/mCBQvQuHFj9O7dW6KIiIjInlW8MMs5IbH04msdOlju2OYmm+nJRUVF+PLLLzFmzBgoDPzJUFhYCLVarfMgIrKk4mLg5k3jymZnm+99K/8aTE/XX0ahKIuRamZsa1R15eylRevQIakjMJ5sEpVNmzYhKysLo0aNMlgmMTERPj4+2kdERIT1AiQih+TmBgQHG3eB8vW1XBwhIYb3OTtb5j0zMu4mQ/boxg3AUf/edbGhqTQKIeTR+NW/f3+4ubnhv//9r8EyhYWFKCws1D5Xq9WIiIhAdnY2VLY8SZyIZKs2F2lz/FY1NPXZUDyW+E1uK90kxjLlXBqqb8Vj3LhRlsSaiyWnu1c89oABQFKS4f3WONdqtRo+Pj5GXb9lkVNduXIFO3fuxPfff19tOaVSCaVSaaWoiIhqp3z2iK+v+X/pFxQA7u7mPaYx5HrDOmuqnEhUGmZZZ9YaLF05SalMoQCKigBXV8vHYgxZdP2sWrUKwcHBGDRokNShEBGZRXk3UHnXibku8vxbTT7stUsMAP7+W+oI7pI8UdFoNFi1ahUSEhLgYkudZkREJnByqv14iJIS88ZSW6dPAxqN1FFYR+WxOZmZ0sUihc6dpY7gLskzg507dyIlJQVjxoyROhQiIovy8aldy4qlBsuaqk2bsn8dsQsoIEDqCGqvNucrJ8f8cdSW5IlKv379IJPxvEREJnPERdg0mrIWIrINtn6ubDx8IiLLsUQ3R0GB+Y9pbc7O9pWcCWG41UGjAfLyrBuPJTVqJHUEpmOiQkRkQE1dLrW5gHl41C4WkoazM+DtrbutusTGnCzxHhcvGl+2YUPzv39tMFEhIqoFIQBPz9q9VqHQXe22pOTu4M2CgppbK65fr937OipbXbTOml02Tz9ddVtqqvXevzpMVIiIjFDxr9vKS+rX5i/siguFVVyvwpgWl9BQ096rNuxldk91C+RZq2XEFnz+uXw/C8kH0xIR2Qo5/SK39CDeCje2t0lCmN4iYcxnaunxKlIPzpb6/fVhiwoRkR0wdxIll7VbastS3Sa17e6j2mOiQkQkY8beudncF2ZHvSCzO0h+mKgQEZlJxXEPGRk1ly8urrlMYGDd4yKyZUxUiIj0qOtf1cbcsC4/v24xSP2Xv9zGMpB5VDyvCkXNNzG0NCYqRER6mLsrRd+YD19faS725dN1TXlvW+oSqaletlIPqVRuxRs5Upo4yjFRISKqwBLTcrOy5HO/ntpIS5M6AuOxlafuTp7UfV5Ty5+lcXoyEVEF5kwobOEvd4Wi5jjr17/7c0EB4O5u2Zhqy9Kfty2cT3OovE6P1MkfW1SIiGpgrlYWYwbPykF1Fyal0npxmMrWb74nVy4SN2nwtBIR/Y+hv5jN9Rel1L/wHZU5WkKys+t+DFsSE3P3Zz8/6eIAmKgQEWlZ4y9yW+s+sLV4K6tt/JVfp1LVPRZbcvQoMGIEsGwZcOqUtLEwvyciIuTnA15etr90fkUVk43aJCy2nqQBQPfutXudSgV8+aV5Y6kttqgQEaH6m9c5Ai+vsn9NHUws9UBLQ+zlvF2/fveu2rXx22/mjUcKTFSIiByIPbWYOIIGDcr+Neau2pVVTiL//e+6xyMFJipERFYm5V/75hjQK8cbFkq91octeP11qSOoHSYqRER2orbdMKa+To6L15V3XZFhcu2mqwkTFSIimbCXcRVS4+doXzjrh4ioEikvdBqN6ffgsdW/lMl6bDl5Y4sKEZGMMOkg0sVEhYhIAtb6C7finZJNTYJs5a9we0vuLL1Csq1h1w8REWnZSnJCjoMtKkREMmArNyzUR6q/9PW1EpnrBpIkH0xUiMjhyaFJ3Vw3LMzLq31Xjz1wxDrbOyYqRER2xNvbuHKZmZaNg8hcOEaFiEgiUo4H8fOT7r3riq0mjoUtKkTkMIwZv1BUZPk47BGTB7IUJipE5DCcnWseu+Hqar14pMKZPfJX27sl2yMmKkTk0By5JYAJi3wplWXnp/I5csTvKxMVInII+i7Kd+5YPw4p6bvwmZNCAfzzT92PY8tTta3B0ZIVJipE5BCcKv22S0sDPD2liUUK1mo9CQqq2+sVCsDNzXGnV1NVTFSIyCGFhUkdgTxUTGBu3zb+dTdvmj8WfRx5TRgqw0SFiMjBlXcJ+foa/5rAwOrvSaNQ6K7Vom+buXHMzV0TJkgdgfkwUSEisnGlpdK9d3XJQUCAcduMxZYV4y1fLnUE5sNEhYjIxlUef2NtZ89Wv79ycsFkw7psvaVJ8kTl2rVreOqppxAQEAAPDw+0bt0aR44ckTosInJAjjYLyFyaNTO8T6227HuXd1vZ+sW4OvZcN2NIuoT+7du30b17d9x///1ISkpCUFAQzp8/Dz9bXtuZiGySo18MLMXHR+oIHI+9tVhJmqgsXLgQERERWLVqlXZbdHS0hBERkSNikmKbeN6AGzeA+vXLfrbXz0PSrp8ffvgBnTp1wmOPPYbg4GC0b98eK1asMFi+sLAQarVa50FEROSoypMUe2aWRCUrK6tWr/v777+xfPlyNGnSBNu3b8f48eMxefJkrFmzRm/5xMRE+Pj4aB8RERF1iJqIHIEjzxQpLZXv+A3e/NH8unSROgLLUAhh2ld44cKFiIqKwhNPPAEAePzxx/Hdd9+hfv362Lp1K9q2bWv0sdzc3NCpUyf89ttv2m2TJ0/G4cOHceDAgSrlCwsLUVhYqH2uVqsRERGB7OxsqFQqU6pBRHaoNgmJHC/itaGv7tasW10/+zt3TFsp2F7Omykqfsbl9a/8ud+5A3h46G6T42elVqvh4+Nj1PXb5BaVjz/+WNuSsWPHDuzYsQNJSUmIj4/HjBkzTDpWaGgoWrRoobOtefPmSElJ0VteqVRCpVLpPIiIAMdtNbEXTFLMo3KSYg9MHkybnp6uTVS2bNmCxx9/HP369UNUVBS6du1q0rG6d++O5ORknW1//fUXIiMjTQ2LiBwYL1xlnwGTNcfh7g4UFEgdhXWY3KLi5+eH1NRUAMC2bdsQFxcHABBCoNTE5RFfeuklHDx4EG+99RYuXLiAr7/+Gp9++ikmTpxoalhE5MBMWfDMUZIaOY4Bqbx8fk13W9Z3rhzl/NWksNBxElOTW1QeeeQR/Otf/0KTJk1w69YtxMfHAwCOHz+OmJgYk47VuXNnbNy4ETNnzsT8+fMRHR2NxYsXY8SIEaaGRURkNHu92Mm9XvqWyAoKqj7uii1F169bJi6SN5MTlffffx9RUVFITU3F22+/DW9vbwBAWloaJtTiLkgPPvggHnzwQZNfR0RE9qGmlgG5J2DWotFIf7sEKZg860dOTBk1TET2x5Fn+chN5XOhb8yMKeNobt827W7OjsLU73xCArB6tUVCqRNTrt9Gtaj88MMPRr/5kCFDjC5LRGRpFf8KvXlT2lgcmakJIpMU86iw8LvNMipRGTp0qM5zhUKBig0xigopnqkDaomILEmhYCuKrcnIkDoC+2EPA26N6u3SaDTax08//YR27dohKSkJWVlZyMrKwtatW9GhQwds27bN0vESkQMqX2G1Inv4BUz6BQVJHQHJicmDaadMmYKPP/4YPXr00G7r378/PD09MXbsWJw9e9asARIRuVT4TVVT60hGBhAcXPYvL3jWU3H8SUmJtLGQfTF5/PDFixfhq6fz0MfHB5cvXzZDSEREht24UTbuxJDy6a5MUqyv/L5Czs61e/2tW+ymo6pMTlQ6d+6MqVOn4saNG9ptN27cwIwZM9DFXu+IRESyUb++4QthhVuBkQyUJy7GJh/+/paNh2yTyYnKypUrkZaWhoYNGyImJgYxMTFo2LAhrl27hpUrV1oiRiKiGpWUAG5uUkdBROZm8hiVJk2a4NSpU9ixYwfOnTsHoOxGgnFxcTqzf4iIrIXdBbaj8qJlPHfmUfmuyUVFgKurdPGYk0mJSnFxMTw8PHDixAn069cP/fr1s1RcREQAgLw8qSMgc1IogKtXgfBwJim1UfEzq9g24O6uW85ekhTAxETF1dUVDRs25FopRGQ1/7tLh0HVDawleWrQgEmKOTjKZ2jyGJV///vfeO2115BZ+TaYREQSYI8zkX0zeYzKhx9+iAsXLiAsLAyRkZHw8vLS2X/s2DGzBUdEjo03qyMikxOVysvpExFZApMUIgJ492Qikil9iYrt/rYisryK/2fk/n/FlOu3yWNUiIiIiKzF5K6f0tJSvP/++/j222+RkpKCoqIinf0cZEtERETmYnKLyrx587Bo0SI88cQTyM7OxtSpU/HII4/AyckJc+fOtUCIRERE5KhMTlS++uorrFixAtOmTYOLiwuGDx+Ozz77DLNnz8bBgwctESMREW7elDoCIpKCyYlKeno6WrduDQDw9vZGdnY2AODBBx/Ejz/+aN7oiIhQNjAwMFDqKIjkzdSbQNoKkxOV8PBwpKWlAQAaN26Mn376CQBw+PBhKJVK80ZHREREDs3kROXhhx/Gzz//DAB44YUXMGvWLDRp0gQjR47EmDFjzB4gETkOheLug4gIMMM6KgcPHsRvv/2GJk2aYPDgweaKyyhcR4XIPuTnA0ol4GJgHqK9NWUTOTpTrt8mT0+urFu3bujWrVtdD0NEDqqm1hPeA5XIsZnc9dOwYUOMHDkSK1euxMWLFy0RExE5gJIS47p4nLgsJZFDM/lXwFtvvQV3d3csXLgQTZo0QUREBJ566imsWLEC58+ft0SMRGSHXF2ljoCIbEGdxqikpaVhz5492LJlC7755htoNBqUWrGdlmNUiGyXsQNmOT6FyP5YfIxKfn4+9u3bh927d2PXrl04fvw4WrVqhfvuu682hyMiIiLSy+RE5d5778Xx48fRvHlz3HfffXj11VfRq1cv+Pn5WSI+InJgGo3UERCR1Eweo3Lu3Dl4eXmhWbNmaNasGZo3b84khYjMrrSU66kQUS0SlVu3buGXX35Bt27dsH37dnTv3h0NGjTAv/71L6xYscISMRKRHahuIbeKS3+XPzjbh4iAOg6mFULg6NGj+PDDD/HVV19xMC0R6VU5QSktBZyd7z7ngFkix2LRwbTHjh3D7t27sXv3buzbtw85OTlo3bo1XnjhBfTu3bvWQROR46iYpBARVcfkRKVLly5o3749evfujeeeew69evWCj4+PJWIjIjvAcSZEVBcmJyqZmZnsZiEiIiKrMHm4mkqlQlZWFj777DPMnDkTmZmZAMq6hK5du2b2AInIdhnTmsLxKURUHZNbVE6dOoU+ffrA19cXly9fxnPPPQd/f398//33SElJweeff26JOInIxly5InUERGQPTG5RmTp1KkaPHo3z58/D3d1du33gwIHYu3evSceaO3cuFAqFzqNZs2amhkREMhQVJXUERGQPTG5ROXz4MD755JMq2xs0aID09HSTA2jZsiV27tx5NyCXWq3qT0Q2iN0+RFQTk7MCpVIJtVpdZftff/2FoKAg0wNwcUH9+vVNfh0R2bbr16WOgIhsgcldP0OGDMH8+fNRXFwMAFAoFEhJScErr7yCRx991OQAzp8/j7CwMDRq1AgjRoxASkqKyccgInnRN4i2cutJaKh1YiEi22byyrTZ2dkYNmwYjhw5gpycHISFhSE9PR3dunVDUlISvLy8jD5WUlIScnNz0bRpU6SlpWHevHm4du0azpw5g3r16lUpX1hYiMLCQu1ztVqNiIgIrkxLJDOVE5Xy3zLp6XcTFHb7EDkuU1amrfUS+vv27cOpU6eQm5uLDh06IC4urlbBVpSVlYXIyEgsWrQIzzzzTJX9c+fOxbx586psZ6JCJB/GtKYQkWOzSqJS2bFjxzB79mxs2bKlTsfp3Lkz4uLikJiYWGUfW1SI5I+JChHVxJRExaQxKtu3b8f06dPx2muv4e+//wYAnDt3DkOHDkXnzp2h0WhqHzWA3NxcXLx4EaEGOq+VSiVUKpXOg4jkq6SESQoR1Y3RicrKlSsRHx+P1atXY+HChejWrRu+/PJLxMbGon79+jhz5gy2bt1q0ptPnz4de/bsweXLl/Hbb7/h4YcfhrOzM4YPH25yRYhIfpxMHq5PRKTL6OnJS5YswcKFCzFjxgx89913eOyxx/DRRx/h9OnTCA8Pr9WbX716FcOHD8etW7cQFBSEHj164ODBg7Wa5kxE8sMbEhJRXRk9RsXLywt//PEHoqKiIISAUqnErl270L17d0vHaJApfVxEZHklJYCr693n7PYhIn0sMkblzp078PT0BFC2dopSqTQ4loSIHFPFJIWIyBxMWpn2s88+g7e3NwCgpKQEq1evRmBgoE6ZyZMnmy86IiIicmhGd/1ERUVBUUOHs0Kh0M4GsgZ2/RDJS8VfEbm5gAnrPxKRAzHl+m10i8rly5frGhcR2bHKf8dwxg8RmQN/lRCRRXh4SB0BEdkDJipEREQkW0xUiKjOKo9047RkIjIXJipEVGccj0JElmLUr5epU6ciLy8PALB3716UlJRYNCgiIiIiwMhEZenSpcjNzQUA3H///cjMzLRoUERkO9LTdZ+z24eIzMmo6clRUVH44IMP0K9fPwghcODAAfj5+ekt26tXL7MGSETyxgWqiciSjFrwbdOmTRg3bhwyMjKgUChg6CUKhQKlpaVmD9IQLvhGJL3K66ewRYWIamLK9dvolWkBIDc3FyqVCsnJyQgODtZbxsfHx7Ro64CJCpH0KiYqajVQr550sRCRbbDIyrQA4O3tjV27diE6OhouLia9lIjsUOXWFCYpRGRuJmcbvXv3RmlpKb777jucPXsWANCiRQs89NBDcHZ2NnuARERE5LhMTlQuXLiAQYMG4erVq2jatCkAIDExEREREfjxxx/RuHFjswdJREREjsnkZZomT56MRo0aITU1FceOHcOxY8eQkpKC6OhoTJ482RIxEhERkYMyuUVlz549OHjwIPz9/bXbAgICsGDBAnTv3t2swRGRfFUen0JEZAkmt6golUrk5ORU2Z6bmws3NzezBEVE8sY1H4nIWkxOVB588EGMHTsWhw4dghACQggcPHgQ48aNw5AhQywRIxHJTEBA1W0ajfXjICL7Z3Ki8sEHH6Bx48aIjY2Fu7s73N3d0b17d8TExGDJkiWWiJGIbAC7gojIEkweo+Lr64vNmzfjwoUL2unJzZs3R0xMjNmDIyL5+d/9SXVwNVoispRar9oWExPD5ITIAXl7Sx0BETkSk7t+iIgqYmsKEVkSExUiIiKSLSYqRFRrbE0hIkszOVFJSUmBvhsuCyGQkpJilqCIiIiIgFokKtHR0bh582aV7ZmZmYiOjjZLUEQkT2xBISJrMzlREUJAoWfBhNzcXLi7u5slKCKSJyd2FhORlRk9PXnq1KkAAIVCgVmzZsHT01O7r7S0FIcOHUK7du3MHiARERE5LqMTlePHjwMoa1E5ffq0zn193Nzc0LZtW0yfPt38ERKRLLEbiIiswehEZdeuXQCA0aNHY8mSJVCpVBYLioiIiAioxcq0q1atskQcRERERFWYnKjk5eVhwYIF+Pnnn5GRkQFNpVum/v3332YLjojkgzcdJCIpmJyoPPvss9izZw+efvpphIaG6p0BRERERGQOJicqSUlJ+PHHH9G9e3dLxENERESkZfKqCH5+fvD397dELERkIzjjh4isxeRE5fXXX8fs2bORn59viXiIiIiItExOVN577z1s374dISEhaN26NTp06KDzqK0FCxZAoVBgypQptT4GERER2ReTx6gMHTrU7EEcPnwYn3zyCdq0aWP2YxMREZHtMjlRmTNnjlkDyM3NxYgRI7BixQq88cYbZj02ERER2TbJbzE2ceJEDBo0CHFxcTWWLSwshFqt1nkQkeVxFQIikorJLSpOTk7Vrp1SWlpq9LHWrVuHY8eO4fDhw0aVT0xMxLx584w+PhHVHZMUIpKSyYnKxo0bdZ4XFxfj+PHjWLNmjUlJRGpqKl588UXs2LED7u7uRr1m5syZ2rs4A4BarUZERITR70lEdVdcLHUERORIFEKYZ0WEr7/+Gt988w02b95sVPlNmzbh4YcfhrOzs3ZbaWkpFAoFnJycUFhYqLNPH7VaDR8fH2RnZ/MmiURmZqglpagIcHW1bixEZF9MuX6b3KJiSLdu3TB27Fijy/fp0wenT5/W2TZ69Gg0a9YMr7zySo1JChFJg0kKEVmTWRKVO3fu4IMPPkCDBg2Mfk29evXQqlUrnW1eXl4ICAiosp2IzK9iiwlXmiUiuTI5UfHz89MZTCuEQE5ODjw9PfHll1+aNTgisp7y/9ZpaUBQkLSxEBGVMzlRWbx4sc5zJycnBAUFoWvXrvDz86tTMLt3767T64moZkIATpUWJigpuftzaKjh1xERWZvJiUpCQoIl4iAiK6mcpAAcd0JE8lWrMSpZWVlYuXIlzp49CwBo2bIlxowZAx8fH7MGR0TmVZs1UdRqoF4988dCRGQMk1emPXLkCBo3boz3338fmZmZyMzMxKJFi9C4cWMcO3bMEjESkYSYpBCRlExeR6Vnz56IiYnBihUr4OJS1iBTUlKCZ599Fn///Tf27t1rkUD14ToqRMbTaIDazPrn2BQiMjdTrt8mJyoeHh44fvw4mjVrprP9zz//RKdOnZCfn296xLXERIXIOPq6fISouSsoLw/w9LRMTETkuEy5fpvc9aNSqZCSklJle2pqKuqxjZjIrjBJISKpmZyoPPHEE3jmmWfwzTffIDU1FampqVi3bh2effZZDB8+3BIxElEd8KaCRGTLTJ718+6770KhUGDkyJEo+d/iC66urhg/fjwWLFhg9gCJyPz0dfga0xVERGRttb4pYX5+Pi5evAgAaNy4MTwlaCPmGBWimhkan1J5n75EhQNpicgSrHJTQk9PT7Ru3bq2LyciiVRMPrKyAF/fsjsiExHJkcmJSkFBAZYuXYpdu3YhIyMDGo1GZz/XUiGSt4otJz4+uomLRnN35Vq2phCRHJicqDzzzDP46aefMGzYMHTp0kXnBoVEJG81JR8KBRMUIpIXkxOVLVu2YOvWrejevbsl4iEiIiLSMnl6coMGDbheCpGNqNQzS0Rkc0xOVN577z288soruHLliiXiISIzqs2S+UREcmJy10+nTp1QUFCARo0awdPTE66V7g+fmZlptuCIiIjIsZmcqAwfPhzXrl3DW2+9hZCQEA6mJSIiIosxOVH57bffcODAAbRt29YS8RCRGVS3yBsRkS0xeYxKs2bNcOfOHUvEQkRmwEZOIrInJicqCxYswLRp07B7927cunULarVa50FERERkLibf68fpf8tWVh6bIoSAQqFAaWmp+aKrAe/1Q1SVoRYVdv0QkVxY9F4/u3btqnVgRCQN3suHiGyVyYlK7969De47c+ZMnYIhorox1GpSaRUBIiKbYfIYlcpycnLw6aefokuXLpwJRCQxJz3/o9nlQ0S2rNaJyt69e5GQkIDQ0FC8++67eOCBB3Dw4EFzxkZEREQOzqSun/T0dKxevRorV66EWq3G448/jsLCQmzatAktWrSwVIxEVAsaDacqE5HtM7pFZfDgwWjatClOnTqFxYsX4/r161i6dKklYyOiOmCSQkT2wOgWlaSkJEyePBnjx49HkyZNLBkTEREREQATWlT27duHnJwcdOzYEV27dsWHH36If/75x5KxEZEJ2IJCRPbI6ESlW7duWLFiBdLS0vD8889j3bp1CAsLg0ajwY4dO5CTk2PJOInIgLQ0JilEZL9MXpm2ouTkZKxcuRJffPEFsrKy0LdvX/zwww/mjK9aXJmWiCvREpHtMeX6Xad1VJo2bYq3334bV69exdq1a+tyKCIyIyYpRGQv6tSiIjW2qBDpb1Gx3f/VROQIrNaiQkTSYpJCRPaOiQqRjeIAWiJyBExUiIiISLZMvnsyEckTu3yIyB6xRYXIBjEpISJHIWmisnz5crRp0wYqlQoqlQqxsbFISkqSMiQim+BU6X8uExcisleSJirh4eFYsGABjh49iiNHjuCBBx7AQw89hD/++EPKsIiIiEgmZLeOir+/P9555x0888wzNZblOirkiIqLATc33W3y+l9MRFQ9U67fshlMW1paivXr1yMvLw+xsbF6yxQWFqKwsFD7XK1WWySWitM+eQEguamcpBAR2TPJB9OePn0a3t7eUCqVGDduHDZu3IgWLVroLZuYmAgfHx/tIyIiwsrREskPk2kismeSd/0UFRUhJSUF2dnZ2LBhAz777DPs2bNHb7Kir0UlIiLC7F0/bFEhOau80Bu/o0Rka0zp+pE8UaksLi4OjRs3xieffFJjWUuNUWGiQnLG7ycR2TqbvtePRqPRaTUhcmTFxUxGiMixSTqYdubMmYiPj0fDhg2Rk5ODr7/+Grt378b27dulDItINjhwlogcnaSJSkZGBkaOHIm0tDT4+PigTZs22L59O/r27StlWERERCQTkiYqK1eulPLtiYiISOZkN0aFiIiIqBwTFSKZqjwNuTKOOSciR8BEhUhm8vNrTlIADrQlIsfARIVIZry8ai7DKctE5CiYqBAREZFsyeamhERUM7akEJGjYaJCJAM1jUlhgkJEjopdP0QSM2bgLBGRo2KiQiRjGg1bU4jIsTFRIZIxtrYQkaNjokIkIbXa8D62pBARMVGpUWam1BGQPfPxkToCIiJ5Y6JSg4AAqSMgIiJyXJyeTCQBfWNP2NVDRFQVW1SIrIwDZImIjMdEhYiIiGSLiQqRFZ09q3/79evWjYOIyFZwjAqRlVTX5RMaar04iIhsCVtUiIiISLaYqBBJrLhY6giIiOSLiQqRBWVklHX5ZGTo35+bC7iwA5aIyCAmKkQWFBKi+29FV64AXl7WjYeIyNbwbzkiC6lu8CwXdyMiMg5bVIiIiEi2mKgQWRlvdElEZDwmKkRW5ucndQRERLaDiYoReG8WMhW/M0RE5sFEhcjMmKQQEZkPExUiK8rLkzoCIiLbwunJRiouBlxdpY6C5M5QawqnIxMR1Q5bVIzk5iZ1BGSrsrOljoCIyHYxUTEB/yqm6hhqTVGprBsHEZE9YaJiAid+WmQiJrdERHXDSy9RNRSKu4+CAtNeyySFiKjumKgQ6aHRVO3K8fAwXL5y2aIi88dEROSImKgQ6eHsrH97xYSkvKUlJaVqOc4QIyIyDyYqRCZKTdVNWCIjpYuFiMjeMVEhqiQnp/r9DRtWv59jU4iIzEfSRCUxMRGdO3dGvXr1EBwcjKFDhyI5OVnKkGrE5dHtH6cTExHJh6SJyp49ezBx4kQcPHgQO3bsQHFxMfr164c8rjNOEsnNlToCIiKqSCGEfBqqb968ieDgYOzZswe9evWqsbxarYaPjw+ys7OhMuOfwTW1msjnEyNzqemcq9XGt7Tw+0FEVD1Trt+yutdP9v/WGvf399e7v7CwEIWFhdrnarXaKnFVxvv+2JeSEsP7KiYdQlSf0DBBISIyP9kMptVoNJgyZQq6d++OVq1a6S2TmJgIHx8f7SMiIsLKUZbhfX/siylJZ+Xc+NatsjVXmKQQEVmGbLp+xo8fj6SkJOzbtw/h4eF6y+hrUYmIiDB71w/A7h9HYuodj4uLARcXDqwmIqotm+v6mTRpErZs2YK9e/caTFIAQKlUQqlUWjEyoqrY7UdEZD2Sdv0IITBp0iRs3LgRv/zyC6Kjo6UMp1qcDUJERGR9kraoTJw4EV9//TU2b96MevXqIT09HQDg4+MDj+purCIBLy+pIyBLuH5d6giIiKg6ko5RURjo5F+1ahVGjRpV4+stNT25LDbd55VnfHCMin3gLB4iIuuzmTEqMhnHS6TFryQRkbzIZnoykdQ4DomISH6YqNSSQnG32+DGDd3nZJs4DomISH6YqJhB/fpSR0BERGSfmKgYobpxC5VbUdiqYjt4roiI5I+JihGKisr+LS2VNg4iIiJHw0TFCOX39nGywKdVVFR2rxhr4IwWw/jZEBHJkyyW0HdkFe8IYOmLZcVEixdmIiKyBWxRMZElL/DlM4fkPnaipMR2YiUiItvGRKUWUlKq328LF+/bt01/TUFBWd14Uz4iIrIWJiq1EBFR1rJS/khNrb58RkbZBT4v724rhLUH5lZOnvz9TT+Godsv2WLLSmam1BEQEZExmKgYcPWq8WUbNKh+f0hI2b/e3ne3ubhIf3E3pY7GsJXuoOvXgYAAqaMgIiJjMFExoEGDuy0mNVEogPz8qtvqctG2xsU+IsLy7yFHNSWWREQkH0xUzMRQt0hdKBRl3UoKRdn4EFsi91YVIiKyDUxUzMgSM4IaNiz718PD9i7+covXFrqliIhIFxMVG5OTY/prrl2r+/tWvsALYdm7DWdlmTexKC42vK82nykREVkHExUbo1KZ/prwcMP7akoGSksN7/fyqrkV6c4d3fE65Y+KyUFubtU4/PyqP265nBzdY1Y8TsX3K19duDIhdAc5ExGRvHBlWjMTonatAOUXfHO1IJjjOOY4hqen/u2GEi5T37PicUxN4mxt3A8RkSNii4oFlM8Wqs09fIydaVRbxh67uoShcpePHJfjNybhqXj7AiIikicmKhakUJSNjai4OJw+5XdnNuf71uY1eXnGlfXyqrqtpjrWBQfBEhE5LiYqFuZSqXNN34Vc35L0UrRSeHvXnBDIpfVELnEQEZFlMVGRgBDAjRs1lystLVtIrvJFOTPTcCtDdYnGnTt33786ho5hbHJg6STixo2yO0GzlYWIyP5xMK1EgoNrvqA7OelfSK7i8u8ZGWXHAmq+cLu73/25toN+pVSXeDWass+zXHp63eMhIiLLY4uKjSu/j1BNd0Ou600Q1WrTyteUhAlRds8dU15TFwqF7jia8s+NiIjkjS0qdqKmuyE76UlJjW1VqW0CUbkVo7LQUI41ISKi6rFFxY4ZMxPHmJaP2qrcimEqfeNzjFH5/QoLTT8GERHJA1tU7EBdx5qYe7G5mt6nrmXM+X5ERCRvbFGxEda46FZs/bD0wnOmqKlFSAggLa3sOVebJSKyL0xUbFRNs1Yc7YJdv35ZwsLVZomI7Au7fmyIXNYxkYK+gb/2WE8iItLFRIVsBhMTIiLHw64fO5OVJXUERERE5sMWFTvCFgciIrI3bFGxYSUlUkdARERkWUxUbJizs9QREBERWRYTFRuXn1+2VD27fYiIyB5xjIqN03d3ZSIiInvBFhUiIiKSLUkTlb1792Lw4MEICwuDQqHApk2bpAyHiIiIZEbSRCUvLw9t27bFsmXLpAyDiIiIZErSMSrx8fGIj4+XMgQiIiKSMY5RISIiItmyqVk/hYWFKCws1D5Xq9USRkNERESWZlMtKomJifDx8dE+IiIipA6JiIiILMimEpWZM2ciOztb+0hNTZU6JCIiIrIgm+r6USqVUCqVUodBREREViJpopKbm4sLFy5on1+6dAknTpyAv78/GjZsKGFkREREJAeSJipHjhzB/fffr30+depUAEBCQgJWr14tUVREREQkF5ImKvfddx8E76ZHREREBtjUYFoiIiJyLDY1mLay8tYYrqdCRERkO8qv28b0qth0opKTkwMAXE+FiIjIBuXk5MDHx6faMgphw4NENBoNrl+/jnr16kGhUJj12Gq1GhEREUhNTYVKpTLrseXAnutnz3UDWD9bx/rZNtbPPIQQyMnJQVhYGJycqh+FYtMtKk5OTggPD7foe6hUKrv8Mpaz5/rZc90A1s/WsX62jfWru5paUspxMC0RERHJFhMVIiIiki0mKgYolUrMmTPHbpfst+f62XPdANbP1rF+to31sz6bHkxLRERE9o0tKkRERCRbTFSIiIhItpioEBERkWwxUSEiIiLZYqKix7JlyxAVFQV3d3d07doVv//+u9QhGWXu3LlQKBQ6j2bNmmn3FxQUYOLEiQgICIC3tzceffRR3LhxQ+cYKSkpGDRoEDw9PREcHIwZM2agpKTE2lXB3r17MXjwYISFhUGhUGDTpk06+4UQmD17NkJDQ+Hh4YG4uDicP39ep0xmZiZGjBgBlUoFX19fPPPMM8jNzdUpc+rUKfTs2RPu7u6IiIjA22+/bemqAai5fqNGjapyLgcMGKBTRs71S0xMROfOnVGvXj0EBwdj6NChSE5O1iljru/j7t270aFDByiVSsTExGD16tWWrp5R9bvvvvuqnMNx48bplJFr/ZYvX442bdpoF/2KjY1FUlKSdr8tn7ua6mbL502fBQsWQKFQYMqUKdptNnf+BOlYt26dcHNzE//5z3/EH3/8IZ577jnh6+srbty4IXVoNZozZ45o2bKlSEtL0z5u3ryp3T9u3DgREREhfv75Z3HkyBHRrVs3ce+992r3l5SUiFatWom4uDhx/PhxsXXrVhEYGChmzpxp9bps3bpV/Pvf/xbff/+9ACA2btyos3/BggXCx8dHbNq0SZw8eVIMGTJEREdHizt37mjLDBgwQLRt21YcPHhQ/PrrryImJkYMHz5cuz87O1uEhISIESNGiDNnzoi1a9cKDw8P8cknn0hev4SEBDFgwACdc5mZmalTRs7169+/v1i1apU4c+aMOHHihBg4cKBo2LChyM3N1ZYxx/fx77//Fp6enmLq1Knizz//FEuXLhXOzs5i27Ztktevd+/e4rnnntM5h9nZ2TZRvx9++EH8+OOP4q+//hLJycnitddeE66uruLMmTNCCNs+dzXVzZbPW2W///67iIqKEm3atBEvvviidrutnT8mKpV06dJFTJw4Ufu8tLRUhIWFicTERAmjMs6cOXNE27Zt9e7LysoSrq6uYv369dptZ8+eFQDEgQMHhBBlF08nJyeRnp6uLbN8+XKhUqlEYWGhRWOvTuULuUajEfXr1xfvvPOOdltWVpZQKpVi7dq1Qggh/vzzTwFAHD58WFsmKSlJKBQKce3aNSGEEB999JHw8/PTqdsrr7wimjZtauEa6TKUqDz00EMGX2NL9RNCiIyMDAFA7NmzRwhhvu/jyy+/LFq2bKnzXk888YTo37+/pauko3L9hCi74FW8OFRmS/UTQgg/Pz/x2Wef2d25E+Ju3YSwn/OWk5MjmjRpInbs2KFTJ1s8f+z6qaCoqAhHjx5FXFycdpuTkxPi4uJw4MABCSMz3vnz5xEWFoZGjRphxIgRSElJAQAcPXoUxcXFOnVr1qwZGjZsqK3bgQMH0Lp1a4SEhGjL9O/fH2q1Gn/88Yd1K1KNS5cuIT09XacuPj4+6Nq1q05dfH190alTJ22ZuLg4ODk54dChQ9oyvXr1gpubm7ZM//79kZycjNu3b1upNobt3r0bwcHBaNq0KcaPH49bt25p99la/bKzswEA/v7+AMz3fTxw4IDOMcrLWPv/a+X6lfvqq68QGBiIVq1aYebMmcjPz9fus5X6lZaWYt26dcjLy0NsbKxdnbvKdStnD+dt4sSJGDRoUJU4bPH82fRNCc3tn3/+QWlpqc7JAYCQkBCcO3dOoqiM17VrV6xevRpNmzZFWloa5s2bh549e+LMmTNIT0+Hm5sbfH19dV4TEhKC9PR0AEB6erreupfvk4vyWPTFWrEuwcHBOvtdXFzg7++vUyY6OrrKMcr3+fn5WSR+YwwYMACPPPIIoqOjcfHiRbz22muIj4/HgQMH4OzsbFP102g0mDJlCrp3745WrVpp398c30dDZdRqNe7cuQMPDw9LVEmHvvoBwL/+9S9ERkYiLCwMp06dwiuvvILk5GR8//331cZevq+6Mtao3+nTpxEbG4uCggJ4e3tj48aNaNGiBU6cOGHz585Q3QDbP28AsG7dOhw7dgyHDx+uss8W/+8xUbEj8fHx2p/btGmDrl27IjIyEt9++61VfmGT+Tz55JPan1u3bo02bdqgcePG2L17N/r06SNhZKabOHEizpw5g3379kkdikUYqt/YsWO1P7du3RqhoaHo06cPLl68iMaNG1s7TJM1bdoUJ06cQHZ2NjZs2ICEhATs2bNH6rDMwlDdWrRoYfPnLTU1FS+++CJ27NgBd3d3qcMxC3b9VBAYGAhnZ+cqo59v3LiB+vXrSxRV7fn6+uKee+7BhQsXUL9+fRQVFSErK0unTMW61a9fX2/dy/fJRXks1Z2n+vXrIyMjQ2d/SUkJMjMzba6+ANCoUSMEBgbiwoULAGynfpMmTcKWLVuwa9cuhIeHa7eb6/toqIxKpbJKcm6ofvp07doVAHTOoZzr5+bmhpiYGHTs2BGJiYlo27YtlixZYhfnzlDd9LG183b06FFkZGSgQ4cOcHFxgYuLC/bs2YMPPvgALi4uCAkJsbnzx0SlAjc3N3Ts2BE///yzdptGo8HPP/+s039pK3Jzc3Hx4kWEhoaiY8eOcHV11albcnIyUlJStHWLjY3F6dOndS6AO3bsgEql0jaLykF0dDTq16+vUxe1Wo1Dhw7p1CUrKwtHjx7Vlvnll1+g0Wi0v3hiY2Oxd+9eFBcXa8vs2LEDTZs2lbTbR5+rV6/i1q1bCA0NBSD/+gkhMGnSJGzcuBG//PJLlS4oc30fY2NjdY5RXsbS/19rqp8+J06cAACdcyjX+umj0WhQWFho8+dOn/K66WNr561Pnz44ffo0Tpw4oX106tQJI0aM0P5sc+fP7MNzbdy6deuEUqkUq1evFn/++acYO3as8PX11Rn9LFfTpk0Tu3fvFpcuXRL79+8XcXFxIjAwUGRkZAghyqakNWzYUPzyyy/iyJEjIjY2VsTGxmpfXz4lrV+/fuLEiRNi27ZtIigoSJLpyTk5OeL48ePi+PHjAoBYtGiROH78uLhy5YoQomx6sq+vr9i8ebM4deqUeOihh/ROT27fvr04dOiQ2Ldvn2jSpInO9N2srCwREhIinn76aXHmzBmxbt064enpaZXpu9XVLycnR0yfPl0cOHBAXLp0SezcuVN06NBBNGnSRBQUFNhE/caPHy98fHzE7t27daZ55ufna8uY4/tYPkVyxowZ4uzZs2LZsmVWmQZaU/0uXLgg5s+fL44cOSIuXbokNm/eLBo1aiR69eplE/V79dVXxZ49e8SlS5fEqVOnxKuvvioUCoX46aefhBC2fe6qq5utnzdDKs9ksrXzx0RFj6VLl4qGDRsKNzc30aVLF3Hw4EGpQzLKE088IUJDQ4Wbm5to0KCBeOKJJ8SFCxe0++/cuSMmTJgg/Pz8hKenp3j44YdFWlqazjEuX74s4uPjhYeHhwgMDBTTpk0TxcXF1q6K2LVrlwBQ5ZGQkCCEKJuiPGvWLBESEiKUSqXo06ePSE5O1jnGrVu3xPDhw4W3t7dQqVRi9OjRIicnR6fMyZMnRY8ePYRSqRQNGjQQCxYskLx++fn5ol+/fiIoKEi4urqKyMhI8dxzz1VJluVcP311AyBWrVqlLWOu7+OuXbtEu3bthJubm2jUqJHOe0hVv5SUFNGrVy/h7+8vlEqliImJETNmzNBZj0PO9RszZoyIjIwUbm5uIigoSPTp00ebpAhh2+euurrZ+nkzpHKiYmvnTyGEEOZvpyEiIiKqO45RISIiItliokJERESyxUSFiIiIZIuJChEREckWExUiIiKSLSYqREREJFtMVIiIiEi2mKgQEQDg8uXLUCgU2iXD5eDcuXPo1q0b3N3d0a5dO4u9jzXqPmrUKAwdOtRixyeyV0xUiGRi1KhRUCgUWLBggc72TZs2QaFQSBSVtObMmQMvLy8kJydXua9IufLPrfJjwIABRr9PREQE0tLS0KpVK3OFTkRmwkSFSEbc3d2xcOFC3L59W+pQzKaoqKjWr7148SJ69OiByMhIBAQEGCw3YMAApKWl6TzWrl1r9Ps4Ozujfv36cHFxqXWsRGQZTFSIZCQuLg7169dHYmKiwTJz586t0g2yePFiREVFaZ+XdzO89dZbCAkJga+vL+bPn4+SkhLMmDED/v7+CA8Px6pVq6oc/9y5c7j33nvh7u6OVq1aYc+ePTr7z5w5g/j4eHh7eyMkJARPP/00/vnnH+3+++67D5MmTcKUKVMQGBiI/v37662HRqPB/PnzER4eDqVSiXbt2mHbtm3a/QqFAkePHsX8+fOhUCgwd+5cg5+JUqlE/fr1dR4V7xCtUCiwfPlyxMfHw8PDA40aNcKGDRu0+yt3/dy+fRsjRoxAUFAQPDw80KRJE53P6vTp03jggQfg4eGBgIAAjB07Frm5udr9paWlmDp1Knx9fREQEICXX34Zle9WotFokJiYiOjoaHh4eKBt27Y6MdUUA5GjYKJCJCPOzs546623sHTpUly9erVOx/rll19w/fp17N27F4sWLcKcOXPw4IMPws/PD4cOHcK4cePw/PPPV3mfGTNmYNq0aTh+/DhiY2MxePBg3Lp1CwCQlZWFBx54AO3bt8eRI0ewbds23LhxA48//rjOMdasWQM3Nzfs378fH3/8sd74lixZgvfeew/vvvsuTp06hf79+2PIkCE4f/48ACAtLQ0tW7bEtGnTkJaWhunTp9fp85g1axYeffRRnDx5EiNGjMCTTz6Js2fPGiz7559/IikpCWfPnsXy5csRGBgIAMjLy0P//v3h5+eHw4cPY/369di5cycmTZqkff17772H1atX4z//+Q/27duHzMxMbNy4Uec9EhMT8fnnn+Pjjz/GH3/8gZdeeglPPfWUNjGsLgYih2KRWx0SkckSEhLEQw89JIQQolu3bmLMmDFCCCE2btwoKv5XnTNnjmjbtq3Oa99//30RGRmpc6zIyEhRWlqq3da0aVPRs2dP7fOSkhLh5eUl1q5dK4QQ4tKlSwKAzh2Wi4uLRXh4uFi4cKEQQojXX39d9OvXT+e9U1NTBQDt3at79+4t2rdvX2N9w8LCxJtvvqmzrXPnzmLChAna523bthVz5syp9jgJCQnC2dlZeHl56TwqHhuAGDdunM7runbtKsaPH69T9+PHjwshhBg8eLAYPXq03vf79NNPhZ+fn8jNzdVu+/HHH4WTk5P2DtehoaHi7bff1u4v/xzLz29BQYHw9PQUv/32m86xn3nmGTF8+PAaYyByJOyQJZKhhQsX4oEHHqhTK0LLli3h5HS30TQkJERnsKizszMCAgKQkZGh87rY2Fjtzy4uLujUqZO25eHkyZPYtWsXvL29q7zfxYsXcc899wAAOnbsWG1sarUa169fR/fu3XW2d+/eHSdPnjSyhnfdf//9WL58uc42f39/necV61X+3NAsn/Hjx+PRRx/FsWPH0K9fPwwdOhT33nsvAODs2bNo27YtvLy8dOLWaDRITk6Gu7s70tLS0LVrV+3+8s9R/K/758KFC8jPz0ffvn113reoqAjt27evMQYiR8JEhUiGevXqhf79+2PmzJkYNWqUzj4nJ6cq4x2Ki4urHMPV1VXnuUKh0LtNo9EYHVdubi4GDx6MhQsXVtkXGhqq/bniRdwavLy8EBMTY7bjxcfH48qVK9i6dSt27NiBPn36YOLEiXj33XfNcvzy8Sw//vgjGjRooLNPqVRaJQYiW8ExKkQytWDBAvz3v//FgQMHdLYHBQUhPT1dJ1kx5/ofBw8e1P5cUlKCo0ePonnz5gCADh064I8//kBUVBRiYmJ0HqYkJyqVCmFhYdi/f7/O9v3796NFixbmqUglFetV/ry8XvoEBQUhISEBX375JRYvXoxPP/0UANC8eXOcPHkSeXl5OnE7OTmhadOm8PHxQWhoKA4dOqTdX/45lmvRogWUSiVSUlKqfI4RERE1xkDkSNiiQiRTrVu3xogRI/DBBx/obL/vvvtw8+ZNvP322xg2bBi2bduGpKQkqFQqs7zvsmXL0KRJEzRv3hzvv/8+bt++jTFjxgAAJk6ciBUrVmD48OF4+eWX4e/vjwsXLmDdunX47LPP4OzsbPT7zJgxA3PmzEHjxo3Rrl07rFq1CidOnMBXX31lcsyFhYVIT0/X2ebi4qIz+HT9+vXo1KkTevToga+++gq///47Vq5cqfd4s2fPRseOHdGyZUsUFhZiy5Yt2qRmxIgRmDNnDhISEjB37lzcvHkTL7zwAp5++mmEhIQAAF588UUsWLAATZo0QbNmzbBo0SJkZWVpj1+vXj1Mnz4dL730EjQaDXr06IHs7Gzs378fKpUKCQkJ1cZA5EjYokIkY/Pnz6/SNdO8eXN89NFHWLZsGdq2bYvff/+9zjNiKlqwYAEWLFiAtm3bYt++ffjhhx+0F/zyVpDS0lL069cPrVu3xpQpU+Dr66szHsYYkydPxtSpUzFt2jS0bt0a27Ztww8//IAmTZqYHPO2bdsQGhqq8+jRo4dOmXnz5mHdunVo06YNPv/8c6xdu9Zg642bmxtmzpyJNm3aoFevXnB2dsa6desAAJ6enti+fTsyMzPRuXNnDBs2DH369MGHH36off20adPw9NNPIyEhAbGxsahXrx4efvhhnfd4/fXXMWvWLCQmJqJ58+YYMGAAfvzxR0RHR9cYA5EjUYjKnd1ERHZGoVBg48aNXMKeyAaxRYWIiIhki4kKERERyRYH0xKR3WMPN5HtYosKERERyRYTFSIiIpItJipEREQkW0xUiIiISLaYqBAREZFsMVEhIiIi2WKiQkRERLLFRIWIiIhki4kKERERydb/A00Tp3WyubcNAAAAAElFTkSuQmCC\n"},"metadata":{}}],"source":["rl_rewards, episodes = [], []\n","best_rl_reward_from_eval = 0\n","for e in range(num_episodes):\n","    done = False\n","    run_score = 0\n","\n","    state_history = np.zeros([5, 84, 84], dtype=np.uint8) # 5 x 84 x 84\n","    step = 0\n","    state = env.reset() # reset the environment for new episode\n","    subsequent_state = state\n","    life = max_number_of_lives_in_game # resetting life count - new game\n","\n","    get_initialization_state(state_history, state, history_length) # set up the states\n","\n","    while not done:\n","        step += 1\n","        cnt_frame+= 1\n","\n","        if step > 1 and len(np.unique(subsequent_state[:189] == state[:189])) < 2:\n","            action = 0  # This is going to \"fire\"  - this is checking to see if you need to start the game\n","        else:\n","            action = agent.select_action(np.float32(state_history[:4, :, :]) / 255.) # converting imgs to 0-1\n","        state = subsequent_state\n","        subsequent_state, rl_reward, done, info_dictionary = env.step(action + 1)\n","\n","        frame_counter_subsequent_state = process_frame(subsequent_state)\n","        state_history[4, :, :] = frame_counter_subsequent_state\n","        last_state = check_if_live(life, info_dictionary['lives'])\n","\n","        life = info_dictionary['lives']\n","        r = rl_reward\n","\n","        agent.sys_memory.record(deepcopy(frame_counter_subsequent_state), action, r, last_state)\n","\n","        # only train when ready\n","        if(cnt_frame>= training_frames):\n","            agent.p_net_training(cnt_frame)\n","            if double_d and (cnt_frame% target_update_frequency)== 0:\n","                agent.target_to_policy()\n","        run_score += rl_reward\n","        state_history[:4, :, :] = state_history[1:, :, :] # cut off last\n","\n","        if done:\n","            rl_reward_from_eval.append(run_score)\n","            rl_rewards.append(np.mean(rl_reward_from_eval))\n","            episodes.append(e)\n","            pylab.plot(episodes, rl_rewards, 'b')\n","            pylab.xlabel('Number of Episodes')\n","            pylab.ylabel('Amount of Rewards')\n","            pylab.title('Plot of Episodes and Rewards')\n","            pylab.savefig(\"./deep_q.png\")\n","\n","            print(\"For episode:\", e, \"  the run_score was:\", run_score, \"  and mem length:\",\n","                  len(agent.sys_memory), \"  eps:\", agent.eps, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    eval rl_reward:\", np.mean(rl_reward_from_eval))\n","\n","            ### You can change this to whatever you want\n","            if np.mean(rl_reward_from_eval) > 5 and np.mean(rl_reward_from_eval) > best_rl_reward_from_eval:\n","                torch.save(agent.policy_network, \"./dqn.pth\")\n","                best_rl_reward_from_eval = np.mean(rl_reward_from_eval)\n"]},{"cell_type":"markdown","metadata":{"id":"Q4otfIYf8-82"},"source":["## Visualizing the Game"]},{"cell_type":"markdown","metadata":{"id":"7zaP8GUo8-82"},"source":["Be careful - you don't want to run this twice in the same kernel or it will crash. Recommend you save your model before making visualization."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"5In0r_Bx8-82","executionInfo":{"status":"ok","timestamp":1714689163006,"user_tz":240,"elapsed":399,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["torch.save(agent.policy_network, \"./dqn_last.pth\")"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"aUtQ6Eev8-83","executionInfo":{"status":"ok","timestamp":1714698457644,"user_tz":240,"elapsed":174,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"outputs":[],"source":["# from gym.wrappers import Monitor # `\n","from gym.wrappers import RecordVideo\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","import glob\n","import io\n","import base64\n","from pyvirtualdisplay import Display\n","\n","def vis_curr(env, step=0, info_dictionary=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Curr Step: %d %s\" % (\"Game\",step, info_dictionary))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True) # for jupyter notebook\n","    ipythondisplay.display(plt.gcf()) # for jupyter\n","\n","# Making a video of the jupyter\n","def make_video_of_jupyter():\n","    videos_from_glob = glob.glob('video.mp4')\n","    if len(videos_from_glob) > 0:\n","        mp4 = videos_from_glob[0] # video path\n","        video = io.open(mp4, 'r+b').read() # load in the video\n","        encoded = base64.b64encode(video) # encode in base 64  # this code below creates html for the video in jupyter\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"No video\")\n","\n","\n","def environment_writer(env):\n","    env = RecordVideo(env, './video')\n","    return env"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1261},"id":"aso2A7m68-83","executionInfo":{"status":"ok","timestamp":1714698512174,"user_tz":240,"elapsed":50992,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"dda89adf-c345-4475-9e08-61887a4b23e3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAS0AAAGbCAYAAACRcMaGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbcUlEQVR4nO3de3BU9d3H8c9u7iQhCZKERErkogngBYsVlI4wIherdWAGCXhpRFq0j6KtY3Qe2xGt1nsFqra2IigaUNFip+ioKDhaaJVWBfEaIICAICEhEHIhu/t7/vDJDiEb2A27Id/wfs1kBs7td3az+87Zk7NZj3POCQCM8B7vHQCASBAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC3DNm/eLI/Ho3ffffd47wrQYU6YaFVUVOjGG2/Uaaedpm7duqlbt24aNGiQbrjhBq1bt+54716HWbp0qS6++GL17NlTiYmJys/P1+TJk7VixYrjvWuqra3VrFmzdPrppys1NVUnnXSShgwZoptvvlk7duwILvf666/rrrvuOn472oYdO3boqquuUmFhodLT05WZmalzzz1Xzz77rNp6t9yLL76o8847T6mpqcrMzNT555/f4nvxzTff6O6779a5556rrKws9ezZU6NGjdLbb7/dUTer04k/3jvQEZYtW6bi4mLFx8fryiuv1FlnnSWv16svv/xSf/vb3/TnP/9ZFRUVKigoON67GjPOOV177bV65plndPbZZ+uWW25Rr1699O2332rp0qUaPXq0Vq1apfPPP/+47F9TU5MuuOACffnllyopKdHMmTNVW1urzz77TIsWLdLEiROVn58v6ftoPfHEE50uXJWVldq2bZsmTZqkPn36qKmpScuXL9c111yjr776Svfdd1+L5e+66y797ne/06RJk3TNNdeoqalJ69ev1/bt24PL/P3vf9eDDz6oCRMmqKSkRD6fTwsXLtSYMWM0f/58TZs2raNv5vHnurgNGza41NRUN3DgQLdjx45W85uamtzcuXPd1q1bj8PeHZuKigonya1cufKoyz788MNOkvvVr37lAoFAq/kLFy50H3zwwTHvUyAQcHV1dSHn1dfXO7/fH3LeSy+95CS5srKykOvV1NQE/3/DDTc4Sw/dSy+91KWmpjqfzxec9q9//ct5PB736KOPHnHd9evXu927d7eY1tDQ4IqKilzv3r1jsr+dnZ3vfDvNmDHDSXL//ve/w15n7dq1rqSkxPXt29clJSW53NxcN23aNFdZWdliuVmzZjlJ7quvvnJXXnml6969u+vZs6f77W9/6wKBgNu6dau77LLLXHp6usvNzXWPPPJIq7EaGhrcnXfe6fr37+8SExNd7969XWlpqWtoaDjqfoYbrbq6OtejRw9XVFTU4onTlubbdbgFCxY4Sa6ioiI4raCgwF1yySXujTfecEOHDnVJSUlu9uzZbuXKlU6SW7x4sfvNb37j8vPzncfjcdXV1SHHvP/++50kt3nz5iPuW0lJiZPU6quZ3+93s2fPdoMGDXJJSUkuJyfHzZgxw1VVVbXYTvN+v/nmm+6ss85ySUlJbuDAge6VV15pNeaGDRvchg0bjrhfR3LjjTc6j8fTIubFxcUuLy/P+f1+FwgE3P79+yPa5i233OIkuX379rV7v6zq8ue0li1bpgEDBmjYsGFhr7N8+XJt2rRJ06ZN02OPPaYpU6bohRde0E9+8pOQ5yaKi4sVCAT0wAMPaNiwYbr33ns1Z84cjRkzRieffLIefPBBDRgwQLfeeqvee++94HqBQECXXXaZHnnkEf30pz/VY489pgkTJmj27NkqLi6Oyu2XpH/+85+qqqrSFVdcobi4uKhtt9lXX32lqVOnasyYMZo7d66GDBkSnHfPPffotdde06233qr77rtPiYmJIbfR/NJ84cKFbZ7/kaTrrrtOY8aMkSQ999xzwa9D55eWlmrEiBGaO3eupk2bprKyMo0bN05NTU0ttlVeXq7i4mJdfPHFuv/++xUfH6/LL79cy5cvb7Hc6NGjNXr06LDvj/r6elVWVmrz5s169tlntWDBAp133nlKSUkJLvPOO+/oRz/6kf74xz8qOztb6enpysvL0+OPPx7WGDt37gyemz3hHO9qxlJNTY2T5CZMmNBqXnV1tdu9e3fw69CfgqFe3ixevNhJcu+9915wWvMRyYwZM4LTfD6f6927t/N4PO6BBx5oMV5KSoorKSkJTnvuueec1+t177//fouxnnzySSfJrVq16oi3L9wjrblz5zpJbunSpUdc7vDbdbi2jrQkuTfeeKPFss1HWv369Wvz5eKh6urqXGFhoZPkCgoK3DXXXOOefvppt2vXrlbLtvXy8P333w/5EvONN95oNb15vw89sqqpqXF5eXnu7LPPbrF+QUGBKygoOOptaNZ81Nj8NXr06BanH6qqqpwkd9JJJ7m0tDT38MMPuxdffNGNHz/eSXJPPvnkEbdfXl7ukpOT3dVXXx32PnUlXfpIa9++fZKktLS0VvNGjRql7Ozs4NcTTzwRnHfoT8SGhgZVVlZq+PDhkqSPPvqo1bZ+/vOfB/8dFxenc845R845TZ8+PTg9MzNThYWF2rRpU3DakiVLNHDgQBUVFamysjL4deGFF0qSVq5c2d6b3kLz/ZCenh6V7R2ub9++GjduXMh5JSUlLe7PtqSkpOiDDz5QaWmpJOmZZ57R9OnTlZeXp5kzZ6qxsfGo21iyZIkyMjI0ZsyYFvfn0KFDlZaW1ur+zM/P18SJE4P/7969u372s5/p448/1s6dO4PTN2/erM2bNx91/GZTp07V8uXLtWjRIl1xxRWSvj/6alZbWytJ2rNnj+bNm6dbb71VkydP1muvvaZBgwbp3nvvbXPbdXV1uvzyy5WSkqIHHngg7H3qSrp0tJqfpM0PkkP95S9/0fLly/X888+3mldVVaWbb75Zubm5SklJUXZ2tvr27StJqqmpabV8nz59Wvw/IyNDycnJ6tmzZ6vp1dXVwf+Xl5frs88+axHP7OxsnXbaaZKk7777LsJbHFr37t0lSfv374/K9g7XfN9EOu9wGRkZeuihh4KRePrpp1VYWKjHH39c99xzz1HXLy8vV01NjXJyclrdp7W1ta3uzwEDBsjj8bSY1nzfRxKpwxUUFOiiiy7S1KlTVVZWpn79+umiiy4Khqs54gkJCZo0aVJwPa/Xq+LiYm3btk1bt25ttV2/368pU6bo888/18svvxz8beqJpktf8pCRkaG8vDytX7++1bzmc1yhHpyTJ0/W6tWrVVpaqiFDhigtLU2BQEDjx49XIBBotXyo80RtnTtyh5yvCQQCOuOMM/Too4+GXPYHP/hByOmRKioqkiR9+umnmjBhwlGXP/yJ3Mzv94ecfqQjqXCOskIpKCjQtddeq4kTJ6pfv34qKys74hGI9P39mZOTo7KyspDzs7Oz27Uvx2rSpEl66qmn9N5772ncuHHq0aOHkpOTlZmZ2epxkpOTI0mqrq5u9cPwF7/4hZYtW6aysrLg0fiJqEtHS5IuueQSzZs3Tx9++KHOPffcoy5fXV2td955R3fffbfuvPPO4PTy8vKo71v//v21du1ajR49us1QRMOPf/xjZWVlafHixbrjjjuOejI+KytLkrR3715lZmYGp2/ZsiVm+3ikfenfv3+LHzxt3Vf9+/fX22+/rREjRoQVyw0bNsg512J7X3/9tSTplFNOObYdP0TzEVbzUbrX69WQIUO0Zs0aHTx4sMUvJ5ovoj08sKWlpVqwYIHmzJmjqVOnRm3fLOrSLw8l6bbbblO3bt107bXXateuXa3mu8N+U9X8hD58+pw5c6K+b5MnT9b27dv11FNPtZpXX1+vAwcORGWcbt266fbbb9cXX3yh22+/PeRv555//nl9+OGHkr5/8ktq8ZvOAwcO6Nlnn43K/oSydu1aVVZWtpq+ZcsWff755yosLAxOS01NlfR9VA81efJk+f3+kC8lfT5fq+V37NihpUuXBv+/b98+LVy4UEOGDFGvXr2C0zdu3KiNGzce9Tbs3r075PSnn35aHo9HP/zhD4PTiouL5ff7W9ynDQ0NKisr06BBg1q89Hv44Yf1yCOP6I477tDNN9981P3o6rr8kdapp56qRYsWaerUqSosLAxeEe+cU0VFhRYtWiSv16vevXtL+v78zwUXXKCHHnpITU1NOvnkk/XWW2+poqIi6vt29dVX66WXXtL111+vlStXasSIEfL7/fryyy/10ksv6c0339Q555wTlbFKS0v12Wef6Q9/+INWrlypSZMmqVevXtq5c6deffVVffjhh1q9erUkaezYserTp4+mT5+u0tJSxcXFaf78+crOzg55riUali9frlmzZumyyy7T8OHDlZaWpk2bNmn+/PlqbGxscfX70KFDJUk33XSTxo0bp7i4OE2ZMkUjR47Uddddp/vvv1+ffPKJxo4dq4SEBJWXl2vJkiWaO3dui3NIp512mqZPn641a9YoNzdX8+fP165du7RgwYIW+9Z8ucPRznP9/ve/16pVqzR+/Hj16dNHVVVVeuWVV7RmzRrNnDlTAwYMCC573XXXad68ebrhhhv09ddfq0+fPnruuee0ZcsW/eMf/wgut3TpUt1222069dRTNXDgwFbnYMeMGaPc3NyI7mvzjuNvLjvUhg0b3C9/+Us3YMAAl5yc7FJSUlxRUZG7/vrr3SeffNJi2W3btrmJEye6zMxMl5GR4S6//HK3Y8cOJ8nNmjUruFzzpQGHX7FcUlLiUlNTW+3DyJEj3eDBg1tMO3jwoHvwwQfd4MGDXVJSksvKynJDhw51d999d4urwEOJ5Ir4Zi+//LIbO3as69Gjh4uPj3d5eXmuuLjYvfvuuy2W++9//+uGDRvmEhMTXZ8+fdyjjz56xItLD9d8ycOSJUvC2q9Nmza5O++80w0fPtzl5OS4+Ph4l52d7S655BK3YsWKFsv6fD43c+ZMl52d7TweT6vLH/7617+6oUOHupSUFJeenu7OOOMMd9ttt7V4R8ShF5eeeeaZLikpyRUVFYXc33AveXjrrbfcpZde6vLz811CQoJLT093I0aMcAsWLAj5LoRdu3a5kpIS16NHD5eUlOSGDRvW6tKR5sdYW1+RfO+7Co9zfO6hVZs3b1bfvn21cuVKjRo16njvjimnnHKKTj/9dC1btux47woi1OXPaQHoWogWAFOIFgBTOKcFwBSOtACYQrQAmBL2xaWxfJsJAEit34kSCkdaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEzp8n8EMBp69OjR4s8OR0NNTY327NkTcl5aWlrwb4VHS319vb799tuQ85KSkpSfnx/Va/F8Pp+2b9/e5t+V70xyc3ODfw31cN99913ID0axJDU1tc0/FFhXV9fik4csIFphOO+88zRy5MiobnP16tV69dVXQ84rLCyM6oe1St//yeB58+aFjEhOTo6mT5/e5geptsfevXv1+OOPBz++rDMbO3aszjjjjFbTnXN64YUX9PHHHx+HvYqefv366aqrrgr5Q+mLL77QM888E9ZFnZ0F0QqD1+tVfHx07yqvt+1X5h6PR3FxcVE98jnaePHx8VG9jdHe/1iKi4sLedudc0e836xofvyG+n7E4hPHY41oHaOj/YSK9hM3luO196etlTihayBax2jdunVat25dyHmDBw9u8Qks0bB169YWn5JzqJNPPlmjRo2K+OigsrJSixcvjni97t27a9y4cUpOTo5oPeBYEK1j9O2337Z5ziMzMzPq0aqurm5zvIaGhnb9rfi6ujqtXbs24vV69uwZ/KQaoKPYf8EO4IRCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYwsWlxygtLU29evUKOS89PT3q46WkpCgvLy/kW26ysrKiPh7Q2RCtYzRs2DANHTo05Lxov8lakgYMGKAbb7wx5Dyv18v7ANHlEa1jlJCQoISEhA4bLy4uTikpKR02HtDZcE4LgCkcaYVh/fr12rt3b1S3uWPHjjbnbd26tc0/ENhee/fuVSAQiOo2a2tr9frrr4c80mxsbFR9fX1Ux4uVDz74QBs3bgw575tvvungvYm+7du3t/l4qqqqMvUHACXJ48LcY86VAIi1cHLEy0MApoT98rBnz56x3A8ACEvY0brppptiuR8AEJawo5WWlhbL/QCAsHBOC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKWF/7mF7OediPQSATsbj8cRs2zGN1sGDB7VixQrV1NTEchgAnUhGRoYuvPBCJSYmxmT7MY2Wz+fT2rVrtWvXrlgOA6ATycvL08iRI2O2fc5pATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMCU+lhtPjotTSb9+asrKiuUwADqRhB49lBQXF7PtxzRaCV6vxufnq1tGRiyHAdCJHEhL03qPR/4YbZ+XhwBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATInpxaXfj+Dk4gMxHwZAJxHnJE/sNh/baHmdArn1cgcPxHQYAJ2HS4w3HC3p++rGu5gPA6CTiPErK85pATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwJbYXl3qkxgSfPJ6mmA4DoPNoTPDLeWJ3QXlMo+Xk1JDUJBdPtIATRWNcbJ/vvDwEYArRAmAK0QJgCtECYArRAmAK0QJgCtECYArRAmBKzP/csvMoplfHAuhcXIwPhWJ7RbxXOpDvU6PXF8thAHQiPr9Prj5224/5ew/9iU4ePtgCOGH4fU5qkBSjpz3ntACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmBLTi0sD8minkuVcSiyHOaE0VDeoZlNNh40XnxKvrMIe8sZ5OmxM2OZxyUqSFKtHTEyj5ZNHHwWyVOtNiOUwJ5Sd5bu09k/bOmy8tN7pGva//RXfLeZvU0UXkebS9SN5FKtnfezfMC0pds09ATnJdeC7opxzfA/RqXBOC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApHXDFoEfOteMaHxdo53AecU1RWyK/XzzySq6d38N26eAL0SRDj5ljuG88HXl8Etv7MrbR8iXK/9HF8jXGRbSaC/hUseEpHaitiHBAjwr6Xa3umadHuJ4d/oo1kj6JeL3UtP7qO+Dn8ngi+17Ep8TLrcmSr4PexuP31Wvj139SY8OuDhnP0mNmz+7V2vHNqxGvl5F5pvr0nfL/cY49f5Jf6rtPiovND5/YRivgVWBXX7kD3SJbLXBQVesbVFP9XYQDepTjTlJ6r6II17PDVW1v13oJiRnqmfNjedvzlqqdMfuMglb8TftV9WmtDtRG+r1vLzuPmbotn+q7LyK/X1xuQL0Ti+TpoGgF0g5IBeulOH9Mts85LQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0ApsT04lLnAjpQu1H79kV2FXYg4JPfV9euMevrtmlfzeftWteCurr2XVzq99Vpf80X8ng799969/nq5Pc3duiYVh4zDQ0727Wer2mf9td83mFXxHvll3OxubBUkjzOhfdmptmzZ0e88bq6ev3pT3/Vzl2RvyUj4D8oKfL3H3q8CRG/VcUS5/xygaZ2rOmVNy4x6vsTdU4KBBrVcdfg23nMuIBPzvkiX9Hjldfbcd/7vF699D//M0MpKckRr/vrX//6qMvE+Meuk9/foIC/IbbDHDpioElO7XlSd3WBDv0+WNLlHzOuY7/3sf6hwzktAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKbEh7tgvScQ8cYbvE7OE/FqUZcSF6f0hIQOG+9gIKC9Bw922HhAZ+IJBJTY2KhET2ye/GFHa1V6fcQbb4qrV53XRbxetI3u1UszTj21w8ZbV12tWevWye+O/20HOlpyfb0G/+c/So3RgULY0WpoR3yaPE5Ox/+JmxIXp5zk5A4bLzMxscPGAjqb5iOtpEDkr87CwTktAKYQLQCmEC0AphAtAKaEfSLesoZAQFWNjR023v6mpg4bCzjRnBDRWrFzp/67Z0+HjdcYCHC5AxAjJ0S0Dvh8OuDzHe/dABAFnNMCYMoJcaQFoOPsbWrSy1u3Kskb+THRsDCWCTtajnM0AMKwp7FRT5aXt2vdOWEs43Fh1qjX8DMj3oGAz6+qzzfKX99xv7kDYFc4OQo7Wp4YvWMbAJqFkyNOxAMwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVPmAZgCkdaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATPk/q3Z1B+JkZUsAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7ac835e28580>"]},"metadata":{},"execution_count":44},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["display = Display(visible=0, size=(300, 200))\n","display.start()\n","\n","# Load agent\n","# might need to write code to load the agent if you are resuming here:\n","#load here\n","#############\n","# agent.eps = 0.0 # Why would we want this?\n","agent = EnvironmentAgent(action_to_take_size)\n","agent.load_policy_network(\"/content/drive/My Drive/part2/dqn_last.pth\")\n","agent.eps = 0.0 # Why would we want this?\n","\n","env = gym.make('BreakoutDeterministic-v4',render_mode='rgb_array')\n","env = environment_writer(env)\n","\n","done = False\n","run_score = 0\n","step = 0\n","state = env.reset()\n","subsequent_state = state\n","life = max_number_of_lives_in_game # this stuff is all same as above\n","state_history = np.zeros([5, 84, 84], dtype=np.uint8)\n","# get_initialization_state(state_history, state)\n","\n","while not done:\n","\n","    # env.render()\n","    vis_curr(env,step)\n","\n","    step += 1\n","    cnt_frame+= 1\n","\n","    if step > 1 and len(np.unique(subsequent_state[:189] == state[:189])) < 2:\n","        action = 0  # This is going to \"fire\"  - this is checking to see if you need to start the game\n","    else:\n","        action = agent.select_action(np.float32(state_history[:4, :, :]) / 255.) # converting imgs to 0-1\n","    state = subsequent_state\n","\n","    # subsequent_state, rl_reward, done, info_dictionary = env.step(action_to_take + 1)\n","    subsequent_state, rl_reward, done, info_dictionary = env.step(action + 1)\n","\n","    frame_counter_subsequent_state = process_frame(subsequent_state)\n","    state_history[4, :, :] = frame_counter_subsequent_state\n","    last_state = check_if_live(life, info_dictionary['lives'])\n","\n","    life = info_dictionary['lives'] # lives in gym\n","    r = np.clip(rl_reward, -1, 1)  # clipping reward between -1 and 1\n","    r = rl_reward\n","\n","    agent.sys_memory.record(deepcopy(frame_counter_subsequent_state), action, r, last_state)\n","\n","    run_score += rl_reward\n","\n","    state_history[:4, :, :] = state_history[1:, :, :]\n","\n","env.close()\n","make_video_of_jupyter()\n","display.stop()"]},{"cell_type":"code","source":["import imageio\n","\n","def make_video(frame_folder='frames', output_video='video.mp4'):\n","    images = []\n","    for file_name in sorted(os.listdir(frame_folder)):\n","        if file_name.endswith('.png'):\n","            file_path = os.path.join(frame_folder, file_name)\n","            images.append(imageio.imread(file_path))\n","    imageio.mimsave(output_video, images, fps=10)  # Adjust fps to your liking\n","\n"],"metadata":{"id":"kU0-7uBv7008","executionInfo":{"status":"ok","timestamp":1714698076272,"user_tz":240,"elapsed":175,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"resources":{"http://localhost:8080/video.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":172},"id":"1IIzXYxf-Geb","executionInfo":{"status":"ok","timestamp":1714698422844,"user_tz":240,"elapsed":173,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}},"outputId":"3d50ae7f-2b7c-445c-9c37-c1543c4eea53"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"video.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"msRKok-O8-83"},"source":["## What to include:\n","Your submission should include videos of your run, along with results from both the DQN and double DQN network showing training progress and final scores.\n","You should run both the same number of iterations and below write a **brief** analysis of any findings of your results."]},{"cell_type":"markdown","source":["For episode: 3666   *the* run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 495    lr: 2.6214400000000017e-08     eval rl_reward: **8.01**\n","For episode: 3667   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     eval rl_reward: 7.99\n","For episode: 3668   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     eval rl_reward: **8.02**\n","For episode: 3669   the run_score was: 6.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     eval rl_reward: **8.03**\n","For episode: 3670   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     eval rl_reward: **8.03**\n","For episode: 3671   the run_score was: 7.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     eval rl_reward: #8.03\n","For episode: 3672   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: #8.02\n","For episode: 3673   the run_score was: 9.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 460    lr: 2.6214400000000017e-08     eval rl_reward: #8.07\n","For episode: 3674   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: #8.02\n","For episode: 3675   the run_score was: 4.0   and mem length: 1000000   eps: 0.009998020008555413    steps: 243    lr: 2.6214400000000017e-08     eval rl_reward: #8.02\n"],"metadata":{"id":"11k50RzCfUwH"}},{"cell_type":"markdown","source":["**I have stopped training with keyboard interupt as the reward reached 8 as discussed in class.**"],"metadata":{"id":"72qJN0fhCDRh"}},{"cell_type":"markdown","source":["Please check my ipynb notebook and the frames folder. We see initially it misses the target however the game as it progresses to further steps learns faster and is more accurate.\n","\n","> Also the memory length reached just when it hit 8.04 so further improvements will take training for around 5000(expected) episodes to reach 10.\n","\n"],"metadata":{"id":"Q5-v2EsYCSXO"}},{"cell_type":"markdown","source":[],"metadata":{"id":"tfrdRVeIGYVZ"}},{"cell_type":"code","source":[],"metadata":{"id":"8q8QQLoI2681","executionInfo":{"status":"ok","timestamp":1714699164370,"user_tz":240,"elapsed":156,"user":{"displayName":"Stanley Gabriel","userId":"15149212554113214565"}}},"execution_count":44,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}